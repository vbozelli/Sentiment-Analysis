[{"corpo":"@jeff IMHO yours seems a little long. However it does seem a little more robust with support for \"yesterday\" and \"years\". But in my experience when this is used the person is most likely to view the content in the first 30 days. It is only the really hardcore people that come after that. So that is why I usually elect to keep this short and simple. This is the method I am currently using on one of my websites. This only returns a relative day, hour, time. And then the user has to slap on \"ago\" in the output. ","pontos":19},{"corpo":"I've had no trouble using the BSD sockets API in C++, in GNU/Linux. Here's the sample program I used: So my take on this is that z/OS is probably the complicating factor here, however, because I've never used z/OS before, much less programmed in it, I can't say this definitively. :-P","pontos":11},{"corpo":"Sure I can post a test app. Compile/Link Output: cxx -Wc,xplink -Wl,xplink -o inet_test inet.C \"./inet.C\", line 5.16: CCN5274 (S) The name lookup for \"AF_INET\" did not find a declaration. CCN0797(I) Compilation failed for file ./inet.C. Object file not created. A check of sys/sockets.h does include the definition I need, and as far as I can tell, it is not being blocked by any #ifdef statements. I have however noticed it contains a the following: which encapsulates basically the whole file. Not sure if it matters.","pontos":16},{"corpo":"Consider using a ManualResetEvent to block the main thread at the end of its processing, and call on it once the timer's processing has finished. If this is something that needs to run constantly, consider moving this into a service process instead of a console app. ","pontos":6},{"corpo":"You can use something like to block the main thread, so other background threads (like timer threads) will still work. You may also use an AutoResetEvent to block the execution, then (when you need to) you can call Set() method on that AutoResetEvent object to release the main thread. Also ensure that your reference to Timer object doesn't go out of scope and garbage collected. ","pontos":24},{"corpo":"Here is one hack that may work. It isn't clean, but it looks like it might work: Essentially, you just try to update a column that doesn't exist. ","pontos":24},{"corpo":"Why don't you want to use triggers. They are a good thing if you use them correctly. If you use them as a way to enforce referential integrity that is when they go from good to bad. But if you use them for monitoring, they are not really considered taboo.","pontos":14},{"corpo":"From my experience, and from what I've read across the internet, the answer is \"No,\" it is not guaranteed. It depends on CPU speed, operating system, flavor of Linux, etc.","pontos":1},{"corpo":"I guess in a managed environment, a leak would be you keeping an unnecessary reference to a large chunk of memory around. ","pontos":8},{"corpo":"I will concur with Bernard as to in .net what a mem leak would be. You could profile your application to see its memory use, and determine that if its managing a lot of memory when it should not be you could say it has a leak. In managed terms I will put my neck on the line to say it does go away once the process is killed/removed. Unmanaged code is it's own beast and if a leak exists within it, it will follow a standard mem. leak definition.","pontos":4},{"corpo":"I have been using the 64Bit version of TortoiseSVN for ages and I have never had issues with it on Windows 64Bit or Vista 64Bit. I am currently not aware of any other similiar SVN clients that do work on Vista. Is it possible the problem could lie within the configuration of TortoiseSVN or even the installation of Vista? Is the problem occurring on Vista native or SP 1?","pontos":33},{"corpo":"I'll second Diago's answer. I use TortoiseSVN on Vista x64 pretty heavily. I did upgrade directly from an older version to 1.5.2 though, and never used 1.5.1. Have you tried 1.5.2?","pontos":4},{"corpo":"I too get explorer crashes in Vista (I'm not in the 64Bit version though). I'm using Vista Super Saijen (or whatever they are calling the most expensive version). I'm not having any bugs with Tortoise. My explorer does, however, crash about every other day (sometimes multiple times a day if it's having an \"off\" day). I'm not positive it's being caused by TortoiseSVN though. From what I hear, the explorer just crashes a lot in Vista... Have you tried uninstalling Tortoise and using Windows for a day or two and seeing if it still crashes? Do you restart your computer at least once a day (It seems the longer I go between restarts, the worse the crashes get)?","pontos":2},{"corpo":"It depends on how the property is used. For example, say you have a student object that has a name property. You could use your Get method to pull the name from the database, if it hasn't been retrieved already. This way you are reducing unnecessary calls to the database. Now let's say you have a private integer counter in your object that counts the number of times the name has been called. You may want to not use the Get method from inside the object because it would produce an invalid count.","pontos":9},{"corpo":"I used to have lots of Explorer crashes (on 32-bit) caused by Tortoise. They seem to have gone away since I used the Include/Exclude path settings in the \"Icon Overlays\" configuration of TSVN. Constraining icon overlays to specific directories where I keep my source made this much more stable.","pontos":3},{"corpo":"Strictly speaking, a memory leak is consuming memory that is \"no longer used\" by the program. \"No longer used\" has more than one meaning, it could mean \"no more reference to it\", that is, totally unrecoverable, or it could mean, referenced, recoverable, unused but the program keeps the references anyway. Only the later applies to .Net for perfectly managed objects. However, not all classes are perfect and at some point an underlying unmanaged implementation could leak resources permanently for that process. In all cases, the application consumes more memory than strictly needed. The sides effects, depending on the ammount leaked, could go from none, to slowdown caused by excessive collection, to a series of memory exceptions and finally a fatal error followed by forced process termination. You know an application has a memory problem when monitoring shows that more and more memory is allocated to your process after each garbage collection cycle. In such case, you are either keeping too much in memory, or some underlying unmanaged implementation is leaking. For most leaks, resources are recovered when the process is terminated, however some resources are not always recovered in some precise cases, GDI cursor handles are notorious for that. Of course, if you have an interprocess communication mechanism, memory allocated in the other process would not be freed until that process frees it or terminates.","pontos":22},{"corpo":"I would define memory leaks as an object not freeing up all the memory allocated after it has completed. I have found this can happen in your application if you are using Windows API and COM (i.e. unmanaged code that has a bug in it or is not being managed correctly), in the framework and in third party components. I have also found not tiding up after using certain objects like pens can cause the issue. I personally have suffered Out of Memory Exceptions which can be caused but are not exclusive to memory leaks in dot net applications. (OOM can also come from pinning see Pinning Artical). If you are not getting OOM errors or need to confirm if it is a memory leak causing it then the only way is to profile your application. I would also try and ensure the following: a) Everything that implements Idisposable is disposed either using a finally block or the using statement these include brushes, pens etc.(some people argue to set everything to nothing in addition) b)Anything that has a close method is closed again using finally or the using statement (although I have found using does not always close depending if you declared the object outside the using statement) c)If you are using unmanaged code/windows API's that these are dealt with correctly after. (some have clean up methods to release resources) Hope this helps.","pontos":11},{"corpo":"You could use conditional comments to get IE and Firefox to do different things The browsers themselves will ignore code that isn't meant for them to read.","pontos":2},{"corpo":"Personally, I feel like it's important to remain consistent. If you have getters and setters, use them. The only time I would access a field directly is when the accessor has a lot of overhead. It may feel like you're bloating your code unnecessarily, but it can certainly save a whole lot of headache in the future. The classic example: Later on, you may desire to change the way that field works. Maybe it should be calculated on-the-fly or maybe you would like to use a different type for the backing store. If you are accessing properties directly, a change like that can break an awful lot of code in one swell foop.","pontos":33},{"corpo":"Looks like Jeff is using CruiseControl.NET based on some leafing through the podcast transcripts. This seems to have automated deployment capabilities from source control to production. Might this be where the insertion is happening?","pontos":23},{"corpo":"I rarely feel the need for getters/setters when programming, it really depends what you are doing... I will sometimes use getters/setters if the member variable is far away. Ex. Instead of I'd use Player.getX() Side note: Private member variables take longer to access than public ","pontos":4},{"corpo":"I don't understand why you would want to do this. It sounds almost like cargo cult coding. Converting a CSV file to XML doesn't add any value. Your program is already reading the CSV file, so arguing that you need XML doesn't work. On the other hand, reading the CSV file, doing something with the values, and then serializing to XML does make sense (well, as much as using XML can make sense... ;)) but you would supposedly already have a means of serializing to XML.","pontos":6},{"corpo":"To set the Apache (not the PHP) log, the easiest way to do this would be to do: VirtualHost IP:Port # Stuff, # More Stuff, ErrorLog /path/where/you/want/the/error.log /VirtualHost If there is no leading \"/\" it is assumed to be relative. Apache Error Log Page ","pontos":59},{"corpo":"The default behaviour is for error_log() to output to the Apache error log. If this isn't happening check your php.ini settings for the error_log directive - leave it unset to use the Apache log file for the current vhost.","pontos":4},{"corpo":"Off the top of my head... ","pontos":22},{"corpo":"Any assemblies that are expected to be in the GAC should stay in the GAC. This includes System.web.dll or any other 3rd party dll that you'll deploy to the GAC in production. This means a new developer would have to install these assemblies. All other 3rd party assemblies should be references through a relative path. My typical structure is: Project.Web and Project reference the assemblies in the root/References folder relatively. These .dlls are checked into subversion. Aside from that, */bin */bin/* obj should be in your global ignore path. With this setup, all references to assemblies are either through the GAC (so should work across all computers), or relative to each project within your solution.","pontos":15},{"corpo":"Yes, I thought about that, but I soon figured out that another Domain-Specific-Language (DSL) would be a bit too much. Essentially, they need to interact with my gamestate in possibly unpredictable ways. For example, a card could have a rule \"When this cards enter play, all your undead minions gain +3 attack against flying enemies, except when the enemy is blessed\". As trading card games are turn based, the GameState Manager will fire OnStageX events and let the cards modify other cards or the GameState in whatever way the card needs. If I try to create a DSL, I have to implement a rather large feature set and possibly constantly update it, which shifts the maintenance work to another part without actually removing it. That's why I wanted to stay with a \"real\" .NET language to essentially be able to just fire the event and let the card manipulate the gamestate in whatever way (within the limits of the code access security). ","pontos":2},{"corpo":" I actually meant to mention this in my answer- the original poster specified higher frequencies in higher-number tags, but HTML uses lower numbers for more significant headings. I wrote my code to spec. ;P AH I see now, it seemed counter-intuitive to me that the higher the count the smaller the tag? My mistake.","pontos":0},{"corpo":"I know that Visual Studio itself (at least in 2003 version) references the IE dll directly to render the \"Design View\". It may be worth looking into that. Otherwise, I can't think of anything beyond the Web Browser control.","pontos":0},{"corpo":"List KeyValuePair string, string myList = aDictionary.ToList(); myList.Sort( delegate(KeyValuePair string, string firstPair, KeyValuePair string, string nextPair) { return firstPair.Value.CompareTo(nextPair.Value); } ); Since you're targeting .net 2.0 or above, you can simplify this into lambda syntax -- it's equivalent but shorter. If you're targeting .net 2.0 you can only use this syntax if you're using the compiler from vs2008 (or above). List KeyValuePair string, string myList = aDictionary.ToList(); myList.Sort((firstPair,nextPair) = { return firstPair.Value.CompareTo(nextPair.Value); } ); ","pontos":295},{"corpo":"Dive Into Python has a chapter. Can't vouch for how good it would be though. ","pontos":3},{"corpo":"timezone.js: function ajaxpage() { var url = \"timezone.php\"; var visitortime = new Date(); var time = visitortime.getTimezoneOffset()/60; var page_request = false; if (window.XMLHttpRequest) { page_request = new XMLHttpRequest(); } else if (window.ActiveXObject) { try { page_request = new ActiveXObject(\"Msxml2.XMLHTTP\"); } catch (e) { try{ page_request = new ActiveXObject(\"Microsoft.XMLHTTP\"); } catch (e) { } } } else { return false; } page_request.onreadystatechange = function() { loadpage(page_request, containerid); } if (bustcachevar) { bustcacheparameter=(url.indexOf(\"?\")!=-1) ? \" \"+new Date().getTime() : \"?\"+new Date().getTime(); } page_request.open('GET', url+bustcacheparameter+\" time=\"+time, true); page_request.send(null); } function loadpage(page_request, containerid) { if (page_request.readyState == 4 (page_request.status==200 || window.location.href.indexOf(\"http\")==-1)) { document.write(' meta http-equiv=\"refresh\" content=\"0;url=http://example.com/\"/ '); } } timezone.php: ?php session_start(); $_SESSION['time'] = $_GET['time']; ? When you want to use it add to the body tag and it should cause the timezone to be stored in the PHP session variable Edit: P.S. This is untested. ","pontos":-17},{"corpo":"There are several ways to do this. Common methods use recursion, memoization, or dynamic programming. The basic idea is that you produce a list of all strings of length 1, then in each iteration, for all strings produced in the last iteration, add that string concatenated with each character in the string individually. (the variable index in the code below keeps track of the start of the last and the next iteration) Some pseudocode: list = originalString.split('') index = (0,0) list = [\"\"] for iteration n in 1 to y: index = (index[1], len(list)) for string s in list.subset(index[0] to end): for character c in originalString: list.add(s + c) you'd then need to remove all strings less than x in length, they'll be the first (x-1) * len(originalString) entries in the list. Mike Stone wrote: FYI, alumb's pseudocode has a bug... Good call Mike. I have amended my solution to fix this issue and an initialization bug. ","pontos":38},{"corpo":"I just whipped this up quick in Ruby: You might look into language API for built in permutation type functions, and you might be able to write more optimized code, but if the numbers are all that high, I'm not sure there is much of a way around having a lot of results. Anyways, the idea behind the code is start with string of length 0, then keep track of all the strings of length Z where Z is the current size in the iteration. Then, go through each string and append each character onto each string. Finally at the end, remove any that were below the x threshold and return the result. I didn't test it with potentially meaningless input (null character list, weird values of x and y, etc).","pontos":4},{"corpo":"Personally I would do something like this: ?php $data = array($rating[0] = array('word0', 'word1', 'word2'), $rating[1] = array('word3', 'word4', 'word8',...)); //assums that $rating is an array with the weight of each word so the more popular words would have a higher value in rating usort($data); //sort the $data variable, this should give us the most popular words first $size = '1'; foreach($data as $rank) { $i=0; while($i $count($rank)) { echo \" h\" . $size . \" \" . $rank[$i] . \" /h\" . $size . \" \"; $i++; } $size++; } ? Assuming I'm not a complete idiot this should work. But it is untested. ","pontos":3},{"corpo":"This warning is there because Java is not actually storing type information at run-time in an object that uses generics. Thus, if is actually a , there will be no at run-time except until an item is accessed from the list that doesn't match the generic type defined in the variable. This can cause further complications if items are added to the list, with this incorrect generic type information. Any code still holding a reference to the list but with the correct generic type information will now have an inconsistent list. To remove the warning, try: List ? list = (List ? ) object; However, note that you will not be able to use certain methods such as add because the compiler doesn't know if you are trying to add an object of incorrect type. The above will work in a lot of situations, but if you have to use add, or some similarly restricted method, you will just have to suffer the yellow underline in Eclipse (or a annotation). ","pontos":33},{"corpo":"The scoring contains the Inverse Document Frequency(IDF). If the term \"John Smith\" is in one partition, 0, 100 times and in partition 1, once. The score for searching for John Smith would be higher search in partition 1 as the term is more scarce. To get round this you would wither have to have your index being over all partitions, or you would need to override the IDF. ","pontos":12},{"corpo":"Because the score is determined on the Index if I am not completely mistaken. If you have different indexes (more/less or different data that was indexed), the score will differ: http://lucene.apache.org/core/3_6_0/scoring.html (Warning: Contains Math :-)) ","pontos":5},{"corpo":"open up a terminal (Applications- Utilities- Terminal) and type this in: This will spit out every file that has the name you want. Warning: there may be alot to wade through.","pontos":1},{"corpo":"I haven't been able to find anything that does this directly. I think you'll have to iterate through the various font folders on the system: , , and there can probably be a user-level directory as well . ","pontos":0},{"corpo":"Doesn't this depend on the hardware as well as number of threads and stuff? I would make a simple test and run it with increasing amounts of threads hammering and see what seems best.","pontos":0},{"corpo":"A few things: You are creating (and not using) an unnecessary toplevel window, named . You can just delete these lines: Also, the flow doesn't seem quite right. starts the GTK main loop, which blocks until something exits it. also starts a main loop, but it exits as soon as one of the buttons is clicked. I think it might be enough for you to remove the and calls, and simply deal with the return value. Also the call is unnecessary, as the dialog window is automatically destroyed when gtk_dialog_run() returns.","pontos":2},{"corpo":"One possibility is Hudson. It's written in Java, but there's integration with Python projects: Hudson embraces Python I've never tried it myself, however. (Update, Sept. 2011: After a trademark dispute Hudson has been renamed to Jenkins.) ","pontos":22},{"corpo":"We run Buildbot - Trac at work, I haven't used it too much since my code base isn't part of the release cycle yet. But we run the tests on different environments (OSX/Linux/Win) and it sends emails --and it's written in python.","pontos":16},{"corpo":"You may also be interested in the output of the explain() method, which will give you an idea of how things are scored the way they are: http://lucene.apache.org/java/2_2_0/api/org/apache/lucene/search/Searcher.html#explain(org.apache.lucene.search.Query,%20int) and the Explanation object: http://lucene.apache.org/java/2_2_0/api/org/apache/lucene/search/Explanation.html (Ick, scary URLs.)","pontos":3},{"corpo":"In Java, the 'int' type is a primitive , whereas the 'Integer' type is an object. In C#, the 'int' type is the same as and is a value type (ie more like the java 'int'). An integer (just like any other value types) can be boxed (\"wrapped\") into an object. The differences between objects and primitives are somewhat beyond the scope of this question, but to summarize: Objects provide facilities for polymorphism, are passed by reference (or more accurately have references passed by value), and are allocated from the heap. Conversely, primitives are immutable types that are passed by value and are often allocated from the stack. ","pontos":113},{"corpo":"Well, in Java an int is a primitive while an Integer is an Object. Meaning, if you made a new Integer: Integer i = new Integer(6); You could call some method on i: String s = i.toString();//sets s the string representation of i Whereas with an int: int i = 6; You cannot call any methods on it, because it is simply a primitive. So: String s = i.toString();//will not work!!! would produce an error, because int is not an object. int is one of the few primitives in Java (along with char and some others). I'm not 100% sure, but I'm thinking that the Integer object more or less just has an int property and a whole bunch of methods to interact with that property (like the toString() method for example). So Integer is a fancy way to work with an int (Just as perhaps String is a fancy way to work with a group of chars). I know that Java isn't C, but since I've never programmed in C this is the closest I could come to the answer. Hope this helps! Integer object javadoc Integer Ojbect vs. int primitive comparison ","pontos":82},{"corpo":"In C#, int is just an alias for , string for , double for etc... Personally I prefer int, string, double, etc. because they don't require a statement :) A silly reason, I know... ","pontos":4},{"corpo":"Confirm that you have the correct email address before sending out emails. If someone gives the wrong email address on sign-up, beat them over the head about it ASAP. Always include clear \"how to unsubscribe\" information in EVERY email. Do not require the user to login to unsubscribe, it should be a unique url for 1-click unsubscribe. This will prevent people from marking your mails as spam because \"unsubscribing\" is too hard.","pontos":14},{"corpo":"The typical solution is to dump the database as necessary and backup those files. Depending on your development platform, there may be opensource plugins available. Rolling your own code to do it is usually fairly trivial. Note: You may want to backup the database dump instead of putting it into version control. The files can get huge fast in version control, and cause your entire source control system to become slow (I'm recalling a CVS horror story at the moment).","pontos":2},{"corpo":"It's been awhile since I used FCGI but I think a FCGI process could throw a SystemExit if the thread was taking too long. This could be the web service not responding or even a slow DNS query. Some google results show a similar error with Python and FCGI so moving to mongrel would be a good idea. This post is my reference I used to setup mongrel and I still refer back to it. ","pontos":4},{"corpo":"I found this page which shows what the difference between Proc.new and lambda are. According to the page, the only difference is that a lambda is strict about the number of arguments it accepts, whereas Proc.new converts missing arguments to nil. Here is an example IRB session illustrating the difference: irb(main):001:0> l = lambda { |x, y| x + y } => # Proc:0x00007fc605ec0748@(irb):1 irb(main):002:0> p = Proc.new { |x, y| x + y } => # Proc:0x00007fc605ea8698@(irb):2 irb(main):003:0> l.call \"hello\", \"world\" => \"helloworld\" irb(main):004:0> p.call \"hello\", \"world\" => \"helloworld\" irb(main):005:0> l.call \"hello\" ArgumentError: wrong number of arguments (1 for 2) from (irb):1 from (irb):5:in `call' from (irb):5 from :0 irb(main):006:0> p.call \"hello\" TypeError: can't convert nil into String from (irb):2:in `+' from (irb):2 from (irb):6:in `call' from (irb):6 from :0 The page also recommends using lambda unless you specifically want the error tolerant behavior. I agree with this sentiment. Using a lambda seems a tad more concise, and with such an insignificant difference, it seems the better choice in the average situation. As for Ruby 1.9, sorry, I haven't looked into 1.9 yet, but I don't imagine they would change it all that much (don't take my word for it though, it seems you have heard of some changes, so I am probably wrong there). ","pontos":35},{"corpo":"With the \"Built in\" stuff, you can't, as using 1.0.* or 1.0.0.* will replace the revision and build numbers with a coded date/timestamp, which is usually also a good way. For more info, see the Assembly Linker Documentation in the /v tag. As for automatically incrementing numbers, use the AssemblyInfo Task: AssemblyInfo Task This can be configured to automatically increment the build number. There are 2 Gotchas: Each of the 4 numbers in the Version string is limited to 65535. This is a Windows Limitation and unlikely to get fixed. Why are build numbers limited to 65535? Using with with Subversion requires a small change: Using MSBuild to generate assembly version info at build time (including SubVersion fix) Retrieving the Version number is then quite easy: Version v = Assembly.GetExecutingAssembly().GetName().Version; string About = string.Format(CultureInfo.InvariantCulture, @\"YourApp Version {0}.{1}.{2} (r{3})\", v.Major, v.Minor, v.Build, v.Revision); And, to clarify: In .net or at least in C#, the build is actually the THIRD number, not the fourth one as some people (for example Delphi Developers who are used to Major.Minor.Release.Build) might expect. In .net, it's Major.Minor.Build.Revision. ","pontos":59},{"corpo":"Perhaps this is a little academic and OT but hX tags are probably not the best choice for a tag cloud for reasons of document structure and all that sort of thing ... Maybe spans or an ol with appropriate class attributes (plus some css)? ","pontos":17},{"corpo":"I'm with Peter. Developer don't seem to understand passwords. We all pick (and I'm guilty of this too) MD5 or SHA1 because they are fast. Thinking about it ('cuz someone recently pointed it out to me) that doesn't make any sense. We should be picking a hashing algorithm that's stupid slow. I mean, on the scale of things, a busy site will hash passwords what? every 1/2 minute? Who cares if it take 0.8 seconds vs 0.03 seconds server wise? But that extra slowness is huge to prevent all types of common brute-forcish attacks. From my reading, bcrypt is specifically designed for secure password hashing. It's based on blowfish, and there are many implementation. For PHP, check out PHPPass http://www.openwall.com/phpass/ For anyone doing .NET, check out BCrypt.NET http://derekslager.com/blog/posts/2007/10/bcrypt-dotnet-strong-password-hashing-for-dotnet-and-mono.ashx","pontos":10},{"corpo":"How often do you need to check for changes and how large (in terms of row size) are the tables in the database? If you use the method suggested by John, it will scan every row of the specified table. The hint helps, but on a large database, you are still hitting every row. You will also need to store the checksum for every row so that you tell one has changed. Have you considered going at this from a different angle? If you do not want to modify the schema to add triggers, (which makes a sense, it's not your database), have you considered working with the application vendor that does make the database? They could implement an API that provides a mechanism for notifying accessory apps that data has changed. It could be as simple as writing to a notification table that lists what table and which row were modified. That could be implemented through triggers or application code. From your side, ti wouldn't matter, your only concern would be scanning the notification table on a periodic basis. The performance hit on the database would be far less than scanning every row for changes. The hard part would be convincing the application vendor to implement this feature. Since this can be handles entirely through SQL via triggers, you could do the bulk of the work for them by writing and testing the triggers and then bringing the code to the application vendor. By having the vendor support the triggers, it prevent the situation where your adding a trigger inadvertently replaces a trigger supplied by the vendor. ","pontos":11},{"corpo":"Without using a ready-made function, a super-simple low-level algorithm to convert a string to title case: This asssumes the \"convert character to uppercase\" will do that correctly regardless of whether or not the character is case-sensitive (e.g., '+').","pontos":-1},{"corpo":"One implementation of this problem is to attempt to call the parameter-less constructor of the Type: Here is the same approach, contained in a generic method: ","pontos":26},{"corpo":"Here is my current method. Any suggestions? ","pontos":1},{"corpo":"I would be wary of automatically upcasing all whitespace-preceded-words in scenarios where I would run the risk of attracting the fury of nitpickers. I would at least consider implementing a dictionary for exception cases like articles and conjunctions. Behold: \"Beauty and the Beast\" And when it comes to proper nouns, the thing gets much uglier.","pontos":10},{"corpo":"I uploaded it and got an internal error After much playing around, I found that if I had It would give me a much more useful answer and say that it was not installed, you can see it yourself -> http://woarl.com/db.py Oddly enough, this would produce an error I looked at some of the other files I had up there and it seems that library was one of the ones I had already tried.","pontos":3},{"corpo":"The magic all seems to be in That's cool, I didn't know about that. Does it work in IE, etc? From there you should be able to use JS to ajax, set cookies, whatever. I'd probably go the cookie route myself. You'll need to allow the user to change it though. We tried to use geolocation (via maxmind) to do this a while ago, and it was wrong reasonably often - enough to make it not worth doing, so we just let the user set it in their profile, and show a notice to users who haven't set theirs yet.","pontos":8},{"corpo":"I'm guessing that because you want to set it for all users, that you're on some kind of shared computer, which is probably running under a domain? HERE BE DRAGONS Let's say Joe and Jane regularly log onto the computer, then they will each have 'registries'. You'll then install your app, and the installer will employ giant hacks and disgusting things to set items under HKCU for them. THEN, bob will come along and log on (he, and 500 other people have accounts in the domain and so can do this). He's never used this computer before, so he has no registry. The first time he logs in, windows creates him one, but he won't have your setting. Your app then falls over or behaves incorrectly, and bob complains loudly about those crappy products from raynixon incorporated. The correct answer is to just have some default settings in your app, which can write them to the registry if it doesn't find them. It's general good practice that your app should never depend on the registry, and should create things as needed, for any registry entry, not just HKCU, anyway","pontos":4},{"corpo":"I ran across this: Javascript/CSS Font Detector which lets you detect what fonts are available based on the size of fonts. From here you can tell what font was loaded onto the page by using the same technique. ","pontos":5},{"corpo":"You're looking for Sandcastle Project Page: Sandcastle Releases Blog: Sandcastle Blog NDoc Code Documentation Generator for .NET used to be the tool of choice, but support has all but stopped. ","pontos":7},{"corpo":"Despite what the MSDN article says about User/Machine Hive, it doesn't write to HKEY_USERS. Rather it writes to HKCU if you select Just Me and HKLM if you select Everyone. So my solution is going to be to use the User/Machine Hive, and then in the application it checks if the registry entries are in HKCU and if not, copies them from HKLM. I know this probably isn't the most ideal way of doing it, but it has the least amount of changes.","pontos":0},{"corpo":"Google Tech Talk: Linus Torvalds on git http://www.youtube.com/watch?v=4XpnKHJAok8 The Git Wiki's comparison page http://git.or.cz/gitwiki/GitSvnComparsion","pontos":55},{"corpo":"Git is not better than Subversion. But is also not worse. It's different. The key difference is that it is decentralized. Imagine you are a developer on the road, you develop on your laptop and you want to have source control so that you can go back 3 hours. With Subversion, you have a Problem: The SVN Repository may be in a location you can't reach (in your company, and you don't have internet at the moment), you cannot commit. If you want to make a copy of your code, you have to literally copy/paste it. With Git, you do not have this problem. Your local copy is a repository, and you can commit to it and get all benefits of source control. When you regain connectivity to the main repository, you can commit against it. This looks good at first, but just keep in mind the added complexity to this approach. Git seems to be the \"new, shiny, cool\" thing. It's by no means bad (there is a reason Linus wrote it for the Linux Kernel development after all), but I feel that many people jump on the \"Distributed Source Control\" train just because it's new and is written by Linus Torvalds, without actually knowing why/if it's better. Subversion has Problems, but so does Git, Mercurial, CVS, TFS or whatever. Edit: So this answer is now a year old and still generates many upvotes, so I thought I'll add some more explanations. In the last year since writing this, Git has gained a lot of momentum and support, particularly since sites like GitHub really took off. I'm using both Git and Subversion nowadays and I'd like to share some personal insight. First of all, Git can be really confusing at first when working decentralized. What is a remote? and How to properly set up the initial repository? are two questions that come up at the beginning, especially compared to SVN's simple \"svnadmin create\", Git's \"git init\" can take the parameters --bare and --shared which seems to be the \"proper\" way to set up a centralized repository. There are reasons for this, but it adds complexity. The documentation of the \"checkout\" command is very confusing to people changing over - the \"proper\" way seems to be \"git clone\", while \"git checkout\" seems to switch branches. Git REALLY shines when you are decentralized. I have a server at home and a Laptop on the road, and SVN simply doesn't work well here. With SVN, I can't have local source control if I'm not connected to the repository (Yes, I know about SVK or about ways to copy the repo). With Git, that's the default mode anyway. It's an extra command though (git commit commits locally, whereas git push origin master pushes the master branch to the remote named \"origin\"). As said above: Git adds complexity. Two modes of creating repositories, checkout vs. clone, commit vs. push... You have to know which commands work locally and which work with \"the server\" (I'm assuming most people still like a central \"master-repository\"). Also, the tooling is still insufficient, at least on Windows. Yes, there is a Visual Studio AddIn, but I still use git bash with msysgit. SVN has the advantage that it's MUCH simpler to learn: There is your repository, all changes to towards it, if you know how to create, commit and checkout and you're ready to go and can pickup stuff like branching, update etc. later on. Git has the advantage that it's MUCH better suited if some developers are not always connected to the master repository. Also, it's much faster than SVN. And from what I hear, branching and merging support is a lot better (which is to be expected, as these are the core reasons it was written). This also explains why it gains so much buzz on the Internet, as Git is perfectly suited for Open Source projects: Just Fork it, commit your changes to your own Fork, and then ask the original project maintainer to pull your changes. With Git, this just works. Really, try it on Github, it's magic. What I also see are Git-SVN Bridges: The central repository is a Subversion repo, but developers locally work with Git and the bridge then pushes their changes to SVN. But even with this lengthy addition, I still stand by my core message: Git is not better or worse, it's just different. If you have the need for \"Offline Source Control\" and the willingness to spend some extra time learning it, it's fantastic. But if you have a strictly centralized Source Control and/or are struggling to introduce Source Control in the first place because your co-workers are not interested, then the simplicity and excellent tooling (at least on Windows) of SVN shine. ","pontos":550},{"corpo":"Git and DVCS in general is great for developers doing a lot of coding independently of each other because everyone has their own branch. If you need a change from someone else, though, she has to commit to her local repo and then she must push that changeset to you or you must pull it from her. My own reasoning also makes me think DVCS makes things harder for QA and release management if you do things like centralized releases. Someone has to be responsible for doing that push/pull from everyone else's repository, resolving any conflicts that would have been resolved at initial commit time before, then doing the build, and then having all the other developers re-sync their repos. All of this can be addressed with human processes, of course; DVCS just broke something that was fixed by centralized version control in order to provide some new conveniences.","pontos":5},{"corpo":"@Karl In PHP5 variables are by default passed by value and objects are by default passed by reference. Either can be optionally passed by reference using the operator. However, most older PHP functions will not alter a primitive even if you pass a reference... $str = \"hello world\"; echo $str; // hello world echo strrev($str); // dlrow olleh strrev( $str ); // ! Warning is issued echo $str; // hello world $str = strrev($str); echo $str; // dlrow olleh If you do try to pass a value as a reference it will throw a warning. It is up to the function to decide to work on the value or reference. ","pontos":21},{"corpo":"I follow this article to setup an Eclipse environment that has debugging features like you mentioned. The ability to step into the code is a much better way to debug then the old method of var_dump and print at various points to see where your flow goes wrong. When all else fails though and all I have is SSH and vim I still / to find where the code goes south. ","pontos":121},{"corpo":"It's all about the ease of use/steps required to do something. If I'm developing a single project on my PC/laptop, git is better, because it is far easier to set up and use. You don't need a server, and you don't need to keep typing repository URL's in when you do merges. If it were just 2 people, I'd say git is also easier, because you can just push and pull from eachother. Once you get beyond that though, I'd go for subversion, because at that point you need to set up a 'dedicated' server or location. You can do this just as well with git as with SVN, but the benefits of git get outweighed by the need to do additional steps to synch with a central server. In SVN you just commit. In git you have to git commit, then git push. The additional step gets annoying simply because you end up doing it so much. SVN also has the benefit of better GUI tools, however the git ecosystem seems to be catching up quickly, so I wouldn't worry about this in the long term.","pontos":6},{"corpo":"I worked on a project for my previous employer that used .NET, and there was a built in .resx format we used. We basically had a file that had all translations in the .resx file, and then multiple files with different translations. The consequence of this is that you have to be very diligent about ensuring that all strings visible in the application are stored in the .resx, and anytime one is changed you have to update all languages you support. If you get lazy and don't notify the people in charge of translations, or you embed strings without going through your localization system, it will be a nightmare to try and fix it later. Similarly, if localization is an afterthought, it will be very difficult to put in place. Bottom line, if you don't have all visible strings stored externally in a standard place, it will be very difficult to find all that need to be localized. One other note, very strictly avoid concatenating visible strings directly, such as String message = \"The \" + item + \" is on sale!\"; Instead, you must use something like String message = String.Format(\"The {0} is on sale!\", item); The reason for this is that different languages often order the words differently, and concatenating strings directly will need a new build to fix, but if you used some kind of string replacement mechanism like above, you can modify your .resx file (or whatever localization files you use) for the specific language that needs to reorder the words. ","pontos":7},{"corpo":"If you can find a professional or some other super-enterprise version of Visual Studio 6.0 - it came with a copy of MSDE (Basically the predecessor to SQL Express). I believe MSDE 2000 is still available as a free download from Microsoft, but I don't know if you can migrate directly from 6.5 to 2000. I think in concept, you won't likely face any danger. Years of practice however tell me that you will always miss some object, permission, or other database item that won't manifest itself immediately. If you can script out the entire dump, the better as you will be less likely to miss something - and if you do miss something, it can be easily added to the script and fixed. I would avoid any manual steps (other than hitting the enter key once) like the plague.","pontos":1},{"corpo":"With Git, you can do practically anything offline, because everybody has their own repository. Making branches and merging between branches is really easy. Even if you don't have commit rights for a project, you can still have your own repository online, and publish \"push requests\" for your patches. Everybody who likes your patches can pull them into their project, including the official maintainers. It's trivial to fork a project, modify it, and still keep merging in the bugfixes from the HEAD branch. Git works for the Linux kernel developers. That means it is really fast (it has to be), and scales to thousands of contributors. Git also uses less space (up to 30 times less space for the Mozilla repository). Git is very flexible, very TIMTOWTDI (There is more than one way to do it). You can use whatever workflow you want, and Git will support it. Finally, there's GitHub, a great site for hosting your Git repositories. Drawbacks of Git: it's much harder to learn, because Git has more concepts and more commands. revisions don't have version numbers like in subversion many Git commands are cryptic, and error messages are very user-unfriendly it lacks a good GUI (such as the great TortoiseSVN) ","pontos":145},{"corpo":"Replace your hyphens with this: It's called a \"soft\" hyphen.","pontos":44},{"corpo":"Does doubling the \\ work? ","pontos":9},{"corpo":"Partially. The text is inserted, but the warning is still generated. I found a discussion that indicated the text needed to be preceded with 'E', as such: insert into EscapeTest (text) values (E'This is the first part \\n And this is the second'); This suppressed the warning, but the text was still not being returned correctly. When I added the additional slash as Michael suggested, it worked. As such: insert into EscapeTest (text) values (E'This is the first part \\\\n And this is the second'); ","pontos":66},{"corpo":"There is nothing I know of that can do this without you at least writing a little bit of code... You will need 2 separate library: A CSV Parser Framework An XML Serialization Framework The CSV parser I would recommend (unless you want to have a little bit of fun to write your own CSV Parser) is OpenCSV (A SourceForge Project for parsing CSV Data) The XML Serialization Framework should be something that can scale in case you want to transform large (or huge) CSV file to XML: My recommendation is the Sun Java Streaming XML Parser Framework (See here) which allows pull-parsing AND serialization. ","pontos":3},{"corpo":"I don't know Python syntax, but I know Ruby can do it, and it is rather trivial. Let's say you want to add a method to Array that prints the length to standard out: If you don't want to modify the whole class, you can just add the method to a single instance of the array, and no other arrays will have the method: Just be aware of the issues involved in using this feature. Jeff Atwood actually wrote about it not too long ago.","pontos":1},{"corpo":"It's a WinForms app. The exceptions that are caught by Application.ThreadException work fine, and I don't get the ugly .NET exception box (OK to terminate, cancel to debug? who came up with that??). I was getting some exceptions that weren't being caught by that and ended up going to the AppDomain.UnhandledException event that were causing problems. I think I've caught most of those exceptions and I am displaying them in our nice error box now. So I'll just have to hope there are not some other circumstances that would cause exceptions to not be caught by the Application.ThreadException handler.","pontos":0},{"corpo":"A quick Google seems to give this advice: Don't try to edit if it's read-only. You might be able to change the permissions on the file. (Whether or not it will let you save is up to experimentation.) If you still edited anyway, save to a temporary file and then move it. http://ubuntuforums.org/showthread.php?t=782136","pontos":0},{"corpo":"Ryan's advice is generally good, however, if following step 3, don't move the temporary file; it'll have the wrong ownership and permissions. Instead, the correct file and read in the contents (using or the like) of the temporary file. If following step 2, use to force the file to be written.","pontos":6},{"corpo":"You can use this program, Handle, to find which process has the lock on your file. It's a command-line tool, so I guess you use the output from that... I'm not sure about finding it programmatically. If deleting the file can wait, you could specify it for deletion when your computer next starts up: 1. Start REGEDT32 (W2K) or REGEDIT (WXP) and navigate to: HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Session Manager 2. W2K: Edit, Add Value..., Data Type: REG_MULTI_SZ, Value Name: PendingFileRenameOperations, OK WXP: Edit, New, Multi-String Value, [enter] PendingFileRenameOperations 3. In the Data area, enter \"\\??\\\" + filename to be deleted. LFNs may be entered without being embedded in quotes. To delete \"C:\\Long Directory Name\\Long File Name.exe\", enter the following data: \\??\\C:\\Long Directory Name\\Long File Name.exe Then press OK. 4. The \"destination file name\" is a null (zero) string. It is entered as follows: W2K: Edit, Binary, select Data Format: Hex, click at the end of the hex string, enter 0000 (four zeros), OK. WXP: Right-click the value, choose \"Modify Binary Data\", click at the end of the hex string, enter 0000 (four zeros), OK. 5. Close REGEDT32/REGEDIT and reboot to delete the file. (Shamelessly stolen from some random forum, for posterity's sake.)","pontos":2},{"corpo":"Killing other processes is not a healthy thing to do. If your scenario involves something like uninstallation, you could use the API function to mark the file for deletion upon next reboot. If it appears that you really need to delete a file in use by another process, I'd recommend re-considering the actual problem before considering any solutions. ","pontos":28},{"corpo":"If you want to do it programatically. I'm not sure... and I'd really recommend against it. If you're just troubleshooting stuff on your own machine, SysInternals Process Explorer can help you Run it, use the Find Handle command (I think it's either in the find or handle menu), and search for the name of your file. Once the handle(s) is found, you can forcibly close them. You can then delete the file and so on. Beware, doing this may cause the program which owns the handles to behave strangely, as you've just pulled the proverbial rug out from under it, but it works well when you are debugging your own errant code, or when visual studio / windows explorer is being crap and not releasing file handles even though you told them to close the file ages ago... sigh :-)","pontos":4},{"corpo":"Oh, one big hack I employed years ago, is that Windows won't let you delete files, but it does let you move them. Pseudo-sort-of-code: mv %WINDIR%\\System32\\mfc42.dll %WINDIR\\System32\\mfc42.dll.old Install new mfc42.dll Tell user to save work and restart applications When the applications restarted (note we didn't need to reboot the machine), they loaded the new , and all was well. That, coupled with to delete the old one the next time the whole system restarted, worked pretty well. ","pontos":1},{"corpo":"Here's a short list of implementations and languages I've tried. It's sorted by closeness to zero: Scheme:  (Chez Scheme, MIT Scheme)  (Guile)  (Chicken with egg)  (MzScheme, SISC, Gauche, Gambit)  (SCM) Common Lisp:  (CLISP)  (CMUCL)  (SBCL) Perl:  Python:  (CPython) Ruby:  (MRI)  (JRuby) R:  ","pontos":5},{"corpo":"Is it possible to settle this dispute? My first thought is to look to a symbolic language, like Maple. I don't think that counts as floating point though. In fact, how does one represent i (or j for the engineers) in a conventional programming language? Perhaps a better example is sin() = 0? (Or have I missed the point again?) ","pontos":3},{"corpo":"The # char is indexed as punctuation and therefore ignored, so it looks like we'll remove the letter C from our word indexing ignore lists. Tested it locally after doing that and rebuilding the indexes and I get results! Looking at using a different word breaker language on the indexed column, so that those special characters aren't ignored. EDIT: I also found this information: c# is indexed as c (if c is not in your noise word list, see more on noise word lists later), but C# is indexed as C# (in SQL 2005 and SQL 2000 running on Win2003 regardless if C or c is in your noise word list). It is not only C# that is stored as C#, but any capital letter followed by #. Conversely, c++ ( and any other lower-cased letter followed by a ++) is indexed as c (regardless of whether c is in your noise word list). ","pontos":7},{"corpo":"Sven, you reached the same conclusion as I did: I found the Shockwave Flash Object, all be it from a slightly different route, but was stumped on how to load the files from somewhere other than file on disk/URL. The F-IN-BOX, although just a wrapper of the Shockwave Flash Object seems to provide much more functionality, which may just help me! Shooting flys with bazookas may be fun, but an embeded web brower is not the path that I am looking for. :) There was a link on Adobe's site that talked about \"Embedding and Communicating with the Macromedia Flash Player in C# Windows Applications\" but they seem to have removed it :( ","pontos":3},{"corpo":"What I did when working against a database of unknown performance was to measure turnaround time on my queries. I kept upping the thread count until turn-around time dropped, and dropping the thread count until turn-around time improved (well, it was processes in my environment, but whatever). There were moving averages and all sorts of metrics involved, but the take-away lesson was: just adapt to how things are working at the moment. You never know when the DBAs will improve performance or hardware will be upgraded, or perhaps another process will come along to load down the system while you're running. So adapt. Oh, and another thing: avoid process switches if you can - batch things up. Oh, I should make this clear: this all happened at run time, not during development. ","pontos":0},{"corpo":"You tried old builds, but is there a reason you can't keep going further back in the repository history and seeing exactly when the bug was introduced? Otherwise, I would suggest adding simple logging of some kind to help track down the problem, though I am at a loss of what specifically you might want to log. If you can find out what exactly CAN cause this problem, via google and documentation of the exceptions you are getting, maybe that will give further insight on what to look for in the code.","pontos":0},{"corpo":"Rex, I suspect a good place to start looking is solutions that compress the ViewState -- they're grabbing ViewState on the server before it's sent down to the client and gzipping it. That's exactly where you want to be. Scott Hanselman on ViewState Compression (2005) ViewState Compression with System.IO.Compression (2007) ","pontos":5},{"corpo":"The trouble with international standards is that pretty much noone uses them. I try where I can, but I am forced to use dd/mm/yyyy almost everywhere in real life, which means I am so used to it it's always a conscious process to use ISO-8601. For the majority of people who don't even try to use ISO-8601 it's even worse. If you can internationalize where you can, I think it's a great advantage.","pontos":0},{"corpo":"Maybe https://ci-bayes.dev.java.net/ or http://www.cs.cmu.edu/~javabayes/Home/node2.html? I never played with it either. ","pontos":3},{"corpo":"See this blog post where the author describes a method for overriding the default behavior for generating the ViewState and instead shows how to save it on the server Session object. In ASP.NET 2.0, ViewState is saved by a descendant of PageStatePersister class. This class is an abstract class for saving and loading ViewsState and there are two implemented descendants of this class in .Net Framework, named HiddenFieldPageStatePersister and SessionPageStatePersister. By default HiddenFieldPageStatePersister is used to save/load ViewState information, but we can easily get the SessionPageStatePersister to work and save ViewState in Session object. Although I did not test his code, it seems to show exactly what you want: a way to gain access to ViewState code while still on the server, before postback. ","pontos":2},{"corpo":"Here is an implementation of Bayesian filtering in C#: A Naive Bayesian Spam Filter for C# (hosted on CodeProject).","pontos":1},{"corpo":"No. See A Pragmatic Look at Exception Specifications for reasons why not. The only way you can \"help\" this is to document the exceptions your function can throw, say as a comment in the header file declaring it. This is not enforced by the compiler or anything. Use code reviews for that purpose. ","pontos":20},{"corpo":"AppDomain.UnhandledException is an event, not a global exception handler. This means, by the time it is raised, your application is already on its way down the drain, and there is nothing you can do about it, except for doing cleanup and error logging. What happened behind the scenes is this: The framework detected the exception, walked up the call stack to the very top, found no handlers that would recover from the error, so was unable to determine if it was safe to continue execution. So, it started the shutdown sequence, and fired up this event as a courtesy to you so you can pay your respects to your already-doomed process. This happens when an exception is left unhandled in the main thread. There is no single-point solution to this kind of error. You need to put a real exception handler (a catch block) upstream of all places where this error occurs and forward it to (for example) a global handler method/class that will determine if it is safe to simply report and continue, based on exception type and/or content. Edit: It is possible to disable (=hack) the error-reporting mechanism built into Windows so the mandatory \"crash and burn\" dialog does not get displayed when your app goes down. However, this becomes effective for all the applications in the system, not just your own.","pontos":3},{"corpo":"Why is it needed? When data is stored on disk based storage devices, it is stored as blocks of data. These blocks are accessed in their entirety, making them the atomic disk access operation. Disk blocks are structured in much the same way as linked lists; both contain a section for data, a pointer to the location of the next node (or block), and both need not be stored contiguously. Due to the fact that a number of records can only be sorted on one field, we can state that searching on a field that isnt sorted requires a Linear Search which requires block accesses (on average), where is the number of blocks that the table spans. If that field is a non-key field (i.e. doesnt contain unique entries) then the entire table space must be searched at block accesses. Whereas with a sorted field, a Binary Search may be used, this has block accesses. Also since the data is sorted given a non-key field, the rest of the table doesnt need to be searched for duplicate values, once a higher value is found. Thus the performance increase is substantial. What is indexing? Indexing is a way of sorting a number of records on multiple fields. Creating an index on a field in a table creates another data structure which holds the field value, and pointer to the record it relates to. This index structure is then sorted, allowing Binary Searches to be performed on it. The downside to indexing is that these indexes require additional space on the disk, since the indexes are stored together in a table using the MyISAM engine, this file can quickly reach the size limits of the underlying file system if many fields within the same table are indexed. How does it work? Firstly, lets outline a sample database table schema; Field name Data type Size on disk id (Primary key) Unsigned INT 4 bytes firstName Char(50) 50 bytes lastName Char(50) 50 bytes emailAddress Char(100) 100 bytes Note: char was used in place of varchar to allow for an accurate size on disk value. This sample database contains five million rows, and is unindexed. The performance of several queries will now be analyzed. These are a query using the id (a sorted key field) and one using the firstName (a non-key unsorted field). Example 1 Given our sample database of records of a fixed size giving a record length of bytes and they are stored in a table using the MyISAM engine which is using the default block size bytes. The blocking factor of the table would be records per disk block. The total number of blocks required to hold the table is blocks. A linear search on the id field would require an average of block accesses to find a value given that the id field is a key field. But since the id field is also sorted a binary search can be conducted requiring an average of block accesses. Instantly we can see this is a drastic improvement. Now the firstName field is neither sorted, so a binary search is impossible, nor are the values unique, and thus the table will require searching to the end for an exact block accesses. It is this situation that indexing aims to correct. Given that an index record contains only the indexed field and a pointer to the original record, it stands to reason that it will be smaller than the multi-field record that it points to. So the index itself requires fewer disk blocks that the original table, which therefore requires fewer block accesses to iterate through. The schema for an index on the firstName field is outlined below; Field name Data type Size on disk firstName Char(50) 50 bytes (record pointer) Special 4 bytes Note: Pointers in MySQL are 2, 3, 4 or 5 bytes in length depending on the size of the table. Example 2 Given our sample database of records with an index record length of bytes and using the default block size bytes. The blocking factor of the index would be records per disk block. The total number of blocks required to hold the table is blocks. Now a search using the firstName field can utilise the index to increase performance. This allows for a binary search of the index with an average of block accesses. To find the address of the actual record, which requires a further block access to read, bringing the total to block accesses, a far cry from the 277,778 block accesses required by the non-indexed table. When should it be used? Given that creating an index requires additional disk space (277,778 blocks extra from the above example), and that too many indexes can cause issues arising from the file systems size limits, careful thought must be used to select the correct fields to index. Since indexes are only used to speed up the searching for a matching field within the records, it stands to reason that indexing fields used only for output would be simply a waste of disk space and processing time when doing an insert or delete operation, and thus should be avoided. Also given the nature of a binary search, the cardinality or uniqueness of the data is important. Indexing on a field with a cardinality of 2 would split the data in half, whereas a cardinality of 1,000 would return approximately 1,000 records. With such a low cardinality the effectiveness is reduced to a linear sort, and the query optimizer will avoid using the index if the cardinality is less than 30% of the record number, effectively making the index a waste of space. ","pontos":1461},{"corpo":"In French, but you should be able to find the download link :) PHP Naive Bayesian Filter","pontos":0},{"corpo":"John Resig did a script to extract images from a PDF as PNG files using ImageMagick.","pontos":1},{"corpo":"Just a shot in the dark because I haven't tried it yet but when you realloc it returns the pointer much like malloc. Because realloc can move the pointer if needed you are most likely operating on an invalid pointer if you don't do the following: ","pontos":4},{"corpo":"Note, try to edit your code to get rid of the html escape codes. Well, though it has been a while since I used C/C++, realloc that grows only reuses the memory pointer value if there is room in memory after your original block. For instance, consider this: (xxxxxxxxxx..........) If your pointer points to the first x, and . means free memory location, and you grow the memory size pointed to by your variable by 5 bytes, it'll succeed. This is of course a simplified example as blocks are rounded up to a certain size for alignment, but anyway. However, if you subsequently try to grow it by another 10 bytes, and there is only 5 available, it will need to move the block in memory and update your pointer. However, in your example you are passing the function a pointer to the character, not a pointer to your variable, and thus while the strrep function internally might be able to adjust the variable in use, it is a local variable to the strrep function and your calling code will be left with the original pointer variable value. This pointer value, however, has been freed. In your case, input is the culprit. However, I would make another suggestion. In your case it looks like the input variable is indeed input, and if it is, it shouldn't be modified, at all. I would thus try to find another way to do what you want to do, without changing input, as side-effects like this can be hard to track down.","pontos":2},{"corpo":"As a general rule, you should never do a free or realloc on a user provided buffer. You don't know where the user allocated the space (in your module, in another DLL) so you cannot use any of the allocation functions on a user buffer. Provided that you now cannot do any reallocation within your function, you should change a little its behavior like doing only one replacement, so the user will be able to compute the resulting string max length and provide you with a buffer long enough for this one replacement to occur. Then you could create another function to do the multiple replacements, but you will have to allocate the whole space for the resulting string and copy the user input string. Then you must provide a way to delete the string you allocated. Resulting in: ","pontos":6},{"corpo":"I've tried using input = realloc(...), but that appears to just case some other problems, which, considering this is a slightly \"non-recommended\" practice of altering strings that I don't know where they've come from, I will take lassevk's advice of doing it another way... ...Since this isn't really production code (it's for learning, only), and the specification said \"you can limit input to 80 characters\", and the only increasing replace is \"Noel\" -> \"Christmas\", I can just initially allocate 161 characters, and leave it be.","pontos":0},{"corpo":"This seems to work; Sigh, is there anyway to post code without it sucking?","pontos":2},{"corpo":"The trick to that is to use URL rewriting so that name.domain.com transparently maps to something like domain.com/users/name on your server. Once you start down that path, it's fairly trivial to implement.","pontos":1},{"corpo":"My first port of call would be to go through the elements on the page and see which controls: Will still work when I switch ViewState off Can be moved out of the page and into an AJAX call to be loaded when required Failing that, and here's the disclaimer - I've never used this solution on a web-facing site - but in the past where I've wanted to eliminate massive ViewStates in limited-audience applications I have stored the ViewState in the Session. It has worked for me because the hit to memory isn't significant for the number of users, but if you're running a fairly popular site I wouldn't recommend this approach. However, if the Session solution works for Safari you could always detect the user agent and fudge appropriately.","pontos":2},{"corpo":"C and C++ compilers will generate a warning when you compare signed and unsigned types; in your example code, you couldn't make your loop variable unsigned and have the compiler generate code without warnings (assuming said warnings were turned on). Naturally, you're compiling with warnings turned all the way up, right? And, have you considered compiling with \"treat warnings as errors\" to take it that one step further? The downside with using signed numbers is that there's a temptation to overload them so that, for example, the values 0- n are the menu selection, and -1 means nothing's selected - rather than creating a class that has two variables, one to indicate if something is selected and another to store what that selection is. Before you know it, you're testing for negative one all over the place and the compiler is complaining about how you're wanting to compare the menu selection against the number of menu selections you have - but that's dangerous because they're different types. So don't do that.","pontos":3},{"corpo":"All memory leaks are resolved by program termination. Leak enough memory and the Operating System may decide to resolve the problem on your behalf.","pontos":5},{"corpo":"I'll just post here since some of the other posts are slightly inaccurate in relation to C#. Correct: int is an alias for System.Int32. Wrong: float is not an alias for System.Float, but for System.Single Basically, int is a reserved keyword in the C# programming language, and is an alias for the System.Int32 value type. float and Float is not the same however, as the right system type for ''float'' is System.Single. There are some types like this that has reserved keywords that doesn't seem to match the type names directly. In C# there is no difference between ''int'' and ''System.Int32'', or any of the other pairs or keywords/system types, except for when defining enums. With enums you can specify the storage size to use and in this case you can only use the reserved keyword, and not the system runtime type name. Wether the value in the int will be stored on the stack, in memory, or as a referenced heap object depends on the context and how you use it. This declaration in a method: defines a variable i of type System.Int32, living in a register or on the stack, depending on optimizations. The same declaration in a type (struct or class) defines a member field. The same declaration in a method argument list defines a parameter, with the same storage options as for a local variable. (note that this paragraph is not valid if you start pulling iterator methods into the mix, these are different beasts altogether) To get a heap object, you can use boxing: this will create a boxed copy of the contents of i on the heap. In IL you can access methods on the heap object directly, but in C# you need to cast it back to an int, which will create another copy. Thus, the object on the heap cannot easily be changed in C# without creating a new boxed copy of a new int value. (Ugh, this paragraph doesn't read all that easily.)","pontos":16},{"corpo":"CVS only tracks modification on a file-by-file basis, while SVN tracks a whole commit as a new revision, which means that it is easier to follow the history of your project. Add the fact that all modern source control software use the concept of revision so it is far easier to migrate from SVN than it is from CVS. There is also the atomic commit problem. While I only encountered it once, it is possible that 2 people committing together in CVS can conflict each other, losing some data and putting your client in an inconsistent state. When detected early, these problems are not major because your data is still out there somewhere, but it can be a pain in a stressful environment. And finally, not many tools are developed around CVS anymore. While the new and shiny-new tools like Git or Mercurial definitely lack tools yet, SVN has a pretty large application base on any system. ","pontos":26},{"corpo":"When I needed to write an application with a client-server model where the clients could leave and enter whenever they want, (I assume that's also the case for your application as you use mobile devices) I made sure that the clients send an online message to the server, indicating they were connected and ready to do whatever they needed doing. at that time the server could send messages back to the client trough the same open connection. Also, but I don't know if that is applicable for you, I had some sort of heartbeat the clients sent to the server, letting it know it was still online. That way the server knows when a client was forcibly disconnected from the network and it could mark that client back as offline.","pontos":3},{"corpo":"You can use the artifact directory variable inside the MSBuild script itself. Here's an example of how I'm running FxCop right now from my CC.Net MSBuild script (this script is what CC.Net points to - there is also a \"Build\" target in the script that includes an MSBuild task against the SLN to do the actual compilation): Exec Command='FxCopCmd.exe /project:\"$(MSBuildProjectDirectory)\\FXCopRules.FxCop\" /out:\"$(CCNetArtifactDirectory)\\ProjectName.FxCop.xml\"' WorkingDirectory=\"C:\\Program Files\\Microsoft FxCop 1.35\" ContinueOnError=\"true\" IgnoreExitCode=\"true\" / ","pontos":4},{"corpo":"No, unfortunately, and if you think about it, that information would be worthless anyway since the file could become locked the very next second (read: short timespan). Why specifically do you need to know if the file is locked anyway? Knowing that might give us some other way of giving you good advice. If your code would look like this: if not locked then open and update file Then between the two lines, another process could easily lock the file, giving you the same problem you were trying to avoid to begin with: exceptions. ","pontos":95},{"corpo":"You might be able to get some implementation ideas from the Ruby/ProgressBar library, which generates text progress bars. I stumbled across it a couple of months back but haven't made any use of it.","pontos":18},{"corpo":"You really need to use a file Sync tool, like SyncBackSE, MS SyncToy, or even something like WinMerge will do the trick. I prefer SyncBack as it allows you to set up very explicit rules for just about every possible case and conflict, at least more so than the other two. With any of these you won't have to keep clicking all the pop-ups and you can verify, without a doubt, that the destination is exactly the same as the source.","pontos":7},{"corpo":"How about good old Command-Line Xcopy? With S: being the source and T: the target: xcopy /K /R /E /I /S /C /H /G /X /Y s:\\*.* t:\\ /K Copies attributes. Normal Xcopy will reset read-only attributes. /R Overwrites read-only files. /E Copies directories and subdirectories, including empty ones. /I If destination does not exist and copying more than one file, assumes that destination must be a directory. /S Copies directories and subdirectories except empty ones. /C Continues copying even if errors occur. /H Copies hidden and system files also. /Y Suppresses prompting to confirm you want to overwrite an existing destination file. /G Allows the copying of encrypted files to destination that does not support encryption. /X Copies file audit settings (implies /O). (Edit: Added /G and /X which are new since a few years)","pontos":20},{"corpo":"You can try SuperCopier, it replaces the standard Windows copy mechanism while loaded. It can retry failed files at the end, resume a canceled copy (even a copy canceled by Windows), accepts \"All\" for every answers. You can even answer the annoying questions (file already exists, error copying file) before they occur.","pontos":6},{"corpo":"Xcopy keeps the Date Modified, only the Date Created and Date Accessed will change. (tested on XP Pro, try it on a small folder to check if you're using Vista as I did not test it under Vista) Edit: You MAY want to redirect the Output though: That way, if files fail to copy you can check the log (i.e. System Volume Information will generate an error, but that folder does not matter anyway for what you're trying to do)","pontos":1},{"corpo":"I've never worked with Rockbox, but I did some snooping around, and I found this link. It may give you the answer for what you need. Or is this a general question about how function pointers work?","pontos":2},{"corpo":"On windows, curses works out of the box, ncurses doesn't, and for a progress bar curses should be sufficient. So, use curses instead of ncurses. Also, both curses and ncurses are wafer-thin wrappers around the c library - that means you don't really need Ruby-specific tutorials. However, on the site for the PickAxe you can download all the code examples for the book. The file \"ex1423.rb\" contains a curses demo which plays Pong - that should give you plenty of material to get you going. ","pontos":1},{"corpo":"Personally I think curses is overkill in this case. While the curses lib is nice (and I frequently use it myself) it's a PITA to relearn every time I haven't needed it for 12 months which has to be the sign of a bad interface design. If for some reason you can't get on with the progress bar lib Joey suggested roll your own and release it under a pretty free licence for instant kudos :) ","pontos":3},{"corpo":"Also I would try: But I don't have Air installed so I can't really test this...","pontos":8},{"corpo":"For some reason Jeff's code didn't seem simple enough. To me this seems simpler and easier to understand: DateTime today = DateTime.Today; int age = today.Year - bday.Year; if (bday today.AddYears(-age)) age--; However, this assumes you are looking for the western idea of age and not using East Asian reckoning. ","pontos":891},{"corpo":"You can relocate it by editing the DocumentRoot setting in XAMPP\\apache\\conf\\httpd.conf. It should currently be: C:/xampp/htdocs Change it to: C:/projects/transitCalculator/trunk ","pontos":67},{"corpo":"Try changing the argument names to \"sender\" and \"args\". And, after you have it working, switch the call over to ScriptManager.RegisterClientScriptBlock, regardless of AJAX use.","pontos":9},{"corpo":"I'm sure you could write a small app that takes an XSD file and parses it into a SQL script. I've never seen code out there to do it though, but that's not saying it doesn't exist.","pontos":1},{"corpo":"Or you could start throwing critical exceptions. Surely, an access violation exception will catch your users' attention.","pontos":-1},{"corpo":"Using SMO/DMO, it isn't too difficult to generate a script of your schema. Data is a little more fun, but still doable. In general, I take \"Script It\" approach, but you might want to consider something along these lines: Distinguish between Development and Staging, such that you can Develop with a subset of data ... this I would create a tool to simply pull down some production data, or generate fake data where security is concerned. For team development, each change to the database will have to be coordinated amongst your team members. Schema and data changes can be intermingled, but a single script should enable a given feature. Once all your features are ready, you bundle these up in a single SQL file and run that against a restore of production. Once your staging has cleared acceptance, you run the single SQL file again on the production machine. I have used the Red Gate tools and they are great tools, but if you can't afford it, building the tools and working this way isn't too far from the ideal.","pontos":1},{"corpo":"This isn't much better: ","pontos":5},{"corpo":"It has been a while, so this is not comprehensive. Character Sets Unicode is great, but you can't get away with ignoring other character sets. The default character set on Windows XP (English) is Cp1252. On the web, you don't know what a browser will send you (though hopefully your container will handle most of this). And don't be surprised when there are bugs in whatever implementation you are using. Character sets can have interesting interactions with filenames when they move to between machines. Translating Strings Translators are, generally speaking, not coders. If you send a source file to a translator, they will break it. Strings should be extracted to resource files (e.g. properties files in Java or resource DLLs in Visual C++). Translators should be given files that are difficult to break and tools that don't let them break them. Translators do not know where strings come from in a product. It is difficult to translate a string without context. If you do not provide guidance, the quality of the translation will suffer. While on the subject of context, you may see the same string \"foo\" crop up in multiple times and think it would be more efficient to have all instances in the UI point to the same resource. This is a bad idea. Words may be very context-sensitive in some languages. Translating strings costs money. If you release a new version of a product, it makes sense to recover the old versions. Have tools to recover strings from your old resource files. String concatenation and manual manipulation of strings should be minimized. Use the format functions where applicable. Translators need to be able to modify hotkeys. Ctrl+P is print in English; the Germans use Ctrl+D. If you have a translation process that requires someone to manually cut and paste strings at any time, you are asking for trouble. Dates, Times, Calendars, Currency, Number Formats, Time Zones These can all vary from country to country. A comma may be used to denote decimal places. Times may be in 24hour notation. Not everyone uses the Gregorian calendar. You need to be unambiguous, too. If you take care to display dates as MM/DD/YYYY for the USA and DD/MM/YYYY for the UK on your website, the dates are ambiguous unless the user knows you've done it. Especially Currency The Locale functions provided in the class libraries will give you the local currency symbol, but you can't just stick a pound (sterling) or euro symbol in front of a value that gives a price in dollars. User Interfaces Layout should be dynamic. Not only are strings likely to double in length on translation, the entire UI may need to be inverted (Hebrew; Arabic) so that the controls run from right to left. And that is before we get to Asia. Testing Prior To Translation Use static analysis of your code to locate problems. At a bare minimum, leverage the tools built into your IDE. (Eclipse users can go to Window > Preferences > Java > Compiler > Errors/Warnings and check for non-externalised strings.) Smoke test by simulating translation. It isn't difficult to parse a resource file and replace strings with a pseudo-translated version that doubles the length and inserts funky characters. You don't have to speak a language to use a foreign operating system. Modern systems should let you log in as a foreign user with translated strings and foreign locale. If you are familiar with your OS, you can figure out what does what without knowing a single word of the language. Keyboard maps and character set references are very useful. Virtualisation would be very useful here. Non-technical Issues Sometimes you have to be sensitive to cultural differences (offence or incomprehension may result). A mistake you often see is the use of flags as a visual cue choosing a website language or geography. Unless you want your software to declare sides in global politics, this is a bad idea. If you were French and offered the option for English with St. George's flag (the flag of England is a red cross on a white field), this might result in confusion for many English speakers - assume similar issues will arise with foreign languages and countries. Icons need to be vetted for cultural relevance. What does a thumbs-up or a green tick mean? Language should be relatively neutral - addressing users in a particular manner may be acceptable in one region, but considered rude in another. Resources C++ and Java programmers may find the ICU website useful: http://www.icu-project.org/ ","pontos":45},{"corpo":"Like Rob Allen, I use SQL Compare / Data Compare by Redgate. I also use the Database publishing wizard by Microsoft. I also have a console app I wrote in C# that takes a sql script and runs it on a server. This way you can run large scripts with 'GO' commands in it from a command line or in a batch script. I use Microsoft.SqlServer.BatchParser.dll and Microsoft.SqlServer.ConnectionInfo.dll libraries in the console application. ","pontos":3},{"corpo":"As far as I can tell Python, up through 2.5, only supports hexadecimal octal literals. I did find some discussions about adding binary to future versions but nothing definite.","pontos":0},{"corpo":"I have to agree with the OP 'wrong' dates really jar with my DD/MM/YYYY upbringing and I find ISO 8601 dates and times extremely easy to work with. For once the standard got it right and engtech has the obvious answer that doesn't require localisation. I was going to report the birthday input form on stack overflow as a bug because of how much of a sore thumb it is to the majority of the world.","pontos":3},{"corpo":"You should be able to check out the current version of the code and then create a git repository around it. Updating that and committing it to your local git repository should be painless. As should cloning it. The only catch is that you need to have them both ignore each other (I've done something similar with SVN) by messing with the appropriate ignore files. I'm presuming SourceSafe let's you ignore things. And you'll need to do certain operations twice (like telling both that you are deleting a file).","pontos":1},{"corpo":"While you cannot prevent usage of those inherited members to my knowledge, you should be able to hide them from IntelliSense using the EditorBrowsableAttribute: Using System.ComponentModel; [EditorBrowsable(EditorBrowsableState.Never)] private string MyHiddenString = \"Muahahahahahahahaha\"; Edit: Just saw this in the documentation comments, which makes it kinda useless for this purpose: There is a prominent note that states that this attribute \"does not suppress members from a class in the same assembly\". That is true but not complete. Actually, the attribute does not suppress members from a class in the same solution. ","pontos":15},{"corpo":"Just wondering, what do you feel your method leaves to be desired? You could replace the anonymous delegate with a.. named? delegate, something like ","pontos":4},{"corpo":"Override them like Michael Suggests above and to prevent folks from using the overridden (sp?) methods, mark them as obsolete: If the second parm is set to true, a compiler error will be generated if anyone tries to call that method and the string in the first parm is the message. If parm2 is false only a compiler warning will be generated.","pontos":28},{"corpo":"less [file name] - shows contents of file screen by screen. I'd recommend that over reading the file through Vim. Also, Pico and Emacs are a little more friendly than Vim for noobs. ","pontos":2},{"corpo":"Let's see... The basics: cd, ls, mv, cp, mkdir, rm, cat, and man. The good ones: ps, chmod, chgrp, sudo (or su), pwd, grep, head, tail, xargs, less, find, awk, sed, ssh/scp, ping, touch, locate/updatedb, ln, kill, echo, wc, passwd, tar, diff, df, du, free, and reboot And the operators: |, >, >>, , and || ... and all the useful associated command line options therein. I could probably come up with another 20 if I thought about it more. ","pontos":0},{"corpo":"Treebeard's Unix Cheat Sheet","pontos":1},{"corpo":"If you're referring to simply accessing your IIS server from a remote location, remote desktop generally solves that problem. Assuming your server has a static IP address or a host name you can access from the internet, remote desktop is a simple and relatively secure solution. Is there a problem with this answer? Now I have negative reputation...","pontos":1},{"corpo":" To capatilise it in, say, C - use the ascii codes (http://www.asciitable.com/) to find the integer value of the char and subtract 32 from it. This is a poor solution if you ever plan to accept characters beyond a-z and A-Z. For instance: ASCII 134: , ASCII 143: . Using arithmetic gets you: ASCII 102: f Use library calls, don't assume you can use integer arithmetic on your characters to get back something useful. Unicode is tricky.","pontos":6},{"corpo":"Seeing that this seems to be a web host, you will probably want to know: How to start/stop/restart the webserver (Distro/server dependent. Try to restart.) How to check the logs (Distro/server dependent. Try ) How to access MySQL directly ( and ) How to upload/download files (Probably using SFTP on the client end) How to edit the webserver configuration (Probably ) How to check/edit UNIX permissions and ownership ( to check and and to change) These are all using complete guesses for file locations etc. and assume that you are using Apache. A bit of investigation is probably needed for your particular setup. A special mention goes to permissions. This causes much of the headaches with running CGI's and security. Below is a rough guide to what permissions should be set. PHP files: readable by web-server () CGI scripts: executable by webserver () Static web files: readable by webserver () Directories: executable by webserver () These settings assume that the webserver process is running as a user who belongs to the same group as the webserver files (this is likely the setup on a managed host). A final headache that may cause trouble is that Linux is case sensitive. When serving static files from Apache, by default you will need to include any weird capitalisation. It's generally a good idea to stick to lower-case and underscores/hyphens for naming directories and files. ","pontos":41},{"corpo":"Depends on how much detail you want it to have, it needs to have the aspect ratio of 1:1 (basically - it needs to be square) I would go with the Apple's own 129*129","pontos":3},{"corpo":"When Management Studio does it, it's creating a temporary table, copying everything across, dropping your original table and renaming the temporary table. There's no simple equivalent T-SQL statement. If you don't fancy doing that, you could always create a view of the table with the columns in the order you'd like and use that? Edit: beaten!","pontos":0},{"corpo":"If the encoding is base64 then this is the solution I've stumbled upon on the web link : \"Decoding XDFL files saved with 'encoding=base64'. Files saved with: are simple base64-encoded gzip files. They can be easily restored to XML by first decoding and then unzipping them. This can be done as follows on Ubuntu: The first command will install uudeview, a package that can decode base64, among others. You can skip this step once it is installed. Assuming your form is saved as 'yourform.xfdl', the uudeview command will decode the contents as 'UNKNOWN.001', since the xfdl file doesn't contain a file name. The '-i' option makes uudeview uninteractive, remove that option for more control. The last command gunzips the decoded file into a file named 'yourform-unpacked.xfdl'. \" Another possible solution - here Side Note: Block quoted code doesn't work for long strings of code","pontos":4},{"corpo":"Here's a dynamic sql script I've used in the past. It can be further modified but it will give you the basics. I prefer scripting it to avoid the mistakes you can make using the Management Studio: ","pontos":3},{"corpo":"It's kinda low tech, and there might be a better solution out there, but you could just store your schema in an SQL script which can be run to create the database. I think you can execute a command to generate this script, but I don't know the command unfortunately. Then, commit the script into source control along with the code that works on it. When you need to change the schema along with the code, the script can be checked in along with the code that requires the changed schema. Then, diffs on the script will indicate diffs on schema changes. With this script, you could integrate it with DBUnit or some kind of build script, so it seems it could fit in with your already automated processes.","pontos":3},{"corpo":"I don't want to get into a religious war here, but regardless of your eventual text editor preference pico and nano are the easiest to jump into because the essential keyboard commands are all displayed for you at the bottom of the screen. I've long been told that vi would be worth using but for when you just need to change one line in a config file its nice not to have to spend 15 minutes trying to remember how to save and quit. That said, if you do find yourself in vi you can press escape to enter 'command mode' (or whatever it is called) and :wq will save and quit. I only mention this because of all things Linux related trying to exit vi is the thing that frustrated me the most until I learnt how!","pontos":4},{"corpo":"By default, always just create new folder within the same project You will get single assembly (without additional ILMerge gymnastic) Easier to obfuscate (because you will have less public types and methods, ideally none at all) Separating your source code into multiple projects makes only sense if you... Have some portions of the source code that are part of the project but not deployable by default or at all (unit tests, extra plugins etc.) More developers involved and you want to treat their work as consumable black box. (not very recommended) If you can clearly separate your project into isolated layers/modules and you want to make sure that they can't cross-consume internal members. (also not recommended because you will need to decide which aspect is the most important) If you think that some portions of your source code could be reusable, still don't create it as a new project. Just wait until you will really want to reuse it in another solution and isolate it out of original project as needed. Programming is not a lego, reusing is usually very difficult and often won't happen as planned.","pontos":15},{"corpo":"If you are using C#, have a look at Subsonic, a very useful ORM tool, but is also generates sql script to recreated your scheme and\\or data. These scripts can then be put into source control. http://subsonicproject.com/","pontos":3},{"corpo":"\"Let's Build a Compiler\" is awesome, but it's a bit outdated. (I'm not saying it makes it even a little bit less valid.) ","pontos":18},{"corpo":"I'm not necessarily looking for the fastest but a nice balance, some of the server that this code is being developed for are fairly slow, the script that hashes and stores the password is taking 5-6 seconds to run, and I've narrowed it down to the hashing (if I comment the hashing out it runs, in 1-2 seconds). It doesn't have to be the MOST secure, I'm not codding for a bank (right now) but I certainly WILL NOT store the passwords as plain-text.","pontos":0},{"corpo":"I'd suggest against passing an integer between them, simply for purposes of readability and debugging. Say you're going through your logs and you see a bunch of 500 errors for DocumentType=4. Now you've got to go look up which DocumentType is 4. Or if one of the applications refers to a number that doesn't exist in the other, perhaps due to mismatched versions. It's a bit more code, and it rubs the static typing part of the brain a bit raw, but in protocols on top of HTTP the received wisdom is to side with legible strings over opaque enumerations.","pontos":4},{"corpo":"I can only speak about .net, but if you have an ASP.net Webservice, you should be able to add an enumeration directly to it. When you then use the \"Add Web Reference\" in your Client Application, the resulting Class should include that enum But this is from the top of my head, i'm pretty sure i've done it in the past, but I can't say for sure.","pontos":2},{"corpo":"I would still use enumeration internally but would expect consumers to pass me only the name, not the numeric value itself. just some silly example to illustrate: ","pontos":4},{"corpo":"This is broken because 'false' as a string will evaluate to true as a boolean. However, this is an unneeded ternary expression, because the resulting values are simple true and false. This would be equivalent: ","pontos":27},{"corpo":"Oh, I also use to look at log files. It's a WHOLE LOT BETTER if you know some shortcuts (these also work in Vim) - Search for the next text which matches - Jump to the next match for the regex you just typed - Jump to previous match - Cancel searches and get yourself out of trouble - Jump to start of file - Jump to end of file - Jump to line 72 ","pontos":2},{"corpo":"for C# 3.5 without notifyicon therefore you will need to terminate this application in task manager manually ","pontos":17},{"corpo":"Wow, that took forever. Ok, here's what I've ended up with It fails hard using IDLE, the python...thing...that comes with python. But once I tried it in DOS (er, CMD.exe), as a real program, then it ran fine. No one try it in IDLE, unless you have Task Manager handy. I've already forgotten how I lived with menus that arn't super-instant responsive.","pontos":2},{"corpo":"Dang -- lbrandy beat me to the punch, but that doesn't mean I can't provide you with the system results for Vista! import os os.name 'nt' import platform platform.system() 'Windows' platform.release() 'Vista' ","pontos":82},{"corpo":" Without the extra quotes around the input string parameter, the Javascript function thinks I'm passing in an integer. Can you do some rudimentary string function to force JavaScript into changing it into a string? Like ","pontos":0},{"corpo":"The reason msvcrt fails in IDLE is because IDLE is not accessing the library that runs msvcrt. Whereas when you run the program natively in cmd.exe it works nicely. For the same reason that your program blows up on Mac and Linux terminals. But I guess if you're going to be using this specifically for windows, more power to ya.","pontos":0},{"corpo":"I had recently similar problem and the only way to solve it was to use plain old HTML codes for single () and double quotes (). Source code was total mess of course but it worked. Try a id=\"aShowHide\" onclick='ToggleDisplay( #34; %# DataBinder.Eval(Container.DataItem, \"JobCode\") % #34;);' Show/Hide /a or a id=\"aShowHide\" onclick='ToggleDisplay( #39; %# DataBinder.Eval(Container.DataItem, \"JobCode\") % #39;);' Show/Hide /a ","pontos":15},{"corpo":"I just tried using the 'Format String' parameter for the but that didn't work either. onclick=' %# DataBinder.Eval(Container.DataItem, \"JOB_Code\", \"ToggleDisplay('{0}');\" % ' ","pontos":0},{"corpo":"I listen to the javaposse regularly, they cover mostly Java, but not solely.","pontos":26},{"corpo":"the problem is that the sphere can be distorted a number of ways, and having all those points known on the equator, lets say, wont help you map points further away. You need better 'close' points, then you can assume these three points are on a plane with the fourth and do the interpolation --knowing that the distance of longitudes is a function, not a constant.","pontos":0},{"corpo":"Ummm. Maybe I am missing something about the question here, but if you have long/lat info, you also have the direction of north? It seems you need to map geodesic coordinates to a projected coordinates system. For example osgb to wgs84. The maths involved is non-trivial, but the code comes out a only a few lines. If I had more time I'd post more but I need a shower so I will be boring and link to the wikipedia entry which is pretty good. Note: Post shower edited.","pontos":0},{"corpo":"@sparkes Sometimes LISP is the clear language choice, namely Emacs extensions. I'm sure I could use Ruby to extend Emacs if I wanted to, but Emacs was designed to be extended with LISP, so it seems to make sense to use it in that situation.","pontos":1},{"corpo":"Re: 2004 No, you will only move the code that changes the data into the delegate function (because the data change is what triggers the control update). Other than that, you should not have to write anything extra. ","pontos":2},{"corpo":"If the thread call is \"illegal\" (i.e. the DataBind call affects controls that were not created in the thread it is being called from) then you need to create a delegate so that even if the decision / preparation for the DataBind is not done in the control-creating thread, any resultant modification of them (i.e. DataBind()) will be. You would call my code from the worker thread like so: This would then cause the original thread to do the binding, which (presuming it is the thread that created the controls) should work.","pontos":0},{"corpo":"Here is my own contribution for the Java programming language. first some code: calling this method will result in this: even using 'real' objects will show a similar result: thus it is clear that Java passes its parameters by value, as the value for pi and everything and the MyObj objects aren't swapped. be aware that \"by value\" is the only way in java to pass parameters to a method. (for example a language like c++ allows the developer to pass a parameter by reference using ' ' after the parameter's type) now the tricky part, or at least the part that will confuse most of the new java developers: (borrowed from javaworld) Original author: Tony Sintes tricky successfully changes the value of pnt1! This would imply that Objects are passed by reference, this is not the case! A correct statement would be: the Object references are passed by value. more from Tony Sintes: The method successfully alters the value of pnt1, even though it is passed by value; however, a swap of pnt1 and pnt2 fails! This is the major source of confusion. In the main() method, pnt1 and pnt2 are nothing more than object references. When you pass pnt1 and pnt2 to the tricky() method, Java passes the references by value just like any other parameter. This means the references passed to the method are actually copies of the original references. Figure 1 below shows two references pointing to the same object after Java passes an object to a method. Conclusion or a long story short: Java passes it parameters by value \"by value\" is the only way in java to pass a parameter to a method using methods from the object given as parameter will alter the object as the references point to the original objects. (if that method itself alters some values) useful links: http://www.javaworld.com/javaworld/javaqa/2000-05/03-qa-0526-pass.html http://www.ibm.com/developerworks/java/library/j-passbyval/ http://www.ibm.com/developerworks/library/j-praxis/pr1.html http://javadude.com/articles/passbyvalue.htm ","pontos":30},{"corpo":"In PHP, best practice is to use MySQLi (Tutorial) or PDO bound parameters in prepared statements. addslashes() is no longer recommended as it is is too easy to defeat. I personally prefer PDO because it supports named parameters: all those placeholders in mysqli are icky and make the query hard to read. ","pontos":3},{"corpo":"For additional details see the SVNBook: \"Status of working copy files and directories\". The common statuses: U: Working file was updated G: Changes on the repo were automatically merged into the working copy M: Working copy is modified C: This file conflicts with the version in the repo ?: This file is not under version control !: This file is under version control but is missing or incomplete A: This file will be added to version control (after commit) A+: This file will be moved (after commit) D: This file will be deleted (after commit) S: This signifies that the file or directory has been switched from the path of the rest of the working copy (using svn switch) to a branch I: Ignored X: External definition ~: Type changed R: Item has been replaced in your working copy. This means the file was scheduled for deletion, and then a new file with the same name was scheduled for addition in its place. L : Item is locked E: Item existed, as it would have been created, by an svn update. ","pontos":331},{"corpo":"You do the unit testing by mocking out the database connection. This way, you can build scenarios where specific queries in the flow of a method call succeed or fail. I usually build my mock expectations so that the actual query text is ignored, because I really want to test the fault tolerance of the method and how it handles itself -- the specifics of the SQL are irrelevant to that end. Obviously this means your test won't actually verify that the method works, because the SQL may be wrong. This is where integration tests kick in. For that, I expect someone else will have a more thorough answer, as I'm just beginning to get to grips with those myself.","pontos":4},{"corpo":"Don't forget there is also pass by name, and pass by value-result. Pass by value-result is similar to pass by value, with the added aspect that the value is set in the original variable that was passed as the parameter. It can, to some extent, avoid interference with global variables. It is apparently better in partitioned memory, where a pass by reference could cause a page fault (Reference). Pass by name means that the values are only calculated when they are actually used, rather than at the start of the procedure. Algol used pass-by-name, but an interesting side effect is that is it very difficult to write a swap procedure (Reference). Also, the expression passed by name is re-evaluated each time it is accessed, which can also have side effects.","pontos":5},{"corpo":"I would also mock the database, and check that the queries are what you expected. There is the risk that the test checks the wrong sql, but this would be detected in the integration tests","pontos":1},{"corpo":"If you correctly markup your HTML code, there is no need for javascript. The following code will allow the user to click on the label text to tick the checkbox. The for attribute on the label element links to the id attribute on the input element and the browser does the rest. This has been testing to work in: IE6 IE7 Firefox ","pontos":35},{"corpo":"No, because while you thought LINQ is really just syntactic sugar, it actually heavily used expression trees -- a feature absent in .NET 2.0. That being said .NET 3.5 only builds up on top of .NET 2.0, and that's the reason why the IL doesn't look \"different\" or \"special\". I do not see a reason why you shouldn't just install the .NET 3.5 Framework. Everything .NET 2.0 will work fine on it, promise :)","pontos":1},{"corpo":"There are some \"Hacks\" that involve using a System.Core.dll from the 3.5 Framework to make it run with .net 2.0, but personally I would not want use such a somewhat shaky foundation. See here: LINQ support on .NET 2.0 Create a new console application Keep only System and System.Core as referenced assemblies Set Copy Local to true for System.Core, because it does not exist in .NET 2.0 Use a LINQ query in the Main method. For example the one below. Build Copy all the bin output to a machine where only .NET 2.0 is installed Run (Requires .net 2.0 SP1 and I have no idea if bundling the System.Core.dll violates the EULA) ","pontos":22},{"corpo":"As far as I know the LINQ library is only available since the framework 3.0. If you want to use something similar in the framework 2.0, you would need to rewritte it yourself :) or find a similar third-party library. I only found a bit of information here but it didn't convinced me either.","pontos":1},{"corpo":"Assuming you have the correct assemblies and a C# compiler you in theory can use whatever you want to edit the code and then just run the compiler by hand or using a build script. That being said it is a real pain doing .NET development without Visual Studio/SharpEdit/Monodevelop in my opinion.","pontos":4},{"corpo":"The JITter will sometimes use non-virtual calls to methods in sealed classes since there is no way they can be extended further. There are complex rules regarding calling type, virtual/nonvirtual, and I don't know them all so I can't really outline them for you, but if you google for sealed classes and virtual methods you might find some articles on the topic. Note that any kind of performance benefit you would obtain from this level of optimization should be regarded as last-resort, always optimize on the algorithmic level before you optimize on the code-level. Here's one link mentioning this: Rambling on the sealed keyword","pontos":29},{"corpo":"Wrapping with the label still doesn't allow clicking 'anywhere in the box' - still just on the text! This does the job for me: div onclick=\"dob.checked=!dob.checked\" class=\"checkbox\" input onclick=\"checked=!checked\" id=\"dob\" type=\"checkbox\"/ Date of birth entry must be completed /div but unfortunately has lots of javascript that is effectively toggling twice.","pontos":-2},{"corpo":"This will allow you to pass a weight of 0 and still work properly. Notice the === operator, this checks to see if weight matches \"null\" in both value and type (as opposed to ==, which is just value, so 0 == null == false). PHP: ","pontos":1},{"corpo":"It really depends on the sort of data you're bringing back. Since a DataSet is (in effect) just a collection of DataTable objects, you can return multiple distinct sets of data into a single, and therefore more manageable, object. Performance-wise, you're more likely to get inefficiency from unoptimized queries than from the \"wrong\" choice of .NET construct. At least, that's been my experience. ","pontos":55},{"corpo":"I am thinking off the top of my head here. If you load both as Data Tables in the same Data Sets, and define a relation between the two over SKU, and then run a query on the Data Set which produces the desired result.","pontos":0},{"corpo":"I would spend time getting to know the people first. Usually they have a IRC chatroom where everyone idles. Spend sometime getting to know the people, study the code, review the documentation, then if you feel like you are a correct fit for the project, start contributing to bug patches. Don't try to add new features at first. They won't generally be accepted. Also watch this google tech talk about How To Protect Your Open Source Project from Poisonous People. It will teach you what not to do. ","pontos":16},{"corpo":"If you need to populate each member variable by hand you can generalize it a bit as far as the primitives are concerned by using FormatterServices to retrieve in order the list of variable types associated with an object. I've had to do this in a project where I had a lot of different message types coming off the stream and I definitely didn't want to write the serializer/deserializer for each message. Here's the code I used to generalize the deserialization from a byte[]. ","pontos":1},{"corpo":"The search seems to be an \"OR\" instead of an \"AND\" :-( If you do a search for ASP.NET SVN on the search bar, you will not find it on Page 6 or so. it definitely should get some refining.","pontos":1},{"corpo":"Apple Menu System Preferences Keyboard Mouse Keyboard Shortcuts: Change the radio button at the bottom from \"Text boxes and lists only\" to \"All controls.\" Edit: Dammit. We're a fast group around here aren't we? :-)","pontos":2},{"corpo":"Probably it comes from VB6. Because with Option Base statement in VB6, you can alter the lower bound of arrays like this: Also in VB6, you can alter the lower bound of a specific array like this: ","pontos":0},{"corpo":"Check out this blog post: Tweaking the ICallbackEventHandler and Viewstate. The author seems to be addressing the very situation that you are experiencing: So when using ICallbackEventHandler you have two obstacles to overcome to have updated state management for callbacks. First is the problem of the read-only viewstate. The other is actually registering the changes the user has made to the page before triggering the callback. See the blog post for his suggestions on how to solve this. Also check out this forum post which discusses the same problem as well.","pontos":0},{"corpo":"The easiest way to grok them (at least for me) is as \"decorators\", adding behavior while preserving the underlying semantics. Or, an even dirtier definition: it's functional programming's operator overloading.","pontos":1},{"corpo":" Option Base doesn't seem to work in ASP Yes it only does in VB6 like I said. My point is that this usage comes from VB6 programmers who are also ASP (VBScript) programmers.","pontos":0},{"corpo":"Why not use ? That way you don't need to care what the and are. Dim x, y, z x = Array(1, 2, 3) For Each y In x z = DoSomethingWith(y) Next ","pontos":34},{"corpo":"Am I going to be downmodded for suggesting that the Stack Overflow podcast is hilariously bad as a podcast? Anywho, you can find it, and a number of not-bad podcasts at itconversations.com. As this question asked for a \"good\" rather than \"exhaustive\" list, then this is obviously just my opinion. My opinion bounces between .NET and Java and just geek. And obvious omissions would reflect my opinion on \"good\". (Ahem, DNR.) The rest of these are easily found by doing a podcast search in iTunes, or just googling (I'll do some repeating here to condense the list): Buzz Out Loud (General Consumer Tech, Daily) This Week in Tech (aka TWiT. Weekly Consumer Tech.) The Java Posse (Weekly.) Google Developer Podcast (which went long fallow, but seems to be coming back, possible renamed as the Google Code Review. Schedule uncertain, technologies vary.) Hanselminutes (Usually, but not always, .NET-related) MacBreak Weekly (The Mac version of TWiT) Polymorphic Podcast (All .NET, usually ASP.NET) Pixel8ed (All .NET, focused on UI. Same guy who does Polymorphic Podcast) tech5 (Consumer Tech. Mostly a fun waste of 5 minutes because Dvorak is so... Spolsky.) ","pontos":35},{"corpo":"I actually found both of those links you provided, but as noted they are simply describing the problem, not solving it. The author of the blog post suggests a workaround by using a different ViewState provider, but unfortunately that isn't a possibility in this case...I really need to leave the particulars of the ViewState alone and just hook on to what is being done out-of-the-box.","pontos":0},{"corpo":"I have never come across this kind of situation, and to be honest the idea of referencing > 256 tables in a query fils me with a mortal dread. Your first question should probably by \"Why so many?\", closely followed by \"what bits of information do I NOT need?\" I'd be worried that the amount of data being returned from such a query would begin to impact performance of the application quite severely, too.","pontos":1},{"corpo":"I'd like to see that query, but I imagine it's some problem with some sort of iterator, and while I can't think of any situations where its possible, I bet it's from a bad while/case/cursor or a ton of poorly implemented views.","pontos":0},{"corpo":"Using the example you gave: If you click on \"Previous Page\" only the value of \"prev\" will be submitted. If you click on \"Next Page\" only the value of \"next\" will be submitted. If however, you press enter somewhere on the form, neither \"prev\" nor \"next\" will be submitted. So using pseudo code you could do the following: ","pontos":-3},{"corpo":"I don't see any problem with your code. just out of my head, what if you try to do it manually? does it work? also try then use buffer[] in your BinaryReader instead of reading data from FileStream to see whether you still get AccessViolation exception. I had no luck using the BinaryFormatter, I guess I have to have a complete struct that matches the content of the file exactly. That makes sense, BinaryFormatter has its own data format, completely incompatible with yours.","pontos":1},{"corpo":"Since programs like AdBlock actually never request the advert, you would have to look the server logs to see if the same user accessed a webpage but didn't access an advert. This is assuming the advert is on the same server. If your adverts are on a separate server, then I would suggest it's impossible to do so. The best way to stop users from blocking adverts, is to have inline text adverts which are generated by the server and dished up inside your html.","pontos":11},{"corpo":"You need to think about the different ways that ads are blocked. The first thing to look at is whether they are running noscript, so you could add a script that would check for that. The next thing is to see if they are blocking flash, a small movie should do that. If you look at the adblock site, there is some indication of how it does blocking: How does element hiding work? If you look further down that page, you will see that conventional chrome probing will not work, so you need to try and parse the altered DOM. ","pontos":4},{"corpo":"The former will throw an exception if the source type can't be cast to the target type. The latter will result in sc2 being a null reference, but no exception. [Edit] My original answer is certainly the most pronounced difference, but as Eric Lippert points out, it's not the only one. Other differences include: You can't use the 'as' operator to cast to a type that doesn't accept 'null' as a value You can't use 'as' to convert things, like numbers to a different representation (float to int, for example). And finally, using 'as' vs. the cast operator, you're also saying \"I'm not sure if this will succeed.\" ","pontos":71},{"corpo":"The parenthetical cast throws an exception if the cast attempt fails. The \"as\" cast returns null if the cast attempt fails.","pontos":1},{"corpo":"Alright. From a theoretical point of view, given that the distortion is \"arbitrary\", and any solution requires you to model this arbitrary distortion, you obviously can't get an \"answer\". However, any solution is going to involve imposing (usually implicitly) some model of the distortion that may or may not reflect the reality of the situation. Since you seem to be most interested in models that presume some sort of local continuity of the distortion mapping, the most obvious choice is the one you've already tried: linear interpolaton between the nearest points. Going beyond that is going to require more sophisticated mathematical and numerical analysis knowledge. You are incorrect, however, in presuming you cannot expand this to more points. You can by using a least-squared error approach. Find the linear answer that minimizes the error of the other points. This is probably the most straight-forward extension. In other words, take the 5 nearest points and try to come up with a linear approximation that minimizes the error of those points. And use that. I would try this next. If that doesn't work, then the assumption of linearity over the area of N points is broken. At that point you'll need to upgrade to either a quadratic or cubic model. The math is going to get hectic at that point.","pontos":2},{"corpo":"They'll throw different exceptions. () : NullReferenceException as : InvalidCastException Which could help for debugging. The \"as\" keyword attempts to cast the object and if the cast fails, null is returned silently. The () cast operator will throw an exception immediately if the cast fails. \"Only use the C# \"as\" keyword where you are expecting the cast to fail in a non-exceptional case. If you are counting on a cast to succeed and are unprepared to receive any object that would fail, you should use the () cast operator so that an appropriate and helpful exception is thrown.\" For code examples and a further explanation: http://blog.nerdbank.net/2008/06/when-not-to-use-c-keyword.html","pontos":0},{"corpo":"Going at it from the other direction is sometimes referred to as graceful degradation. This is usually needed when the site is built first with the enhanced functionality afforded by the various technologies then modified to degrade gracefully for browsers with those technologies are not available. It is also graceful degradation when designing to work with older browsers (ancient in the Internets terminology) such as IE 5.5, Netscape, etc... In my opinion it is much more work to gracefully degrade the application. Progressively enhancing it tends to be much more efficient; however, sometimes the need to take an existing app and make it accessible in these lacking environments arise.","pontos":2},{"corpo":"Behaviour Driven Development seems to focus more on the interaction and communication between Developers and also between Developers and testers. The Wikipedia Article has an explanation: Behavior-driven development Not practicing BDD myself though. ","pontos":1},{"corpo":"The Dragon Book is definitely the \"building compilers\" book, but if your language isn't quite as complicated as the current generation of languages, you may want to look at the Interpreter pattern from Design Patterns. The example in the book designs a regular expression-like language and is well thought through, but as they say in the book, it's good for thinking through the process but is effective really only on small languages. However, it is much faster to write an Interpreter for a small language with this pattern than having to learn about all the different types of parsers, yacc and lex, et cetera...","pontos":9},{"corpo":"I have been using smartassembly. Basically, you pick a dll and it returns it obfuscated. It seems to work fine and I've had no problems so far. Very, very easy to use.","pontos":19},{"corpo":"Firefox 30 ignores for passwords, opting to prompt the user instead whether the password should be stored on the client. Note the following commentary from May 5, 2014: The password manager always prompts if it wants to save a password. Passwords are not saved without permission from the user. We are the third browser to implement this change, after IE and Chrome. According to Mozilla developer documentation the form element attribute prevents form data from being cached in older browsers. input type=\"text\" name=\"foo\" autocomplete=\"off\" / ","pontos":1250},{"corpo":" was a none standard way to do this (I think mozilla and IE still support it) but messing with the users expectations is normally a bad idea. If the user enters their credit card details into a form and then let's someone else use that browser it's not your concern :)","pontos":4},{"corpo":"Use a non-standard name and id for the fields, so rather than \"name\" have \"name_\". Browsers will then not see it as being the name field. The best part about it is that you can do this to some but not all fields and it will autocomplete some but not all fields.","pontos":2},{"corpo":" form name=\"form1\" id=\"form1\" method=\"post\" autocomplete=\"off\" action=\"http://www.example.com/form.cgi\" This will work in IE and FF, the downside is that it is not XHTML standard. ","pontos":63},{"corpo":"It sounds like you are probably hitting F5 in Visual Studio when you receive this error? There are a few things you can try. The easiest is to hit the Stop button before hitting F5. Optionally, when you are finished debugging and starting to make changes you can go to the Debug menu and choose either Stop Debugging or Terminate All.","pontos":2},{"corpo":"It sounds like something is eating up your web server's resources. Perhaps you have some resources (file handlers, wcf proxies) that are being opened and not closed? I've had this happen to me specifically when I was not closing WCF client proxy connections. The problem is not necessarily that you have a debugger attached, but only that the web server is not responding in a timely manner. Note that the message says \"This may be because another debugger is attached\".","pontos":0},{"corpo":"Flash is usually the product of choice: Everyone has it, and using the JW FLV Player makes it relatively easy on your side. As for other Video Formats, there are WMV and QuickTime, but the players are rather \"heavy\", not everyone might have them and they feel so 1990ish... Real Player... Don't let me even start ranting about that pile of ... The only other alternative of Flash that I would personally consider is Silverlight, which allows streaming WMV Videos. I found the production of WMV much better and easier than FLV because all Windows FLV Encoders I tried are not really good and stable, whereas pretty much every tool can natively output WMV. The problem with Silverlight is that no one has that Browser Plugin (yet?). There is also a player from JW.","pontos":5},{"corpo":"Is there a reason that you want it in Flash? If a plain, old PNG will work, try the Google Chart API.","pontos":6},{"corpo":"Not an answer, but a warning: my company bought the 2007 Infragistics ASP.NET controls just for the Grid, and we regret that choice. The quality of API is horrible (in our opinion at least), making it very hard to program against the grid (for example, inconsistent naming conventions, but this is just an inconvenience, we have complaints about the object model as well). So I can't say that I know of a better option, I just know I will give a try to something else before paying for Infragistics products again (and the email support we got was horrible as well).","pontos":3},{"corpo":"In IIS, enable annonymous access and allow the web.config to handle user authentication. If this doesn't work, please can you send a sample of your web.config.","pontos":-1},{"corpo":"The most important thing about version control is: JUST START USING IT Not using version control is a horrible idea. If you are not using version control, stop reading right now and start using it. It is very easy to convert from cvs - svn - git - hg It doesn't matter which one you choose. Just pick the easiest one for you to use and start recording the history of your code. You can always migrate to another (D)VCS later. If you are looking for a easy to use GUI look at TortoiseSVN (Windows) and Versions (Mac) (Suggested by codingwithoutcomments) Edit: pix0r said: Git has some nice features, but you won't be able to appreciate them unless you've already used something more standard like CVS or Subversion. This. Using git is pointless if you don't know what version control can do for you. Edit 2: Just saw this link on reddit: Subversion Cheat Sheet. Good quick reference for the svn command line. ","pontos":78},{"corpo":"When I decided I must use a code versioning system, I looked around for any good tutorials on how to get started but didn't find any that could help me. So I simplely installed the SVN Server and Tortoise SVN for the client and dived into the deepend and i learn't how to use it along the way.","pontos":0},{"corpo":"Yup, SVN for preference unless you really need git's particular features. SVN is hard enough; It sounds like git is more complicated to live with. You can get hosted svn from people like Beanstalk - unless you have in-house Linux people, I'd really recommend it. Things can go wrong horribly easily and it's nice to have someone else whose job it is to fix it. There's an excellent tutorial on revision control from Eric Sink which is worth reading no matter which system you use.","pontos":0},{"corpo":"I don't believe SQL Server has a built-in split function, so other than a UDF, the only other answer I know is to hijack the PARSENAME function: PARSENAME takes a string and splits it on the period character. It takes a number as it's second argument, and that number specifies which segment of the string to return (working from back to front). Obvious problem is when the string already contains a period. I still think using a UDF is the best way...any other suggestions?","pontos":233},{"corpo":"I've also been investigating wiki software for use as a KB, but it is tricky to find something that is easy to use for non-technical people. There are many wikis that attempt to provide WYSIWYG editing, but most of the software I've found generates nasty inefficient html markup from the WYSIWYG editor. One notable exception to this is Confluence which generates wiki syntax from a WYSIWYG editor. This still isn't perfect (show me a WYSIWYG editor that is) but is a pretty good compromise between retaining simple wiki syntax for those who like it and allowing non-technical users to contribute content. The only problem is that Confluence isn't free ($1,200 for 25 user license). Edit: I also tried DekiWiki and while the UI is nice it doesn't seem to be quite ready for primetime (suffers terribly from the bad WYSIWYG output disease mentioned above). Also seems like they lack direction as there are so many different ways of accomplishing the same task. ","pontos":3},{"corpo":"I am not sure if MySql supports parameterized queries, if so, you should make an effort to go this route. This will ensure the users input can't do anything malicious. Otherwise some \"bad\" characters in addition to what you mentioned would be semicolon (;) and comments (-- and /* */).","pontos":-1},{"corpo":"SQLite databases exist independently, so there's not way to do this from the database level. You will have to write your own code to do this.","pontos":-1},{"corpo":"To retrieve the number of widgets from each widget category that has more than 5 widgets, you could do this: SELECT WidgetCategory, count(*) FROM Widgets GROUP BY WidgetCategory HAVING count(*) 5 The \"having\" clause is something people often forget about, instead opting to retrieve all their data to the client and iterating through it there. ","pontos":16},{"corpo":"It depends. Generally, code should fail fast. If the value can be set by multiple points in the code and you validate only on after retrieving the value, the bug appears to be in the code that does the update. If the setters validate the input, you know what code is trying to set invalid values.","pontos":3},{"corpo":"This is a conflict between your graphics driver and Visual Studio. Go to your driver settings page (Control panel) and disable the display rotation shortcuts. With this conflict removed, the shortcut will work in Visual Studio.","pontos":13},{"corpo":"If you use SVN for source control, definitely get VisualSVN. It enables TortoiseSVN interactions from within the Visual Studio IDE. I also echo the Resharper comment. Retail price is a little steep, but if you're a student or otherwise educationally affiliated, it's actually pretty cheap.","pontos":11},{"corpo":"Allright, I figured it out! This is a hard bug to catch, but results from the way pipes are handled by the shell. Every element of a pipeline runs in a separate process. When the read command sets var1 and var2, is sets them it its own subshell, not the parent shell. So when the subshell exits, the values of var1 and var2 are lost. You can, however, try doing var1=$(echo \"Hello\") echo var1 which returns the expected answer. Unfortunately this only works for single variables, you can't set many at a time. In order to set multiple variables at a time you must either read into one variable and chop it up into multiple variables or use something like this: set -- $(echo \"Hello World\") var1=\"$1\" var2=\"$2\" echo $var1 echo $var2 While I admit it's not as elegant as using a pipe, it works. Of course you should keep in mind that read was meant to read from files into variables, so making it read from standard input should be a little harder. ","pontos":5},{"corpo":"Your -- already seems to be the optimum way, at least on MS SQL Server 2005. Some other solutions I've seen have a string-conversion, like in them, which is slower by a factor of 10. ","pontos":10},{"corpo":"any of the popular editors can be turned into an ide. I use Vi on the console and have used various gui editors over the years. This doesn't just go for linux I use Crimson Editor on windows as a C/python/z80asm ide.","pontos":0},{"corpo":"No don't null objects. You can check out http://codebetter.com/blogs/karlseguin/archive/2008/04/27/foundations-of-programming-pt-7-back-to-basics-memory.aspx for more information, but setting things to null won't do anything, except dirty your code.","pontos":9},{"corpo":"The only time you should set a variable to null is when the variable does not go out of scope and you no longer need the data associated with it. Otherwise there is no need. ","pontos":1},{"corpo":"Currently in my winforms app I have handlers for , as above, but also Most exceptions arrive via the handler, but the AppDomain one has also caught a few in my experience","pontos":8},{"corpo":"Your status page is available now without logging in (click logout and try it). When the beta-cookie is disabled, there will be nothing between you and your status page.","pontos":7},{"corpo":"There are some cases where it makes sense to null references. For instance, when you're writing a collection--like a priority queue--and by your contract, you shouldn't be keeping those objects alive for the client after the client has removed them from the queue. But this sort of thing only matters in long lived collections. If the queue's not going to survive the end of the function it was created in, then it matters a whole lot less. On a whole, you really shouldn't bother. Let the compiler and GC do their jobs so you can do yours.","pontos":1},{"corpo":"I couldn't figure out how to get the cookies to work either, but I was able to get to my status page in my browser while I was logged out, so I assume this will work once stackoverflow goes public. This is an interesting idea, but won't you also pick up diffs of the underlying html code? Do you have a strategy to avoid ending up with a diff of the html and not the actual content?","pontos":2},{"corpo":"Try this, Chris: TERRIBLY SORRY! I mixed up what you were asking for. I prefer the XML AUTO just for ease of maintainance, but I believe either one is effective. My apologies for the oversight ;-)","pontos":0},{"corpo":"Non-standard things are always strange :) for the long long portion under GNU it's , or and under windows I believe it's only","pontos":3},{"corpo":"The way I have done this is to create a command script file and pass this on the command line via the /b command to psftp.exe. I have also tried this in Perl and have yet to find a neater way of doing it. There is an issue with this method, in that you already have to have accepted the RSA finger-print. If not, then the script will either wait for user input to accept it or will skip over it if you are running in full batch mode, with a failure. Also, if the server changes so that it's RSA finger-print changes (e.g. a cluster) then you need to re-accept the finger-print again. Not an ideal method, but the only one I know. I shall be watching this question incase anyone knows another way.","pontos":2},{"corpo":"I had followed a different tutorial on setting up my xen on ubuntu before 8.04 but now upgraded to 8.04. I used the extra line in my cfg as folows: extra = ' TERM=xterm xencons=tty console=tty1' It allows me to \"xm console hostname\" from dom0. I think this was from a problem with the xen setup in the version prior to 8.04 (I'm not sure which version that was). I'm not sure if the same change is necessary in 8.04 as I'm an upgrade and didn't change any of my domU configs after the upgrade. ","pontos":4},{"corpo":"You can't check for changes without some sort of audit mechanism. You are looking to extract information that ha not been collected. If you just need to know when a record was added or edited, adding a datetime field that gets updated via a trigger when the record is updated would be the simplest choice. If you also need to track when a record has been deleted, then you'll want to use an audit table and populate it from triggers with a row when a record has been added, edited, or deleted.","pontos":1},{"corpo":"Just to check, if you use just this part you get an error? If so, do you still get an error if you copy and paste one of those Inserts into this page, I am trying to see if it's local to the page or that actual line. Also, can you post a copy of the connection calls (minus passwords), unless the inserts use exactly the same syntax as this example.","pontos":0},{"corpo":"Does the apache user require a password to connect to the database? If so, then the fact that it says \"using password: NO\" would lead me to believe that the code is trying to connect without a password. If, however, the apache user doesn't require a password, a double-check of the permissions may be a good idea (which you mentioned you already checked). It may still be beneficial to try executing something like this at a mysql prompt: databasename That syntax should be correct. Other than that, I'm just as stumped as you are.","pontos":0},{"corpo":"If you use JavaScript to open the popup, you can use something like this: var newWin = window.open(url); if(!newWin || newWin.closed || typeof newWin.closed=='undefined') { //POPUP BLOCKED } ","pontos":31},{"corpo":"I have the exact same problem with my work and I find that the best idea is to have a PHP script to re-create the database and then a seperate script where I throw crazy data at it to see if it breaks it. I have not ever used any Unit testing or suchlike so cannot say if it works or not sorry.","pontos":1},{"corpo":"I'm not rousing debate about Emacs Vs. Vi. I'm saying I know I can use Vi as a text editor, what are my other choices? Update: I haven't gotten the same responses. I got pointed to SciTe which I didn't know about along with gedit. Hmm.. I think I know why you took this question personally.","pontos":2},{"corpo":"Don't overlook the compiler itself. Read the compiler's documentation and find all the warnings and errors it can provide, and then enable as many as make sense for you. Also make sure to tell your compiler to treat warnings like errors so you're forced to fix them right away. (\"-Werror\" on gcc) Also: \"-Wall\" on gcc does not enable all warnings, don't be fooled. Also also: check out valgrind (free!) - it \"automatically detect[s] many memory management and threading bugs, and profile[s] your programs in detail.\" Valgrind isn't a static checker, but it's a great tool! http://valgrind.org","pontos":20},{"corpo":"A quick hack you can consider is doing a chmod on the file you're editing, save with vim, and then chmod back to what the file was originally. Of course I don't recommend this approach in a system where you're worried about security, as for a few seconds anyone can read/change the file without you realizing.","pontos":-1},{"corpo":" Just to check, if you use just this part you get an error? If so, do you still get an error if you copy and paste one of those Inserts into this >page, I am trying to see if it's local to the page or that actual line. Also, can you post a copy of the connection calls (minus passwords), unless the inserts >use exactly the same syntax as this example. Here is what is in the connection.php file. I linked to the file through an include in the same fashion as where I execute the INSERT queries elsewhere in the code. $conn = mysql_connect(\"localhost\", ******, ******) or die(\"Could not connect\"); mysql_select_db(\"adbay_com_-_cms\") or die(\"Could not select database\"); I will try the working INSERT query in this area to check that out. As to the others posting about the password access. I did, as stated in my first posting, check permissions. I used phpMyAdmin to verify that the permissions for the user account I was using were correct. And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database. I don't have any user accounts with the name apache in them at all for that matter. ","pontos":0},{"corpo":" I guess in a managed environment, a leak would be you keeping an unnecessary reference to a large chunk of memory around. Absolutely. Also, not using the .Dispose() method on disposable objects when appropriate can cause mem leaks. The easiest way to do it is with a using block because it automatically executes .Dispose() at the end: And if you create a class that is using unmanaged objects, if you're not implementing IDisposable correctly, you could be causing memory leaks for your class's users.","pontos":5},{"corpo":"I'm sure this is possible if you hack at it hard enough, but I'd suggest it is not a good idea. 'Windows' (that you see on the screen) are highly coupled to processes. That is, each process which displays any GUI is expected to have a Message Loop, which processes all of the messages which are involved with creating and managing windows (things like 'clicked the button', 'closed the app', 'redraw the screen' and so on. Because of this, it is more or less assumed that if you have any message loop, it must be available for the lifetime of your process. For example windows might send you a 'quit' message, and you need to have a message loop available to handle that, even if you've got nothing on the screen. Your best bet is do it like this: Make a fake form which is never shown which is your 'main app' Start up Call Application.Run and pass in this fake form. Do your work in another thread, and fire events at the main thread when you need to do Gui stuff.","pontos":0},{"corpo":"I recommend a sieve, either the Sieve of Eratosthenes or the Sieve of Atkin. The sieve or Eratosthenes is probably the most intuitive method of finding a list of primes. Basically you: Write down a list of numbers from 2 to whatever limit you want, let's say 1000. Take the first number that isn't crossed off (for the first iteration this is 2) and cross off all multiples of that number from the list. Repeat step 2 until you reach the end of the list. All the numbers that aren't crossed off are prime. Obviously there are quite a few optimizations that can be done to make this algorithm work faster, but this is the basic idea. The sieve of Atkin uses a similar approach, but unfortunately I don't know enough about it to explain it to you. But I do know that the algorithm I linked takes 8 seconds to figure out all the primes up to 1000000000 on an ancient Pentium II-350 Sieve of Eratosthenes Source Code: http://web.archive.org/web/20140705111241/http://primes.utm.edu/links/programs/sieves/Eratosthenes/C_source_code/ Sieve of Atkin Source Code: http://cr.yp.to/primegen.html ","pontos":26},{"corpo":" And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database. I don't have any user accounts with the name apache in them at all for that matter. If it is saying 'apache@localhost' the username is not getting passed correctly to the MySQL connection. 'apache' is normally the user that runs the httpd process (at least on Redhat-based systems) and if no username is passed during the connection MySQL uses whomever is calling for the connection. If you do the connection right in your script, not in a called file, do you get the same error?","pontos":5},{"corpo":"Is the site just plain static HTML? i.e. he hasn't managed to code himself an upload page that permits anyone driving by to upload compromised scripts/pages? Why not ask webhost4life if they have any FTP logs available and report the issue to them. You never know, they may be quite receptive and find out for you exactly what happened? I work for a shared hoster and we always welcome reports such as these and can usually pinpoint the exact vector of attack based and advise as to where the customer went wrong.","pontos":2},{"corpo":"The solution is to delete and re-add BOTH tables to the LINQ to SQL diagram, not just the one you have added the second field and keys to. Alternatively, it appears you can make two associations using the LINQ to SQL interface - just don't try and bundle them into a single association.","pontos":3},{"corpo":"Unfortunately, I do not think that there is a clean way to do this in SQL2000. If you narrow your requirements to SQL Server 2005 (and later), then you are in business. You can use the class in . See Query Notifications in SQL Server (ADO.NET). ","pontos":10},{"corpo":"You need a reverse DNS entry. You need to not send the same content to the same user twice. You need to test it with some common webmail and email clients. Personally I ran mine through a freshly installed spam assassin, a trained spam assassin, and multiple hotmail, gmail, and aol accounts. But have you seen that spam that doesn't seem to link to or advertise anything? That's a spammer trying to affect your Bayesian filter. If he can get a high rating and then include some words that would be in his future emails it might be automatically learned as good. So you can't really guess what a user's filter is going to be set as at the time of your mailing. Lastly, I did not sort my list by the domains, but randomized it.","pontos":6},{"corpo":"How can anything on a website not have a UI? Could you maybe be more specific about what you mean by this? I think by definition a Turing test needs a UI -- it has to interact with a user. Did you mean a GUI? Does that mean a non-image based Captcha? ","pontos":0},{"corpo":"A recursive function is one which calls itself. The most common reason I've found to use it is traversing a tree structure. For example, if I have a TreeView with checkboxes (think installation of a new program, \"choose features to install\" page), I might want a \"check all\" button which would be something like this (pseudocode): So you can see that the checkRecursively first checks the node which it is passed, then calls itself for each of that node's children. You do need to be a bit careful with recursion. If you get into an infinite recursive loop, you will get a Stack Overflow exception :) I can't think of a reason why people shouldn't use it, when appropriate. It is useful in some circumstances, and not in others. I think that because it's an interesting technique, some coders perhaps end up using it more often than they should, without real justification. This has given recursion a bad name in some circles.","pontos":6},{"corpo":"Visual Studio also has a feature that will generate a Property from a private variable. If you right-click on a variable, in the context menu that pops up click on the \"Refactor\" item. Then choose encapsulate field. This will create a getter/setter property for a variable. I'm not too big a fan of this technique as it is a little bit awkward to use if you have to create a lot of getters/setters, and it puts the property directly below the private field, which bugs me because I usually have all of my private fields grouped together, and this Visual Studio feature breaks my class' formatting.","pontos":35},{"corpo":"I have created a recursive function to concatenate a list of strings with a separator between them. I use it mostly to create SQL expressions, by passing a list of fields as the 'items' and a 'comma+space' as the separator. Here's the function (It uses some Borland Builder native data types, but can be adapted to fit any other environment): I call it this way: Imagine you have an array named 'fields' with this data inside it: 'albumName', 'releaseDate', 'labelId'. Then you call the function: As the function starts to work, the variable 'result' receives the value of the position 0 of the array, which is 'albumName'. Then it checks if the position it's dealing with is the last one. As it isn't, then it concatenates the result with the separator and the result of a function, which, oh God, is this same function. But this time, check it out, it call itself adding 1 to the position. It keeps repeating, creating a LIFO pile, until it reaches a point where the position being dealt with IS the last one, so the function returns only the item on that position on the list, not concatenating anymore. Then the pile is concatenated backwards. Got it? If you don't, I have another way to explain it. :o)","pontos":0},{"corpo":"Unfortunately the only API that isn't deprecated is located in the ApplicationServices framework, which doesn't have a bridge support file, and thus isn't available in the bridge. If you're wanting to use ctypes, you can use ATSFontGetFileReference after looking up the ATSFontRef. Cocoa doesn't have any native support, at least as of 10.5, for getting the location of a font.","pontos":7},{"corpo":"Recursion works best with what I like to call \"fractal problems\", where you're dealing with a big thing that's made of smaller versions of that big thing, each of which is an even smaller version of the big thing, and so on. If you ever have to traverse or search through something like a tree or nested identical structures, you've got a problem that might be a good candidate for recursion. People avoid recursion for a number of reasons: Most people (myself included) cut their programming teeth on procedural or object-oriented programming as opposed to functional programming. To such people, the iterative approach (typically using loops) feels more natural. Those of us who cut our programming teeth on procedural or object-oriented programming have often been told to avoid recursion because it's error prone. We're often told that recursion is slow. Calling and returning from a routine repeatedly involves a lot of stack pushing and popping, which is slower than looping. I think some languages handle this better than others, and those languages are most likely not those where the dominant paradigm is procedural or object-oriented. For at least a couple of programming languages I've used, I remember hearing recommendations not to use recursion if it gets beyond a certain depth because its stack isn't that deep. ","pontos":4},{"corpo":"I use recursion. What does that have to do with having a CS degree... (which I don't, by the way) Common uses I have found: sitemaps - recurse through filesystem starting at document root spiders - crawling through a website to find email address, links, etc. ? ","pontos":0},{"corpo":"Mario, I don't understand why you used recursion for that example.. Why not simply loop through each entry? Something like this: The above method would be faster, and is simpler. There's no need to use recursion in place of a simple loop. I think these sorts of examples is why recursion gets a bad rap. Even the canonical factorial function example is better implemented with a loop. ","pontos":1},{"corpo":"I think you might be alluding to an \"invisible\" captcha. Check out the Subkismet project for an invisible captcha implementation. http://www.codeplex.com/subkismet","pontos":4},{"corpo":"Build a time machine and go back to 1987? Ho ho. Ok, no more snarky comments. How do I figure out what the configuration settings (e.g. baud rate) should be... Read the datasheet? Ok, ok. Seriously, last one. If you don't know the baud rate of the device you are trying to communicate with, you have two choices. Start guessing, or possibly bust out an o-scope. If you need a good starting point, let me suggest 9600-8-N-1. My suspicion is you can get there with brute force relatively quickly. There's a third option of having an old-school ninja who can tell just by the LOOK of the garbled characters at some standard baud rate what actual baud rate is. An impressive party trick to be sure. Hopefully though you have access to this information. In unix/linux, you can get ahold of minicom to play with the serial port directly. This should make it fairly quick to get the configuration figured out. one of the major Unix shells In Unix the serial port(s) is/are file-mapped into the /dev/ subdir. ttyS0, for example. If you setup the correct baud rate and whatnot using minicom, you can even cat stuff to that file to send stuff out there. On to the meat of the question, you can access it programmatically through the POSIX headers. termios.h is the big one. See: http://www.easysw.com/~mike/serial/serial.html#3_1 but I also have some interest in serial programming using Windows/Hyperterminal. Hyperterminal and minicom are basically the same program. As for how Windows let's you get access to the serial port, I'll leave that question for someone else. I haven't done that in Windows since the Win95 days.","pontos":20},{"corpo":"To recurse on a solved problem: do nothing, you're done. To recurse on an open problem: do the next step, then recurse on the rest.","pontos":2},{"corpo":"Bottom line: no, because the overhead of interpretation overwhelms the overhead of method dispatching.","pontos":4},{"corpo":"Maybe I'm crazy but worrying about speed in cases like this using an interpretive language is like trying to figure out what color to paint the shed. Let's not even get into the idea that this kind of optimization is entirely pre-mature. You hit the nail on the head when you said 'maintainability'. I'd choose the approach that is the most productive and most maintainable. If you need speed later, it ain't gonna come from switching between procedural versus object oriented coding paradigms inside an interpreted language.","pontos":13},{"corpo":"I may get bitten by this one but I think that it's personal preference. I can't find any reference in the docs to each() being different than keys() or values() (other than the obvious \"they return different things\" answer. In fact the docs state the use the same iterator and they all return actual list values instead of copies of them, and that modifying the hash while iterating over it using any call is bad. All that said, I almost always use keys() because to me it is usually more self documenting to access the key's value via the hash itself. I occasionally use values() when the value is a reference to a large structure and the key to the hash was already stored in the structure, at which point the key is redundant and I don't need it. I think I've used each() 2 times in 10 years of Perl programming and it was probably the wrong choice both times =) ","pontos":2},{"corpo":" Wikipedia Article. To me, inversion of control is turning your sequentially written code and turning it into an delegation structure. Instead of your program explicitly controlling everything, your program sets up a class or library with certain functions to be called when certain things happen. It solves code duplication. For example, in the old days you would manually write your own event loop, polling the system libraries for new events. Nowadays, most modern APIs you simply tell the system libraries what events you're interested in, and it will let you know when they happen. Inversion of control is a practical way to reduce code duplication, and if you find yourself copying an entire method and only changing a small piece of the code, you can consider tackling it with inversion of control. Inversion of control is made easy in many languages through the concept of delegates, interfaces, or even raw function pointers. It is not appropriate to use in all cases, because the flow of a program can be harder to follow when written this way. It's a useful way to design methods when writing a library that will be reused, but it should be used sparingly in the core of your own program unless it really solves a code duplication problem. ","pontos":37},{"corpo":"You need to have Sharepoint 2007 service pack 1 -- or else there's no chance. (Sharepoint 2007 predates ajax 1.0 -- they built some support into service pack 1) Next, from a trouble shooting point of view, test that the exact same code functions as expected when hosted in a regular asp.net page. (Literally copy and paste your code across into a fresh page, to rule out any typographical errors). Ruling sharepoint in or out of the problem area will help narrow down the solution space.","pontos":2},{"corpo":"Some of the neat features are available in Visual Assist X, though not all of them. I've asked on their forums, but they haven't appeared as yet. VAX gets updated regularly on a rough 4 week period for bug fixes and a new feature every couple of months.","pontos":2},{"corpo":"If he's interested, aren't the minor details the good parts? Using python, you've already cut the GUI off of it so that confusion is gone. Why not pick a project, a game or something, and implement it. The classic hi-lo number guessing game can be simply implemented from the command line in 20-30 lines of code (depending on language of course) and gives you variables, conditions, loops, and user input.","pontos":4},{"corpo":"There are a number of good explanations of recursion in this thread, this answer is about why you shouldn't use it in most languages.* In the majority of major imperative language implementations (i.e. every major implementation of C, C++, Basic, Python, Ruby,Java, and C#) iteration is vastly preferable to recursion. To see why, walk through the steps that the above languages use to call a function: space is carved out on the stack for the function's arguments and local variables the function's arguments are copied into this new space control jumps to the function the function's code runs the function's result is copied into a return value the stack is rewound to its previous position control jumps back to where the function was called Doing all of these steps takes time, usually a little bit more than it takes to iterate through a loop. However, the real problem is in step #1. When many programs start, they allocate a single chunk of memory for their stack, and when they run out of that memory (often, but not always due to recursion), the program crashes due to a stack overflow. So in these languages recursion is slower and it makes you vulnerable to crashing. There are still some arguments for using it though. In general, code written recursively is shorter and a bit more elegant, once you know how to read it. There is a technique that language implementers can use called tail call optimization which can eliminate some classes of stack overflow. Put succinctly: if a function's return expression is simply the result of a function call, then you don't need to add a new level onto the stack, you can reuse the current one for the function being called. Regrettably, few imperative language-implementations have tail-call optimization built in. * I love recursion. My favorite static language doesn't use loops at all, recursion is the only way to do something repeatedly. I just don't think that recursion is generally a good idea in languages that aren't tuned for it. ** By the way Mario, the typical name for your ArrangeString function is \"join\", and I'd be surprised if your language of choice doesn't already have an implementation of it. ","pontos":52},{"corpo":"I agree with NilObject, but I'd like to add to this: if you find yourself copying an entire method and only changing a small piece of the code, you can consider tackling it with inversion of control If you find yourself copying and pasting code around, you're almost always doing something wrong. Codified as the design principle Once and Only Once.","pontos":8},{"corpo":"Inversion of Control is what you get when your program callbacks, e.g. like a gui program. For example, in an old school menu, you might have: print \"enter your name\" read name print \"enter your address\" read address etc... store in database thereby controlling the flow of user interaction. In a GUI program or somesuch, instead we say when the user types in field a, store it in NAME when the user types in field b, store it in ADDRESS when the user clicks the save button, call StoreInDatabase So now control is inverted... instead of the computer accepting user input in a fixed order, the user controls the order in which the data is entered, and when the data is saved in the database. Basically, anything with an event loop, callbacks, or execute triggers falls into this category. ","pontos":266},{"corpo":"Resharper does this with the Ctrl-N keyword. Unfortunately it doesn't come for free. Visual Studio doesn't have anything like this feature beyond Find.","pontos":2},{"corpo":"I think the \"wisdom of crowds\" work here. How did most people learn how to program? Many claim that they did so by copying programs of others, usually games they wanted to play in BASIC. Maybe that route will work with him too?","pontos":0},{"corpo":"I've just tested this with: #!/usr/bin/perl -w use strict; sub testit { my @ret = (); if (shift){ push @ret,1; push @ret,2; push @ret,3; }else{ push @ret,\"oneonly\"; } return \\@ret; } foreach my $r (@{testit(1)}){ print $r.\" test1\\n\"; } foreach my $r (@{testit()}){ print $r.\" test2\\n\"; } And it seems to work ok, so I'm thinking it has something to do with the result getting returned from the service? If you have no control over the returning service this might be hard one to crack ","pontos":0},{"corpo":"I happened to stumble across the same problem you are describing, one of the processes of vista itself that uses all, or most, of the CPU resources for a few seconds to return to normal afterward, and back again. It wasn't my own computer so at first I hadn't a clue of what was installed recently, if the problem did occur before but was never noticed etc, so I had to go look and see if others might have the same problem As it turned out it was a misbehaving driver of one hardware components that caused the problem, unfortunately the driver wasn't updated yet so I couldn't fix the problem entirely, (disabling did help though)... However you are using VMware thus a driver issue is, i think, rather unlikely. of course you never know.","pontos":1},{"corpo":"I used to do that with FTP on windows (create a file of commands and shell out FTP.exe) Xetius I tried to upvote yours and accept your answer too and I received an warning that I needed 25 rep to do that. Sorry. ","pontos":0},{"corpo":"SQL Server 2008 has a new date data type and this simplifies this problem to: SELECT CAST(CAST(GETDATE() AS date) AS datetime) ","pontos":23},{"corpo":"You will with the above response receive email with any text written to stderr. Some people redirect that away too, and make sure that the script writes a log instead. ... 2 1 .... ","pontos":5},{"corpo":"Well I've used the c# version on codeproject and its really good for what I wanted... http://www.codeproject.com/KB/recipes/diffengine.aspx You can probably get this translated into VB.net via an online converter if you can't do it yourself...","pontos":7},{"corpo":"I think that it depends on what purpose the Extension methods serve. Extension methods that relate to specific business needs of a project (whether they are connected to basic data types or custom objects) should not be included in a library that would be distributed across multiple projects. Extension methods that relate to basic data types (int, string, etc) or generics that have a wider application could be packaged and distributed across projects. Take care not to globally include Extension methods that have little application, as they just clog up intellisense and can lead to confusion and/or misuse. ","pontos":2},{"corpo":"Remove the [L] from the previous rules: [L] means \"Stop the rewriting process here and don't apply any more rewriting rules.\"","pontos":1},{"corpo":"Could you not apply the condition to the following rules, but with negation, as in (with some variation thereof, I'm not too good at remembering .htaccess rules, so the flags might be wrong): ","pontos":1},{"corpo":"I use UnitTest++. While the example tutorial is for Visual Studio 2005, the concepts are similar (try setting one up for VC6...). Update: The VC6 hacks are now included in the source! ","pontos":1},{"corpo":"I'm guessing Date.Parse() doesn't work?","pontos":2},{"corpo":"Couldn't be simpler... This could also be extended to delete duplicates: ","pontos":32},{"corpo":"The best I've found is gedit unfortunately. Spend a few hours with it and you'll discover it's not so bad, with plugins and themes. You can use the command line to open documents in it.","pontos":2},{"corpo":"Try akismet from wp guys ","pontos":3},{"corpo":"I found that if you append the last modified timestamp of the file onto the end of the URL the browser will request the files when it is modified. For example in PHP: ","pontos":14},{"corpo":"Some solutions I have seen involve adding a version number to the end of the file in the form of a query string. script type=\"text/javascript\" src=\"funkycode.js?v1\" You could use the SVN revision number to automate this for you by including the word LastChangedRevision in your html file after where v1 appears above. You must also setup your repository to do this. I hope this further clarifies my answer? Firefox also allows pressing CTRL + R to reload everything on a particular page. ","pontos":7},{"corpo":"This should work reasonably well: (Edited to make it considerably more concise.)","pontos":44},{"corpo":"Static methods cannot be inherited or overridden, and that is why they can't be abstract. Since static methods are defined on the type, not the instance, of a class, they must be called explicitly on that type. So when you want to call a method on a child class, you need to use its name to call it. This makes inheritance irrelevant. Assume you could, for a moment, inherit static methods. Imagine this scenario: If you call Base.GetNumber(), which method would be called? Which value returned? Its pretty easy to see that without creating instances of objects, inheritance is rather hard. Abstract methods without inheritance are just methods that don't have a body, so can't be called.","pontos":36},{"corpo":"Break down the algorithm into pieces you know the big O notation for, and combine through big O operators. That's the only way I know of. For more information, check the Wikipedia page on the subject.","pontos":2},{"corpo":"I think you want to cross-correlate your signal with an expected, exemplar signal. But, it has been such a long time since I studied signal processing and even then I didn't take much notice.","pontos":1},{"corpo":"This also works: host_name = Socket.getaddrinfo(current_ip,nil) append_to_file(\"#{host_name[0][2]} - #{current_ip} - #{mac_addr}\\n\") I'm not sure why didn't also work. ","pontos":2},{"corpo":"You'd be looking to static link (as opposed to dynamically link) I'm not sure how many of the MS redistributables statically link in.","pontos":0},{"corpo":"It's a tricky question. Since lisp is already structurally so close to a parse tree the difference between a large number of macros and implementing your own mini-language in a parser generator isn't very clear. But, except for the opening and closing paren, you could very easily end up with something that looks nothing like lisp.","pontos":0},{"corpo":"In general, CSS properties are converted to JavaScript by making them camelCase without any dashes. So becomes . function setColor(element, color) { element.style.backgroundColor = color; } ","pontos":80},{"corpo":"I have same problems in my work (we also use sometimes). And there is no easy solution for it. I have only some hints: Try with automatic crash dumps on production machine (see Process Dumper). My experience says Dr. Watson is not perfect for dumping. Remove all catch(...) from your code. They often hide serious memory exceptions. Check Advanced Windows Debugging - there are lots of great tips for problems like yours. I recomend this with all my heart. If you use try and checked builds. Invalid iterator are hell. Good luck. Problems like yours take us months to solve. Be ready for this... ","pontos":8},{"corpo":" What is the difference between SetForeGroundWindow, SetActiveWindow, and BringWindowToTop? It appears as if they all do the same thing. According to MSDN, SetForeGroundWindow will activate the window and direct keyboard focus to it. This attempts to work even when your process is in the background. SetActiveWindow does the same thing as SetForeGroundWindow, but it doesn't do anything if your application isn't the frontmost application. Finally, BringWindowToTop only brings the window to the top, and doesn't change the keyboard focus.","pontos":5},{"corpo":"Or, using a little jQuery: ","pontos":9},{"corpo":"I would advise against changing the default behaviour of a key. I do as much as possible without touching a mouse, so if you make my tab key not move to the next field on a form I will be very aggravated. A shortcut key could be useful however, especially with large code blocks and nesting. Shift-TAB is a bad option because that normally takes me to the previous field on a form. Maybe a new button on the WMD editor to insert a code-TAB, with a shortcut key, would be possible?","pontos":4},{"corpo":"If possible, have you tried using TCP as a protocol? I've had all sorts of connecting as well as staying connected when using UDP. My config is below and not much different than yours but I can stay connected for hours at a time. I'm using IPCop 1.4.16 with the ZERINA OpenVPN server: ","pontos":2},{"corpo":"I'm not sure I understand. When you want to update multiple rows, do you want to update them all with the same value? in that case: or did you want to set multiple rows to different values?","pontos":2},{"corpo":"e-texteditor seems to be growing as the editor of choice for rails development on ruby. Too bad it isn't free. Aside from that, the RailsOnWindows guide works fine. And Sqlite is by far your best choice for development: RailsWithSqlite","pontos":5},{"corpo":"It depends. I had that issue with my blog where a YouTube video caused invalid XHTML, but it rendered fine. On the other hand, I have a \"Valid XHTML\" link, and a combination of a \"Valid XHTML\" claim and invalid XHTML is not professional. As SO does not claim to be valid, I think it's acceptable, but personally if I were Jeff i would be bothered and try to fix it even if it looks good in modern browsers, but some people rather just move on and actually get things done instead of fixing non-existent bugs.","pontos":0},{"corpo":"I wouldn't use XHTML at all just to save myself the philosophical stress. It's not like any browsers are treating it like XHTML anyway. Browsers will reject poor mark-up if the page is sent as application/xhtml+xml, but they rarely are. This is fine. I would be more concerned about things like inline use of CSS and JavaScript with Stack Overflow, just because they make maintenance harder.","pontos":1},{"corpo":"I say, if it renders OK, then it doesn't matter if it's pixel perfect. It takes a while to get a site up and running the way you want it, going back and making changes is going to change the way the page renders slightly, then you have to fix those problems. Now, I'm not saying you should built sloppy web pages, but I see no reason to fix what ain't broke. Browsers aren't going to drop support for error correction anytime in the near future.","pontos":0},{"corpo":"I don't understand why everyone get caught up trying to make their websites fit the standard when some browsers sill have problems properly rendering standard code. I've been in web design for something like 10 years and I stopped double codding (read: hacking css), and changing stupid stuff just so I could put a button on my site. I believe that using a div will cause you to be invalid regardless, and it get a bit harder to do any major JavaScript/AJAX without it.","pontos":0},{"corpo":"One more thing that I don't see in previous answers: In Java the primitive wrappers classes like Integer, Double, Float, Boolean... and String are suposed to be invariant, so that when you pass an instance of those classes the invoked method couldn't alter your data in any way, in opositin with most of other classes, which internal data could be altered by its public methods. So that this classes only has 'getter' methods, no 'setters', besides the constructor. In a java program String literals are stored in a separate portion of heap memory, only a instance for literal, to save memory reusing those instances ","pontos":2},{"corpo":"There are so many standards and they are so badly \"enforced\" or supported that I don't think it matters. Don't get me wrong, I think there should be standards but because they are not enforced, nobody follows them and it's a massive downward spiral.","pontos":0},{"corpo":"Though I believe in striving for valid XHTML and CSS, it's often hard to do for a number of reasons. First, some of the content could be loaded via AJAX. Sometimes, fragments are not properly inserted into the existing DOM. The HTML that you are viewing may not have all been produced in the same document. For example, the page could be made of up components, or templates, and then thrown together right before the browser renders it. This isn't an excuse, but you can't assume that the HTML you're seeing was hand coded all at once. What if some of the code generated by Markdown is invalid? You can't blame Stack Overflow for not producing valid code. Lastly, the purpose of the DOCTYPE is not to simply say \"Hey, I'm using valid code\" but it's also to give the browser a heads up what you're trying to do so that it can at least come close to correctly parsing that information. I don't think that most developers specify a DOCTYPE and then explicitly fail to adhere to it.","pontos":1},{"corpo":"You should take a look at the UNPIVOT clause. Update1: GateKiller, strangely enough I read an article (about something unrelated) about it this morning and I'm trying to jog my memory where I saw it again, had some decent looking examples too. It'll come back to me I'm sure. Update2: Found it: http://weblogs.sqlteam.com/jeffs/archive/2008/04/23/unpivot.aspx","pontos":5},{"corpo":"There are many reasons to use valid markup. My favorite is that it allows you to use validation as a form of regression testing, preventing the markup equivalent of \"delta rot\" from leading to real rendering problems once the errors reach some critical mass. And really, it's just plain sloppy to allow \"lazy\" errors like typos and mis-nested/unclosed tags to accumulate. Valid markup is one way to identify passionate programmers. There's also the issue of debugging: valid markup also gives you a stable baseline from which to work on the inevitable cross-browser compatibility woes. No web developer who values his time should begin debugging browser compatibility problems without first ensuring that the markup is at least syntactically validand any other invalid markup should have a good reason for being there. (Incidentally, stackoverflow.com fails both these tests, and suggestions to fix the problems were declined.) All of that said, to answer your specific question, it's probably not worthwhile to use one of the XHTML doctypes unless you plan to produce valid (or at least well-formed) markup. XHTML's primary advantages are derived from the fact that XHTML is XML, allowing it to be processed and transformed by tools and technologies that work with XML. If you don't plan to make your XHTML well-formed XML, then there's little point in choosing that doctype. The latest HTML 4 spec will probably do everything you need, and it's much more forgiving.","pontos":16},{"corpo":"I don't have a solution, but I'm betting that relying on the referrer will never work because user-agents are free to not send it at all or spoof it to something that will let them in. ","pontos":1},{"corpo":"http://www.easymaths.com/What_on_earth_is_Bodmas.htm: What do you think the answer to 2 + 3 x 5 is? Is it (2 + 3) x 5 = 5 x 5 = 25 ? or 2 + (3 x 5) = 2 + 15 = 17 ? BODMAS can come to the rescue and give us rules to follow so that we always get the right answer: (B)rackets (O)rder (D)ivision (M)ultiplication (A)ddition (S)ubtraction According to BODMAS, multiplication should always be done before addition, therefore 17 is actually the correct answer according to BODMAS and will also be the answer which your calculator will give if you type in 2 + 3 x 5 . Why it is useful in programming? No idea, but i assume it's because you can get rid of some brackets? I am a quite defensive programmer, so my lines can look like this: result = (((i + 4) - (a + b)) * MAGIC_NUMBER) - ANOTHER_MAGIC_NUMBER; with BODMAS you can make this a bit clearer: result = (i + 4 - (a + b)) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER; I think i'd still use the first variant - more brackets, but that way i do not have to learn yet another rule and i run into less risk of forgetting it and causing those weird hard to debug errors? Just guessing at that part though. Mike Stone EDIT: Fixed math as Gaius points out ","pontos":20},{"corpo":"You can't tell apart users and malicious scripts by their http request. But you can analyze which users are requesting too many pages in too short a time, and block their ip-addresses.","pontos":1},{"corpo":"Using a referrer is very unreliable as a method of verification. As other people have mentioned, it is easily spoofed. Your best solution is to modify the application (if you can) You could use a CAPTCHA, or set some sort of cookie or session cookie that keeps track of what page the user last visited (a session would be harder to spoof) and keep track of page view history, and only allow users who have browsed the pages required to get to the page you want to block. This obviously requires you to have access to the application in question, however it is the most foolproof way (not completely, but \"good enough\" in my opinion.)","pontos":1},{"corpo":"I had to do this for a project before. One of the major difficulties I had was explaining what I was trying to do to other people. I spent a ton of time trying to do this in SQL, but I found the pivot function woefully inadequate. I do not remember the exact reason why it was, but it is too simplistic for most applications, and it isn't full implemented in MS SQL 2000. I wound up writing a pivot function in .NET. I'll post it here in hopes it helps someone, someday. ","pontos":1},{"corpo":"If you're trying to prevent search engine bots from accessing certain pages, make sure you're using a properly formatted robots.txt file. Using HTTP_REFERER is unreliable because it is easily faked. Another option is to check the user agent string for known bots (this may require code modification).","pontos":0},{"corpo":"I don't believe there is any easy way to make a Windows Installer project have the ease or upgradability of ClickOnce. I use ClickOnce for all the internal .NET apps I develop (with the exception of Console Apps). I find that in an enterprise environment, the ease of deployment outweighs the lack of flexibility.","pontos":1},{"corpo":"Nope. The reason ActiveX can do it is because ActiveX is a little application that runs on the client's machine. I would imagine access to such information via JavaScript would be a security vulnerability.","pontos":3},{"corpo":"None. .NET relies on underlying Windows API calls that really, really hate that amount of files themselves. As Ronnie says: split them up. ","pontos":1},{"corpo":"Why not just use SQL Management Studio to create a complete script of your database and the objects?","pontos":1},{"corpo":"To make the things a little more clear: Yes, I know that using HTTP_REFERER is completely unreliable and somewhat childish but I'm pretty sure that the people that learned (from me maybe?) to make automations with Excel VBA will not know how to subvert a HTTP_REFERER within the time span to have the final solution. I don't have access/privilege to modify the application code. Politics. Do you believe that? So, I must to wait until the rights holder make the changes I requested. From previous experiences, I know that the requested changes will take two month to get in Production. No, tossing them Agile Methodologies Books in their heads didn't improve anything. This is an intranet app. So I don't have a lot of youngsters trying to undermine my prestige. But I'm young enough as to try to undermine the prestige of \"a very fancy global consultancy services that comes from India\" but where, curiously, there are not a single indian working there. So far, the best answer comes from \"Michel de Mare\": block users based on their IPs. Well, that I did yesterday. Today I wanted to make something more generic because I have a lot of kangaroo users (jumping from an Ip address to another) because they use VPN or DHCP. ","pontos":0},{"corpo":"Use a 3 step process: Generate a script from the working database Create a new database from that script Create a backup of the new database ","pontos":7},{"corpo":"This answer is incomplete and flawed! It only works from TortoisSVN to Fogbugz, but not the other way around. I still need to know how to get it to work backwards from Fogbugz (like it's designed to) so that I can see the Revision number a bug is addressed in from Fogbugz while looking at a bug. Helpful URLS http://tortoisesvn.net/docs/release/TortoiseSVN_en/tsvn-dug-propertypage.html http://tortoisesvn.net/issuetracker_integration Set the \"Hooks\" Go into your fogbugz account and click Extras > Configure Source Control Integration Download \"post-commit.bat\" and the VBScript file for Subversion Create a \"hooks\" directory in a common easily accessed location (preferably with no spaces in the file path) Place a copy of the files in the hooks directories Rename the files without the \".safe\" extension Right click on any directory. Select \"TortoiseSVN > Settings\" (in the right click menu from the last step) Select \"Hook Scripts\" Click \"Add\" Set the properties thus: Hook Type: Post-Commit Hook Working Copy Path: C:\\\\Projects (or whatever your root directory for all of your projects is. If you have multiple you will need to do this step for each one.) Command Line To Execute: C:\\\\subversion\\\\hooks\\\\post-commit.bat (this needs to point to wherever you put your hooks directory from step 3) I also selected the checkbox to Wait for the script to finish... WARNING: Don't forget the double back-slash! \"\\\\\" Click OK... Note: the screenshot is different, follow the text for the file paths, NOT the screenshot... At this point it would seem you could click \"Issue Tracker Integration\" and select Fogbugz. nope. It just returns \"There are no issue-tracker providers available\". Click \"OK\" to close the whole settings dialogue window Configure the Properties Once again, Right click on the root directory of the checked out project you want to work with (you need to do this \"configure the properties\" step for each project -- See \"Migrating Properties Between Projects\" below) Select \"TortoiseSVN > Properties\" (in the right click menu from the last step) Add five property value pairs by clicking \"New...\" and inserting the following in \"Property Name\" and \"Property Value\" respectively: bugtraq:label BugzID: bugtraq:message BugzID: %%BUGID%% bugtraq:number true bugtraq:url http://[your fogbugz URL here]/default.asp?%BUGID% bugtraq:warnifnoissue false Click \"OK\" Commiting Changes and Viewing the Logs Now when you are commiting, you can specify one bug that the commit addresses. This kind of forces you to commit after fixing each bug... When you view the log (Right click root of project, TortoiseSVN > show log) you can see the bug id that each checking corresponds to (1), and you can click the bug id number to be taken to fogbugz to view that bug automatically if you are looking at the actual log message. Pretty nifty! Migrating Properties Between Projects Right click on a project that already has the proper Properties configuration Select \"TortoiseSVN > Properties\" (from the right-click menu from step 1) Highlight all of the desired properties Click \"Export\" Name the file after the property, and place in an easily accessible directory (I placed mine with the hooks files) Right click on the root directory of the checked out project needing properties set for. Click \"Import\" Select the file you exported in step 4 above Click Open ","pontos":11},{"corpo":"Wow. Not a lot of help here but, My Fiance works for SAP here in latin america and constantly complains on the low out-SAP developer base SAP has. I suppose through purchases and whatnot (Bobj, all-in-one and whatnot) eventually something will spark interest but nothing comes to mind. /mp","pontos":0},{"corpo":" is the important line it says you can't put the file where you want it and this normally means a permissions problem check the process running the app (normally the webservers process for php) has the rights to write a file there. EDIT: hang on a bit I jumped the gun a little is the path to the file in the first line correct?","pontos":0},{"corpo":"Anything that renders your page is will do so regardless of which popular standard you use. XHTML is stricter and probably \"better\" but I can't see what advantages you will get with one standard over another.","pontos":1},{"corpo":"Dillie-O is right on with his answer of XHTML 1.0 Transitional but I would suggest shooting for XHTML 1.0 Strict and only falling back on Transitional if there's some piece of functionality you absolutely need that Strict is not allowing.","pontos":2},{"corpo":"Some days when dealing with this DOCTYPE, strict/transitional quirks-mode crap I can't believe that the world wide web works at all!","pontos":0},{"corpo":"A simple trunk branch contains the most current code, then cut a branch whenever we go live. This seems to work pretty effectively. You can easily go to the previous branch whenever the current branch that you cut for the live system fails. Also, it is easy to fix bugs on the branch that is currently live, and since the branch effectively dies when you cut a new one, there is only ever 1 real branch you need to work on (and then merge fixes from there to the live branch).","pontos":2},{"corpo":"Dump your schema into a file and add it to source control. Then a simple diff will show you what changed.","pontos":4},{"corpo":"HTML 4.01. There is absolutely no reason to use XHTML for anything but experimental or academic problems that you only want to run on the 'obscure' web browsers. XHTML Transitional is completely pointless even to those browsers, so I'm not sure why anyone would aim for that. It's actually pretty alarming that a number of people would recommend that. I'd say aiming for HTML 4.01 is the most predictable, but Teifion is right really, \"anything that renders your page will do\". in response to Michael Stum: XHTML is XML based, so it allows easier parsing and you can also use the XML Components of most IDEs to programatically query and insert stuff. This is certainly not true. A lot of XHTML on the web (if not most) does not conform to XML validity (and it needn't - it's not being sent as XML). Trying to treat this like XML when dealing with it is just going to earn you a lot of headaches. This page on Stack Overflow, for instance, will generate errors with many unforgiving XML tools for having invalid mark-up.","pontos":25},{"corpo":"When i worked in a small dev team (small meaning me, another programmer and the boss), it was quite the chaotic mess. However we found that Assigning a \"gatekeeper\" type of process worked for us. The gatekeeper was the person who had done the most work on the app (in this case, i had 2 projects i developed from the ground up, he had like 4). Basically, whenever he had to work on my projects, he'd notify me that he was doing work, i'd make sure the repository was up-to-date and buildable, then he would pull down, make his changes, then commit. He would inform me that it was done, i would pull down, build and deploy. If there were DB changes we had a DB Change folder with all the scripts that would correct the DB. It's obviously got a lot of holes in it, but the process worked for us, and kept us from building over each other.","pontos":3},{"corpo":"Normally, I'm storngly against taking the most expensive and hardest to scale part of your infrastructure (the database) and putting all load into it. On the other hand: It greatly simplifies backup strategy, especially when you have multiple web servers and need to somehow keep the data synchronized. Like most other things, It depends on the expected size and Budget.","pontos":14},{"corpo":"@Michal For whatever reason, your example only works when the where @recnum uses a less than operator. I think when the where filters out a row, the rownum doesn't get incremented, and it can't match anything else. If the original table has an auto incremented id column, and rows were inserted in chronological order, then this should work: select timefield from entries where uid = ? and id % 150 = 0 order by timefield; Of course that doesn't work if there is no correlation between the id and the timefield, unless you don't actually care about getting evenly spaced timefields, just 20 random ones. ","pontos":0},{"corpo":"You should probably just use the standard ASP.Net LinkButton, unless it's really missing something you need.","pontos":0},{"corpo":"A basic paper version is the way to go for an initial mock-up. It's been my experience that if you do a \"real\" mock-up, even if you explain to the customer that it's a non-functional mock-up, they are confused when things don't work. Bottom line: keep it as simple as possible. If it's on paper, there is no way the customer will confuse it with a working product.","pontos":2},{"corpo":"Is it possible to use the System.Xml namespace objects to get the job done here instead of using LINQ? As you already mentioned, XmlNode.InnerXml is exactly what you need.","pontos":0},{"corpo":"@Greg: It appears you've edited your answer to be a completely different answer. To which my answer is yes, I could do this using System.Xml but was hoping to get my feet wet with LINQ to XML. I'll leave my original reply below in case anyone else wonders why I can't just use the XElement's .Value property to get what I need: @Greg: The Value property concatenates all the text contents of any child nodes. So if the body element contains only text it works, but if it contains XHTML I get all the text concatenated together but none of the tags.","pontos":2},{"corpo":"GoldenGate is a very good solution, but probably as expensive as the MySQL replicator. It basically tails the journal, and applies changes based on what's committed. They support bi-directional replication (a hard task), and replication between heterogenous systems. Since they work by processing the journal file, they can do large-scale distributed replication without affecting performance on the source machine(s).","pontos":0},{"corpo":"Isn't there an option in the Print Dialog? Edit: There is. Go to File = Print, and then in the bottom left there is \"Print what\" and then \"Include line Numbers\"","pontos":7},{"corpo":"We use apache on linux, which forks a process to handle requests. We've found that more cores help our throughput, since they reduce the latency of processes waiting to be placed on the run queue. I don't have much experience with IIS, but I imagine the same scenario applies with its thread pool.","pontos":3},{"corpo":"I'm not sure if I can solve this in one go, but we can go back and forth as necessary. First, I want to repeat what I think you are saying and make sure I'm clear. You want to disallow requests to servlet1 and servlet2 is the request doesn't have the proper referer and it does have a query string? I'm not sure I understand (servlet1|servlet2)/.+\\?.+ because it looks like you are requiring a file under servlet1 and 2. I think maybe you are combining PATH_INFO (before the \"?\") with a GET query string (after the \"?\"). It appears that the PATH_INFO part will work but the GET query test will not. I made a quick test on my server using script1.cgi and script2.cgi and the following rules worked to accomplish what you are asking for. They are obviously edited a little to match my environment: The above caught all wrong-referer requests to script1.cgi and script2.cgi that tried to submit data using a query string. However, you can also submit data using a path_info and by posting data. I used this form to protect against any of the three methods being used with incorrect referer: Based on the example you were trying to get working, I think this is what you want: Hopefully this at least gets you closer to your goal. Please let us know how it works, I'm interested in your problem. (BTW, I agree that referer blocking is poor security, but I also understand that relaity forces imperfect and partial solutions sometimes, which you seem to already acknowledge.)","pontos":2},{"corpo":"How much writing vs. reading of this table(s) do you expect? I've used a single audit table, with columns for Table, Column, OldValue, NewValue, User, and ChangeDateTime - generic enough to work with any other changes in the DB, and while a LOT of data got written to that table, reports on that data were sparse enough that they could be run at low-use periods of the day. Added: If the amount of data vs. reporting is a concern, the audit table could be replicated to a read-only database server, allowing you to run reports whenever necessary without bogging down the master server from doing their work.","pontos":15},{"corpo":"Also try out visual svn for your server if you want to avoid any command line work.","pontos":3},{"corpo":"Version Control is essential to development, even if you're working by yourself because it protects you from yourself. If you make a mistake, it's a simple matter to rollback to a previous version of your code that you know works. This also frees you to explore and experiment with your code because you're free of having to worry about whether what you're doing is reversible or not. There are two major branches of Version Control Systems (VCS), Centralized and Distributed. Centralized VCS are based on using a central server, where everyone \"checks out\" a project, works on it, and \"commits\" their changes back to the server for anybody else to use. The major Centralized VCS are CVS and SVN. Both have been heavily criticized because \"merging\" \"branches\" is extremely painful with them. [TODO: write explanation on what branches are and why merging is hard with CVS SVN] Distributed VCS let everyone have their own server, where you can \"pull\" changes from other people and \"push\" changes to a server. The most common Distributed VCS are Git and Mercurial. [TODO: write more on Distributed VCS] If you're working on a project I heavily recommend using a distributed VCS. I recommend Git because it's blazingly fast, but is has been criticized as being too hard to use. If you don't mind using a commercial product BitKeeper is supposedly easy to use.","pontos":5},{"corpo":"I'm not a Java developer, but just from the sound of it, it seems like an is called for if you don't want null to be an allowed value, and the would be thrown if you were trying to use a variable that turns out to be null. ","pontos":144},{"corpo":"I have had the same problem in the past on many sites I have done here at work. The only guaranteed method of making sure the user gets the email is to advise the user to add you to there safe list. Any other method is really only going to be something that can help with it and isn't guaranteed.","pontos":3},{"corpo":"If it's a setter method and null is being passed to it, I think it would make more sense to throw an IllegalArgumentException. A NullPointerException seems to make more sense in the case where you're attempting to actually use the null. So, if you're using it and it's null, NullPointer. If it's being passed in and it's null, IllegalArgument.","pontos":9},{"corpo":"To everyone just starting using version control: Please do not use git (or hg or bzr) because of the hype Use git (or hg or bzr) because they are better tools for managing source code than SVN. I used SVN for a few years at work, and switched over to git 6 months ago. Without learning SVN first I would be totaly lost when it comes to using a DVCS. For people just starting out with version control: Start by downloading SVN Learn why you need version control Learn how to commit, checkout, branch Learn why merging in SVN is such a pain Then switch over to a DVCS and learn: How to clone/branch/commit How easy it is to merge your branches back (go branch crazy!) How easy it is to rewrite commit history and keep your branchesup to date with the main line (git rebase -i, ) How to publish your changes so others can benefit tldr; crowd: Start with SVN and learn the basics, then graduate to a DVCS. ","pontos":6},{"corpo":"Could you be a little more specific about the use case? Removing the decimal point from the representation is a little unusual given that you'll lose all information about the scale. Are you assuming that there will always be two digits? If so, you could simplify multiply by 100 and then round before converting to a string.","pontos":0},{"corpo":" Would be my way of doing it. I dont know how that scales. I don't understand the Does it apply only to the last SELECT in the union? Does mysql actually allow you to group by a column and still not do aggregates on the other columns? EDIT: aaahh. I see that mysql actually does. Its a special version of DISTINCT(b) or something. I wouldnt want to try to be an expert on that area :)","pontos":1},{"corpo":"We use and like Mercurial. It follows a distributed model - it eliminates some of the sense of having to \"check in\" work. Mozilla has moved to Mercurial, which is a good sign that it's not going to go away any time soon. One con, in my opinion, is that there isn't a very good GUI for it. If you're comfortable with the command line, though, it's pretty handy. Mercurial Documentation Unofficial Manual","pontos":1},{"corpo":"The easiest way to test for 64-bit under .NET is to check the value of IntPtr.Size. EDIT: Doh! This will tell you whether or not the current process is 64-bit, not the OS as a whole. Sorry!","pontos":1},{"corpo":"There's a hotfix that appears to address this problem.","pontos":4},{"corpo":"I aim for XHTML 1.0 Trans. It's better to conform so when bugs are fixed in the browsers you won't suddenly be working against the clock trying to figure out what actually needs changing. In my opinion 1.1 is borked and 2.0 has been smashed to smithereens: Do I really need/want a header/footer tag?","pontos":0},{"corpo":"So you want to download a webpage as an XML object using javascript, but you don't want to use a webpage? Since you have no control over what the user will do (closing tabs or windows or whatnot) you would need to do this in like a OSX Dashboard widget or some separate application. A Firefox extension would also work, unless you have to worry about the user closing the browser.","pontos":1},{"corpo":"@Mike: While I agree that validity is not needed to make a page render (after all, we have to keep IE6 compatibility in...), creating valid XHTML that IS compatible AND valid is not a problem. The problems start when people are used to HTML 4 and using the depreciated tags and attributes. Just because the Web is a pile of crap does not mean that every new page needs to be a pile of crap as well. Most Validation errors on SO are so trivial, it shouldn't take too long to fix, like missing quotes on attributes. But it may still be kind of pointless, given the fact that the W3C does not have any idea where they want to be going anyway (see HTML 5) and a certain big Browser company that also makes operating systems does not care as well, so a site could as well send out it's doctype as HTML 1337 Sucks and browsers will still try to render it.","pontos":3},{"corpo":"Using IP address isn't really the best idea in my experience. For example; my office has two IP addresses that get used depending on load and we constantly run into issues using IP addresses. Instead, I've opted for storing the sessions in a separate database for the domains on my servers. This way no one on the file system has access to that session info. This was really helpful with phpBB before 3.0 (they've since fixed this) but it's still a good idea I think.","pontos":5},{"corpo":"Your best researching the most common type of queries that happen on your database and creating indexes based on that research. For example, if there is a table which stores website hits, which is written to very very often but hardly even read from. Then don't index the table in away. If how ever you have a list of users which is access more often than is written to, then I would firstly create a clustered index on the column that is access the most, usually the primary key. I would then create an index on commonly search columns, and those which are use in order by clauses.","pontos":0},{"corpo":"No I have successfully done this with my Vista 64-bit machine. You may want to try using the IP Address of the machine and try connecting that way. Or maybe check out the log files on the Mac to see what the rejection error was.","pontos":0},{"corpo":"But I think you have to be very careful with it. If you will overuse this pattern, you will make very complicated design and even more complicated code. Like in this example with TextEditor: if you have only one SpellChecker maybe it is not really necessary to use IoC ? Unless you need to write unit tests or something ... Anyway: be reasonable. Design pattern are good practices but not Bible to be preached. Do not stick it everywhere.","pontos":23},{"corpo":"I can't say if this is overkill without knowing the details of your usage case, but consider creating a spreadsheet C to hold all data held in common between the two. Links can become dizzyingly complex as spreadsheets age, and having a shared data source might help clear up the confusion. Perhaps even more \"enterprise-y\" is the concept of just pasting in all data that otherwise would be shared. That is the official best practice in my company, because external links have caused so much trouble with maintainability. It may seem cumbersome at first, but I've found it may just be the best way to promote maintainability in addition to ease of use, assuming you don't mind the manual intervention.","pontos":0},{"corpo":"My favorites are: Hanselminutes .NET Rocks StackOverflow SoftwareEngeneeringRadio TWiT and CrankyGeeks I listen to if I want a laugh or get mad, they are horrible. ","pontos":0},{"corpo":"After having this problem for weeks on Vista 64, I found a post by Dave Bouwman just today, and it fixed this problem. ","pontos":2},{"corpo":"There's not really enough information to go on here. will merge any files changed in the revision 67212 in the folder /trunk on the repository and merge them into your current working directory. If you do: What files does it show changed? Merge will only pull changes from the first argument, and apply them to the second. It does not upload back to the server in the first argument. If this doesn't answer your question, could you post more details as to what exactly is happening?","pontos":0},{"corpo":"The simple answer is, do you like Undo buttons? The answer is of course yes, because we as human being make mistakes all the time. As programmers, its often the case though that it can take several hours of testing, code changes, overwrites, deletions, file moves and renames before we work out the method we are trying to use to fix a problem is entirely the wrong one and the code is more broken than when we started. As such, Source Control is a massive Undo button to revert the code to an earlier time when the grass was green and the food plentiful. And not only that, because of how source control works, you can still keep a copy of your broken code, in case a few weeks down the line you want to refer to it again and cherry pick any good ideas that did come out of it. I personally (though it could be called overkill) use a free Single user license version of Source Gear Fortress (which is their Vault source control product with bug tracking features). I find the UI really simple to use, it supports both the checkout edit checkin model and the edit merge commit model. It can be a little tricky to set up though, requiring you to run a local copy of ISS and SQL server. You might want to try a smaller program, like those recommended by other answers here. See what you like and what you can afford.","pontos":2},{"corpo":"Mark said: git - very hot since Linus switched to it I just want to point out that Linus didn't switch to it, Linus wrote it.","pontos":2},{"corpo":"sp_fulltext_database 'enable' CREATE FULLTEXT CATALOG [myFullText] WITH ACCENT_SENSITIVITY = ON CREATE FULLTEXT INDEX ON [dbo].[tblName] KEY INDEX [PK_something] ON [myFullText] WITH CHANGE_TRACKING AUTO ALTER FULLTEXT INDEX ON [dbo].[otherTable] ADD ([Text]) ALTER FULLTEXT INDEX ON [dbo].[teyOtherTable] ENABLE ","pontos":13},{"corpo":"1) I use print_r(). In TextMate, I have a snippet for 'pre' which expands to this: echo \" pre \"; print_r(); echo \" /pre \"; 2) I use Xdebug, but haven't been able to get the GUI to work right on my Mac. It at least prints out a readable version of the stack trace. ","pontos":13},{"corpo":"I would expect tools that need this simply walk the tree in a depth-first manner and when they hit a leaf, just process it (e.g. compile) and remove it from the graph (or mark it as processed, and treat nodes with all leaves processed as leaves). As long as it's a DAG, this simple stack-based walk should be trivial.","pontos":1},{"corpo":"Could I ask why you're not saving the user's settings in a database? Generally, I save application settings that are changed very infrequently in the appSettings section (the default email address error logs are sent to, the number of minutes after which you are automatically logged out, etc.) The scope of this really is at the application, not at the user, and is generally used for deployment settings.","pontos":0},{"corpo":"one thing I would look at doing is caching the appsettings on a read, then flushing the settings from the cache on the write which should minimize the amount of actual load the server has to deal with for processing the appSettings. Also, if possible, look at breaking the appSettings up into configSections so you can read write and cache related settings. Having said all that, I would seriously consider looking at storing these values in a database as you seem to actually be storing user preferences, and not application settings.","pontos":0},{"corpo":"I've come up with a fairly naive recursive algorithm (pseudocode): The biggest problem with this is that it has no ability to detect cyclic dependencies - it can go into infinite recursion (ie stack overflow ;-p). The only way around that that I can see would be to flip the recursive algorithm into an interative one with a manual stack, and manually check the stack for repeated elements. Anyone have something better?","pontos":0},{"corpo":"AdBlock forum says this is used to detect AdBlock. After some tweaking you could use this to gather some statistics. ","pontos":4},{"corpo":"I've never tried it, but you should write a test case to see if reading from a stream after you have hit the end will work, regardless of if there is more data written to the file. Is there a reason you can't use a piped input/output stream? Is the data being written and read from the same application (if so, you have the data, why do you need to read from the file)? Otherwise, maybe read till end of file, then monitor for changes and seek to where you left off and continue... though watch out for race conditions.","pontos":0},{"corpo":"PrcView seems to work off the command line as well: http://www.teamcti.com/pview/prcview.htm (Check the -ph parameter)","pontos":1},{"corpo":"Java autoboxing/unboxing doesn't go to the extent to allow you to dereference a primitive, so your compiler prevents it. Your compiler still knows as a primitive. There's a paper about this issue at jcp.org. Autoboxing is mainly useful during assignment or parameter passing -- allowing you to pass a primitive as an object (or vice versa), or assign a primitive to an object (or vice versa). So unfortunately, you would have to do it like this: (kudos Patrick, I switched to your way) Integer.toString(myInt); ","pontos":37},{"corpo":"Woo, another Debian nut! I think you need to be a bit more specific here, Forum != CMS. Is this for internal company or external customer use? What language(s) do you know/prefer? There's no point in recommending a Perl or PHP framework if your language of choice is Ruby. Do you need to plan for scalability? What's wrong with Joomla or Drupal? I would argue that they can be successfully used on small sites. Maybe a framework isn't what you're looking for, maybe you just need a library or two (eg. PEAR?). If you need something smaller, maybe writing your own backend library that you can reuse for future projects would be a better solution. For a one-size-fits-all framework have a look at Turbogears. (\"it's a big hammer, that makes every problem look like a nail\")","pontos":2},{"corpo":"The appSettings isn't really meant for what you are trying to do. When your .NET application starts, it reads in the app.config file, and caches its contents in memory. For that reason, after you write to the app.config file, you'll have to somehow force the runtime to re-parse the app.config file so it can cache the settings again. This is unnecessary The best approach would be to use a database to store your configuration settings. Barring the use of a database, you could easily setup an external XML configuration file. When your application starts, you could cache its contents in a NameValueCollection object or HashTable object. As you change/add settings, you would do it to that cached copy. When your application shuts down, or at an appropriate time interval, you can write the cache contents back out to file.","pontos":2},{"corpo":"You could always do this: But I wouldn't recommend it. There's no guarantee that the last inserted key will be at the end of the array. The ordering for Keys on MSDN is unspecified, and subject to change. In my very brief test, it does seem to be in order of insertion, but you'd be better off building in proper bookkeeping like a stack--as you suggest (though I don't see the need of a struct based on your other statements)--or single variable cache if you just need to know the latest key.","pontos":4},{"corpo":"I think you can do something like this, the syntax might be wrong, havent used C# in a while To get the last item Dictionary string, int .KeyCollection keys = mydict.keys; string lastKey = keys.Last(); or use Max instead of Last to get the max value, I dont know which one fits your code better.","pontos":4},{"corpo":"Why not use a map of primitives (triangles, squares), distribute the starting points for the countries (the \"capitals\"), and then randomly expanding the countries by adding a random adjacent primitive to the country.","pontos":3},{"corpo":"The best reference I've seen on them is Computational Geometry: Algorithms and Applications, which covers Voronoi diagrams, Delaunay triangulations (similar to Voronoi diagrams and each can be converted into the other), and other similar data structures. They talk about all the data structures you need but they don't give you the code necessary to implement it (which may be a good exercise). In terms of code, an Amazon search shows the book Computational Geometry in C, which presumably comes with the code (although since you're stuck in C, you'd mind as well get the other one and implement it in whatever language you want). I also don't have any experience with this book, only the first. Sorry to have only books to recommend! The only decent online resource I've seen on them are the two Wikipedia articles, which doesn't really tell you implementation details. This link may be helpful though.","pontos":6},{"corpo":"Where I work we've been using http://www.clickatell.com for sending out SMS - it looks like its about 6 or 7 cents a message. They just take http POST requests to send out a message. I don't know if you'll be able to find any good free gateways. We used to send out emails, but found they were unreliable.","pontos":7},{"corpo":"I would say mbUnit also, I like being able to run a single test many times just by specifying inputs and result right above the test function. Horrible description of what I mean so here is a link that shows you what I mean.","pontos":2},{"corpo":"The benefits part has recently been covered, as for where to start....on a small enterprisey system where there aren't too many unknowns so the risks are low. If you don't already know a testing framework (like NUnit), start by learning that. Otherwise start by writing your first test :)","pontos":3},{"corpo":"I agree with the second part of Patrick's answer. Even if in some tests it seems to keep insertion order, the documentation (and normal behavior for dictionaries and hashes) explicitly states the ordering is unspecified. You're just asking for trouble depending on the ordering of the keys. Add your own bookkeeping (as Patrick said, just a single variable for the last added key) to be sure. Also, don't be tempted by all the methods such as Last and Max on the dictionary as those are probably in relation to the key comparator (I'm not sure about that). ","pontos":3},{"corpo":"It allows you to test how one part of your project interacts with the rest, without building the entire thing and potentially missing a vital part. EDIT: Great example from wikipedia: It allows you to test out code beforehand, like a car designer uses a crash test dummy to test the behavior of a car during an accident.","pontos":4},{"corpo":"A mock object lets you test against just what you are writing, and abstract details such as accessing a resource (disk, a network service, etc). The mock then lets you pretend to be that external resource, or class or whatever. You don't really need a mock object framework, just extend the class of the functionality you don't want to worry about in your test and make sure the class you are testing can use your mock instead of the real thing (pass it in via a constructor or setter or something. Practice will show when mocks are helpful and when they aren't. EDIT: Mocking resources is especially important so you don't have to rely on them to exist during the test, and you can mock the details of how they exist and what they respond (such as simulating a FileNotFoundException, or a webservice that is missing, or various possible return values of a webservice)... all without the slow access times involved (mocking will prove MUCH faster than accessing such resources in the test).","pontos":10},{"corpo":"Like everything else it is environmental and depends on the use of the system. The question you need to ask your self is: Will this be actively developed Is this going to be used over the course of many years and expanded on Is the expansion of the application unknown and thus infinite Really it comes down to laziness. How much time to do you want to spend reworking the system from the UI? Because having no business layer means duplication of rules in your UI across possibility many many pages. Then again if this is a proof of concept or short demo or class project. Take the easy way out.","pontos":1},{"corpo":"If you want to set priority when launching a process you could use the built-in start command: START [\"title\"] [/Dpath] [/I] [/MIN] [/MAX] [/SEPARATE | /SHARED] [/LOW | /NORMAL | /HIGH | /REALTIME | /ABOVENORMAL | /BELOWNORMAL] [/WAIT] [/B] [command/program] [parameters] Use the low through belownormal options to set priority of the launched command/program. Seems like the most straightforward solution. No downloads or script writing. The other solutions probably work on already running procs though. ","pontos":40},{"corpo":"I think you should definitely throw a IllegalArgumentException and thus fail-fast. Let other developers know by marking it in the JavaDocs and also define constraints on your methods, so that they see what happens when they pass an invalid objects. I wrote about this a couple of weeks ago, if you want to follow up.","pontos":0},{"corpo":" Do I need a Mock Object Framework? Certainly not. Sometimes, writing mocks by hand can be quite tedious. But for simple things, it's not bad at all. Applying the principle of Last Responsible Moment to mocking frameworks, you should only switch from hand-written mocks to a framework when you've proven to yourself that hand-writing mocks is more trouble than it's worth. If you're just getting starting with mocking, jumping straight into a framework is going to at least double your learning curve (can you double a curve?). Mocking frameworks will make much more sense when you've spent a few projects writing mocks by hand.","pontos":6},{"corpo":"This should work Edit: added imporvement by aussieviking","pontos":100},{"corpo":"Some things to think about when choosing between these mechanisms are: Do you just want stdout or do you need stderr as well? or even separated out? How big is your output? Do you want to hold the entire result in memory? Do you want to read some of your output while the subprocess is still running? Do you need result codes? Do you need a ruby object that represents the process and lets you kill it on demand? You may need anything from simple backticks (IO.popenKernel.forkKernel.execIO.pipeIO.select`. You may also want to throw timeouts into the mix if a subprocess takes too long to execute. Unfortunately, it very much depends. ","pontos":16},{"corpo":"Keep in mind that TempData stores the form collection in session. If you don't like that behavior, you can implement the new ITempDataProvider interface and use some other mechanism for storing temp data. I wouldn't do that unless you know for a fact (via measurement and profiling) that the use of Session state is hurting you.","pontos":34},{"corpo":"I've been running Vista(x86 on laptop and x64 on desktop) for over a year, and I would never go back to XP. I haven't had any compatibility, reliability, or performance issues. As David said, its good to keep an XP VM around for IE6 and IIS6 testing, but I rarely have to use the one I have. EDIT: Get Vista x64 if you have more than 2gb of ram!! You're just wasting it if you don't.","pontos":8},{"corpo":"And the correct answer iiiiis... RewriteRule ^(a|bunch|of|old|directories).* - [NC,L] # all other requests will be forwarded to Cake RewriteRule ^$ app/webroot/ [L] RewriteRule (.*) app/webroot/$1 [L] I still don't get why the index.php file in the root directory was called initially even with these directives in place. It is now located in /appRoot/app/views/pages/home.ctp and handled through Cake as well. With this in place now, I suppose this would have worked as well (slightly altered version of Mike's suggestion, untested): RewriteCond $1 !^(a|bunch|of|old|directories).*$ [NC] RewriteRule ^(.*)$ app/webroot/$1 [L] ","pontos":4},{"corpo":"If you're testing the implementation, why are you trying to mock it out in the first place? Why not just CageThe(IAnimal) and then check that Animals contains that IAnimal? I get that you're mocking the IAnimals, seeing as apparently you don't yet have any concrete animals to play with, but why not just make them stubs, because obviously you're not expecting anything else to happen to them apart from being put into the list? Edit: Something roughly along these lines (not tested, might not compile, may eat your dog etc.): ","pontos":4},{"corpo":" Sorry, PHP specific example, but might help somebody.","pontos":0},{"corpo":" I like the idea of adding the comma by checking if the container is empty, but doesn't that mean more processing as it needs to check the length of the string on each occurrence? You're prematurely optimizing, the performance hit would be negligible.","pontos":1},{"corpo":"The answer seems to be \"no\" ... and \"yes\". There seems to be no real way to know if a file is open for writing by another application. So, reading from such a file will just progress until content is exhausted. I took Mike's advice and wrote some test code: Writer.java writes a string to file and then waits for the user to hit enter before writing another line to file. The idea being that it could be started up, then a reader can be started to see how it copes with the \"partial\" file. The reader I wrote is in Reader.java. Writer.java Reader.java No guarantees that this code is best practice. This leaves the option suggested by Mike of periodically checking if there is new data to be read from the file. This then requires user intervention to close the file reader when it is determined that the reading is completed. Or, the reader needs to be made aware the content of the file and be able to determine and end of write condition. If the content were XML, the end of document could be used to signal this.","pontos":2},{"corpo":"How about some trimming? ","pontos":0},{"corpo":"An etag is an arbitrary string that the server sends to the client that the client will send back to the server the next time the file is requested. The etag should be computable on the server based on the file. Sort of like a checksum, but you might not want to checksum every file sending it out. server client ------------- request file foo file foo etag: \"xyz\" -------- ------------- request file foo etag: \"xyz\" (what the server just sent) (the etag is the same, so the server can send a 304) I built up a string in the format \"file inode number/datestamp/file size\". So, if a file is changed on the server after it has been served out to the client, the newly regenerated etag won't match if the client re-requests it. char *mketag(char *s, struct stat *sb) { sprintf(s, \"%d/%d/%d\", sb->st_ino, sb->st_mtime, sb->st_size); return s; } ","pontos":10},{"corpo":"No, it can't do that since there is no way to express constant over time for a value. If the compiler should be able to do that, there would have to be a guarantee from the code returning the value that the value is constant, and for the duration of the loop won't change. But, in this case, you're free to add new rows to the data table as part of your loop, and thus it's up to you to make that guarantee, in the way you have done it. So in short, the compiler will not do that optimization if the end-index is anything other than a variable. In the case of a variable, where the compiler can just look at the loop-code and see that this particular variable is not changed, it might do that and load the value into a register before starting the loop, but any performance gain from this would most likely be negligible, unless your loop body is empty. Conclusion: If you know, or is willing to accept, that the end loop index is constant for the duration of the loop, place it into a variable. Edit: Re-read your post, and yes, you might see negligible performance gains for your two cases as well, because the JITter optimizes the code. The JITter might optimize your end-index read into a direct access to the variable inside the data table that contains the row count, and a memory read isn't all that expensive anyway. If, on the other hand, reading that property was a very expensive operation, you'd see a more noticable difference.","pontos":4},{"corpo":"There's no known trick 'in the wild' for getting around this, other than using CTP-6 of SQL Server 2008 (in favour of the RTM). the reasons for removing backward compatability (and a lot more discussion besides) are provided at the relevant feedback in microsoft connect. edit: sorry i don't know where this ctp is available, if at all ","pontos":7},{"corpo":"Why don't you just extend the dictionary class to add in a last key inserted property. Something like the following maybe? public class ExtendedDictionary : Dictionary string, int { private int lastKeyInserted = -1; public int LastKeyInserted { get { return lastKeyInserted; } set { lastKeyInserted = value; } } public void AddNew(string s, int i) { lastKeyInserted = i; base.Add(s, i); } } ","pontos":5},{"corpo":"Calling process.Start on the Mailto: protocol (as shown below) will give you basic functionality but not attachments. You can do this approach with attachment paths but this option only works with some old version of outlook such as 98. I assume this is due to the potential securty risk. If anyone does use outlook.exe it will give security warnings under outlook 2003 (and 2007 Dependant on settings). ","pontos":1},{"corpo":"Just a thought, but remember to handle comma's and quotation marks (\") in the field values, otherwise your CSV file may break the consumers reader.","pontos":1},{"corpo":"Using the 3.5 compiler you can use an Extension Method: You can use this on a CLR 2.0 targeted project (3.5 compiler) by including this hack: ","pontos":0},{"corpo":"Not really. You can use reflection to achieve what you want, but it won't be nearly as simple as in Javascript. For example, if you wanted to set the private field of an object to something, you could use this function: ","pontos":14},{"corpo":"Unfortunately, the statement .NET versions can be installed side-by-side, so it won't disrupt any \"legacy\" apps isn't entirely true. If you install 3.5, it requires 2.0 SP1, which can disrupt legacy applications that uses 2.0 and connects to Oracle database servers.","pontos":2},{"corpo":"All of that would definitely work. Personally, for that particular problem, I would probably take a little different approach. Maybe something like this: When using patterns like this, you have to be careful that your data is stored by reference and not by value. In other words, don't do this with primitives. You have to use their big bloated class counterparts. I realized that's not exactly the question, but the question has been pretty well answered and I thought maybe an alternative approach might help.","pontos":7},{"corpo":"Correct. The only way anything makes it onto the closed network is via flash drive.","pontos":0},{"corpo":"You should do a CRC check on each file... from the wiki: Cyclic redundancy check, a type of hash function used to produce a checksum, in order to detect errors in transmission or storage. It produces an almost unique value based on the contents of the file.","pontos":0},{"corpo":"The normal way is to compute a hash of the two files and compare that. MD5 and SHA1 are typical hash algorithms. md5sum should be installed by default on most unix type machines, and Wikipedia's md5sum article has links to some windows implementations.","pontos":1},{"corpo":"I had nothing but problems with Xming. When I could get it to work it was extremely slow (this is over a VPN). IMO X is not designed to run over slow connections its too chatty. And by slow connection I mean anything less then a LAN connection. My solution was to use x11vnc. It lets you access your existing X11 session through VNC. I just ssh into my box through the VPN and launch: That way I can access everything I had opened during the day. Then when I don't I just exit (Ctrl-C) in the terminal to close x11vnc.","pontos":1},{"corpo":"The only 100% way to figure out if two files are equal is to do a binary comparison of the two. If you can live with the risk of false positives (ie. two files which aren't 100% identical but your code says they are), then the digest and checksum algorithms can be used to lessen the work, particularly if the files lives on two different machines with less than optimal bandwidth so that a binary comparison is infeasible. The digest and checksum algorithms all have chances of false positives, but the exact chance varies with the algorithm. General rule is that the more crypto-made it is, and the more bits it outputs, the less chance of a false positive. Even the CRC-32 algorithm is fairly good to use and it should be easy to find code examples on the internet that implements it. If you only do a size/timestamp comparison then I'm sorry to say that this is easy to circumvent and won't actually give you much of a certainty that the files are the same or different. It depends though, if you know that in your world, timestamps are kept, and only changed when the file is modified, then you can use it, otherwise it holds no guarantee.","pontos":3},{"corpo":"I don't use Consolas, though it does look good on LCD, but sometimes I'm not on LCD, like when I'm giving presentations and then it looks crap. My current font of choice for programming is the Liberation Mono font. Oh man, just discovered why the text on Stack Overflow looks like crap, it forces Consolas which is a cleartype font, and on my current setup which didn't have cleartype enabled, it looks very bad. Going to make a bugreport on uservoice.","pontos":15},{"corpo":"For UltraEdit and anything for that matter, I use the good old Courier New. I've found Consolas to difficult to read with it's over anti-aliasing.","pontos":23},{"corpo":"I never found a reason to stray from Courier New. I don't think I'd have a problem with any font so long as it's sans-serif. Mono-spaced fonts are nice for coding, too.","pontos":7},{"corpo":"Also keep in mind that .NET has two heaps, one being the large object heap. I believe objects of roughly 85k or larger are put on this heap. This heap has a different lifetime rules than the regular heap. If you are creating large memory structures (Dictionary's or List's) it would prudent to go lookup what the exact rules are. As far as reclaiming the memory on process termination, unless your running Win98 or it equivalents, everything is released back to the OS on termination. The only exceptions are things that are opened cross-process and another process still has the resource open. COM Objects can be tricky tho. If you always use the pattern, you'll be safe. But I've run across a few interop assemblies that implement . The key here is to call when you're done with it. The COM Objects still use standard COM reference counting. ","pontos":3},{"corpo":"The users outside the network can make patches, and/or use email to send the updates to the main repo or someone, like yourself to merge them. The other internal people can have local copies, like yourself and do merges --but if you are having these out of network patches, it might be better that one person deal with them so nobody gets confused, but that's something you'd have to consider yourself. Syncing the other way, you'd create a patch, and them email or get a flash drive to the remote developers to patch their system. You're going to need some good communication in the team man, I am thankful I'm not in your shoes. Those are my only suggestions --well, the obvious, get them a VPN connection! I'd love to hear how it goes, what plans stabilize into a weekly groove, et cetera. ","pontos":1},{"corpo":"complicated syntax?? The syntax for lisp is incredibly simple. Killer app written in lisp: emacs. Lisp will allow you to extend emacs at will to do almost anything you can think of that an editor might do. But, you should only learn lisp if you want to, and you may never get to use at work ever, but it is still awesome. Also, I want to add: even if you find places where lisp will make sense, you will probably not convince anyone else that it should be used over java, c++, c#, python, ruby, etc.","pontos":35},{"corpo":"I can't answer from first-hand experience but you should read what Paul Graham wrote on Lisp. As for the \"killer-app\" part, read Beating the averages.","pontos":18},{"corpo":"Okay, I might be weird but I really don't like Paul Graham's essays that much on Lisp is a really rough going book if you don't have some grasp of Common Lisp already. Instead, I'd say go for Siebel's Practical Common Lisp. As for \"killer-apps\", Common Lisp seems to find its place in niche shops, like ITA, so while there isn't an app synonymous with CL the way Rails is for Ruby there are places in industry that use it if you do a little digging.","pontos":3},{"corpo":"You have multiple groups in Facebook being the mainly one the SAP Group. ","pontos":1},{"corpo":" @prakesh As long as you associate all of them to the same email address, i would think it would lead you to same account. But whats your experience? When I tried it out I got a whole new account with 0 rep and no steenkin badges. So at the moment SO does not allow multiple OpenID's to be associated with the one account","pontos":3},{"corpo":"I have to agree with Kevin Kenny, Proggy fonts all the way, though I prefer Proggy Clean. But either way you have to go with a font that clearly shows the difference between the number 0 and the letter O. Which the preview font here doesn't really show that.","pontos":1},{"corpo":"Without doing detailed analysis, I'd guess that it's faster because of the question marks. These allow the regular expression to be \"lazy,\" and stop as soon as they have enough to match, rather than checking if the rest of the input matches. I'm not entirely happy with this answer though, because this mostly applies to question marks after * or +. If I were more familiar with the input, it might make more sense to me. (Also, for the code formatting, you can select all of your code and press Ctrl+K to have it add the four spaces required.) ","pontos":1},{"corpo":"I agree with you in that it is quite an annoyance to me (I also copy and paste my address into the second input). That being said, for less savvy users, it is probably a good idea. Watching my mother type is affirmation that many users do not look at the screen when they type (when she's using her laptop she resembles Linus from Peanuts when he's playing the piano). If it's important for you to have the user's correct email address then I would say having a confirmation input is a very good idea (one of these days I'll probably type my email address wrong in the first box and paste it wrong into the second box and then feel like a complete idiot).","pontos":3},{"corpo":"My Environment: Fedora 8; WAS 6.1 (as installed with Rational Application Developer 7) The documentation is very poor in this area and there is a dearth of practical examples. Using the WebSphere Application Server (WAS) Ant tasks To run as described here, you need to run them from your server profile bin directory using the ws_ant.sh or ws_ant.bat commands. ?xml version=\"1.0\"? project name=\"project\" default=\"wasListApps\" basedir=\".\" description Script for listing installed apps. Example run from: /opt/IBM/SDP70/runtimes/base_v61/profiles/AppSrv01/bin /description property name=\"was_home\" value=\"/opt/IBM/SDP70/runtimes/base_v61/\" /property path id=\"was.runtime\" fileset dir=\"${was_home}/lib\" include name=\"**/*.jar\" / /fileset fileset dir=\"${was_home}/plugins\" include name=\"**/*.jar\" / /fileset /path property name=\"was_cp\" value=\"${toString:was.runtime}\" /property property environment=\"env\" /property target name=\"wasListApps\" taskdef name=\"wsListApp\" classname=\"com.ibm.websphere.ant.tasks.ListApplications\" classpath=\"${was_cp}\" /taskdef wsListApp wasHome=\"${was_home}\" / /target /project Command: ./ws_ant.sh -buildfile ~/IBM/rationalsdp7.0/workspace/mywebappDeploy/applist.xml A Deployment Script ?xml version=\"1.0\"? project name=\"project\" default=\"default\" basedir=\".\" description Build/Deploy an EAR to WebSphere Application Server 6.1 /description property name=\"was_home\" value=\"/opt/IBM/SDP70/runtimes/base_v61/\" / path id=\"was.runtime\" fileset dir=\"${was_home}/lib\" include name=\"**/*.jar\" / /fileset fileset dir=\"${was_home}/plugins\" include name=\"**/*.jar\" / /fileset /path property name=\"was_cp\" value=\"${toString:was.runtime}\" / property environment=\"env\" / property name=\"ear\" value=\"${env.HOME}/IBM/rationalsdp7.0/workspace/mywebappDeploy/mywebappEAR.ear\" / target name=\"default\" depends=\"deployEar\" /target target name=\"generateWar\" depends=\"compileWarClasses\" jar destfile=\"mywebapp.war\" fileset dir=\"../mywebapp/WebContent\" /fileset /jar /target target name=\"compileWarClasses\" echo message=\"was_cp=${was_cp}\" / javac srcdir=\"../mywebapp/src\" destdir=\"../mywebapp/WebContent/WEB-INF/classes\" classpath=\"${was_cp}\" /javac /target target name=\"generateEar\" depends=\"generateWar\" mkdir dir=\"./earbin/META-INF\"/ move file=\"mywebapp.war\" todir=\"./earbin\" / copy file=\"../mywebappEAR/META-INF/application.xml\" todir=\"./earbin/META-INF\" / jar destfile=\"${ear}\" fileset dir=\"./earbin\" / /jar /target !-- http://publib.boulder.ibm.com/infocenter/wasinfo/v6r1/index.jsp?topic=/com.ibm.websphere.javadoc.doc/public_html/api/com/ibm/websphere/ant/tasks/package-summary.html -- target name=\"deployEar\" depends=\"generateEar\" taskdef name=\"wsInstallApp\" classname=\"com.ibm.websphere.ant.tasks.InstallApplication\" classpath=\"${was_cp}\"/ wsInstallApp ear=\"${ear}\" failonerror=\"true\" debug=\"true\" taskname=\"\" washome=\"${was_home}\" / /target /project Notes: You can only run this once! You cannot install if the app name is in use - see other tasks like wsUninstallApp It probably won't start the app either You need to run this on the server and the script is quite fragile Alternatives I would probably use Java Management Extensions (JMX). You could write a file-upload servlet that accepts an EAR and uses the deployment MBeans to deploy the EAR on the server. You would just POST the file over HTTP. This would avoid any WAS API dependencies on your dev/build machine and could be independent of any one project. ","pontos":13},{"corpo":"If you're already shuffling the ViewState around anyway, you might as well use an UpdatePanel. Its partial postbacks will update the page's ViewState automatically.","pontos":1},{"corpo":"The reason why #1 is slower is that [\\d;]+ is a greedy quantifier. Using +? or *? is going to do lazy quantifing. See MSDN - Quantifiers for more info. You may want to try: That may be faster for you.","pontos":3},{"corpo":"Here's what I would do. Compile your application to a SWF file. Then encrypt the SWF using AES. Make a \"wrapper\" application that loads the encrypted SWF into a ByteArray using URLLoader Use the as3crypto library to decrypt the swf at runtime. Once decrypted, use Loader.loadBytes to load the decrypted swf into the wrapper application. This will make it a lot harder to get your code. Not impossible, but harder. For AIR applications you could leave the SWF encrypted when delivering the application to the end-user. Then you could provide a registration key that contains the key used to decrypt the SWF. Also, here is a link to an AS3 obfuscator. I am not sure how well it works though. http://www.ambiera.com/irrfuscator/index.html","pontos":12},{"corpo":"I've seen plenty of people type their email address wrong and I've also looked through user databases full of invalid email address. The way I see it you've got two options. Use a second box to confirm the input, or send an authentication/activation email. Both are annoyances so you get to choose which you think will annoy your users less. Most would argue that having to find an email and click on a link is more annoying, but it avoids the copy/paste a bad address issue, and it allows you to do things like delete or roll back users if they don't activate after say 48 hours.","pontos":14},{"corpo":"You could theoretically modify the actual registry files, but I would highly discourage that idea. ","pontos":0},{"corpo":"Have you obtained the fix from http://www-1.ibm.com/support/docview.wss?rs=404 uid=swg1PK17150?","pontos":1},{"corpo":"Invest the time to write a generic \"drop all constraints\" script, so you don't have to maintain it. (A cursor over \"Select * From Information_Schema.Table_Constraints\" and \"Select * From Information_Schema.Referential_Constraints\" does the trick).","pontos":1},{"corpo":" I never found a reason to stray from Courier New. I don't think I'd have a problem with any font so long as it's sans-serif. Mono-spaced fonts are nice for coding, too. Courier New has serifs.","pontos":3},{"corpo":"Within your overridden ProcessCmdKey how are you determining which key has been pressed? The value of keyData (the second parameter) will change dependant on the key pressed and any modifier keys, so, for example, pressing the left arrow will return code 37, shift-left will return 65573, ctrl-left 131109 and alt-left 262181. You can extract the modifiers and the key pressed by ANDing with appropriate enum values:protected override bool ProcessCmdKey(ref Message msg, Keys keyData) { bool shiftPressed = (keyData Keys.Shift) != 0; Keys unmodifiedKey = (keyData Keys.KeyCode); // rest of code goes here } ","pontos":9},{"corpo":"Here's an example of equal-height columns - Equal Height Columns - revisited You can also check out the idea of \"Faux Columns\" as well - Faux Columns Don't go the table route. If it's not tabular data, don't treat it as such. It's bad for accessibility and flexibility. ","pontos":3},{"corpo":"I suppose you have three options. Set user permissions so that user x can only read from the database. Set the database into single user mode so only one connection can access it sp_dboption 'myDataBaseName', single, true Set the database to readonly sp_dboption 'myDataBaseName', read only, true ","pontos":3},{"corpo":"Volumes 1-5 (1996 - 2000) can be found at http://www.foo.be/docs/tpj/ Hmm, looks like that was the entire run? I though it was longer than that for some reason.","pontos":14},{"corpo":"Here is a list of a dozen or so CMS systems for ASP.NET, with a little commentary about most of them. They are not all open source, but a number of them are. ","pontos":6},{"corpo":"We've tried a number of obfuscators. None of them work on a large client/server app that uses remoting. Problem is that client and server share some dlls, and we haven't found any obfuscator that can handle it. We've tried DotFuscator Pro, SmartAssembly, XenoCode, Salamander, and several small time apps whose names escape me. Frankly, I'm convinced obfuscation is a big hack. Even the problems it addresses is not entirely a real problem. The only thing you really need to protect is connection strings, activation codes, security-sensitive things like that. This nonsense that another company is going to reverse-engineer your whole codebase and create a competing product from it is something from a paranoid manager's nightmare, not reality. ","pontos":43},{"corpo":"User corrected this weird problem by recreating their FireFox profile. How to manage FireFox profiles I imagine a re-install of FireFox would have corrected the problem as well.","pontos":2},{"corpo":"In the first case, you have a widening conversion happening. This can be see when runinng the \"javap\" utility program (included w/ the JDK), on the compiled class: Clearly, you see the I2L, which is the mnemonic for the widening Integer-To-Long bytecode instruction. See reference here. And in the other case, replacing the \"long x\" with the object \"Long x\" signature, you'll have this code in the main method: So you see the compiler has created the instruction Integer.valueOf(int), to box the primitive inside the wrapper.","pontos":10},{"corpo":"You should just skip RoR and focus on learning Grails that you'll be needing for work.","pontos":1},{"corpo":" I imagine a re-install of FireFox would have corrected the problem as well. Profile related problems cannot usually be solved by re-installing Firefox since reinstalling (or upgrading) would re-use the same \"damaged\" profile.","pontos":0},{"corpo":"Why not use a SQL Job instead of the Windows Service? You can encapsulate all of you db \"trigger\" code in Stored Procedures. Then your UI and SQL Job can call the same Stored Procedures and create the triggers the same way whether it's manually or at a time interval.","pontos":1},{"corpo":"I would use a userid. If you want to use an user name, you are going to make the \"change the username\" feature very expensive.","pontos":4},{"corpo":"Different engine versions? Have you tried naming that expression in the result? SELECT SUBSTRING(field FROM 5 FOR 15) AS x FROM table; ","pontos":0},{"corpo":"You could consider an EC2 instance from Amazon. That way you can easily test out \"stuff\" without messing with production. And only pay for the space,time and bandwidth you use.","pontos":1},{"corpo":"Yes, mod_python is pretty confusing to set up. Here's how I did it. In httpd.conf: and in your application directory: Repeat the configuration for each python program you wish to have running under mod_python.","pontos":8},{"corpo":"If you mean a VS2005 \"Web Reference\", then the generated proxy classes have a URL property that is the SOAP endpoint url of that service. You can change this property and have your subsequent http communications be made to that new endpoint. Edit: Ah, thanks bcaff86. I didn't know you could do that simply by changing a property.","pontos":0},{"corpo":"LINQ turns into method calls like the code you have. In other words, there should be no difference. However, in your two pieces of code you are not calling .ToList in the first, so the first piece of code will produce an enumerable data source, but if you call .ToList on it, the two should be the same.","pontos":5},{"corpo":"I like Envy Code R. ","pontos":41},{"corpo":"Are you trying to determine if the user is an administrator or not? If so you could grad the username by with \"File.userDirectory.name\". And I think to figure out if the user is an administrator you could probably try to access a file that requires administrator privileges (maybe try writing a file to Windows/System32). If the file access fails you could probably assume that the user is under a Limited account.","pontos":1},{"corpo":"Only way I could figure out how to do it without just moving the file and telling the user was to pass it off to the browser. navigateToURL(new URLRequest(File.applicationStorageDirectory.nativePath + \"/courses/\" + fileName)); ","pontos":2},{"corpo":"The left one, then stops if it is null. Edit: In vb.net it will evaluate both and possibly throw an error, unless you use AndAlso","pontos":2},{"corpo":"I have heard somewhere that compilers work backwards, but I am unsure how true this is.","pontos":0},{"corpo":"The concept modesty is referring to is operator overloading. in the statement:if( A B){ // do something } A is evaluated first, if it evaluates to false, B is never evaluated. The same applies toif(A || B){ //do something } A is evaluated first, if it evaluates to true, B is never evaluated. This concept, overloading, applies to (i think) all of the C style languages, and many others as well.","pontos":2},{"corpo":"ZombieSheep is dead-on. The only \"gotcha\" that might be waiting is that this is only true if you are using the operator. When using the operator, both expressions will be evaluated every time, regardless if one or both evaluate to false. ","pontos":4},{"corpo":"Some languages have interesting situations where expressions are executed in a different order. I am specifically thinking of Ruby, but I'm sure they borrowed it from elsewhere (probably Perl). The expressions in the logic will stay left to right, but for example: The above will evaluate \"message.nil?\" first, then if it evaluates to false (unless is like if except it executes when the condition is false instead of true), \"puts message\" will execute, which prints the contents of the message variable to the screen. It's kind of an interesting way to structure your code sometimes... I personally like to use it for very short 1 liners like the above. Edit: To make it a little clearer, the above is the same as: ","pontos":4},{"corpo":"Nopes, at least the C# compiler doesn't work backwards (in either or ||). It's left to right.","pontos":1},{"corpo":"I disagree with John's answer. The DataContext (or Linq to Entities ObjectContext) is more of a \"unit of work\" than a connection. It manages change tracking, etc. See this blog post for a description: Lifetime of a LINQ to SQL DataContext The four main points of this blog post are that DataContext: Is ideally suited for a \"unit of work\" approach Is also designed for \"stateless\" server operation Is not designed for Long-lived usage Should be used very carefully after any SumbitChanges() operation. Considering that, I don't think using more than one DataContext would do any harm- in fact, creating different DataContexts for different types of work would help make your LinqToSql impelmentation more usuable and organized. The only downside is you wouldn't be able to use sqlmetal to auto-generate your dmbl. ","pontos":20},{"corpo":"Mark's solution resolves the spaces issue, but produces this issue: cvs add: cannot open CVS/Entries for reading: No such file or directory cvs [add aborted]: no repository To fix it, the actual command to use is: find . -type f -exec cvs add {} \\; ","pontos":0},{"corpo":"Okay, how about these? The difference between the approaches should speak for themselves. Also, this is tested about as far as I can throw it. The warranty lasts until... now. Hope it helps!Module Module1 Public Function IsInBusinessHours(ByVal d As Date) As Boolean Return Not (d.Hour 8 OrElse d.Hour 17 OrElse d.DayOfWeek = DayOfWeek.Saturday OrElse d.DayOfWeek = DayOfWeek.Sunday) End Function Public Function AddInBusinessHours(ByVal fromDate As Date, ByVal hours As Integer) As Date Dim work As Date = fromDate.AddHours(hours) While Not IsInBusinessHours(work) work = work.AddHours(1) End While Return work End Function Public Function LoopInBusinessHours(ByVal fromDate As Date, ByVal hours As Integer) As Date Dim work As Date = fromDate While hours 0 While hours 0 AndAlso IsInBusinessHours(work) work = work.AddHours(1) hours -= 1 End While While Not IsInBusinessHours(work) work = work.AddHours(1) End While End While Return work End Function Sub Main() Dim test As Date = New Date(2008, 8, 8, 15, 0, 0) Dim hours As Integer = 5 Console.WriteLine(\"Date: \" + test.ToString() + \", \" + hours.ToString()) Console.WriteLine(\"Just skipping: \" + AddInBusinessHours(test, hours)) Console.WriteLine(\"Looping: \" + LoopInBusinessHours(test, hours)) Console.ReadLine() End Sub End Module ","pontos":2},{"corpo":"Business reason for CSS layout: You can blow away the customers by saying \"our portal is totally customizable/skinnable without writing code!\" Then again, I don't see any evil in designing block elements with tables. By block elements I mean where it doesn't make any sense to break apart the said element in different designs. So, tabular data would best be presented with tables, of course. Designing major building blocks (such as a menu bar, news ticker, etc.) within their own tables should be OK as well. Just don't rely on tables for the overall page layout and you'll be fine, methinks.","pontos":1},{"corpo":"The idea is that Designers can Design and Web Developers can implement. This is especially the case in dynamic web applications where you do not want your Designers to mess around in your Source Code. Now, while there are templating engines, Designers apparantly just love to go crazy and CSS allows to pull a lot more stunts than tables. That being said: As a developer, i abandoned CSS Layout mostly because my Design sucks anyway, so at least it can suck properly :-) But if I would ever hire a Designer, I would let him use whatever his WYSIWYG Editor spits out.","pontos":4},{"corpo":"Using semantic HTML design is one of those things where you don't know what you're missing unless you make a practice of it. I've worked on several sites where the site was restyled after the fact with little or no impact to the server-side code. Restyling sites is a very common request, something that I've noticed more now that I'm able to say \"yes\" to instead of try to talk my way out of. And, once you've learned to work with the page layout system, it's usually no harder than table based layout.","pontos":8},{"corpo":"Is my assumption incorrect then that change requests should be generated from bugs? I'm confused because I don't think all bugs should be automatically approved for implementation -- they may be trivial and at least in our case will go through the same review process as a change request before being assigned to a developer.","pontos":0},{"corpo":"Unfortunately, compilers can't work on theoretical principles, and even though you may know that it is safe in your case, if they allowed it, it would have to be safe for all cases. In other words, the compiler isn't stopping just you, it's stopping everyone, including all those that don't know that it is unsafe and needs special handling. There are probably other reasons for this as well, as all languages usually have ways to do unsafe things if one knows how to deal with them. In C# .NET there are similar provisions, and the only way to declare a constructor that calls a base constructor is this: in doing so, the base constructor will be called before the body of the constructor, and you cannot change this order.","pontos":10},{"corpo":"Use high contrast color combos; Black text on white background is the best example of a high contrast combo. A bad combo is green text on red background. It's horrible for color blind people (like myself). See what your site looks like to a color blind person: colorfilter.wickline.org","pontos":1},{"corpo":"I don't know how Java is implemented internally, but if the constructor of the superclass throws an exception, then there isn't a instance of the class you extend. It would be impossible to call the or methods, for example, since they are inherited in most cases. Java may allow a try/catch around the super() call in the constructor if 1. you override ALL methods from the superclasses, and 2. you don't use the super.XXX() clause, but that all sounds too complicated to me. ","pontos":1},{"corpo":"I can't presume to have a deep understanding of Java internals, but it is my understanding that, when a compiler needs to instantiate a derived class, it has to first create the base (and its base before that(...)) and then slap on the extensions made in the subclass. So it is not even the danger of uninited variables or anything like that at all. When you try to do something in the subclass' constructor before the base class' constructor, you are basically asking the compiler to extend a base object instance that doesn't exist yet. Edit:In your case, MyClass becomes the base object, and MyClassMock is a subclass.","pontos":1},{"corpo":"As for desktop applications: Whatever you do, do not use hand-picked colors. Stick with the named system colors such as \"Window Background\", \"Menu Text\", etc. Otherwise, people relying on OS accessibility features will be locked with your color choices (unable to choose a high-contrast theme, for instance) and to people who like to customize their desktop themes will think your application is fugly.","pontos":0},{"corpo":"Generally, though I can't speak for CMM, change requests and bugs are handled and considered differently because they typically refer to different pieces of your application lifecycle. A bug is a defect in your program implementation. For instance, if you design your program to be able to add two numbers and give the user the sum, a defect would be that it does not handle negative numbers correctly, and thus a bug. A change request is when you have a design defect. For instance, you might have specifically said that your program should not handle negative numbers. A change request is then filed in order to redesign and thus reimplement that part. The design defect might not be intentional, but could easily be because you just didn't consider that part when you originally designed your program, or new cases that didn't exist at the time when the original design was created have been invented or discovered since. In other words, a program might operate exactly as designed, but need to be changed. This is a change request. Typically, fixing a bug is considered a much cheaper action than executing a change request, as the bug was never intended to be part of your program. The design, however, was. And thus a different workflow might be necessary to handle the two different scenarios. For instance, you might have a different way of confirming and filing bugs than you have for change requests, which might require more work to lay out the consequences of the change.","pontos":2},{"corpo":"@shsteimer The concept modesty is referring to is operator overloading. in the statement: ... A is evaluated first, if it evaluates to false, B is never evaluated. The same applies to That's not operator overloading. Operator overloading is the term given for letting you define custom behaviour for operators, such as *, +, = and so on. This would let you write your own 'Log' class, and then do Doing this is actually called Short Circuit Evaluation","pontos":5},{"corpo":"You use when you specifically want to evaluate all the sub-expressions, most likely because they have side-effects you want, even though the final result will be false and thus not execute your then part of your if-statement. Note that and | operates for both bitwise masks and boolean values and is not just for bitwise operations. They're called bitwise, but they are defined for both integers and boolean data types in C#.","pontos":0},{"corpo":"When things are all in-line, they're executed left-to-right. When things are nested, they're executed inner-to-outer. This may seem confusing as usually what's \"innermost\" is on the right-hand side of the line, so it seems like it's going backwards... For example Things happen like this: Call with the literal Call with the literal and the result of Call with the literal and the result of Assign this value to ","pontos":1},{"corpo":"@Luke I don't disagree with you, but this difference is typically the explanation given for why there is two different processes available for handling the two types of issues. I'd say that if the color of the home page was originally designed to be red, and for some reason it is blue, that's easily a quick fix and doesn't need to involve many people or man-hours to do the change. Just check out the file, change the color, check it back in and update the bug. However, if the color of the home page was designed to be red, and is red, but someone thinks it needs to be blue, that is, to me anyway, a different type of change. For instance, have someone thought about the impact this might have on other parts of the page, like images and logos overlaying the blue background? Could there be borders of things that looks bad? Link underlining is blue, will that show up? As an example, I am red/green color blind, changing the color of something is, for me, not something I take lightly. There are enough webpages on the web that gives me problems. Just to make a point that even the most trivial change can be nontrivial if you consider everything. The actual end implementation change is probably much of the same, but to me a change request is a different beast, precisely because it needs to be thought about more to make sure it will work as expected. A bug, however, is that someone said this is how we're going to do it and then someone did it differently. A change request is more like but we need to consider this other thing as well... hmm.... There are exceptions of course, but let me take your examples apart. If the server was designed to handle more than 300,000,000,000 pageviews, then yes, it is a bug that it doesn't. But designing a server to handle that many pageviews is more than just saying our server should handle 300,000,000,000 pageviews, it should contain a very detailed specification for how it can do that, right down to processing time guarantees and disk access average times. If the code is then implemented exactly as designed, and unable to perform as expected, then the question becomes: did we design it incorrectly or did we implement it incorrectly?. I agree that in this case, wether it is to be considered a design flaw or a implementation flaw depends on the actual reason for why it fails to live up to expectations. For instance, if someone assumed disks were 100x times as fast as they actually are, and this is deemed to be the reason for why the server fails to perform as expected, I'd say this is a design bug, and someone needs to redesign. If the original requirement of that many pageviews is still to be held, a major redesign with more in-memory data and similar might have to be undertaken. However, if someone has just failed to take into account how raid disks operate and how to correctly benefit from striped media, that's a bug and might not need that big of a change to fix. Again, there will of course be exceptions. In any case, the original difference I stated is the one I have found to be true in most cases.","pontos":9},{"corpo":"I like to implement IDataErrorInfo and put my validation logic in its Error and this[columnName] properties. That way if you want to check programmatically whether there's an error you can simply test either of those properties in code, or you can hand the validation off to the data binding in Web Forms, Windows Forms or WPF. WPF's \"ValidatesOnDataError\" Binding property makes this particularly easy.","pontos":1},{"corpo":" When a screenreader reads a page and sees a table, it'll tell the user it's a table. Hence, if you use a table for layout, it gets very confusing because the user doesn't know that the content of the table is actually the article instead of some other tabular data This is actually not true; screen readers like JAWS, Window Eyes and HAL ignore layout tables. They work really well at dealing with the real web.","pontos":0},{"corpo":" doing a complete revamp of a 15 page web site just by updating 1 file is heaven. This is true. Unfortunately, having one CSS file used by 15,000 complex and widely differing pages is your worst nightmare come true. Change something - did it break a thousand pages? Who knows? CSS is a double-edged sword on big sites like ours.","pontos":6},{"corpo":"Considering that most people that use Hungarian Notation is following the misunderstood version of it, I'd say it's pretty pointless. If you want to use the original definition of it, it might make more sense, but other than that it is mostly syntactic sugar. If you read the Wikipedia article on the subject, you'll find two conflicting notations, Systems Hungarian Notation and Apps Hungarian Notation. The original, good, definition is the Apps Hungarian Notation, but most people use the Systems Hungarian Notation. As an example of the two, consider prefixing variables with l for length, a for area and v for volume. With such notation, the following expression makes sense: int vBox = aBottom * lVerticalSide; but this doesn't: int aBottom = lSide1; If you're mixing the prefixes, they're to be considered part of the equation, and volume = area * length is fine for a box, but copying a length value into an area variable should raise some red flags. Unfortunately, the other notation is less useful, where people prefix the variable names with the type of the value, like this: int iLength; int iVolume; int iArea; some people use n for number, or i for integer, f for float, s for string etc. The original prefix was meant to be used to spot problems in equations, but has somehow devolved into making the code slightly easier to read since you don't have to go look for the variable declaration. With todays smart editors where you can simply hover over any variable to find the full type, and not just an abbreviation for it, this type of hungarian notation has lost a lot of its meaning. But, you should make up your own mind. All I can say is that I don't use either. Edit Just to add a short notice, while I don't use Hungarian Notation, I do use a prefix, and it's the underscore. I prefix all private fields of classes with a _ and otherwise spell their names as I would a property, titlecase with the first letter uppercase. ","pontos":53},{"corpo":"I've been working for IBM for the past 6 months and I haven't seen it anywhere (thank god because I hate it.) I see either camelCase or c_style. ","pontos":1},{"corpo":"It depends on your language and environment. As a rule I wouldn't use it, unless the development environment you're in makes it hard to find the type of the variable. There's also two different types of Hungarian notation. See Joel's article. I can't find it (his names don't exactly make them easy to find), anyone have a link to the one I mean? Edit: Wedge has the article I mean in his post.","pontos":0},{"corpo":"It is pointless (and distracting) but is in relatively heavy use at my company, at least for types like ints, strings, booleans, and doubles. Things like , , or , and are everywhere. Once upon a time there was a good reason for this convention. Now, it is a cancer.","pontos":9},{"corpo":"I know this is a little late in the game, but the URL mentioned for the JavaScript is mentioned in a list of sites known to have been part of the ASPRox bot resurgence that started up in June (at least that's when we were getting flagged with it). Some details about it are mentioned below: http://www.bloombit.com/Articles/2008/05/ASCII-Encoded-Binary-String-Automated-SQL-Injection.aspx The nasty thing about this is that effectively every varchar type field in the database is \"infected\" to spit out a reference to this URL, in which the the browser gets an tiny iframe that turns it into a bot. A basic SQL fix for this can be found here: http://aspadvice.com/blogs/programming_shorts/archive/2008/06/27/Asprox-Recovery.aspx The scary thing though is that the virus looks to the system tables for values to infect and a lot of shared hosting plans also share the database space for their clients. So most likely it wasn't even your dad's site that was infected, but somebody else's site within his hosting cluster that wrote some poor code and opened the door to SQL Injection attack. If he hasn't done so yet, I'd send an URGENT e-mail to their host and give them a link to that SQL code to fix the entire system. You can fix your own affected database tables, but most likely the bots that are doing the infection are going to pass right through that hole again and infect the whole lot. Hopefully this gives you some more info to work with. EDIT: One more quick thought, if he's using one of the hosts online design tools for building his website, all of that content is probably sitting in a column and was infected that way.","pontos":14},{"corpo":"I think hungarian notation is an interesting footnote along the 'path' to more readable code, and if done properly, is preferable to not-doing it. In saying that though, I'd rather do away with it, and instead of this: write this: It's 2008. We don't have 80 character fixed width screens anymore! Also, if you're writing variable names which are much longer than that you should be looking at refactoring into objects or functions anyway.","pontos":8},{"corpo":"The Hungarian Naming Convention can be useful when used correctly, unfortunately it tends to be misused more often than not. Read Joel Spolsky's article Making Wrong Code Look Wrong for appropriate perspective and justification. Essentially, type based Hungarian notation, where variables are prefixed with information about their type (e.g. whether an object is a string, a handle, an int, etc.) is mostly useless and generally just adds overhead with very little benefit. This, sadly, is the Hungarian notation most people are familiar with. However, the intent of Hungarian notation as envisioned is to add information on the \"kind\" of data the variable contains. This allows you to partition kinds of data from other kinds of data which shouldn't be allowed to be mixed together except, possibly, through some conversion process. For example, pixel based coordinates vs. coordinates in other units, or unsafe user input versus data from safe sources, etc. Look at it this way, if you find yourself spelunking through code to find out information on a variable then you probably need to adjust your naming scheme to contain that information, this is the essence of the Hungarian convention. Note that an alternative to Hungarian notation is to use more classes to show the intent of variable usage rather than relying on primitive types everywhere. For example, instead of having variable prefixes for unsafe user input, you can have simple string wrapper class for unsafe user input, and a separate wrapper class for safe data. This has the advantage, in strongly typed languages, of having partitioning enforced by the compiler (even in less strongly typed languages you can usually add your own tripwire code) but adds a not insignificant amount of overhead.","pontos":17},{"corpo":"Ok, I finally figured it out. Silly problem really, I simply needed to leave out the quotes and the braces. One of those times when I thought that I'd already tried that. :D Oh, and I mistyped @myId in the first example, the code was actually $myId. xsl:variable name=\"myId\" select=\"@id\" / xsl value-of select=\"//Root/Some/Other/Path/Where[@id=$myId]/@Name\" / ","pontos":11},{"corpo":"Have you tried removing the SSP using the command line? I found this worked once when we had a broken an SSP and just wanted to get rid of it. The command is: stsadm.exe -o deletessp -title sspname [-deletedatabases] The switch is optional. Also, check in Central Administration under Job Definitions and Job Schedules to ensure no SSP related jobs are still running ","pontos":1},{"corpo":"If you are using a button or hyperlink or something to trigger the popup to show, could you also add an additional handler to the onClick event of the trigger which should still fire the modal popup and run the javascript at the same time?","pontos":0},{"corpo":"The ModalPopupExtender modifies the button/hyperlink that you tell it to be the \"trigger\" element. The onclick script I add triggers before the popup is shown. I want script to fire after the popup is shown. Also, still leaves me with the problem of when I show the modal from server side.","pontos":0},{"corpo":"I don't think there is a business reason at all. Technical reason, maybe, even so, barely - it is a huge timesuck the world over, and then you look at it in IE and break down and weep.","pontos":0},{"corpo":"Learning C or a lower level language can definitely be useful. However, I don't see any obvious advantage in using the unmanaged WinAPI.","pontos":3},{"corpo":"I've seen low level Windows API code... it ain't pretty... I wish I could unlearn it. I think it benefits to learn low level as in C, as you gain a better understanding of the hardware architecture and how all that stuff works. Learning old Windows API... I think that stuff can be left to the people at Microsoft who may need to learn it to build higher level languages and API... they built it, let them suffer with it ;-) However, if you happen to find a situation where you feel you just can't do what you need to do in a higher level language (few and far between), then perhaps start the dangerous dive into that world.","pontos":3},{"corpo":"It's sort of a chicken-and-egg problem, they're not hard to implement but there really isn't any sort of widespread adoption of microformat consuming software. On the other hand, since microformats aren't widely adopted, there really isn't any need for people to download and install microformat consuming software. Given a new project, I'd probably implement microformats where appropriate, but it's always pretty low on the priority list (I'll do it whenever I can get around to it).","pontos":1},{"corpo":"One of the killers I've found with J# in the past is that there is no built in support for referencing web services. That alone has been enough to deter me from it ever since.","pontos":0},{"corpo":"What has probably happened is that the object provided when rendering the user control is actually null.","pontos":1},{"corpo":"I still use Hungarian Notation when it comes to UI elements, where several UI elements are related to a particular object/value, e.g., lblFirstName for the label object, txtFirstName for the text box. I definitely can't name them both \"FirstName\" even if that is the concern/responsibility of both objects. How do others approach naming UI elements?","pontos":12},{"corpo":"You could use modules to the same effect I believe, although its not \"the singleton pattern\" you can have global state that way (which is what a singleton is ! Naughty global state !). ","pontos":0},{"corpo":"Do you want something that has a server side component or entirely client driven? The best ones I have seen are all flash, alas. I have done little tricks with JS and GWT before, but there is only sophisticated I will get before I go hunting for a library to do it for me. ","pontos":0},{"corpo":"I can think of 2 options Use javascript to resize the smaller column on page load. Fake the equal heights by setting the for the column on the container instead () with ","pontos":0},{"corpo":"RadControls by telerik is pretty good. edit: wtf, stole my answer","pontos":3},{"corpo":"Comments at the top of the page before will throw IE into quirks mode, which could explain why the page breaks, if that's where your comment appears. For more information, check out the \"Triggering different rendering modes\" on this wikipedia page","pontos":1},{"corpo":"My question to you would be why use it if you don't use any of the new/unsupported features. I'm not saying you couldn't play around with it, but why start building sites with a doctype that offers no benefits and could be supplemented by XHTML5.","pontos":3},{"corpo":"I don't understand why you would use a custom control for that, when the builtin ASP.NET AJAX UpdatePanel does the same thing. It just adds more complexity, gives you less support, and makes it more difficult for others to work on your app.","pontos":0},{"corpo":"According to this support message, the feature is not yet currently implemented: The FogBugz wiki does not currently support anchors within a document, unfortunately. It's definitely on the list of features we're considering for the next release, though. ","pontos":4},{"corpo":"It doesn't appear to be possible.","pontos":0},{"corpo":"It appears that for this particular author, the text was edited in some editor that assumed it wasn't UTF8, and then re-wrote it out in UTF8. I'm basing this off the fact that if I tell my browser to interpret the page as different common encodings, none make it display correctly. This tells me that some conversion was done at some point improperly. The only problem with UTF8 is that there isn't a standardized way to recognize that a file is UTF8, and until all editors are standardizing on UTF8, there will still be conversion errors. For other unicode variants, a Byte Order Mark (BOM) is fairly standard to help identify a file, but BOMs in UTF8 files are pretty rare. To keep it from showing up in your content, make sure you're always using unicode-aware editors, and make sure that you always open your files with the proper encodings. It's a pain, unfortunately, and errors will occasionally crop up. The key is just catching them early so that you can undo it or make a few edits.","pontos":2},{"corpo":"I'm fairly positive it's nothing you can do. I've seen this on the front page of digg alot recently. It more than likely has to do with a character being encoded improperly. Not necessarily a factor of the font, just a mistake made somewhere in translation.","pontos":0},{"corpo":"Personally I'd say no. There is no clear benefit to HTML5 and in fact would go as far as to say that the whole thing is botched from the start. Having specialised tags for header, footers and sidebars is a huge mistake - you've got them already in the form of tags (div) and names (classes/id's). Why do we need the specialist ones? XHTML1.1 is good enough, period. In fact, since most browsers don't support HTML4 correctly, there is little point in using a doctype that is going to take years to get proper support.","pontos":-16},{"corpo":"Forget about finding a IDE to write/run/compile assembler on Mac. But, remember mac is UNIX. See http://asm.sourceforge.net/articles/linasm.html. A decent guide (though short) to running assembler via GCC on Linux. You can mimic this. Macs use Intel chips so you want to look at Intel syntax.","pontos":0},{"corpo":"What type is selectedYear? A DateTime? If so then you might need to convert to a string.","pontos":4},{"corpo":"I don't quite see how you expect to set up mock expectations on an object that isn't a mock to begin with. Also, you're setting up the expectation to return an IList which isn't really what happens when the compiler generates an iterator. If you want to specifically test the iterator, you should probably And then verify that the enumerator actually enumerates over all the things you added to the Zoo. Which is what I was going for there. :) I'm not sure if it's even possible to test if yield return is being called, because yield return is just syntactic sugar for a compiler-generated IEnumerable. For instance, calling will not execute any of the code you wrote in the enumerator. The first time that happens is on the first call to IEnumerator.MoveNext(); Now, if you're trying to test the interaction between the concrete Zoo and the IEnumerable contained by that Zoo, you should make the IEnumerable a field on Zoo and inject a mock IEnumerable to that field instead of implementing a concrete IEnumerable directly in Zoo. I hope this is of some assistance.","pontos":3},{"corpo":"It looked for a while like the underscore and angle bracket problem had gone away, but it seems it might not be fixed. here's a small sample, which should look like this: __ #include ____ #include Update: it looks like it's fixed in display mode, and only broken in edit mode","pontos":0},{"corpo":"I use Hungarian Naming for UI elements like buttons, textboxes and lables. The main benefit is grouping in the Visual Studio Intellisense Popup. If I want to access my lables, I simply start typing lbl.... and Visual Studio will suggest all my lables, nicley grouped together. However, after doing more and more Silverlight and WPF stuff, leveraging data binding, I don't even name all my controls anymore, since I don't have to reference them from code-behind (since there really isn't any codebehind anymore ;)","pontos":1},{"corpo":"The best way to implement sparse matrices is to not to implement them - atleast not on your own. I would suggest to BLAS (which I think is a part of LAPACK) which can handle really huge matrices.","pontos":1},{"corpo":"Windows PowerShell is the obvious choice when it comes to \"better windows command line shell other than cmd\". Its clipboard handling isn't that much of an improvement - mark with the mouse, Enter to copy, or right mouse click to paste.","pontos":24},{"corpo":" Why are pointers such a leading factor of confusion for many new, and even old, college level students in the C/C++ language? The concept of a placeholder for a value - variables - maps onto something we're taught in school - algebra. There isn't an existing parallel you can draw without understanding how memory is physically laid out within a computer, and no one thinks about this kind of thing until they're dealing with low level things - at the C/C++/byte communications level. Are there any tools or thought processes that helped you understand how pointers work at the variable, function, and beyond level? Addresses boxes. I remember when I was learning to program BASIC into microcomputers, there were these pretty books with games in them, and sometimes you had to poke values into particular addresses. They had a picture of a bunch of boxes, incrementally labelled with 0, 1, 2... and it was explained that only one small thing (a byte) could fit in these boxes, and there were a lot of them - some computers had as many as 65535! They were next to each other, and they all had an address. What are some good practice things that can be done to bring somebody to the level of, \"Ah-hah, I got it,\" without getting them bogged down in the overall concept? Basically, drill like scenarios. For a drill? Make a struct: struct { char a; char b; char c; char d; } mystruct; mystruct.a = 'r'; mystruct.b = 's'; mystruct.c = 't'; mystruct.d = 'u'; char* my_pointer; my_pointer = mystruct.b; cout 'Start: my_pointer = ' *my_pointer endl; my_pointer++; cout 'After: my_pointer = ' *my_pointer endl; my_pointer = mystruct.a; cout 'Then: my_pointer = ' *my_pointer endl; my_pointer = my_pointer + 3; cout 'End: my_pointer = ' *my_pointer endl; Same example as above, except in C: // Same example as above, except in C: struct { char a; char b; char c; char d; } mystruct; mystruct.a = 'r'; mystruct.b = 's'; mystruct.c = 't'; mystruct.d = 'u'; char* my_pointer; my_pointer = mystruct.b; printf(\"Start: my_pointer = %c\\n\", *my_pointer); my_pointer++; printf(\"After: my_pointer = %c\\n\", *my_pointer); my_pointer = mystruct.a; printf(\"Then: my_pointer = %c\\n\", *my_pointer); my_pointer = my_pointer + 3; printf(\"End: my_pointer = %c\\n\", *my_pointer); Output: Start: my_pointer = s After: my_pointer = t Then: my_pointer = r End: my_pointer = u Perhaps that explains some of the basics through example? ","pontos":20},{"corpo":"A Primary Key needn't be an autoincrementing field, in many cases this just means you are complicating your table structure. Instead, a Primary Key should be the minimum collection of attributes (note that most DBMS will allow a composite primary key) that uniquely identifies a tuple. In technical terms, it should be the field that every other field in the tuple is fully functionally dependent upon. (If it isn't you might need to normalise). In practice, performance issues may mean that you merge tables, and use an incrementing field, but I seem to recall something about premature optimisation being evil...","pontos":1},{"corpo":"Googling for \"GWT +sparklines\" has gotten me to gchart, which seems like what I need. From what I understand - it's all client side and requires nothing more than their JAR file.","pontos":6},{"corpo":"\"C# : Left to right, and processing stops if a match (evaluates to true) is found.\" Zombie sheep is wrong, not enough rep to down vote it. The question is about the operator, not the || operator. In the case of evaluation will stop if a FALSE is found. In the case of || evaluation stops if a TRUE is found.","pontos":8},{"corpo":"I think that the main reason that people have trouble with it is because it's generally not taught in an interesting and engaging manner. I'd like to see a lecturer get 10 volunteers from the crowd and give them a 1 meter ruler each, get them to stand around in a certain configuration and use the rulers to point at each other. Then show pointer arithmetic by moving people around (and where they point their rulers). It'd be a simple but effective (and above all memorable) way of showing the concepts without getting too bogged down in the mechanics. Once you get to C and C++ it seems to get harder for some people. I'm not sure if this is because they are finally putting theory that they don't properly grasp into practice or because pointer manipulation is inherently harder in those languages. I can't remember my own transition that well, but I knew pointers in Pascal and then moved to C and got totally lost. ","pontos":2},{"corpo":"Pointers is a concept that for many can be confusing at first, in particular when it comes to copying pointer values around and still referencing the same memory block. I've found that the best analogy is to consider the pointer as a piece of paper with a house address on it, and the memory block it references as the actual house. All sorts of operations can thus be easily explained. I've added some Delphi code down below, and some comments where appropriate. I chose Delphi since my other main programming language, C#, does not exhibit things like memory leaks in the same way. If you only wish to learn the high-level concept of pointers, then you should ignore the parts labelled \"Memory layout\" in the explanation below. They are intended to give examples of what memory could look like after operations, but they are more low-level in nature. However, in order to accurately explain how buffer overruns really work, it was important that I added these diagrams. Disclaimer: For all intents and purposes, this explanation and the example memory layouts are vastly simplified. There's more overhead and a lot more details you would need to know if you need to deal with memory on a low-level basis. However, for the intents of explaining memory and pointers, it is accurate enough. Let's assume the THouse class used below looks like this: type THouse = class private FName : array[0..9] of Char; public constructor Create(name: PChar); end; When you initialize the house object, the name given to the constructor is copied into the private field FName. There is a reason it is defined as a fixed-size array. In memory, there will be some overhead associated with the house allocation, I'll illustrate this below like this: ---[ttttNNNNNNNNNN]--- ^ ^ | | | +- the FName array | +- overhead The \"tttt\" area is overhead, there will typically be more of this for various types of runtimes and languages, like 8 or 12 bytes. It is imperative that whatever values are stored in this area never gets changed by anything other than the memory allocator or the core system routines, or you risk crashing the program. Allocate memory Get an entrepreneur to build your house, and give you the address to the house. In contrast to the real world, memory allocation cannot be told where to allocate, but will find a suitable spot with enough room, and report back the address to the allocated memory. In other words, the entrepreneur will choose the spot. THouse.Create('My house'); Memory layout: ---[ttttNNNNNNNNNN]--- 1234My house Keep a variable with the address Write the address to your new house down on a piece of paper. This paper will serve as your reference to your house. Without this piece of paper, you're lost, and cannot find the house, unless you're already in it. var h: THouse; begin h := THouse.Create('My house'); ... Memory layout: h v ---[ttttNNNNNNNNNN]--- 1234My house Copy pointer value Just write the address on a new piece of paper. You now have two pieces of paper that will get you to the same house, not two separate houses. Any attempts to follow the address from one paper and rearrange the furniture at that house will make it seem that the other house has been modified in the same manner, unless you can explicitly detect that it's actually just one house. Note This is usually the concept that I have the most problem explaining to people, two pointers does not mean two objects or memory blocks. var h1, h2: THouse; begin h1 := THouse.Create('My house'); h2 := h1; // copies the address, not the house ... h1 v ---[ttttNNNNNNNNNN]--- 1234My house ^ h2 Freeing the memory Demolish the house. You can then later on reuse the paper for a new address if you so wish, or clear it to forget the address to the house that no longer exists. var h: THouse; begin h := THouse.Create('My house'); ... h.Free; h := nil; Here I first construct the house, and get hold of its address. Then I do something to the house (use it, the ... code, left as an exercise for the reader), and then I free it. Lastly I clear the address from my variable. Memory layout: h --+ v +- before free ---[ttttNNNNNNNNNN]--- | 1234My house --+ h (now points nowhere) --+ +- after free ---------------------- | (note, memory might still xx34My house --+ contain some data) Dangling pointers You tell your entrepreneur to destroy the house, but you forget to erase the address from your piece of paper. When later on you look at the piece of paper, you've forgotten that the house is no longer there, and goes to visit it, with failed results (see also the part about an invalid reference below). var h: THouse; begin h := THouse.Create('My house'); ... h.Free; ... // forgot to clear h here h.OpenFrontDoor; // will most likely fail Using after the call to might work, but that is just pure luck. Most likely it will fail, at a customers place, in the middle of a critical operation. h --+ v +- before free ---[ttttNNNNNNNNNN]--- | 1234My house --+ h --+ v +- after free ---------------------- | xx34My house --+ As you can see, h still points to the remnants of the data in memory, but since it might not be complete, using it as before might fail. Memory leak You lose the piece of paper and cannot find the house. The house is still standing somewhere though, and when you later on want to construct a new house, you cannot reuse that spot. var h: THouse; begin h := THouse.Create('My house'); h := THouse.Create('My house'); // uh-oh, what happened to our first house? ... h.Free; h := nil; Here we overwrote the contents of the variable with the address of a new house, but the old one is still standing... somewhere. After this code, there is no way to reach that house, and it will be left standing. In other words, the allocated memory will stay allocated until the application closes, at which point the operating system will tear it down. Memory layout after first allocation: h v ---[ttttNNNNNNNNNN]--- 1234My house Memory layout after second allocation: h v ---[ttttNNNNNNNNNN]---[ttttNNNNNNNNNN] 1234My house 5678My house A more common way to get this method is just to forget to free something, instead of overwriting it as above. In Delphi terms, this will occur with the following method: procedure OpenTheFrontDoorOfANewHouse; var h: THouse; begin h := THouse.Create('My house'); h.OpenFrontDoor; // uh-oh, no .Free here, where does the address go? end; After this method has executed, there's no place in our variables that the address to the house exists, but the house is still out there. Memory layout: h --+ v +- before losing pointer ---[ttttNNNNNNNNNN]--- | 1234My house --+ h (now points nowhere) --+ +- after losing pointer ---[ttttNNNNNNNNNN]--- | 1234My house --+ As you can see, the old data is left intact in memory, and will not be reused by the memory allocator. The allocator keeps track of which areas of memory has been used, and will not reuse them unless you free it. Freeing the memory but keeping a (now invalid) reference Demolish the house, erase one of the pieces of paper but you also have another piece of paper with the old address on it, when you go to the address, you won't find a house, but you might find something that resembles the ruins of one. Perhaps you will even find a house, but it is not the house you were originally given the address to, and thus any attempts to use it as though it belongs to you might fail horribly. Sometimes you might even find that a neighbouring address has a rather big house set up on it that occupies three address (Main Street 1-3), and your address goes to the middle of the house. Any attempts to treat that part of the large 3-address house as a single small house might also fail horribly. var h1, h2: THouse; begin h1 := THouse.Create('My house'); h2 := h1; // copies the address, not the house ... h1.Free; h1 := nil; h2.OpenFrontDoor; // uh-oh, what happened to our house? Here the house was torn down, through the reference in , and while was cleared as well, still has the old, out-of-date, address. Access to the house that is no longer standing might or might not work. This is a variation of the dangling pointer above. See its memory layout. Buffer overrun You move more stuff into the house than you can possibly fit, spilling into the neighbours house or yard. When the owner of that neighbouring house later on comes home, he'll find all sorts of things he'll consider his own. This is the reason I chose a fixed-size array. To set the stage, assume that the second house we allocate will, for some reason, be placed before the first one in memory. In other words, the second house will have a lower address than the first one. Also, they're allocated right next to each other. Thus, this code: var h1, h2: THouse; begin h1 := THouse.Create('My house'); h2 := THouse.Create('My other house somewhere'); ^-----------------------^ longer than 10 characters 0123456789 -- 10 characters Memory layout after first allocation: h1 v -----------------------[ttttNNNNNNNNNN] 5678My house Memory layout after second allocation: h2 h1 v v ---[ttttNNNNNNNNNN]----[ttttNNNNNNNNNN] 1234My other house somewhereouse ^---+--^ | +- overwritten The part that will most often cause crash is when you overwrite important parts of the data you stored that really should not be randomly changed. For instance it might not be a problem that parts of the name of the h1-house was changed, in terms of crashing the program, but overwriting the overhead of the object will most likely crash when you try to use the broken object, as will overwriting links that is stored to other objects in the object. Linked lists When you follow an address on a piece of paper, you get to a house, and at that house there is another piece of paper with a new address on it, for the next house in the chain, and so on. var h1, h2: THouse; begin h1 := THouse.Create('Home'); h2 := THouse.Create('Cabin'); h1.NextHouse := h2; Here we create a link from our home house to our cabin. We can follow the chain until a house has no reference, which means it's the last one. To visit all our houses, we could use the following code: var h1, h2: THouse; h: THouse; begin h1 := THouse.Create('Home'); h2 := THouse.Create('Cabin'); h1.NextHouse := h2; ... h := h1; while h nil do begin h.LockAllDoors; h.CloseAllWindows; h := h.NextHouse; end; Memory layout (added NextHouse as a link in the object, noted with the four LLLL's in the below diagram): h1 h2 v v ---[ttttNNNNNNNNNNLLLL]----[ttttNNNNNNNNNNLLLL] 1234Home + 5678Cabin + | ^ | +--------+ * (no link) In basic terms, what is a memory address? A memory address is in basic terms just a number. If you think of memory as a big array of bytes, the very first byte has the address 0, the next one the address 1 and so on upwards. This is simplified, but good enough. So this memory layout: h1 h2 v v ---[ttttNNNNNNNNNN]---[ttttNNNNNNNNNN] 1234My house 5678My house Might have these two address (the leftmost - is address 0): h1 = 4 h2 = 23 Which means that our linked list above might actuall look like this: h1 (=4) h2 (=28) v v ---[ttttNNNNNNNNNNLLLL]----[ttttNNNNNNNNNNLLLL] 1234Home 0028 5678Cabin 0000 | ^ | +--------+ * (no link) It is typical to store an address that \"points nowhere\" as a zero-address. In basic terms, what is a pointer? A pointer is just a variable holding a memory address. You can typically ask the programming language to give you its number, but most programming languages and runtimes tries to hide the fact that there is a number beneath, just because the number itself does not really hold any meaning to you. It is best to think of a pointer as a black box, ie. you don't really know or care about how it is actually implemented, just as long as it works. ","pontos":624},{"corpo":"I usually use svn through a gui, either my IDE or a client. Because of that, I can never remember the codes when I do have to resort to the command line. I find this cheat sheet a great help: Subversion Cheat Sheet ","pontos":11},{"corpo":"I was bored so i modified some stuff i wrote. It try's to encapsulate the parsing in an OO manner whle cutting down on the amount of iterations through the file, it only iterates once at the top foreach. using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.IO; namespace ConsoleApplication1 { class Program { static void Main(string[] args) { // usage: // note this wont run as getting streams is not Implemented // but will get you started CSVFileParser fileParser = new CSVFileParser(); // TO Do: configure fileparser PersonParser personParser = new PersonParser(fileParser); List Person persons = new List Person (); // if the file is large and there is a good way to limit // without having to reparse the whole file you can use a // linq query if you desire foreach (Person person in personParser.GetPersons()) { persons.Add(person); } // now we have a list of Person objects } } public abstract class CSVParser { protected String[] deliniators = { \",\" }; protected internal IEnumerable String[] GetRecords() { Stream stream = GetStream(); StreamReader reader = new StreamReader(stream); String[] aRecord; while (!reader.EndOfStream) { aRecord = reader.ReadLine().Split(deliniators, StringSplitOptions.None); yield return aRecord; } } protected abstract Stream GetStream(); } public class CSVFileParser : CSVParser { // to do: add logic to get a stream from a file protected override Stream GetStream() { throw new NotImplementedException(); } } public class CSVWebParser : CSVParser { // to do: add logic to get a stream from a web request protected override Stream GetStream() { throw new NotImplementedException(); } } public class Person { public String Name { get; set; } public String Address { get; set; } public DateTime DOB { get; set; } } public class PersonParser { public PersonParser(CSVParser parser) { this.Parser = parser; } public CSVParser Parser { get; set; } public IEnumerable Person GetPersons() { foreach (String[] record in this.Parser.GetRecords()) { yield return new Person() { Name = record[0], Address = record[1], DOB = DateTime.Parse(record[2]), }; } } } } ","pontos":4},{"corpo":"You could create a template in the template pane in Management Studio. And then use that template every time you want to create a new table. Failing that, you could store the CreatedOn and CreatedBy fields in an Audit trail table referencing the original table and id. Failing that, do it manually.","pontos":0},{"corpo":"I would definitely add Konqueror to that list. Also, you could have a look at your web page through Links (doesn't show up correctly in the editor, but search for it on Wikipedia)","pontos":0},{"corpo":"PostgreSQL has this feature. Just add this to the end of your table definition: The child table will have all the columns of its parent, and changes to the parent table will change the child. Also, everything in the child table will come up in queries to the parent table (by default). Unfortunately indices don't cross the parent/child border, which also means you can't make sure that certain columns are unique across both the parent and child. As far as I know, it's not a feature used very often.","pontos":2},{"corpo":"I'm leaning towards the \"Is Nothing\" alternative, primarily because it seems more OO. Surely Visual Basic ain't got the Ain't keyword.","pontos":4},{"corpo":"Why can't you simply install a subversion server? If you download VisualSVN Server, which is free, you get a http server for your source code and can thus use the FogBugz scripts for integrating the two. The reason I'm asking is because all scripts and documentation so far assumes you have the server, client-side scripts are too new for FogBugz to have templates for them so you're pretty much left to your own devices on that.","pontos":2},{"corpo":"I am not sure I follow you. Do you have the repositories on the network or on your C:\\ drive? According to two of your posts, you have both, or neither, or one of them or... You can not get VisualSVN or Apache to safely serve repositories from a network share. Since you originally said you had the repositories on your C:\\ drive, that's what you get advice for. If you have a different setup, you need to tell us about that. If you have the repositories on your local harddisk, I would install VisualSVN, or integrate it into Apache. VisualSVN can run fine alongside Apache so if you go that route you only have to install it. Your existing repositories can also just be copied into the repository root directory of VisualSVN and you're up and running. I am unsure why that big post here is labelled as incomplete, as it details the steps necessary to set up a hook script to inform FogBugz about the new revisions linked to the cases, which should be what the incomplete message says it doesn't do. Is that not working?","pontos":0},{"corpo":"If you take a look at the MSIL as it's being executed you'll see that it doesn't compile down to the exact same code. When you use IsNothing() it actually makes a call to that method as opposed to just evaluating the expression. The reason I would tend to lean towards using \"Is Nothing\" is when I'm negating it becomes \"IsNot Nothing' rather than \"Not IsNothing(object)\" which I personally feel looks more readable. ","pontos":71},{"corpo":"I worked on a project last summer that required some pretty heavy modifications to .NET Remoting. I don't remember all the specifics, but if we had more than one network interface, we couldn't get the out-of-the-box Remoting implementation to reliably detect which one the Remoting traffic came from, which did horrible things to performance. This sounds like a similar, if not the same, issue.","pontos":0},{"corpo":"I also tend to use the Is Nothing version partially from using it as much as I do in SQL. ","pontos":1},{"corpo":"I get downmodded for this? $sql = \"UPDATE skills SET level = level+1 WHERE id = $id\"; $result = $db- sql_query($sql); $db- sql_freeresult($result); In Teifion's specific case, the phpBB DDL lists that particular field as NOT NULL, so there's no danger of incrementing NULL. In the general case, you should not use NULL to represent zero. Incrementing NULL should give an answer of NULL. If you're the kind of misguided developer who thinks NULL=0, step away from keyboard and find another pastime, you're just making life hard for the rest of us. Of course, this is the computer industry and who are we to say you're wrong? If you're not wrong, use $sql = \"UPDATE skills SET level = COALESCE(level,0)+1 WHERE id = $id\"; ...but let's face it: you're wrong. If everyone starts at level 0, then your DDL should include level INT DEFAULT '0' NOT NULL in case the programmers forget to set it when they create a record. If not everyone starts on level 0, then skip the DEFAULT and force the programmer to supply a value on creation. If some people are beyond levels, for whom having a level is a meaningless thing, then adding one to their level equally has no meaning. In that case, drop the NOT NULL from the DDL. ","pontos":23},{"corpo":"Josh: I downmodded you because, as Mat said, you had the completely wrong answer. What's showing up now isn't what I saw.","pontos":-1},{"corpo":"Does the e-mail content need to be in the e-mail? Could you store the large content somewhere centrally (file-share/FTP site) then just send a link to the content? This makes the recipient have an extra step, but you have a consistent e-mail size, so won't run into reliability problems due to unexpectedly large or excessive content.","pontos":0},{"corpo":"Unfortunately, it seems SQL Server 2008 Client Tools requires Visual Studio 2008 SP1, and I'm loath to install a beta of this on my main development machine. I'll wait until SP1 is RTM before I move on. Edit: Yes, I do have Visual Studio 2008 on this machine, but I'd like to avoid beta installations of debugger applications. They tend to dig themselves too deep in for my taste.","pontos":0},{"corpo":"Sorry I couldn't be more help. I would definately keep looking at xdelta because I have used it a number of times to produce quality diffs on 600MB+ ISO files we have generated for distributing our products and it performs very well.","pontos":3},{"corpo":"FTP Drop for Yahoo Widgets allows you to drag files over the widget and the file will be sent to the defined ftp server.","pontos":1},{"corpo":"it tends to take an inexperienced team longer to build 3-tier.It's more code, so more bugs. I'm just playing the devil's advocate though.","pontos":2},{"corpo":"One possibility lies with Win32 ANSI/Unicode \"name-mangling\", which turns the symbol \"GetMessage\" into either \"GetMessageA\" or \"GetMessageW\". There are three possibilities: Windows.h hasn't been loaded, so GetMessage stays GetMessage Windows.h was loaded with symbols set for ANSI, so GetMessage becomes GetMessageA Windows.h was loaded with symbols set for Unicode, so GetMessage becomes GetMessageW If you've compiled two different files in ways that trigger two different scenarios, you'll get a linker error. The error message indicates that the Comms::Exception class was an instance of #2, above -- perhaps it's used somewhere that windows.h hasn't been loaded? Other things I'd do in your place, just as a matter of routine: 1) Ensure that my include and library paths don't contain anything that I'm not expecting. 2) Do a \"build clean\" and then manually verify it, deleting any extra object files if necessary. 3) Make sure there aren't any hardcoded paths in include statements that don't mean what they meant when the project was originally rebuilt. EDIT: Fighting with the formatting :(","pontos":2},{"corpo":"I tried removing domain-needed from my own configuration to replicate your issue and it did not produce this behavior. It's the only other parameter I could find that might be close to relevant. What does your hosts file look like? Maybe something weird is going on there that makes it think all weird domains are local to your network?","pontos":0},{"corpo":"I use Textmate (Mac only) which has Code folding and I find it really useful for folding functions, I know what my \"getGet\" function does, I don't need it taking up 10 lines of oh so valuable screen space. I never use it to hide a for loop, if statement or similar unless showing the code to someone else where I will hide code they have seen to avoid showing the same code twice.","pontos":3},{"corpo":" Should work","pontos":5},{"corpo":"This should return the text value of the selected value var vSkill = document.getElementById('newSkill'); var vSkillText = vSkill.options[vSkill.selectedIndex].innerHTML; alert(vSkillText); Props: @Tanerax for reading the question, knowing what was asked and answering it before others figured it out. Edit: DownModed, cause I actually read a question fully, and answered it, sad world it is.","pontos":3},{"corpo":"windows.h is declared at the top of IOCompletionPort.h as an include - I was sick of seeing 7 lines just to include 1 file so I have wrapped it its own file and includes that itself. This also contains some additional #defines (ie ULONG_PTR) as our main app won't compile with the Platform SDK installed:-( That is confirmed. Nothing is out of place. I've done that - deleted the build directories I never use hard-coded paths. ","pontos":0},{"corpo":"Presuming you haven't futzed around with the Project settings deleting something you ought not have (which is where I'd expect external dependencies like User32.lib to be): Check Tools | Options | Directories | Libraries (going from memory here) and ensure that you're not missing the common-all-garden variety lib directories (again, without VC6 in front of me, I can't tell you what they are)","pontos":0},{"corpo":"While I understand the problem that Jeff, et. al. have with regions, what I don't understand is why hitting CTRL+M,CTRL+L to expand all regions in a file is so difficult to deal with. ","pontos":5},{"corpo":"I prefer #regions myself, but an old coworker couldn't stand to have things hidden. I understood his point once I worked on a page with 7 #regions, at least 3 of which had been auto-generated and had the same name, but in general I think they're a useful way of splitting things up and keeping everything less cluttered.","pontos":0},{"corpo":"I work with a student management system which uses UUID's in the form of an integer. They have a table which hold the next unique ID. Although this is probably a good idea for an architectural point of view, it makes working with on a daily basis difficult. Sometimes there is a need to do bulk inserts and having a UUID makes this very difficult, usually requiring writing a cursor instead of a simple SELECT INTO statement.","pontos":0},{"corpo":"I prefer partial classes as opposed to regions. Extensive use of regions by others also give me the impression that someone, somewhere, is violating the Single Responsibility Principle and is trying to do too many things with one object.","pontos":3},{"corpo":"I'm not a fan of partial classes - I try to develop my classes such that each class has a very clear, single issue for which it's responsible. To that end, I don't believe that something with a clear responsibility should be split across multiple files. That's why I don't like partial classes. With that said, I'm on the fence about regions. For the most part, I don't use them; however, I work with code every day that includes regions - some people go really heavy on them (folding up private methods into a region and then each method folded into its own region), and some people go light on them (folding up enums, folding up attributes, etc). My general rule of thumb, as of now, is that I only put code in regions if (a) the data is likely to remain static or will not be touched very often (like enums), or (b) if there are methods that are implemented out of necessity because of subclassing or abstract method implementation, but, again, won't be touched very often.","pontos":2},{"corpo":" This work fine except, if I don't make any changes to that file, it doesn't get committed. If the file never changes, why would you need it to commmit every single time? [EDIT] @Sean = I understand what he's trying to do, but if the file is never getting updated via a hook or some other process and therefore never changing then SVN will never pick it up.","pontos":3},{"corpo":"@gradonmantank: Because he wants that file to be updated with the latest revision number. Did you read his question completely? The pre-commit hook might work.","pontos":1},{"corpo":"I used to have a manual way of doing that. I'd run a script that would use sed to replace a comment with the current timestamp in my $Rev$ file. That way, the file contents would change and Subversion would commit it. What I didn't do was to take that to the next step: using Subversion's repository hooks to automate the process. Trouble is, I'm not sure if you're allowed to change file contents in hooks. The documentation seems to suggest that you can't. Instead, I guess you'd need a little script that you'd execute in place of the command that first updates the timestamp and then runs the normal commit.","pontos":1},{"corpo":"I have reproduced what you are seeing: Outputs this: What am I doing wrong here? Is os.stat().st_size not returning the correct size? Edit: OK, I figured out what the problem was: this outputs: Make sure you are opening both files for binary read/write. ","pontos":15},{"corpo":"I use #Region to hide ugly and useless automatically generated code, which really belongs in the automatically generated part of the partial class. But, when working with old projects or upgraded projects, you don't always have that luxury. As for other types of folding, I fold Functions all the time. If you name the function well, you will never have to look inside unless you're testing something or (re-)writing it.","pontos":5},{"corpo":"The reason for not implementing Getters and Setters for components on a form I believe is cause they wouldn't be \"Thread Safe\" .Net objects are suppose to be only modified by the form thread that created them, If you put on getter and setters you are potentially opening it up for any thread. Instead your suppose to implement a delegate system where changes to these objects are delegated to the thread that created them and ran there.","pontos":1},{"corpo":"Don't version that file. Version a template or something.","pontos":16},{"corpo":"You can use svn pre-commit-hooks to do it. The general idea I have in mind is create one that before the commit will put the new revision number in the file (get it using svnlook) or maybe change a bogus property on the file (it has to change or SVN will ignore it). For more information about pre-commit-hooks I found this page useful.","pontos":1},{"corpo":"\"However, the VS designer doesn't seem to implement such Getters/Setters for those public objects that are components on a form (and therefore does not comply with good programming practice).\" If you mean the controls you're dragging and dropping onto the form, these are marked as private instance members and are added to the form's Controls collection. Why would they be otherwise? A form could have forty or fifty controls, it'd be somewhat unnecessary and unwieldy to provide a getter/setter for every control on the form. The designer leaves it up to you to provide delegated access to specific controls via public getter/setters. The designer does the right thing here.","pontos":3},{"corpo":"The checked-in, plain-vanilla version of app/web.config should be generic enough to work on all developer machines, and be kept up to date with any new setting changes, etc. If you require a specific set of settings for dev/test/production settings, check in separate files with those settings, as GateKiller stated, with some sort of naming convention, though I usually go with \"web.prod.config\", as not to change the file extension.","pontos":2},{"corpo":"I am looking for many answers to learn about new tools and consolidate this knowledge in a one question/thread, so I doubt there will be 1 true answer to this question. My answer to my own question is that we use: Findbugs to look for common errors bad/coding - run from maven, and also integrates easily into Eclipse Cobertura for our coverage reports - run from maven Hudson also has a task-scanner plugin that will display a count of your TODO and FIXMEs, as well as show where they are in the source files. All are integrated with Maven 1.x in our case and tied into Hudson, which runs our builds on check-in as well as extra things nightly and weekly. Hudson trend graphs our JUnit tests, coverage, findbugs, as well as open tasks. There is also a Hudson plugin that reports and graphs our compile warnings. We also have several performance tests with their own graphs of performance and memory use over time using the Hudson plots plugin as well.","pontos":0},{"corpo":"We have a SProc that adds audit columns to a given table, and (optionally) creates a history table and associated triggers to track changes to a value. Unfortunately, company policy means I can't share, but it really isn't difficult to achieve. ","pontos":0},{"corpo":"I don't think a GUID gives you many benefits. Users hate long, incomprehensible URLs. Create a shorter ID that you can map to the URL, or enforce a unique user name convention (http://example.com/user/brianly). The guys at 37Signals would probably mock you for worrying about something like this when it comes to a web app. Incidentally you can force your database to start creating integer IDs from a base value.","pontos":1},{"corpo":"For what it's worth, I've seen a long running stored procedure (9+ seconds) drop to just a few hundred milliseconds of run time simply by switching from GUID primary keys to integers. That's not to say displaying a GUID is a bad idea, but as others have pointed out, joining on them, and indexing them, by definition, is not going to be anywhere near as fast as with integers.","pontos":19},{"corpo":"I personally would say Email w/ Verification, OpenId is a great idea but I find that finding a provider that your already with is a pain, I only had an openId for here cause just 2 days before beta i decided to start a blog on blogspot. But everyone on the internet has en email address, especially when dealing with businesses, people aren't very opt to using there personal blog or whatnot for a business login.","pontos":1},{"corpo":"I might be wrong and this might not make a difference but have you tried: instead of ","pontos":0},{"corpo":"The others have pointed out that Subversion and its kin have no trouble dealing with binary files (although not nearly as space-efficiently as text). The database backup requirement is more interesting though, and one that I've come up against more than once. Ideally, I would want a text representation of the diff between two versions of a database (schema and data). Applying such a diff would take you from one version to the next. The source control engine could just store that with each commit. Rails migrations is a nifty way of handling schema diffs, but I haven't seen anything that can handle full schema and data diffs in a simple text format. Failing that, I suppose you could check in a text database dump like the type the command for MySQL generates. The source control tool's diff algorithm probably won't handle it efficiently, but it's likely to require less space than checking in an opaque binary database file.","pontos":2},{"corpo":"Please update the question, do you have a list of CompanyNames available to you? I ask because you maybe able to use Levenshtein algo to find a relationship between your list of CompanyNames and LocationNames. Update There is not a list of Company Names, I will have to generate the company name from the most descriptive or best Location Name that represents the multiple locations. Okay... try this: Build a list of candidate CompanyNames by finding LocationNames made up of mostly or all alphabetic characters. You can use regular expressions for this. Store this list in a separate table. Sort that list alphabetically and (manually) determine which entries should be CompanyNames. Compare each CompanyName to each LocationName and come up with a match score (use Levenshtein or some other string matching algo). Store the result in a separate table. Set a threshold score such that any MatchScore Threshold will not be considered a match for a given CompanyName. Manually vet through the LocationNames by CompanyName | LocationName | MatchScore, and figure out which ones actually match. Ordering by MatchScore should make the process less painful. The whole purpose of the above actions is to automate parts and limit the scope of your problem. It's far from perfect, but will hopefully save you the trouble of going through 18K records by hand.","pontos":0},{"corpo":"I was going to recommend some complicated token matching algorithm but it's really tricky to get right and if you're data does not have a lot of correlation (typos, etc) then it's not going to give very good results. I would recommend you submit a job to the Amazon Mechanical Turk and let a human sort it out.","pontos":0},{"corpo":"First, I'd remove all the parts, that would make it 50% shorter ;) When I have big condition I search for the reasons. Sometimes I see I should use polymorphism, sometimes I need to add some state object. Basically, it implies a refactoring is needed (a code smell). Sometimes I use De-Morgan's laws to simplify boolean expressions a bit. ","pontos":3},{"corpo":"For most needs on the desktop you wont need to know the Win32, however there is a LOT of Win32 not in .NET, but it is in the outlaying stuff that may end up being less than 1% of your application. USB support, HID support, Windows Media Foundation just off the top of my head. There are many cool Vista API's only available from Win32. You will do yourself a large favor by learning how to do interop with a Win32 API, if you do desktop programing, because when you do need to call Win32, and you will, you won't spend weeks scratching your head.","pontos":3},{"corpo":"Well, first off, why not: if (var1 var2 var2 var3 var4 var5 var6) { ... Also, it's very hard to refactor abstract code examples. If you showed a specific example it would be easier to identify a better pattern to fit the problem. It's no better, but what I've done in the past: (The following method prevents short-circuiting boolean testing, all tests are run even if the first is false. Not a recommended pattern unless you know you need to always execute all the code before returning -- Thanks to ptomato for spotting my mistake!) boolean ok = cond1; ok = cond2; ok = cond3; ok = cond4; ok = cond5; ok = cond6; Which is the same as: (not the same, see above note!) ok = (cond1 cond2 cond3 cond4 cond5 cond6); ","pontos":2},{"corpo":"The file in the .svn directory that keeps track of what you have checked out, when, what revision, and from where, has gotten corrupted somehow, for that particular file. This is no more dangerous or critical than the normal odd file problem, and can be because of various problems, like a subversion program dying mid-change, power-disruption, etc. Unless it happens more I wouldn't make much out of it. It can be fixed by doing what you did, make a copy of your work-files, check out a fresh copy, and add the modified files back in. Note that this might cause problems if you have a busy project where you would normally have to merge in changes. For instance, you and a collegue both check out a fresh copy, and start working on the same file. At some point, your collegue checks in his modifications. When you attempt to do the same, you get the checksum problem you have. If you now make copies of your changed files, do a fresh checkout, then subversion will lose track of how your changes should be merged back in. If you didn't get the problem in this case, when you got around to checkin in your modifications, you would need to update your working copy first, and possibly handle a conflict with your file. However, if you do a fresh checkout, complete with your collegues changes, it now looks like you removed his changes and substituted with your own. No conflicts, and no indications from subversion that something is amiss.","pontos":33},{"corpo":"Found an answer that works for me: warning: this will find and kill long running processes ps -eo uid,pid,etime | egrep '^ *user-id' | egrep ' ([0-9]+-)?([0-9]{2}:?){3}' | awk '{print $2}' | xargs -I{} kill {} (Where user-id is a specific user's ID with long-running processes.) The second regular expression matches the a time that has an optional days figure, followed by an hour, minute, and second component, and so is at least one hour in length. ","pontos":35},{"corpo":"I'm surprised no one got this one yet. There's a refactoring specifically for this type of problem: http://www.refactoring.com/catalog/decomposeConditional.html ","pontos":11},{"corpo":"I hate to say this but as soon as you put something on a client machine, security for that data goes out the window. If your program is going to decrypt that string, you need to assume that an attacker can do the same. Attaching a debugger to your program would be one way. Storing the connection string on a server, and obtaining it through a web connection sounds good, until you realize that you need security on that web connection as well, otherwise an attacker could just as well impersonate your program and talk to the web connection. Let me ask a question. Who are you hiding the connection string from? The user or an attacker? And if the user, why?","pontos":1},{"corpo":"The most common one I think is to allow people to change revision comments after comitting. You need to enable the 'pre-revprop-change' hook script to allow that. The example provided, if enabled allows editing only the comment property and only be the original comitter. Great for correcting typos.","pontos":0},{"corpo":"Call me crazy, but why not put plus and minus buttons at either side of the TextBox control and simply prevent the TextBox from receiving cursor focus, thereby creating your own cheap NumericUpDown control?","pontos":0},{"corpo":"There are some other idea's also. You can always use impersonation. Also, you can use the Enterprise Library's (Common Library). ","pontos":0},{"corpo":"URL's? As in images/scripts/css/etc.? ","pontos":0},{"corpo":"I don't have time to try and think of a regex that probably won't work, but I wanted to comment that you should most definitely break up your regex, at least if it gets to this level of ugliness: (?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^() @,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t] )+|\\Z|(?=[\\[\"() @,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?: \\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^() @,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:( ?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"() @,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^() @,;:\\\\\".\\[\\] \\000-\\0 ....*SNIP*.... *))*@(?:(?:\\r\\n)?[ \\t])*(?:[^() @,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t]) +|\\Z|(?=[\\[\"() @,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\ .(?:(?:\\r\\n)?[ \\t])*(?:[^() @,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z |(?=[\\[\"() @,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\ (?:( ?:\\r\\n)?[ \\t])*))*)?;\\s*) (this supposedly matches email addresses) Edit: I can't even fit it on one post it's so nasty....","pontos":1},{"corpo":"This question used to be in the official FAQ What are some limits in memcached I might hit? (Wayback Machine) To quote: The simple limits you will probably see with memcache are the key and item size limits. Keys are restricted to 250 characters. Stored data cannot exceed 1 megabyte in size, since that is the largest typical slab size.\" The FAQ has now been revised and there are now two separate questions covering this: What is the maxiumum key length? (250 bytes) The maximum size of a key is 250 characters. Note this value will be less if you are using client \"prefixes\" or similar features, since the prefix is tacked onto the front of the original key. Shorter keys are generally better since they save memory and use less bandwidth. Why are items limited to 1 megabyte in size? Ahh, this is a popular question! Short answer: Because of how the memory allocator's algorithm works. Long answer: Memcached's memory storage engine (which will be pluggable/adjusted in the future...), uses a slabs approach to memory management. Memory is broken up into slabs chunks of varying sizes, starting at a minimum number and ascending by a factorial up to the largest possible value. Say the minimum value is 400 bytes, and the maximum value is 1 megabyte, and the factorial is 1.20: slab 1 - 400 bytes slab 2 - 480 bytes slab 3 - 576 bytes ... etc. The larger the slab, the more of a gap there is between it and the previous slab. So the larger the maximum value the less efficient the memory storage is. Memcached also has to pre-allocate some memory for every slab that exists, so setting a smaller factorial with a larger max value will require even more overhead. There're other reason why you wouldn't want to do that... If we're talking about a web page and you're attempting to store/load values that large, you're probably doing something wrong. At that size it'll take a noticeable amount of time to load and unpack the data structure into memory, and your site will likely not perform very well. If you really do want to store items larger than 1MB, you can recompile memcached with an edited value, or use the inefficient malloc/free backend. Other suggestions include a database, MogileFS, etc. ","pontos":4},{"corpo":"You want to be able to distribute the DLL with all of the setup information being in a configurable place, but the fact is you can't have one of the handy-dandy .NET config files for a DLL unless you do something custom. Maybe you need to rethink what responsibility your DLL should have. Would it be possible, or make sense to require that the connection string be passed in by the user of your library? Does it really make sense that your DLL reads a config file?","pontos":0},{"corpo":"In many simple cases, you can use the MethodInvoker delegate and avoid the need to create your own delegate type.","pontos":0},{"corpo":"Ok, so my final solution is this: Use the export command to export to a folder called \"export\" in the same directory as a file called \"deploy.bat\", then I run the deploy script (v1 stands for version 1, which is what version I am currently on in this project) This script utilizes 7-Zip, which I have placed on my system path so I can use it as a command line utility: I didn't have time to check out the SyncToy solution, so don't take this as me rejecting that method. I just knew how to do this, and didn't have time to check that one out (under a time crunch right now). Sources: http://commandwindows.com/command2.htm http://www.ss64.com/nt/","pontos":1},{"corpo":"To simplify Simon's code a bit, you could use the built in generic Action delegate. It saves peppering your code with a bunch of delegate types you don't really need. Also, in .NET 3.5 they added a params parameter to the Invoke method so you don't have to define a temporary array. void SomethingHappened(object sender, EventArgs ea) { if (InvokeRequired) { Invoke(new Action object, EventArgs (SomethingHappened), sender, ea); return; } textBox1.Text = \"Something happened\"; } ","pontos":26},{"corpo":"Rather than URLs like this: Why not have: Which is friendlier to humans and doesn't leak that tiny bit of information?","pontos":0},{"corpo":"May I suggest the jQuery Media Plugin? Provides embed code for all kinds of video, not just WMV and does browser detection, keeping all that messy switch/case statements out of your templates.","pontos":18},{"corpo":"I've used the following database project structure in Visual Studio for several projects and it's worked pretty well: Database Change Scripts 0.PreDeploy.sql 1.SchemaChanges.sql 2.DataChanges.sql 3.Permissions.sql Create Scripts Sprocs Functions Views Our build system then updates the database from one version to the next by executing the scripts in the following order: 1.PreDeploy.sql 2.SchemaChanges.sql Contents of Create Scripts folder 2.DataChanges.sql 3.Permissions.sql Each developer checks in their changes for a particular bug/feature by appending their code onto the end of each file. Once a major version is complete and branched in source control, the contents of the .sql files in the Change Scripts folder are deleted.","pontos":3},{"corpo":"I would first suggesting getting you html and css code validated. If there are any errors in your markup, these can cause errors in the rendering. CSS Validator HTML Validator ","pontos":6},{"corpo":"I've also run into differences between FF3 on WinXP and FF3 on OS X (mostly with CSS positioning). The CSS and HTML both validated properly, but I was never able to figure out why there was this difference. I would think that the rendering engine would be the same, but apparently there are at least a few subtle differences.","pontos":1},{"corpo":"In my work place we've set up a post-commit hook that generates RSS feeds that are displayed in various dash boards and are used for code reviewers to know when it is time to review and for us to see that new employees are committing enough.","pontos":3},{"corpo":"I would be wary of the impression of randomness: there have been many experiments where people would choose the less random distribution. It seems the mind is not very good at producing or estimating randomness. There are good articles on randomness at Fourmilab, including another true random generator. Maybe you could get random data from both sites so if one is down you still have the other. Fourmilab also provides a test program to check randomness. You could use it to check your various myRand() programs. As for your last program, if you generate 10000 values, why don't you choose the final value amongst the 10 thousand? You restrict yourself to a subset. Also, it won't work if your $min and $max are greater than 10000. Anyway, the randomness you need depends on your application. rand() will be OK for an online game, but not OK for cryptography (anything not thoroughly tested with statistical programs will not be suitable for cryptography anyway). You be the judge!","pontos":3},{"corpo":"Not sure. Maybe: %span{:class = item.dashboardstatus.cssclass }= item.dashboardstatus.status ","pontos":15},{"corpo":"The second example will execute the function after creating it. edit: this isn't really true.","pontos":0},{"corpo":"@Lance: the first one is also executing. Compare it with a named constructor: this is actually also executing code. The same goes for the anonymous constructor... But that was not the question ;-)","pontos":2},{"corpo":"First off, sorry I'm late to the party. This is my first stackoverflow answer. :) As has been pointed out, when realloc() is called, you can potentially change the pointer to the memory being reallocated. When this happens, the argument \"string\" becomes invalid. Even if you reassign it, the change goes out of scope once the function ends. To answer the OP, realloc() returns a pointer to the newly-reallocated memory. The return value needs to be stored somewhere. Generally, you would do this: As TyBoer points out, you guys can't change the value of the pointer being passed in as the input to this function. You can assign whatever you want, but the change will go out of scope at the end of the function. In the following block, \"input\" may or may not be an invalid pointer once the function completes: Mark tries to work around this by returning the new pointer as the output of the function. If you do that, the onus is on the caller to never again use the pointer he used for input. If it matches the return value, then you have two pointers to the same spot and only need to call free() on one of them. If they don't match, the input pointer now points to memory that may or may not be owned by the process. Dereferencing it could cause a segmentation fault. You could use a double pointer for the input, like this: If the caller has a duplicate of the input pointer somewhere, that duplicate still might be invalid now. I think the cleanest solution here is to avoid using realloc() when trying to modify the function caller's input. Just malloc() a new buffer, return that, and let the caller decide whether or not to free the old text. This has the added benefit of letting the caller keep the original string!","pontos":8},{"corpo":"break would stop the foreach loop completely, continue would skip to the next DataRow","pontos":12},{"corpo":" will exit the loop completely, will just skip the current iteration. For example: for(int i = 0; i 10; i++){ if(i == 0) break; DoSomeThingWith(i); } The break will cause the loop to exit on the first iteration - will never be executed. This here: for(int i = 0; i 10; i++){ if(i == 0) continue; DoSomeThingWith(i); } Will not execute for , but the loop will continue and will be executed for to . ","pontos":689},{"corpo":"Both cases will execute the function, the only real difference is what the return value of the expression may be, and what the value of \"this\" will be inside the function. Basically behaviour of Is effectively equivalent to Although of course tempObject and result are transient values you can never see (they're implementation details in the interpreter), and there is no JS mechanism to do the \"is not an object\" check. Broadly speaking the \"new function() { .. }\" method will be slower due to the need to create the this object for the constructor. That said this should be not be a real difference as object allocation is not slow, and you shouldn't be using such code in hot code (due to the cost of creating the function object and associated closure). Edit: one thing i realised that i missed from this is that the will get s prototype, eg. (before the ) ","pontos":5},{"corpo":"There are more than a few people who don't like and . The latest complaint I saw about them was in JavaScript: The Good Parts by Douglas Crockford. But I find that sometimes using one of them really simplifies things, especially if your language doesn't include a or style of loop. I tend to use in loops that are searching a list for something. Once found, there's no point in continuing, so you might as well quit. I use when doing something with most elements of a list, but still want to skip over a few. The statement also comes in handy when polling for a valid response from somebody or something. Instead of: You could eliminate some duplication and use: The loop that I mentioned before is the more elegant solution for that particular problem: No duplication, and no needed either.","pontos":11},{"corpo":"Why not grab one of the AJAX scripting libraries, they abstract away a lot of the cross browser DOM scripting black magic and make life a hell of a lot easier.","pontos":1},{"corpo":"It's a \"quirk\" in the way the JVM looks up the zoneinfo file. See Bug ID 6456628. The easiest workaround is to make /etc/localtime a symlink to the correct zoneinfo file. For Pacific time, the following commands should work: I haven't had any problems with the symlink approach. Edit: Added \"sudo\" to the commands.","pontos":13},{"corpo":"The result of a DCT is a transformation of the original source into the frequency domain. The top left entry stores the \"amplitude\" the \"base\" frequency and frequency increases both along the horizontal and vertical axes. The outcome of the DCT is usually a collection of amplitudes at the more usual lower frequencies (the top left quadrant) and less entries at the higher frequencies. As lassevk mentioned, it is usual to just zero out these higher frequencies as they typically constitute very minor parts of the source. However, this does result in loss of information. To complete the compression it is usual to use a lossless compression over the DCT'd source. This is where the compression comes in as all those runs of zeros get packed down to almost nothing. One possible advantage of using the DCT to find similar regions is that you can do a first pass match on low frequency values (top-left corner). This reduces the number of values you need to match against. If you find matches of low frequency values, you can increase into comparing the higher frequencies. Hope this helps","pontos":14},{"corpo":"I occasionally get similar things, usually with files that nobody has been near in weeks. Generally, if you know you haven't been working in the directory in question, you can just delete the directory with the problem and run to recreate it. If you have live changes in the directory then as lassevk and you yourself suggested, a more careful approach is required. Generally speaking I would say it's a good idea not to leave edited files uncommitted, and keep the working copy tidy - don't add a whole bunch of extra files into the working copy that you aren't going to use. Commit regularly, and then if the working copy goes tits up, you can just delete the whole thing and start over without worrying about what you might or might not be losing, and without the pain of trying to figure out what files to save. ","pontos":6},{"corpo":"App_Data folder on the root of the project. It isn't served to web requests; so other people can't snoop for it.","pontos":5},{"corpo":"They both create a closure by executing the code block. As a matter of style I much prefer the second for a couple of reasons: It's not immediately obvious by glancing at the first that the code will actually be executed; the line looks like it is creating a new function, rather than executing it as a constructor, but that's not what's actually happening. Avoid code that doesn't do what it looks like it's doing! Also the ... make nice bookend tokens so that you can immediately see that you're entering and leaving a closure scope. This is good because it alerts the programmer reading it to the scope change, and is especially useful if you're doing some postprocessing of the file, eg for minification.","pontos":1},{"corpo":"Is there a way to implement a sealed class from an interface... and mock the interface instead? Something in me feels that having sealed classes is wrong in the first place, but that's just me :)","pontos":0},{"corpo":"They each break when dropped from the same height, or are they different? If they're the same, I go to the 50th floor and drop the first marble. If it doesn't break, I go to the 75th floor and do the same, as long as it keeps not breaking I keep going up by 50% of what's left. When it does break, I go back to one higher than where I was previously (so if it broke at the 75th floor I go back to the 51st floor) and drop the second marble and move up a floor at a time until it breaks, at which point I know the highest floor I can drop from with no marble breakage. Probably not the best answer, I'm curious to see how others answer.","pontos":1},{"corpo":"Ruby unfortunately is a bit different. PS: My memory is a bit hazy on this so apologies if I'm wrong instead of break/continue, it has break/next, which behave the same in terms of loops Loops (like everything else) are expressions, and \"return\" the last thing that they did. Most of the time, getting the return value from a loop is pointless, so everyone just does this You can however do this HOWEVER, a lot of ruby code 'emulates' a loop by using a block. The canonical example is As it is much more common for people to want to do things with the result of a block, this is where it gets messy. break/next mean different things in the context of a block. break will jump out of the code that called the block next will skip the rest of the code in the block, and 'return' what you specify to the caller of the block. This doesn't make any sense without examples. So yeah. Ruby is awesome, but it has some awful corner-cases. This is the second worst one I've seen in my years of using it :-)","pontos":3},{"corpo":"I'm personally not very big a fan of such puzzle questions, I prefer actual programming exercises in interviews. That said, first it would depend on if I can tell if they are broken or not from the floor I am dropping them at. I will presume I can. I would go up to the second floor, drop the first marble. If it broke I would try the first floor. If that broke I would know it was no floor. If the first didn't break, I would go to the 4th floor and drop from there. If that broke, I would go back down and get the other marble, then drop at the 3rd floor, breaking or not I would know which is the limit. If neither broke, I would go get both, and do the same process, this time starting at the 6th floor. This way, I can skip every other floor until I get a marble that breaks. This would be optimized for if the marble breaks early... I suppose there is probably an optimal amount of floors I could skip to get the most for each skip... but then if one breaks, I would have to check each floor individually from the first floor above the last known floor... which of course would be a pain if I skipped too many floors (sorry, not going to figure out the optimal solution right now). Ideally, I would want a whole bag of marbles, then I could use a binary search algorithm and divide the number of floors in half with each drop... but then, that wasn't the question, was it?","pontos":1},{"corpo":"The interesting thing here is how you can do it in the least amount of drops possible. Going to the 50th floor and dropping the first would be disastrous if the breaking floor is the 49th, resulting in us having to do 50 drops. We should drop the first marble at floor n, where n is the max amount of drops required. If the marble breaks at floor n, we may have to make n-1 drops after that. If the marble doesn't break we go up to floor 2n-1 and if it breaks here we have to drop the second marble n-2 times in the worst case. We continue like this up to the 100th floor and try to break it at 3n-2, 4n-3.... and n+(n-1)+(n-2)+...1 =100 n=14 Is the maximum drops required","pontos":42},{"corpo":"This has a lot to do with covariance, e.g., generic types are considered as parameters, and if the parameters do not resolve properly to a more specific type then the operation fails. The implication of such is that you really cannot cast to a more general type like object. And as stated by Rex, the List object won't convert each object for you. You might want to try the ff code instead: or: ol will (theoretically) copy all the contents of sl without problems.","pontos":6},{"corpo":" FLOSS Weekly Pragmatic Podcasts Rails Envy Webdev Radio ","pontos":7},{"corpo":"Joshua (#6591) - The Garbage collection stuff in Mac OS X 10.5 seems pretty cool, but isn't available for the iPhone (or if you want your app to run on pre-10.5 versions of Mac OS X). Also, if you're writing a library or something that might be reused, using the GC mode locks anyone using the code into also using the GC mode, so as I understand it, anyone trying to write widely reusable code tends to go for managing memory manually.","pontos":5},{"corpo":"What you want to do is to specify the sha1 of the commit you want to restore to. You can get the sha1 by examining the reflog () and then doing But don't wait too long... after a few weeks git will eventually see that commit as unreferenced and delete all the blobs.","pontos":175},{"corpo":"The short answer Use one of these two methods: For example: InputStream inputStream = YourClass.class.getResourceAsStream(\"image.jpg\"); -- The long answer Typically, one would not want to load files using absolute paths. For example, dont do this if you can help it: File file = new File(\"C:\\\\Users\\\\Joe\\\\image.jpg\"); This technique is not recommended for at least two reasons. First, it creates a dependency on a particular operating system, which prevents the application from easily moving to another operating system. One of Javas main benefits is the ability to run the same bytecode on many different platforms. Using an absolute path like this makes the code much less portable. Second, depending on the relative location of the file, this technique might create an external dependency and limit the applications mobility. If the file exists outside the applications current directory, this creates an external dependency and one would have to be aware of the dependency in order to move the application to another machine (error prone). Instead, use the methods in the class. This makes the application much more portable. It can be moved to different platforms, machines, or directories and still function correctly. ","pontos":41},{"corpo":"Well, the file is in the root so it does not show whether the tag works or if the browser just got the icon from the usual location (the root). Edit: I'll try it and see if it works. Edit 2: Using both tags make it work even for any file name as long as the file is an icon for IE7: I tried using files and it only worked with Firefox.","pontos":0},{"corpo":"Response to the Update: Oh, you're right, I guess PHP must convert array index strings to numbers if they contain only digits. I tried this code: $array = array('1' = 100, '2' = 200, 1 = 300, 2 = 400); print_r($array); And the output was: Array([1] = 300 [2] = 400) I've done some more tests and found that if an array index (or key) is made up of only digits, it's always converted to an integer, otherwise it's a string. ejunker: Can you explain why that's faster? Doesn't it take the interpreter an extra step to parse \"$index\" into the string to use as an index instead of just using $index as the index? ","pontos":1},{"corpo":"I've used both, but I have to agree with Justin Standard that you shouldn't really consider rewriting your existing tests to any new format. Regardless of the decision, it is pretty trivial to run both. TestNG strives to be much more configurable than JUnit, but in the end they both work equally well. TestNG has a neat feature where you can mark tests as a particular group, and then easily run all tests of a specific group, or exclude tests of a particular group. Thus you can mark tests that run slowly as in the \"slow\" group and then ignore them when you want quick results. A suggestion from their documentation is to mark some subset as \"checkin\" tests which should be run whenever you check new files in. I never saw such a feature in JUnit, but then again, if you don't have it, you don't REALLY miss it. For all its claims of high configuration, I did run into a corner case the a couple weeks ago where I couldn't do what I wanted to do... I wish I could remember what it is, but I wanted to bring it up so you know that it's not perfect. The biggest advantage TestNG has is annotations... which JUnit added in version 4 anyways.","pontos":41},{"corpo":" I believe from a performance perspective that $array[\"$index\"] is faster than $array[$index] See Best practices to optimize PHP code performance Don't believe everything you read so blindly... I think you misinterpreted that. The article says $array['index'] is faster than $array[index] where index is a string, not a variable. That's because if you don't wrap it in quotes PHP looks for a constant var and can't find one so assumes you meant to make it a string.","pontos":6},{"corpo":"This Javascript Cheat Sheet has a complete list of of event handlers. Nearly all of them can be used on any html element except for one or two. If you want to use a lightweight javascript library, DOMAssistant is very lightweight and allows you to add events to elements very easily. Like so: ","pontos":2},{"corpo":"If you set error reporting to E_ALL, it warns in the error log about undefined variables complete with filename and line number (assuming you are logging to a file). However, it will warn only if when it comes across an undefined variable, so I think you will have to test each code path. Running php from the command line doesn't seem to help also. There is a debugging tool named xdebug, haven't tried it, but maybe that can be useful?","pontos":4},{"corpo":"About a year ago, we had the same problem. I spent sometime considering which move was better, and eventually we realized that TestNG has no 'killer features'. It's nice, and has some features JUnit 4 doesn't have, but we don't need them. We didn't want people to feel uncomfortable writing tests while getting to know TestNG because we wanted them to keep writing a lot of tests. Also, JUnit is pretty much the de-facto standard in the Java world. There's no decent tool that doesn't support it from the box, you can find a lot of help on the web and they added a lot of new features in the past year which shows it's alive. We decided to stick with JUnit and never looked back. ","pontos":15},{"corpo":"Your code not really compliant with full CSV format. If you are just generating CSV from data that has no commas, leading/trailing spaces, tabs, newlines or quotes, it should be fine. However, in most real-world data-exchange scenarios, you do need the full imlementation. For generation to proper CSV, you can use this: Might not be world's most efficient code, but it has been tested. Real world sucks compared to quick sample code :)","pontos":7},{"corpo":"I know you asked for Java, but this strikes me as a task well suited to a scripting language. Here is a quick (very simple) solution written in Groovy. test.csv string,float1,float2,integer hello world,1.0,3.3,4 goodbye world,1e9,-3.3,45 hello again,-1,23.33,456 hello world 3,1.40,34.83,4999 hello 2 world,9981.05,43.33,444 csvtoxml.groovy #!/usr/bin/env groovy def csvdata = [] new File(\"test.csv\").eachLine { line - csvdata line.split(',') } def headers = csvdata[0] def dataRows = csvdata[1..-1] def xml = new groovy.xml.MarkupBuilder() // write 'root' element xml.root { dataRows.eachWithIndex { dataRow, index - // write 'entry' element with 'id' attribute entry(id:index+1) { headers.eachWithIndex { heading, i - // write each heading with associated content \"${heading}\"(dataRow[i]) } } } } Writes the following XML to stdout: root entry id='1' string hello world /string float1 1.0 /float1 float2 3.3 /float2 integer 4 /integer /entry entry id='2' string goodbye world /string float1 1e9 /float1 float2 -3.3 /float2 integer 45 /integer /entry entry id='3' string hello again /string float1 -1 /float1 float2 23.33 /float2 integer 456 /integer /entry entry id='4' string hello world 3 /string float1 1.40 /float1 float2 34.83 /float2 integer 4999 /integer /entry entry id='5' string hello 2 world /string float1 9981.05 /float1 float2 43.33 /float2 integer 444 /integer /entry /root However, the code does very simple parsing (not taking into account quoted or escaped commas) and it does not account for possible absent data. ","pontos":18},{"corpo":"In general, there's no need to null objects after use, but in some cases I find it's a good practice. If an object implements IDisposable and is stored in a field, I think it's good to null it, just to avoid using the disposed object. The bugs of the following sort can be painful: It's good to null the field after disposing it, and get a NullPtrEx right at the line where the field is used again. Otherwise, you might run into some cryptic bug down the line (depending on exactly what DoSomething does). ","pontos":5},{"corpo":"I am sold to OOP. Anytime you can define a concept for a problem, it can probably be wrapped in an object. The problem with OOP is that some people overused it and made their code even more difficult to understand. If you are careful about what you put in objects and what you put in services (static classes) you will benefit from using objects. Just don't put something that doesn't belong to an object in the object because you need your object to do something new that you didn't think of initially, refactor and find the best way to add that functionality.","pontos":4},{"corpo":"For the record, .Net Framework 3.5 SP1 is required for Microsoft SQL Server 2008 to install and RTM'd around the same time as the release this week. Still a hefty install but you can extract the client profile from it. Just not to sure how.","pontos":1},{"corpo":"@Teifion Although these will both solve your problems, it is still less secure then actually fixing the code.","pontos":0},{"corpo":"As long as it changes whenever the resource representation changes, how you produce it is completely up to you. You should try to produce it in a way that additionally: doesn't require you to re-compute it on each conditional GET, and doesn't change if the resource content hasn't changed Using hashes of content can cause you to fail at #1 if you don't store the computed hashes along with the files. Using inode numbers can cause you to fail at #2 if you rearrange your filesystem or you serve content from multiple servers. One mechanism that can work is to use something entirely content dependent such as a SHA-1 hash or a version string, computed and stored once whenever your resource content changes.","pontos":13},{"corpo":"I don't know about Java and 2008... but you shouldn't have too much trouble with Java and SQL2000. As lubos suggested, you'd be doing yourself a favour to look at c# but if you're much more comfortable with Java then there shouldn't be any real limitations as the JDBC connector is supported by Microsoft ","pontos":1},{"corpo":"Enabling windowless mode (wmode=) makes embedded flash act and render just like other elements. Without that, it's rendered in a seperate step and just overlaid on the browser's window. Could the flash element be losing focus? Sounds like input focus is moved to the scollbar, then you have to move it back. Also you weren't clear whether the focus issue was only in FF or also in IE.","pontos":0},{"corpo":"When you release a new version of your CSS or JS libraries, cause the following to occur: modify the filename to include a unique version string modify the HTML files which reference the library to point at the versioned file (this is usually a pretty simple matter for a release script) Now you can set the Expires for the CSS/JS to be years in the future. Whenever you change the content, if the referencing HTML points to a new URI, browsers will no longer use the old cached copy. This causes the caching behavior you want without requiring anything of the user.","pontos":4},{"corpo":"Drop the first marble at floor 10, 20, 30, etc. until it breaks then jump back to the last known good floor and start dropping marbles from there one floor at a time. Worst case is 99 being the Magic Floor and you can always find it in 19 drops or less. ","pontos":0},{"corpo":" uses a internally: public static string Format(IFormatProvider provider, string format, params object[] args) { if ((format == null) || (args == null)) { throw new ArgumentNullException((format == null) ? \"format\" : \"args\"); } StringBuilder builder = new StringBuilder(format.Length + (args.Length * 8)); builder.AppendFormat(provider, format, args); return builder.ToString(); } The above code is a snippet from mscorlib, so the question becomes \"is faster than \"? Without benchmarking I'd probably say that the code sample above would run more quickly using . But it's a guess, try benchmarking and/or profiling the two to get a proper comparison. This chap, Jerry Dixon, did some benchmarking: http://jdixon.dotnetdevelopersjournal.com/string_concatenation_stringbuilder_and_stringformat.htm Updated: Sadly the link above has since died. However there's still a copy on the Way Back Machine: http://web.archive.org/web/20090417100252/http://jdixon.dotnetdevelopersjournal.com/string_concatenation_stringbuilder_and_stringformat.htm At the end of the day it depends whether your string formatting is going to be called repetitively, i.e. you're doing some serious text processing over 100's of megabytes of text, or whether it's being called when a user clicks a button now and again. Unless you're doing some huge batch processing job I'd stick with String.Format, it aids code readability. If you suspect a perf bottleneck then stick a profiler on your code and see where it really is. ","pontos":100},{"corpo":" In both cases above I want to inject one or more strings into the middle of a predefined template string. In which case, I would suggest String.Format is the quickest because it is design for that exact purpose.","pontos":-1},{"corpo":"Two more general-purpose mechanisms for fixing some of Eclipse's idiosyncrasies: Close and open the project Delete the project (but not from disk!) and reimport it as an existing project Failing that, bugs.eclipse.org might provide the answer. If the workspace is caching something broken, you may be able to delete it by poking around in workspace/.metadata/.plugins. Most of that stuff is fairly transient (though backup and watch for deleted preferences).","pontos":60},{"corpo":"As far as I know you cannot find the compression level of an already compressed file. When you are compressing the file you can specify the compression level with -# where the # is from 1 to 9 (1 being the fastest compression and 9 being the most compressed file). In practice you should never compare a compressed file with one that has been extracted and recompressed, slight variations can easily crop up. In your case I would compare the base64 encoded versions instead of the gzip'd versions.","pontos":2},{"corpo":"I would expect String.Format to be slower - it has to parse the string and then concatenate it. Couple of notes: Format is the way to go for user-visible strings in professional applications; this avoids localization bugs If you know the length of the resultant string beforehand, use the StringBuilder(Int32) constructor to predefine the capacity ","pontos":6},{"corpo":"I always work to prevent things like injection attacks. However, when you work on an internal intranet site, most of the security features feel like wasted effort. I still do them, maybe just not as well.","pontos":0},{"corpo":"Interesting, I'll give it a shot. The variations aren't slight, however. The newly encoded file is longer and when comparing the binary of the before and after, the data hardly matches up at all. Before (the first three lines) H4sIAAAAAAAAC+19eZOiyNb3/34K3r4RT/WEU40ssvTtrhuIuKK44Bo3YoJdFAFZ3D79C6hVVhUq dsnUVN/qmIkSOLlwlt/JPCfJ/PGf9dwAlorj6pb58wv0LfcFUEzJknVT+/ml2uXuCSJP3kNf/vOQ +TEsFVkgoDfdn18mnmd/B8HVavWt5TsKI2vKN8magyENiH3Lf9kRfpd817PmF+jpiOhQRFZcXTMV After (the first three lines): H4sICJ/YnEgAAzEyNDQ2LTExNjk2NzUueGZkbC54bWwA7D1pU+JK19/9FV2+H5wpByEhJMRH uRUgCMom4DBYt2oqkAZyDQlmQZ1f/3YSNqGzKT3oDH6RdE4vOXuf08vFP88TFcygYSq6dnlM naWOAdQGuqxoo8vjSruRyGYzfII6/id3dPGjVKwCBK+Zl8djy5qeJ5NPT09nTduAojyCZwN9 As you can see 'H4SI' match up, then after that it's pandemonium. ","pontos":0},{"corpo":"I like the free silk icons at famfamfam, but they're png's, and when I convert them to ico format, they look pretty crappy. Not sure what I'm doing wrong...","pontos":3},{"corpo":"You have to always program defensively I would say even for internal apps, simply because users could just through sheer luck write something that breaks your app. Granted you probably don't have to worry about trying to cheat you out of money but still. Always program defensively and assume the app will fail.","pontos":0},{"corpo":"How is the input file sorted? Like, cat file|sort, or sorted via a single specific field, or multiple fields? If multiple fields, what fields and what order? It appears the hour fields are a 24 hour clock, not 12, right? Are all the date/time fields zero-padded (would 9am be \"9\" or \"09\"?) Without taking into account performance it looks like your code has problems with month boundaries since it assumes all months are 30 days long. Take the two dates 2008-05-31/12:00:00 and 2008-06-01:12:00:00. Those are 24 hours apart but your code produces the same time code for both (63339969600)","pontos":1},{"corpo":"The allocator in FreeBSD recently got an update for FreeBSD 7. The new one is called jemaloc and is apparently much more scaleable with respect to multiple threads. You didn't mention which platform you are using, so perhaps this allocator is available to you. (I believe Firefox 3 uses jemalloc, even on windows. So ports must exist somewhere.)","pontos":1},{"corpo":"I've not seen this particular problem, but recently for us a \"C1001: An internal error has occurred in the compiler\" type crash from cl.exe was fixed after installing some random and unrelated (or so we thought) Windows security updates. We knew the code didn't crash the compiler on other machines using the same version and service pack level of Visual Studio, but we were really clutching at straws when we tried the Windows security updates.","pontos":0},{"corpo":"I ran some quick performance benchmarks, and for 100,000 operations averaged over 10 runs, the first method (String Builder) takes almost half the time of the second (String Format). So, if this is infrequent, it doesn't matter. But if it is a common operation, then you may want to use the first method.","pontos":8},{"corpo":"The throw in your first example has the overhead of the creation of a new CustomException object. The re-throw in your second example will throw an exception of type Exception. The re-throw in your third example will throw an exception of the same type that was thrown by your \"some code\". So the second and third examples use less resources.","pontos":0},{"corpo":"Like David, I suppose that the second and third perform better. But would any one of the three perform poorly enough to spend any time worrying about it? I think there are larger problems than performance to worry about. FxCop always recommends the third approach over the second so that the original stack trace is not lost. Edit: Removed stuff that was just plain wrong and Mike was kind enough to point out.","pontos":2},{"corpo":"@Brad Tutterow The exception is not being lost in the first case, it is being passed in to the constructor. I will agree with you on the rest though, the second approach is a very bad idea because of the loss of stack trace. When I worked with .NET, I ran into many cases where other programmers did just that, and it frustrated me to no end when I needed to see the true cause of an exception, only to find it being rethrown from a huge try block where I now have no idea where the problem originated. I also second Brad's comment that you shouldn't worry about the performance. This kind of micro optimization is a HORRIBLE idea. Unless you are talking about throwing an exception in every iteration of a for loop that is running for a long time, you will more than likely not run into performance issues by the way of your exception usage. Always optimize performance when you have metrics that indicate you NEED to optimize performance, and then hit the spots that are proven to be the culprit. It is much better to have readable code with easy debugging capabilities (IE not hiding the stack trace) rather than make something run a nanosecond faster. A final note about wrapping exceptions into a custom exception... this can be a very useful construct, especially when dealing with UIs. You can wrap every known and reasonable exceptional case into some base custom exception (or one that extends from said base exception), and then the UI can just catch this base exception. When caught, the exception will need to provide means of displaying information to the user, say a ReadableMessage property, or something along those lines. Thus, any time the UI misses an exception, it is because of a bug you need to fix, and anytime it catches an exception, it is a known error condition that can and should be handled properly by the UI.","pontos":10},{"corpo":"I tried this and it works ok. Can you paste in the whole exception and stack trace? Updated: Strangely I can't find that interop assy on my machine either other than under the c:\\windows\\assembly\\GAC_MSIL folders. Why not fire up SysInternals FileMon or Process Monitor, it'd save some guesswork.","pontos":0},{"corpo":"A couple of other books that are going to be helpful are: Synchronization Algorithms and Concurrent Programming Patterns for Parallel Programming Communicating Sequential Processes by C. A. R. Hoare (a classic, free PDF at that link) Also, consider relying less on sharing state between concurrent processes. You'll scale much, much better if you can avoid it because you'll be able to parcel out independent units of work without having to do as much synchronization between them. Even if you need to share some state, see if you can partition the shared state from the actual processing. That will let you do as much of the processing in parallel, independently from the integration of the completed units of work back into the shared state. Obviously this doesn't work if you have dependencies among units of work, but it's worth investigating instead of just assuming that the state is always going to be shared.","pontos":5},{"corpo":"I suspect there is a problem with my Microsoft.VisualStudio.DeviceConnectivity.Interop assembly. There is no copy of that on disk that I can find. It's in the GAC only. I tried to inspect in Reflector, but it needs that Interop assembly also. Since ConManServerClass is obviously COM, maybe there's a COM library that has to be registered?","pontos":0},{"corpo":"If I'm reading this properly, you're starting work items on bunch of threads but you're concerned that the threads are completing out of order, and, would prefer to wait until each thread completes in the order they were started ? If this is the case then I'm not sure why you're creating a thread per work item. Maybe you could expand? If you did need to wait for a thread to complete the you could just do: t.Join(); ","pontos":2},{"corpo":"Unfortunately, Matt's answer features what's called double-checked locking which isn't supported by the C/C++ memory model. (It is supported by the Java 1.5 and later  and I think .NET  memory model.) This means that between the time when the check takes place and when the lock (mutex) is acquired, may have already been assigned on another thread. Thread switching happens whenever the OS wants it to, not between \"lines\" of a program (which have no meaning post-compilation in most languages). Furthermore, as Matt acknowledges, he uses an as a lock rather than an OS primitive. Don't do that. Proper locks require the use of memory barrier instructions, potentially cache-line flushes, and so on; use your operating system's primitives for locking. This is especially important because the primitives used can change between the individual CPU lines that your operating system runs on; what works on a CPU Foo might not work on CPU Foo2. Most operating systems either natively support POSIX threads (pthreads) or offer them as a wrapper for the OS threading package, so it's often best to illustrate examples using them. If your operating system offers appropriate primitives, and if you absolutely need it for performance, instead of doing this type of locking/initialization you can use an atomic compare and swap operation to initialize a shared global variable. Essentially, what you write will look like this: MySingleton *MySingleton::GetSingleton() { if (pObj == NULL) { // create a temporary instance of the singleton MySingleton *temp = new MySingleton(); if (OSAtomicCompareAndSwapPtrBarrier(NULL, temp, pObj) == false) { // if the swap didn't take place, delete the temporary instance delete temp; } } return pObj; } This only works if it's safe to create multiple instances of your singleton (one per thread that happens to invoke GetSingleton() simultaneously), and then throw extras away. The function provided on Mac OS X  most operating systems provide a similar primitive  checks whether is and only actually sets it to to it if it is. This uses hardware support to really, literally only perform the swap once and tell whether it happened. Another facility to leverage if your OS offers it that's in between these two extremes is . This lets you set up a function that's run only once - basically by doing all of the locking/barrier/etc. trickery for you - no matter how many times it's invoked or on how many threads it's invoked. ","pontos":13},{"corpo":" On a bit of a side note, $array[$index] does not produce any notices/warnings where $array[3] will throw a message (notice level I think) about 3 being an undefined constant. That is absolutely not true.","pontos":6},{"corpo":"I have three monitors, so I usually run with this configuration: Left Monitor: documentation / ebooks. Middle Monitor: code / debugging Right Monitor: Test application / scrolling logfiles (if needed) This usually works pretty well, and since the monitors are fairly big I rarely need to use the test application in full-screen, so there's plenty of room for my tail -f windows. I also use AutoHotkey to assign hotkeys that flip to the most important windows, like Firefox or my SSH session. That way I can simply use a shortcut key to access them when necessary. The left monitor is actually a separate computer running Linux and keyboard/mouse shared with Synergy, so I have multiple ebooks or documentation pages open, one on each virtual desktop... I can flip between the documentation by moving my mouse to the left and using a shortcut key.","pontos":5},{"corpo":"Basically, you're asking for synchronized creation of a singleton, without using any synchronization (previously-constructed variables). In general, no, this is not possible. You need something available for synchronization. As for your other question, yes, static variables which can be statically initialized (i.e. no runtime code necessary) are guaranteed to be initialized before other code is executed. This makes it possible to use a statically-initialized mutex to synchronize creation of the singleton. From the 2003 revision of the C++ standard: Objects with static storage duration (3.7.1) shall be zero-initialized (8.5) before any other initialization takes place. Zero-initialization and initialization with a constant expression are collectively called static initialization; all other initialization is dynamic initialization. Objects of POD types (3.9) with static storage duration initialized with constant expressions (5.19) shall be initialized before any dynamic initialization takes place. Objects with static storage duration defined in namespace scope in the same translation unit and dynamically initialized shall be initialized in the order in which their definition appears in the translation unit. If you know that you will be using this singleton during the initialization of other static objects, I think you'll find that synchronization is a non-issue. To the best of my knowledge, all major compilers initialize static objects in a single thread, so thread-safety during static initialization. You can declare your singleton pointer to be NULL, and then check to see if it's been initialized before you use it. However, this assumes that you know that you'll use this singleton during static initialization. This is also not guaranteed by the standard, so if you want to be completely safe, use a statically-initialized mutex. Edit: Chris's suggestion to use an atomic compare-and-swap would certainly work. If portability is not an issue (and creating additional temporary singletons is not a problem), then it is a slightly lower overhead solution.","pontos":12},{"corpo":"I have VS in my left monitor and the GUI/running window in the right. However, if you want to have to code tabs open on each monitor, you could use UltraMon's option to expand a window across both monitors, then drag a code page over such that it puts up a divider. Then, you align that divider with the break in your monitors. I've done that before, just to test it out. It's not a bad setup.","pontos":2},{"corpo":"Using Test Driven Development certainly helps. You write a single component at a time and then enumerate all of the potential cases for inputs (via tests) before writing the code. This ensures that you've covered all bases and haven't written any cool code that no-one will use but might break. Although I don't do anything formal I generally spend some time looking at each class and ensuring that: if they are in a valid state that they stay in a valid state there is no way to construct them in an invalid state Under exceptional circumstances they will fail as gracefully as possible (frequently this is a cleanup and throw)","pontos":0},{"corpo":"As others have stated, the best performance comes from the bottom one since you are just rethrowing an existing object. The middle one is least correct because it looses the stack. I personally use custom exceptions if I want to decouple certain dependencies in code. For example, I have a method that loads data from an XML file. This can go wrong in many different ways. It could fail to read from the disk (FileIOException), the user could try to access it from somewhere where they are not allowed (SecurityException), the file could be corrupt (XmlParseException), data could be in the wrong format (DeserialisationException). In this case, so its easier for the calling class to make sense of all this, all these exceptions rethrow a single custom exception (FileOperationException) so that means the caller does not need references to System.IO or System.Xml, but can still access what error occurred through an enum and any important information. As stated, don't try to micro-optimize something like this, the act of throwing an exception at all is the slowest thing that occurs here. The best improvement to make is to try avoiding an exception at all. public bool Load(string filepath) { if (File.Exists(filepath)) //Avoid throwing by checking state { //Wrap anyways in case something changes between check and operation try { .... } catch (IOException ioFault) { .... } catch (OtherException otherFault) { .... } return true; //Inform caller of success } else { return false; } //Inform caller of failure due to state } ","pontos":1},{"corpo":"Looking around, it seems some people resolved this by repairing or reinstalling the .NET SDK. You might want to give that a try. P.S. I see why you didn't include more of the compiler output, now. Not much to really see there. :)","pontos":0},{"corpo":"I don't know if this will help, but from this forum: Add an .ico file to the application section of the properties page, and recieved the error thats been described, when I checked the Icon file with an icon editor, it turn out that the file had more than one version of the image ie (16 x 16, 24 x 24, 32 x 32, 48 x 48 vista compressed), I removed the other formats that I didnt want resaved the file (just with 32x 32) and the application now compiles without error. Try opening the icon in an icon editor and see if you see other formats like described (also, try removing the icon and seeing if the project will build again, just to verify the icon is causing it).","pontos":5},{"corpo":"Can you sniff the traffic to find what's actually being sent? Is it sending any auth data at all and it's incorrect or being presented in a form the server doesn't like, or is it never being sent by firefox at all?","pontos":2},{"corpo":"Ah, this is killing me! I did this at work about 3 months ago, and now I can't remember all the details. I do remember, however, that you need basicHttpBinding, and you can't use the new serializer (which is the default); you have to use the \"old\" XmlSerializer. Unfortunately, I don't work at the place where I did this anymore, so I can't go look at the code. I'll call my boss and see what I can dig up. ","pontos":2},{"corpo":"Joel Lucsy: That implementation of SQLite is a mixed-mode assembly which is not supported by Silverlight. Only a pure managed implementation would work under the Silverlight CLR.","pontos":5},{"corpo":"I'd go with your original idea. If you are concerned that the queue might get too large implement a buffer-zone for it (i.e. If is gets above 100 lines the stop reading the file and if it gets below 20 then start reading again. You'd need to do some testing to find the optimal barriers). Make it so that any of the threads can potentially be the \"reader thread\" as it has to lock the queue to pull an item out anyway it can also check to see if the \"low buffer region\" has been hit and start reading again. While it's doing this the other threads can read out the rest of the queue. Or if you prefer, have one reader thread assign the lines to three other processor threads (via their own queues) and implement a work-stealing strategy. I've never done this so I don't know how hard it is.","pontos":8},{"corpo":"If you use javascript to hide the buttons, you open a security hole in the application. A malicious user could either disable javascript or apply some of their own to get around your security. I suggest using PHP to chose to either render the buttons or not. I do this in .NET quite often. You should be able to check the user's access on the server-side whenever they try to use a restricted button as well.","pontos":1},{"corpo":"Here's a little Tcl script that will do what you want. The Wish interpreter should be installed by default on Ubuntu. Call it like this: ","pontos":4},{"corpo":"This will eliminate bottlenecks of having a single thread do the reading: ","pontos":3},{"corpo":" You could use Matt's solution, but you'd need to use a proper mutex/critical section for locking, and by checking \"pObj == NULL\" both before and after the lock. Of course, pObj would also have to be static ;) . A mutex would be unnecessarily heavy in this case, you'd be better going with a critical section. OJ, that doesn't work. As Chris pointed out, that's double-check locking, which is not guaranteed to work in the current C++ standard. See: C++ and the Perils of Double-Checked Locking Edit: No problem, OJ. It's really nice in languages where it does work. I expect it will work in C++0x (though I'm not certain), because it's such a convenient idiom. ","pontos":1},{"corpo":"Regarding security, you cannot trust what comes from the client: The visitor can see all your code (HTML and Javascript, not PHP) and try stuff The visitor may not even use a browser; it's trivially easy to send a request with a script This means hiding the buttons is good User Interface design (because you can't use them if you are not logged in). But it's not a security feature. The security feature is checking, on the server, that the visitor is logged in before each action that requires it. If you don't intend to show the buttons, it's not useful to send the HTML and images to the browser and then hide them with Javascript. I would check with PHP. ","pontos":11},{"corpo":"It depends. If I am genuinely hacking something up for my own use then I will write the best code that I don't have to think about. Let the compiler be my friend for warnings etc. but I won't automatically create types for the hell of it. The more likely the code is to be used, even occasionally, I ramp up the level of checks. minimal magic numbers better variable names fully checked defined array/string lengths programming by contract assertions null value checks exceptions (depending upon context of the code) basic explanatory comments accessible usage documentation (if perl etc.) ","pontos":0},{"corpo":"Valters, you cannot establish global aliases in the style of , , etc. so far as I know. However, you can do more localized aliasing for types and namespaces with the keyword. e.g. using str = System.String; //... str s = \"Now you've got another alias for string!\"; See here: using Directive (C# Reference) ","pontos":96},{"corpo":"I looked at this early on in the creation of Stack Overflow and couldn't find any method of creating rounded corners that didn't leave me feeling like I just walked through a sewer. CSS3 does finally define the border-radius: Which is exactly how you'd want it to work. Although this works OK in the latest versions of Safari and Firefox, but not at all in IE7 (and I don't think in IE8) or Opera. In the meantime, it's hacks all the way down. I'm interested in hearing what other people think is the cleanest way to do this across IE7, FF2/3, Safari3, and Opera 9.5 at the moment.. ","pontos":78},{"corpo":"How much order do you need to impose on the threads? If you just need all of the work started in the loop to finish before the code continues, but you don't care about the order the work within the loop finishes, then calling Join is the answer. To add more detail to Kevin Kenny's answer, you should call Join outside the loop. This means you will need a collection to hold references to the threads you started: // Start all of the threads. List Thread startedThreads = new List Thread (); foreach (...) { Thread thread = new Thread(new ThreadStart(MyMethod)); thread.Start(); startedThreads.Add(thread); } // Wait for all of the threads to finish. foreach (Thread thread in startedThreads) { thread.Join(); } In contrast, if you called Join inside the loop, the result would basically be the same as not using threads at all. Each iteration of the loop body would create and start a thread but then immediately Join it and wait for it to finish. If the individual threads produce some result (write a message in a log, for example) then the messages may still appear out of order because there's no coordination between the threads. It is possible to get the threads to output their results in order by coordinating them with a Monitor. ","pontos":5},{"corpo":"Using a static constructor actually is threadsafe. The static constructor is guaranteed to be executed only once. From the C# language specification http://msdn.microsoft.com/en-us/library/aa645612(VS.71).aspx: The static constructor for a class executes at most once in a given application domain. The execution of a static constructor is triggered by the first of the following events to occur within an application domain: An instance of the class is created. Any of the static members of the class are referenced. So yes, you can trust that your singleton will be correctly instantiated. Zooba made an excellent point (and 15 seconds before me, too!) that the static constructor will not guarantee thread-safe shared access to the singleton. That will need to be handled in another manner. ","pontos":18},{"corpo":"I suspect these are related to the SQL Server Agent trying to login to a database that no longer exists. To clear it up you need to: 1. Go to SQL Server Management Studio 2. Disable the job called jobdeleteExpiredSessions If that works, then you should be all clear to delete it. ","pontos":2},{"corpo":"I would recommend using background images. The other ways aren't nearly as good: No anti-aliasing and senseless markup. This is not the place to use JavaScript. ","pontos":11},{"corpo":"I'd recommend being defensive for data that enter a \"component\" or framework. Within a \"component\" or framework one should think that the data is \"correct\". Thinking like this. It is up to the caller to supply correct parameters otherwise ALL functions and methods have to check every incomming parameter. But if the check is only done for the caller the check is only needed once. So, a parameter should be \"correct\" and thus can be passed through to lower levels. Always check data from external sources, users etc A \"component\" or framework should always check incomming calls. If there is a bug and a wrong value is used in a call. What is really the right thing todo? One only have an indication that the \"data\" the program is working on is wrong and some like ASSERTS but others want to use advanced error reporting and possible error recovery. In any case the data is found to be faulty and in few cases it's good to continue working on it. (note it's good if servers don't die at least) An image sent from a satellite might be a case to try advanced error recovery on...an image downloaded from the internet to put up an error icon for... ","pontos":1},{"corpo":"We had a series of mini-presentations (5-10 minutes maximum) all given back to back to take up a 2 hour session. The rule was that only people who were presenting were allowed to attend this special session. It seemed to encourage more people to participate and present (smaller audience, only a very short presentation, audience members were likely to be more forgiving than a real audience). ","pontos":5},{"corpo":"People who are afraid to give a longer talk can be convinced to give a very short talk. (Love the mini-presentations suggestion from pauldoo). Once they've given shorter talks, some people will realise that it's not as scary as they thought and volunteer for more and more talks. This happened to me. ;-) ","pontos":3},{"corpo":"I am very much of the opinion that correct programming will protect against these risks. Things like avoiding deprecated functions, which (in the Microsoft C++ libraries at least) are commonly deprecated because of security vulnerabilities, and validating everything that crosses an external boundary. Functions that are only called from your code should not require excessive parameter validation because you control the caller, that is, no external boundary is crossed. Functions called by other people's code should assume that the incoming parameters will be invalid and/or malicious at some point. My approach to dealing with exposed functions is to simply crash out, with a helpful message if possible. If the caller can't get the parameters right then the problem is in their code and they should fix it, not you. (Obviously you have provided documentation for your function, since it is exposed.) Code injection is only an issue if your application is able to elevate the current user. If a process can inject code into your application then it could easily write the code to memory and execute it anyway. Without being able to gain full access to the system code injection attacks are pointless. (This is why applications used by administrators should not be writeable by lesser users.) ","pontos":0},{"corpo":"I am also having a number of problems with VS 2008. Who would guess that I don't ever need to select multiple controls on a web form... Anyway, a lot has been fixed in Service Pack 1, which is in Beta currently. Might be worth installing that. It has gone a little way to fixing absolute positioning. This isn't your problem, of course, but your fix might be in there as well. ","pontos":1},{"corpo":"You cannot cast between generic types with different type parameters. Specialized generic types don't form part of the same inheritance tree and so are unrelated types. To do this pre-NET 3.5: List string sl = new List string (); // Add strings to sl List object ol = new List object (); foreach(string s in sl) { ol.Add((object)s); // The cast is performed implicitly even if omitted } Using Linq: var sl = new List string (); // Add strings to sl var ol = new List object (sl.Cast object ()); // OR var ol = sl.Cast object ().ToList(); // OR (note that the cast to object here is required) var ol = sl.Select(s = (object)s).ToList(); ","pontos":12},{"corpo":"We've had problems when trying to add large numbers of files to repositories through the client which I assume created orphaned processes on the server when we killed the crashed client. We had to kill the server processes too and restart the subversion service (we run SVN as a windows service). Our SVN machine is dedicated so we actually just rebooted the box and everything went back to normal. ","pontos":0},{"corpo":"JavaScript is probably the way to go if you want to avoid Flash. Check this: http://www.webreference.com/programming/javascript/java_anim/ It won't work for embedded video, though, so you're stuck with Flash for that (or Silverlight, or QuickTime). ","pontos":0},{"corpo":"Note that Matt's code above will result in an extra comma at the end of the string; using COALESCE (or ISNULL for that matter) as shown in the link in Lance's post uses a similar method but doesn't leave you with an extra comma to remove. For the sake of completeness, here's the relevant code from Lance's link on sqlteam.com: DECLARE @EmployeeList varchar(100) SELECT @EmployeeList = COALESCE(@EmployeeList + ', ', '') + CAST(EmpUniqueID AS varchar(5)) FROM SalesCallsEmployees WHERE SalCal_UniqueID = 1 ","pontos":58},{"corpo":"Have a look at the jQuery cross browser JavaScript library for animation (it is what is used on Stack Overflow). The reference for it can be found at http://visualjquery.com/1.1.2.html. Unfortunately without Flash, Silverlight or another plug-in cross system video support is limited. ","pontos":2},{"corpo":"Pylons is particularly suited for your situation. It uses lots of standard libraries (Paste, Beaker, Mako, SQLAlchemy, Routes etc...) and more or less just acts a 'glue' between them. Other libraries can be easily swapped in (i.e. SQLObject instead of SQLAlchemy, Genshi instead of Mako) and is strictly WSGI compliant making middleware insertion easy. I used Pylons over Django since it was highly compartmentalised. I wanted to access the data in the web-app using a desktop application. I just imported the SQLAlchemy library into my desktop app and worked with it exactly as I would in the web-app. Turbogears 2.0 will actually be written on top of the Pylons framwork. ","pontos":2},{"corpo":"That's actually so that you don't try to put any odd \"object\" in your \"ol\" list variant (as would seem to allow) - because your code would crash then (because the list really is and will only accept String type objects). That's why you can't cast your variable to a more general specification. On Java it's the other way around, you don't have generics, and instead everything is List of object at runtime, and you really can stuff any strange object in your supposedly-strictly typed List. Search for \"Reified generics\" to see a wider discussion of java's problem... ","pontos":1},{"corpo":"There is now a Firebug Lite that works on other browsers such as Internet Explorer, Safari and Opera built. It does have a limited set of commands and is not as fully featured as the version in Firefox. If you are using ASP.NET in Visual Studio 2008 will also debug JavaScript in Internet Explorer. ","pontos":0},{"corpo":"I assume that you want this \"pause\" for debugging purposes, otherwise think about it, you'll always have some better tasks to do for your server than sleep ... A suggestion: Maybe you could get CURRENT, add it a few seconds ( let mytimestamp ) then in a while loop select CURRENT while CURRENT = mytimestamp . I've no informix setup around my desk to try it, so you'll have to figure the correct syntax. Again, do not put such a hack on a production server. You've been warned :D ","pontos":0},{"corpo":"@lassevk I found the referenced article, from DDJ: The Maximal Rectangle Problem ","pontos":15},{"corpo":"If the junior programmer, or anyone, doesn't see the value in testing, then it will be hard to get them to do it...period. I would have made the junior programmer sacrifice their weekend to fix the bug. His actions (or lack there of) are not affecting him directly. Also, make it apparent, that he will not see advancement and/or pay increases if he doesn't improve his skills in testing. In the end, even with all your help, encouragement, mentoring, he might not be a fit for your team, so let him go and look for someone who does get it. ","pontos":1},{"corpo":"The Sieve of Eratosthenes is a decent algorithm: Take the list of positive integers 2 to any given Ceiling. Take the next item in the list (2 in the first iteration) and remove all multiples of it (beyond the first) from the list. Repeat step two until you reach the given Ceiling. Your list is now composed purely of primes. There is a functional limit to this algorithm in that it exchanges speed for memory. When generating very large lists of primes the memory capacity needed skyrockets. ","pontos":2},{"corpo":"I think the only real problem is that it makes the XML harder to read. e.g. Something Contains An Address 15 Sample St Example Bay Some Country /Address /An /Contains /Something If pretty XML isn't a concern, I'd probably not worry about it, so long as it's working. If pretty XML is a concern, I'd convert the explicit newlines into tags or before embedding them in the XML. ","pontos":2},{"corpo":"I don't think that pointers themselves are confusing. Most people can understand the concept. Now how many pointers can you think about or how many levels of indirection are you comfortable with. It doesn't take too many to put people over the edge. The fact that they can be changed accidently by bugs in your program can also make them very difficult to debug when things go wrong in your code. ","pontos":2},{"corpo":"It depends on how you're reading and writing the XML. If XML is being generated automatically - if newlines or explicit \\n flags are being parsed into - then there's nothing to worry about. Your input likely doesn't have any other XML in it so it's just cleaner to not mess with XML at all. If tags are being worked with manually, it's still cleaner to just have a line break, if you ask me. The exception is if you're using DOM to get some structure out of the XML. In that case line breaks are obviously evil because they don't represent the heirarchy properly. It sounds like the heirarchy is irrelevant for your application, though, so line breaks sound sufficient. If the XML just looks bad (especially when automatically generated), Tidy can help, although it works better with HTML than with XML. ","pontos":1},{"corpo":"After some experimentation, I've overcome my mental block. In retrospect, it's all obvious, but in the spirit of Stack Overflow, here's what I learned. As Sebastjan said, **you first have to sort your data. This is important.** The part I didn't get is that in the example construction groups = [] uniquekeys = [] for k, g in groupby(data, keyfunc): groups.append(list(g)) # Store group iterator as a list uniquekeys.append(k) \"k\" is the current grouping key, and \"g\" is an iterator that you can use to iterate over the group defined by that grouping key. In other words, the groupby iterator itself returns iterators. Here's an example of that, using clearer variable names: from itertools import groupby things = [(\"animal\", \"bear\"), (\"animal\", \"duck\"), (\"plant\", \"cactus\"), (\"vehicle\", \"speed boat\"), (\"vehicle\", \"school bus\")] for key, group in groupby(things, lambda x: x[0]): for thing in group: print \"A %s is a %s.\" % (thing[1], key) print \" \" This will give you the output: A bear is a animal. A duck is a animal. A cactus is a plant. A speed boat is a vehicle. A school bus is a vehicle. In this example, \"things\" is a list of tuples where the first item in each tuple is the group the second item belongs to. The groupby() function takes two arguments: (1) the data to group and (2) the function to group it with. Here, \"lambda x: x[0]\" tells groupby() to use the first item in each tuple as the grouping key. In the above \"for\" statement, groupby returns three (key, group iterator) pairs - once for each unique key. You can use the returned iterator to iterate over each individual item in that group. Here's a slightly different example with the same data, using a list comprehension: for key, group in groupby(things, lambda x: x[0]): listOfThings = \" and \".join([thing[1] for thing in group]) print key + \"s: \" + listOfThings + \".\" This will give you the output: animals: bear and duck. plants: cactus. vehicles: speed boat and school bus. Python's pretty cool, no? ","pontos":287},{"corpo":"It's generally considered bad practice to rely on linebreaks, since it's a fragile way to differentiate data. While most XML processors will preserve any whitespace you put in your XML, it's not guaranteed. The real problem is that most applications that output your XML into a readable format consider all whitespace in an XML interchangable, and might collapse those linebreaks into a single space. That's why your XSLT has to jump through such hoops to render the data properly. Using a \"br\" tag would vastly simplify the transform. Another potential problem is that if you open up your XML document in an XML editor and pretty-print it, you're likely to lose those line breaks. If you do keep using linebreaks, make sure add an xml:space=\"preserve\" attribute to \"address.\" (You can do this in your DTD, if you're using one.) Some suggested reading An article from XML.com says the following: XML applications often seem to take a cavalier attitude toward whitespace because the rules about the places in an XML document where whitespace doesn't matter sometimes give these applications free rein to add or remove whitespace in certain places. A collection of XSL-list posts regarding whitespace. ","pontos":8},{"corpo":"I've had to do similar things a few times. The easiest approach for me has been to write a script that pulls from one data source and produces an output for the new data source. Just do a query for each table in your current database, and then dump all the rows into an query for your new database. You can either dump this into a file or pipe it straight into the database frontend. It's not pretty, but honestly, pretty hardly seems to be a major concern for things like this. This technique is quick to write, and it works. Those are my primary criteria for things like this. You might want to check out this thread, too. It looks like a couple of people have already put together basically what you need. I didn't look that far into it, though, so no guarantees. ","pontos":4},{"corpo":"Microsoft loosened it's constraint on the Testing Platform by including it in Visual Studio 2008 Professional and allowing for the tests to be run from the command line with Framework 3.5 installed. We did a crossover for a client recently and so far they have been able to run all the tests without the need for NUnit. ","pontos":0},{"corpo":"In your algorithm using the list from 2 to the root of the integer, you can improve performance by only testing odd numbers after 2. That is, your list only needs to contain 2 and all odd numbers from 3 to the square root of the integer. This cuts the number of times you loop in half without introducing any more complexity. ","pontos":0},{"corpo":"I am not sure why would you say that unit tests are going be removed once refactoring is completed. Actually your unit-test suite should run after main build (you can create a separate \"tests\" build, that just runs the unit tests after the main product is built). Then you will immediately see if changes in one piece break the tests in other subsystem. Note it's a bit different than running tests during build (as some may advocate) - some limited testing is useful during build, but usually it's unproductive to \"crash\" the build just because some unit test happens to fail. If you are writing Java (chances are), check out http://www.easymock.org/ - may be useful for reducing coupling for the test purposes. ","pontos":0},{"corpo":"I'm not in a position to modify the permissions on folders (especially outside of the virtual directory home folder), and don't already have an App_Data folder, so am a bit hesitant to go with that. So for the moment I'm going with the CommonApplicationData Folder. On Vista/Server 2008 this is C:\\ProgramData\\ On XP/Server 2003 this is C:\\Documents and Settings\\All Users\\Application Data\\ ","pontos":0},{"corpo":" I'm not in a position to modify the permissions on folders (especially outside of the virtual directory home folder), and don't already have an App_Data folder, so am a bit hesitant to go with that. If you have a website, you clearly have a folder somewhere. Can you not add a (non-web-facing) subfolder? It seems like that would be a more appropriate place to put your logs than dumping them into a global, shared folder. ","pontos":0},{"corpo":"If you need your linebreaks preserved, use a CDATA block, as tweakt said Otherwise beware. Most of the time, the linebreaks will be preserved by XML software, but sometimes they won't, and you really don't want to be relying on things which only work by coincidence ","pontos":-2},{"corpo":"What about using attributes to store the data, rather than text nodes: Address Street=\"15 Sample St\" City=\"Example Bay\" State=\"\" Country=\"Some Country\"/ I know the use of attributes vs. text nodes is an often debated subject, but I've stuck with attributes 95% of the time, and haven't had any troubles because of it. ","pontos":2},{"corpo":"We use pdflib to create PDF files from our rails apps. It has bindings for PHP, and a ton of other languages. We use the commmercial version, but they also have a free/open source version which has some limitations. Unfortunately, this only allows creation of PDF's. If you want to open and 'edit' existing files, pdflib do provide a product which does this this, but costs a LOT ","pontos":0},{"corpo":"@valters I disagree with your statement that tests shouldn't break the build. The tests should be an indication that the application doesn't have new bugs introduced for the functionality that is tested (and a found bug is an indication of a missing test). If tests don't break the build, then you can easily run into the situation where new code breaks the build and it isn't known for a while, even though a test covered it. A failing test should be a red flag that either the test or the code has to be fixed. Furthermore, allowing the tests to not break the build will cause the failure rate to slowly creep up, to the point where you no longer have a reliable set of regression tests. If there is a problem with tests breaking too often, it may be an indication that the tests are being written in too fragile a manner (dependence on resources that could change, such as the database without using DB Unit properly, or an external web service that should be mocked), or it may be an indication that there are developers in the team that don't give the tests proper attention. I firmly believe that a failing test should be fixed ASAP, just as you would fix code that fails to compile ASAP. ","pontos":3},{"corpo":"Have a code review before every commit (even if it's a 1 minute \"I've changed this variable name\"), and as part of the code review, review any unit tests. Don't sign off on the commit until the tests are in place. (Also - If his work wasn't tested - why was it in a production build in the first place? If it's not tested, don't let it in, then you won't have to work weekends) ","pontos":20},{"corpo":"I second RodeoClown's comment about code reviewing every commit. Once he's done it a fair few times he'll get in the habit of testing stuff. I don't know if you need to block commits like that though. At my workplace everyone has free commit to everything, and all SVN commit messages (with diffs) are emailed to the team. Note: you really want the thunderbird colored-diffs addon if you plan on doing this. My boss or myself (the 2 'senior' coders) will end up reading over the commits, and if there's any stuff like \"you forgot to add unit tests\" we just flick an email or go and chat to the person, explaining why they needed unit tests or whatever. Everyone else is encouraged to read the commits too, as it's a great way of seeing what's going on, but the junior devs don't comment so much. You can help encourage people to get into the habit of this by periodically saying things like \"Hey, bob, did you see that commit I did this morning, I found this neat trick where you can do blah blah whatever, read the commit and see how it works!\" NB: We have 2 'senior' devs and 3 junior ones. This may not scale, or you might need to adjust the process a bit with more developers. ","pontos":2},{"corpo":"If you are taking a 'fill in the blank' approach, you can precisely position text anywhere you want on the page. So it's relatively easy (if not a bit tedious) to add the missing text to the document. For example with Zend Framework: ?php require_once 'Zend/Pdf.php'; $pdf = Zend_Pdf::load('blank.pdf'); $page = $pdf- pages[0]; $font = Zend_Pdf_Font::fontWithName(Zend_Pdf_Font::FONT_HELVETICA); $page- setFont($font, 12); $page- drawText('Hello world!', 72, 720); $pdf- save('zend.pdf'); If you're trying to replace inline content, such as a \"[placeholder string],\" it gets much more complicated. While it's technically possible to do, you're likely to mess up the layout of the page. A PDF document is comprised of a set of primitive drawing operations: line here, image here, text chunk there, etc. It does not contain any information about the layout intent of those primitives. ","pontos":48},{"corpo":"one of my application's emails was constantly being tagged as spam. it was html with a single link, which i sent as html in the body with a text/html content type. my most successful resolution to this problem was to compose the email so it looked like it was generated by an email client. i changed the email to be a multipart/alternative mime document and i now generate both text/plain and text/html parts. the email no longer is detected as junk by outlook. ","pontos":6},{"corpo":"I wrote a script using the built-in Tokenizer functions. Its pretty rough but it worked for the code base I was working on. I believe you could also use CodeSniffer. ","pontos":2},{"corpo":"What we have done at my work is have a library the provides functions such as checking if the user is logged in. For example: ?php require_once 'Auth.php'; // output some html if (isLoggedIn()) { echo 'html for logged in user'; } // rest of html For pages that only authenicated users should see, the controller checks if they are logged in and if not it redirects them to the login page. ?php public function viewCustomer($customerId) { if (!isLoggedIn()) redirectToLoginPage(); } ","pontos":0},{"corpo":"My eventual (and hopefully temporary) solution to this problem was a Python CGI script. My script follows for anyone who might find it useful (despite the fact that this is a total hack). #!/usr/bin/python \"\"\"A CGI script to produce an RSS feed of top-level Gallery2 albums.\"\"\" #import cgi #import cgitb; cgitb.enable() from time import gmtime, strftime import MySQLdb ALBUM_QUERY = ''' select g_id, g_title, g_originationTimestamp from g_Item where g_canContainChildren = 1 order by g_originationTimestamp desc limit 0, 20 ''' RSS_TEMPLATE = '''Content-Type: text/xml ?xml version=\"1.0\"? rss version=\"2.0\" channel title TITLE /title link http://example.com/gallery2/main.php /link description DESCRIPTION /description ttl 1440 /ttl %s /channel /rss ''' ITEM_TEMPLATE = ''' item title %s /title link http://example.com/gallery2/main.php?g2_itemId=%s /link description %s /description pubDate %s /pubDate /item ''' def to_item(row): item_id = row[0] title = row[1] date = strftime(\"%a, %d %b %Y %H:%M:%S GMT\", gmtime(row[2])) return ITEM_TEMPLATE % (title, item_id, title, date) conn = MySQLdb.connect(host = \"HOST\", user = \"USER\", passwd = \"PASSWORD\", db = \"DATABASE\") curs = conn.cursor() curs.execute(ALBUM_QUERY) print RSS_TEMPLATE % ''.join([ to_item(row) for row in curs.fetchall() ]) curs.close() ","pontos":1},{"corpo":"You could also log to the Windows Event log or to a table in a database. How often are people looking at the event log? If it's being examined on a regualr basis, writing to a table amkes the reporting back much easier as it's trivial to reverse the order and only show the last X events for the current time period. The Windows Event log you can also query the Windows Event Log through PowerShell or with LogParser. ","pontos":0},{"corpo":"It seems a lot of people get confused by the way objects are passed to functions and what pass by reference means. Object variables are still passed by value, its just the value that is passed in PHP5 is a reference handle. As proof: ?php class Holder { private $value; public function __construct($value) { $this- value = $value; } public function getValue() { return $this- value; } } function swap($x, $y) { $tmp = $x; $x = $y; $y = $tmp; } $a = new Holder('a'); $b = new Holder('b'); swap($a, $b); echo $a- getValue() . \", \" . $b- getValue() . \"\\n\"; Outputs: a, b To pass by reference means we can modify the variables that are seen by the caller. Which clearly the code above does not do. We need to change the swap function to: ?php function swap( $x, $y) { $tmp = $x; $x = $y; $y = $tmp; } $a = new Holder('a'); $b = new Holder('b'); swap($a, $b); echo $a- getValue() . \", \" . $b- getValue() . \"\\n\"; Outputs: b, a in order to pass by reference. ","pontos":36},{"corpo":"as abfo says, the POP3 protocol is super simple, getting the messages is a no brainer. Parsing the messages to get the failures is harder, and reliably parsing out which email caused the failure and why it failed is really hard. The problem is that bounce messages don't have a standard format, the default forms vary from MTA to MTA. Then the failure reason can be tweaked by the site admin making it harder to recognize, and the site admin could modify the failure message template which makes it darn near impossible. See if you can find a .NET mailing list manager and if you can repurpose the bounce handling code. Failing that, see if you can change the tool that's sending the messages to send each email from a unique (and reversible) enveloper sender (VERP I think it's called?). That way you don't need to scan the body of the email, you can tell which recipient failed by examining the recipient address of the failure message. ","pontos":3},{"corpo":"A Rutgers grad student recently found a recurrence relation that generates primes. The difference of its successive numbers will generate either primes or 1's. a(1) = 7 a(n) = a(n-1) + gcd(n,a(n-1)). It makes a lot of crap that needs to be filtered out. Benoit Cloitre also has this recurrence that does a similar task: b(1) = 1 b(n) = b(n-1) + lcm(n,b(n-1)) then the ratio of successive numbers, minus one [b(n)/b(n-1)-1] is prime. A full account of all this can be read at Recursivity. For the sieve, you can do better by using a wheel instead of adding one each time, check out the Improved Incremental Prime Number Sieves. Here is an example of a wheel. Let's look at the numbers, 2 and 5 to ignore. Their wheel is, [2,4,2,2]. ","pontos":2},{"corpo":"One more note, for our web application, I found that we had huge performance issues due to contention between threads over locks... so the moral was to think over the locking scheme very carefully. We ended up having worker threads to throttle too many requests using an asynchronous http handler, otherwise the application would just get overwhelmed and crash and burn. It meant a huge backlog could pile up, but at least the site would stay up. ","pontos":0},{"corpo":"@FryHard FirstOrDefault will work but remember that it returns null if none are found. This code isn't tested but should be close to what you want: var app = Process.GetProcesses().FirstOrDefault(p = p.ProcessName.Contains(\"MyAppName\") p.MainWindowHandle != IntPtr.Zero); if (app == null) return; SetForegroundWindow(app.MainWindowHandle); ","pontos":18},{"corpo":"Facebook does it, when you write on people's walls, but only resizes vertically. Horizontal resize strikes me as being a mess, due to word-wrap, long lines, and so on, but vertical resize seems to be pretty safe and nice None of the facebook-using-newbies I know have ever mentioned anything about it or been confused. I'd use this as anecdotal evidence to say 'go ahead, implement it' Some javascript to do it, using prototype.js (because that's what I'm familiar with) !DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\" html head script src=\"http://www.google.com/jsapi\" /script script language=\"javascript\" google.load('prototype', '1.6.0.2'); /script /head body textarea id=\"text-area\" rows=\"1\" cols=\"50\" /textarea script type=\"text/javascript\" language=\"javascript\" resizeIt = function() { var str = $('text-area').value; var cols = $('text-area').cols; var linecount = 0; $A(str.split(\"\\n\")).each( function(l) { linecount += Math.ceil( l.length / cols ); // take into account long lines } ) $('text-area').rows = linecount + 1; }; Event.observe('text-area', 'keydown', resizeIt ); // you could attach to keyUp, etc if keydown doesn't work resizeIt(); //initial on load /script /body /html PS: Obviously this javascript is very naive and not well tested, and you probably don't want to use it on textboxes with novels in them, but you get the general idea ","pontos":59},{"corpo":"Since the bottleneck will generally be in the processing and not the reading when dealing with files I'd go with the producer-consumer pattern. To avoid locking I'd look at lock free lists. Since you are using C# you can take a look at Julian Bucknall's Lock-Free List code. ","pontos":1},{"corpo":"I don't have access to SQL Server to test this, but how about: DROP TABLE IF EXISTS table1, table2, table3 CASCADE; ","pontos":0},{"corpo":"The code was simply an example of where my program was failing (it was allocated on the stack, Jim). I'm not actually looking for 'what have I done wrong', but rather 'how do I diagnose what I've done wrong'. Teach a man to fish and all that. Though looking at the question, I haven't made that clear enough. Thank goodness for the edit function. :') Also, I actually fixed the std::string problem. How? By replacing it with a vector, compiling, then replacing the string again. It was consistently crashing there, and that fixed even though it...couldn't. There's something nasty there, and I'm not sure what. I did want to check the one time I manually allocate memory on the heap, though: this- map = new Area*[largestY + 1]; for (int i = 0; i largestY + 1; i++) { this- map[i] = new Area[largestX + 1]; } and deleting it: for (int i = 0; i largestY + 1; i++) { delete [] this- map[i]; } delete [] this- map; I haven't allocated a 2d array with C++ before. It seems to work. ","pontos":0},{"corpo":" Also, I actually fixed the std::string problem. How? By replacing it with a vector, compiling, then replacing the string again. It was consistently crashing there, and that fixed even though it...couldn't. There's something nasty there, and I'm not sure what. That sounds like you really did shake a chicken at it. If you don't know why it's working now, then it's still broken, and pretty much guaranteed to bite you again later (after you've added even more complexity). ","pontos":0},{"corpo":"It's probably the awesome firefox3 fsync \"bug\", which is a giant pile of fail. In summary Firefox3 saves its bookmarks and history in an SQLite database Every time you load a page it writes to this database several times SQLite cares deeply that you don't lose your bookmarks, so each time it writes, instructs the kernel to flush it's database file to disk and ensure that it's fully written Many variants of linux, when told to flush like that, flush EVERY FILE. This may take up to a minute or more if you have background tasks doing any kind of disk intensive stuff. The kernel makes firefox wait while this flush happens, which locks up the UI. ","pontos":7},{"corpo":"Some places to start: If you're on windows, and using visual C++6 (I hope to god nobody still uses it these days) it's implentation of std::string is not threadsafe, and can lead to this kind of thing. Here's an article I found which explains a lot of the common causes of memory leaks and corruption. At my previous workplace we used Compuware Boundschecker to help with this. It's commercial and very expensive, so may not be an option. Here's a couple of free libraries which may be of some use http://www.codeguru.com/cpp/misc/misc/memory/article.php/c3745/ http://www.codeproject.com/KB/cpp/MemLeakDetect.aspx Hope that helps. Memory corruption is a sucky place to be in! ","pontos":1},{"corpo":"The reorganize and rebuild are different things. Reorganize: it's a defrag for indexes. Takes the existing index(es) and defragments the existing pages. However if the pages are not in a contiguous manner, they stays like before. Only the content of the pages are changing. Rebuild: actually it drops the index and rebuilds it from scratch. It means that you will get a completely new index, with defragmented and contiguous pages. Moreover with rebuild you can change partitioning or file groups, but with reorganize you can defrag not only the whole index, but also only one partition of the index. The update statistics is automatic on clustered indexes, but not on the non-clustered ones. ","pontos":25},{"corpo":"Class names should always be descriptive and self-explanatory. If you have multiple domains of responsibility for your classes then they should probably be refactored. Likewise for you packages. They should be grouped by domain of responsibility. Every domain has it's own exceptions. Generally don't sweat it until you get to a point where it is becoming overwhelming and bloated. Then sit down and don't code, just refactor the classes out, compiling regularly to make sure everything works. Then continue as you did before. ","pontos":2},{"corpo":"Another possibility is to use DTS or Integration Services (DTS for SQL Server 7 or 2000, SSIS for 2005 or higher). Both are from Microsoft, included in the Sql Server installation (in Standard edition at least) and have an FTP task and are designed for import/export jobs from Sql Server. ","pontos":3},{"corpo":"One of the debugging techniques that I use frequently (except in cases of the most extreme weirdness) is to divide and conquer. If your program currently fails with some specific error, then divide it in half in some way and see if it still has the same error. Obviously the trick is to decide where to divide your program! Your example as given doesn't show enough context to determine where the error might be. If anybody else were to try your example, it would work fine. So, in your program, try removing as much of the extra stuff you didn't show us and see if it works then. If so, then add the other code back in a bit at a time until it starts failing. Then, the thing you just added is probably the problem. Note that if your program is multithreaded, then you probably have larger problems. If not, then you should be able to narrow it down in this way. Good luck! ","pontos":0},{"corpo":"Then you'll have to warp CURRENT in another function that you'll call from the first (but this is a hack on the previous hack ...). ","pontos":0},{"corpo":"With javascript alone, it's not possible. Javascript is not intended to do such things and is severely crippled in the way it can interact with anything other than the webbrowser it lives in, (for good reason!). Think about it: a spammer writing a website with client side javascript which will automatically mail to thousands of random email addresses. If people should go to that site they would all be participating in a distributed mass mailing scam, with their own computer... no infection or user interaction needed! ","pontos":4},{"corpo":"You should consider writing your code in such a way that you can mock your I/O completion port. Make an interface/abstract class that exposes the methods you need on the I/O object, and write and test implementation that does things like it's supposed to (and an option to simulate failure perhaps). AFAIK it's a common practice to mock external resources when unit testing, to minimize dependencies. ","pontos":1},{"corpo":"If you are doing this in .NET, there is an ExpectedException attribute that you can add to your test: [Test, ExpectedException(typeof(SpecificException), \"Exception's specific message\")] public void TestWhichHasException() { CallMethodThatThrowsSpecificException(); } Test will pass if the exception of that type and with the specified message is thrown. The attribute has other overloads including having InnerExceptions, etc. ","pontos":3},{"corpo":"There's a way to reference LINQ in the .NET 2.0 Framework, but I have to warn you that it might be against the terms of use/EULA of the framework: http://stackoverflow.com/questions/2138/linq-on-the-net-20-runtime#2146 ","pontos":0},{"corpo":"First of all. Getting linq itself to work on 2.0 is out of the question. Its possible, but really not something to do outside a testing environment. The closest you can get in terms of the ORM/Dynamic Querying part of it, is imho SubSonic, which I'll recommend for anyone stuck in C# 2.0 ","pontos":0},{"corpo":"You can use a similar technique on Windows, you just need to use different words for the same concepts. :) This article: http://msdn.microsoft.com/en-us/library/ms682499.aspx uses a win32 pipe to handle I/O from another process, you just have to do the same thing with threads within the same process. Of course, in your case all output to stderr from anywhere in the process will be redirected to your consumer. Actually, other pieces of the puzzle you may need are fdopen and open_osfhandle. In fact, here's a related example from some code I released years ago: DWORD CALLBACK DoDebugThread(void *) { AllocConsole(); SetConsoleTitle(\"Copilot Debugger\"); // The following is a really disgusting hack to make stdin and stdout attach // to the newly created console using the MSVC++ libraries. I hope other // operating systems don't need this kind of kludge.. :) stdout- _file = _open_osfhandle((long)GetStdHandle(STD_OUTPUT_HANDLE), _O_TEXT); stdin- _file = _open_osfhandle((long)GetStdHandle(STD_INPUT_HANDLE), _O_TEXT); debug(); stdout- _file = -1; stdin- _file = -1; FreeConsole(); CPU_run(); return 0; } In this case, the main process was a GUI process which doesn't start with stdio handles at all. It opens a console, then shoves the right handles into stdout and stdin so the debug() function (which was designed as a stdio interactive function) can interact with the newly created console. You should be able to open some pipes and do the same sort of thing to redirect stderr. ","pontos":4},{"corpo":"Common shell scripts often have to find their \"home\" directory even if they are invoked as a symlink. The script thus have to find their \"real\" position from just $0. cat `mvn` on my system prints a script containing the following, which should be a good hint at what you need. if [ -z \"$M2_HOME\" ] ; then ## resolve links - $0 may be a link to maven's home PRG=\"$0\" # need this for relative symlinks while [ -h \"$PRG\" ] ; do ls=`ls -ld \"$PRG\"` link=`expr \"$ls\" : '.*- \\(.*\\)$'` if expr \"$link\" : '/.*' /dev/null; then PRG=\"$link\" else PRG=\"`dirname \"$PRG\"`/$link\" fi done saveddir=`pwd` M2_HOME=`dirname \"$PRG\"`/.. # make it fully qualified M2_HOME=`cd \"$M2_HOME\" pwd` ","pontos":1},{"corpo":" Definitely keep table names singular, person not people Same here No. I've seen some terrible prefixes, going so far as to state what were dealing with is a table (tbl_) or a user store procedure (usp_). This followed by the database name... Don't do it! Yes. I tend to PascalCase all my table names ","pontos":8},{"corpo":"My opinions on these are: 1) No, table names should be singular. While it appears to make sense for the simple selection () it makes less sense for the OO equivalent (). A table in a DB is really the set of that entity, it makes more sense once you're using set-logic: select Orders.* from Orders inner join Products on Orders.Key = Products.Key That last line, the actual logic of the join, looks confusing with plural table names. I'm not sure about always using an alias (as Matt suggests) clears that up. 2) They should be singular as they only hold 1 property 3) Never, if the column name is ambiguous (as above where they both have a column called [Key]) the name of the table (or its alias) can distinguish them well enough. You want queries to be quick to type and simple - prefixes add unnecessary complexity. 4) Whatever you want, I'd suggest CapitalCase I don't think there's one set of absolute guidelines on any of these. As long as whatever you pick is consistent across the application or DB I don't think it really matters. ","pontos":9},{"corpo":"You have to remember that what MSVCRT calls \"OS handles\" are not Win32 handles, but another layer of handles added just to confuse you. MSVCRT tries to emulate the Unix handle numbers where stdin=0, stdout=1, stderr=2 and so on. Win32 handles are numbered differently and their values always happen to be a multiple of 4. Opening the pipe and getting all the handles configured properly will require getting your hands messy. Using the MSVCRT source code and a debugger is probably a requirement. ","pontos":1},{"corpo":"Do you even need MSDTC? The escalation you're experiencing is often caused by creating multiple connections within a single TransactionScope. If you do need it then you need to enable it as outlined in the error message. On XP: Go to Administrative Tools -> Component Services Expand Component Services -> Computers -> Right-click -> Properties -> MSDTC tab Hit the Security Configuration button ","pontos":62},{"corpo":"Have a look at this: http://www.albahari.com/nutshell/linqbridge.html Linq is several different things, and I'm not 100% sure which bits you want, but the above might be useful in some way. If you don't already have a book on Linq (I guess you don't), then I found \"Linq In Action\" to be be good. ","pontos":4},{"corpo":"If you're looking for high performance, you are going to want to avoid paging completely, so the page file size becomes less significant. Invest in as much RAM as feasible for the DB server. ","pontos":1},{"corpo":"Ends up this resolved my issue: SearchButton.UseSubmitBehavior = False ","pontos":2},{"corpo":"As mentioned d will be while f is The conversion is done by the C# compiler var d = from mp in MyProducts where mp.Price 50d select mp; Is converted to (before compilation to IL and with generics expanded): var d = MyProducts. Where MyProduct ( mp = mp.Price 50d ). Select MyProduct ( mp = mp ); //note that this last select is optimised out if it makes no change Note that in this simple case it makes little difference. Where Linq becomes really valuable is in much more complicated loops. For instance this statement could include group-bys, orders and a few let statements and still be readable in Linq format when the equivalent would get complicated. ","pontos":4},{"corpo":"You may have to generate you own \"glyph cache\" in texture memory as you go, potentially with some sort of LRU policy to avoid destroying all of the texture memory. Not nearly as easy as your current method, but may be the only way given the number of unicode chars ","pontos":2},{"corpo":"Eclipse does some of this in Java (or PHP with plugins) on its own. Allows you to fold functions and such. I tend to like it. If I know what a function does and I am not working on it, I dont need to look at it. ","pontos":0},{"corpo":"@AnotherHowie, I thought the whole preprocessing could be done with sort and uniq. The problem is that the OP's data seems to be comma delimited and (Solaris 8's) uniq doesn't allow you any way specify the record separator, so there wasn't a super clean way to do the preprocessing using standard unix tools. I don't think it would be any faster so I'm not going to look up the exact options, but you could do something like: cut -d, -f8 infile.txt | sort | uniq -d | xargs -i grep {} infile.txt outfile.txt That's not very good because it executes grep for every line containing a duplicate key. You could probably massage the uniq output into a single regexp to feed to grep, but the benefit would only be known if the OP posts expected ratio of lines containing suspected duplicate keys to total lines in the file. ","pontos":1},{"corpo":"This is probably a bit deceptive example, since address is a bit non-normalized in this case. It is a reasonable trade-off, however since address fields are difficult to normalize. If you make the line breaks carry important information, you're un-normalizing and making the post office interpret the meaning of the line break. I would say that normally this is not a big problem, but in this case I think the Line tag is most correct since it explicitly shows that you don't actually interpret what the lines may mean in different cultures. (Remember that most forms for entering an address has zip code etc, and address line 1 and 2.) The awkwardness of having the line tag comes with normal XML, and has been much debated at coding horror. http://www.codinghorror.com/blog/archives/001139.html ","pontos":1},{"corpo":"If you choose to throw a NPE and you are using the argument in your method, it might be redundant and expensive to explicitly check for a null. I think the VM already does that for you. ","pontos":-3},{"corpo":"First of all its a matter of casing... Change to which will fix your binding error.. But I do not think that this is what you are trying to do.. You could use a Grid instead of a canvas, and the Thumb will size automatically. Canvas does not really have a height, for it does not really care about the height of its children... Hope this helps... ","pontos":0},{"corpo":"If you wait until the page is loaded, and then set the button's display to none, that should work. Then you can make it visible at a later point. ","pontos":0},{"corpo":"Here's my strategy (I use JUnit, but I'm sure there's a way to do the equivalent in PHP): I have a method that runs before all of the Unit Tests for a specific DAO class. It puts the dev database into a known state (adds all test data, etc.). As I run tests, I keep track of any data added to the known state. This data is cleaned up at the end of each test. After all the tests for the class have run, another method removes all the test data in the dev database, leaving it in the state it was in before the tests were run. It's a bit of work to do all this, but I usually write the methods in a DBTestCommon class where all of my DAO test classes can get to them. ","pontos":1},{"corpo":"Make sure the Visible property is set to true or the control won't render to the page. Then you can use script to manipulate it. ","pontos":0},{"corpo":"LinqBridge looks like a pretty nice place to start since I have VS2008, I just need to compile and deploy to a .net 2.0 server. I've looked at SubSonic and it's also an interesting alternative, but linqbridge seems to provide a much closer fit so I'm not going to have to go and learn a new ORM / query syntax. ","pontos":0},{"corpo":"Check out this list on Wikipedia: http://en.wikipedia.org/wiki/Windows_Presentation_Foundation#WPF_Applications So, not really all that much. ","pontos":3},{"corpo":"Hmm nah :) It doesn't seem like it: http://weblogs.asp.net/scottgu/pages/silverlight-tutorial-part-5-using-the-listbox-and-databinding-to-display-list-data.aspx ","pontos":0},{"corpo":"In my opinion: Table names should be plural. Column names should be singular. No. Either CamelCase (my preferred) or underscore_separated for both table names and column names. However, like it has been mentioned, any convention is better than no convention. No matter how you choose to do it, document it so that future modifications follow the same conventions. ","pontos":7},{"corpo":"This is more of a comment than an answer, but wouldn't: XmlDocument doc = new XmlDocument(); doc.Load(\"path\"); Read the entire file at once? Just thought I should raise the point since from the look of Thomas' question, he is concerned about reading large files and wants to break the process down.. ","pontos":1},{"corpo":"Safe mode UID check is used to prevent users from accessing other peoples files. GID is used to prevent a GROUP of users from accessing other GROUPS files. ","pontos":1},{"corpo":"Here's another technique for autosizing a textarea. Uses pixel height instead of line height: more accurate handling of line wrap if a proportional font is used. Accepts either ID or element as input Accepts an optional max height param - useful if you'd rather not let the text area grow beyond a certain size (keep it all on-screen, avoid breaking layout, etc.) Tested on Firefox 3 and IE6 Code: (plain vanilla Javascript) function FitToContent(id, maxHeight) { var text = id id.style ? id : document.getElementById(id); if ( !text ) return; /* Accounts for rows being deleted, pixel value may need adjusting */ if (text.clientHeight == text.scrollHeight) { text.style.height = \"30px\"; } var adjustedHeight = text.clientHeight; if ( !maxHeight || maxHeight adjustedHeight ) { adjustedHeight = Math.max(text.scrollHeight, adjustedHeight); if ( maxHeight ) adjustedHeight = Math.min(maxHeight, adjustedHeight); if ( adjustedHeight text.clientHeight ) text.style.height = adjustedHeight + \"px\"; } } Demo: (uses jQuery, targets on the textarea i'm typing into right now - if you have Firebug installed, paste both samples into the console and test on this page) $(\"#post-text\").keyup(function() { FitToContent(this, document.documentElement.clientHeight) }); ","pontos":31},{"corpo":"I'm using Eclipse with a 64bit VM. However I have to use Java 1.5, because with Java 1.6, even 1.6.0_10ea, Eclipse crashed when changing the .classpath-file. On Linux I had the same problems and could only get the 64bit Eclipse to work with 64bit Java 1.5. The problem seems to be with the just in time compilation, since with vmparam -Xint eclipse works -- but this is not a sollution, because it's slow then. Edit: With 1.6.0_11 it seems to work. 1.6_10 final might work as well as mentioned in the comment, but I've not tested that. ","pontos":5},{"corpo":"If it's only two users, then Access should do just fine if you put the .mdb on a shared drive. Have you tried it first rather than just assume it will be a problem. I believe the recommended max concurrent users for Access is 5 but on occasion I've pushed it past this and never come unstuck. On the other hand I did once use Access as the front end to MySQL in a single user environment (me). It was a singularly unpleasant experience, I can't imagine it would become nicer with two users. ","pontos":0},{"corpo":"fstream are great but I will go a little deeper and tell you about RAII. The problem with a classic example is that you are forced to close the file by yourself, meaning that you will have to bend your architecture to this need. RAII makes use of the automatic destructor call in C++ to close the file for you. Update: seems that std::fstream already implements RAII so the code above is useless. I'll keep it here for posterity and as an example of RAII. class FileOpener { public: FileOpener(std::fstream file, const char* fileName): m_file(file) { m_file.open(fileName); } ~FileOpeneer() { file.close(); } private: std::fstream m_file; }; You can now use this class in your code like this: int nsize = 10; char *somedata; ifstream myfile; FileOpener opener(myfile, \" path to file \"); myfile.read(somedata,nsize); // myfile is closed automatically when opener destructor is called Learning how RAII works can save you some headaches and some major memory management bugs. ","pontos":-1},{"corpo":"@Danny All of these are suitable for both text and binary, though none have a specific readline functionality. The facilities actually do have a function. For reasons I don't understand, it's not part of the class, so lots of people overlook it. (I overlooked it for the longest time.) ","pontos":1},{"corpo":"@Vincent The problem with a classic example is that you are forced to close the file by yourself, meaning that you will have to bend your architecture to this need. RAII makes use of the automatic destructor call in C++ to close the file for you. If you declare an on the stack, it will be closed when the destructor is fired. It already implements RAII. ","pontos":5},{"corpo":"Because of budget constraints I think it will have to beta-tester's approch,i tried following the guide and cant seem to get it working. Before I spend time getting it to work, I just confrim, Replicating between SqlServer 2005 and Compact Edition is something that can be done? ","pontos":0},{"corpo":"No you cannot get the MAC address in JavaScript, mainly because the MAC address uniquely identifies the running computer so it would be a security vulnerability. Now if all you need is a unique identifier, I suggest you create one yourself using some cryptographic algorithm and store it in a cookie. If you really need to know the MAC address of the computer AND you are developing for internal applications, then I suggest you use an external component to do that: ActiveX for IE, XPCOM for Firefox (installed as an extension). ","pontos":10},{"corpo":"You use the post-commit hooks. Here's a guide. Here's a sample Ruby script that sends an email after each commit: commit-email.rb ","pontos":28},{"corpo":"What platform? On Mac OS X I have installed msmtp and created a post-commit script under hooks in the repository. A .msmtprc file needs to be setup for the svn (or www) user. REPOS=\"`echo $1 | sed 's/\\/{root of repository}//g'` \" REV=\"$2\" MSG=`/usr/local/bin/svn log -v -r HEAD https://localhost$REPOS` /usr/local/bin/msmtp {list of recipents} EOF Subject: SVN-Commit $REPOS#$REV MIME-Version: 1.0 Content-Type: text/plain; charset=utf-8 Content-Transfer-Encoding: 8Bit $MSG EOF Make {root of repository} and {list of recipents} specific for your needs. Note I have used UTF8 because we have some special characters here in sweden () ","pontos":1},{"corpo":"I don't think there is. I've tried to solve this problem at my job. Hiding the select control was the best we could come up with (being a corporate shop with a captive audience, user experience doesn't usually factor into the PM's decisions). From what I could gather online when looking for a solution, there's just no good solution to this. I like the FogBugz solution (the same thing done by a lot of high-profile sites, like Facebook), and this is actually what I use in my own projects. ","pontos":0},{"corpo":"Have a look at the standalone Subversion Notify tool (Windows only!) It can do emailing on commit and also much more! ","pontos":16},{"corpo":"a) Must look the same b) As standards-compliant as possible, but not so anal that it blocks finishing work In a situation where you have perpetual access to the code, I don't think standards-compliance is all that important, since you can always make changes to the code if something breaks. If you don't have perpetual access (ie, you sign off on the code and it becomes someone else's responsibility), it's probably best to be as standards-compliant as possible to minimize maintenance headaches later... even if you never have to deal with the code again, your reputation persists and can be transmitted to other potential clients, and many teams like to blame the previous developer(s) for problems that come up. ","pontos":8},{"corpo":"I think validation is a good litmus test of whether you've done things properly, so if there are only a few minor problems, why not fix them and ensure your site will at least be understood correctly by browsers in the future (even if they do render things differently for other reasons)? OTOH, for most projects, validation seems like a huge headache and if you can get things working across browsers, it's not worth spending an extra day/week+ on just validation. ","pontos":0},{"corpo":"As far as I know there are only two options, the better of which is the mentioned usage of an iframe. The other one is hiding all selects when the overlay is shown, leading to an even weirder user experience. ","pontos":2},{"corpo":"I do the same thing with select boxes and Flash. When using an overlay, hide the underlying objects that would push through. It's not great, but it works. You can use JavaScript to hide the elements just before displaying an overlay, then show them again once you're done. I try not to mess with iframes unless it's absolutely necessary. The trick of using labels or textboxes instead of select boxes during overlays is neat. I may use that in the future. ","pontos":0},{"corpo":"Daniel's and Eldila's answer have one problem: They remove all quotes and commas in the whole file. What I usually do when I have to do something like this is to first replace all separating quotes and (usually) semicolons by tabs. Search: \";\" Replace: \\t Since I know in which column my affected values will be I then do another search and replace: Search: ^([\\t]+)\\t([\\t]+)\\t([0-9]+),([0-9]+)\\t Replace: \\1\\t\\2\\t\\3\\4\\t ... given the value with the comma is in the third column. You need to start with an \"^\" to make sure that it starts at the beginning of a line. Then you repeat ([0-9]+)\\t as often as there are columns that you just want to leave as they are. ([0-9]+),([0-9]+) searches for values where there is a number, then a comma and then another number. In the replace string we use \\1 and \\2 to just keep the values from the edited line, separating them with \\t (tab). Then we put \\3\\4 (no tab between) to put the two components of the number without the comma right after each other. All values after that will be left alone. If you need your file to have semicolon to separate the elements, you then can go on and replace the tabs with semicolons. However then - if you leave out the quotes - you'll have to make sure that the text values do not contain any semicolons themselves. That's why I prefer to use TAB as column separator. I usually do that in an ordinary text editor (EditPlus) that supports RegExp, but the same regexps can be used in any programming language. ","pontos":-1},{"corpo":"I turn to... DESIGNERS! I remember Jeff Atwood posting about this on Coding Horror a while ago, but it deserves to be said again: programmers make terrible designers! There's sites like 99designs (stack overflow used it to obtain their logo) where you can hire out the work for fairly cheap. ","pontos":3},{"corpo":"My command does remove all ',' and '\"'. In order to convert the sting \"1,000\" more strictly, you will need the following command. Perl -lne 's/\"(\\d+),(\\d+)\"/$1$2/; print' file.txt newfile.txt ","pontos":0},{"corpo":"You don't actually have to use the generated class that the WSDL gives you. If you take a look at the code that it generates, it's just making calls into some .NET framework classes to submit SOAP requests. In the past I have copied that code into a normal .cs file and edited it. Although I haven't tried this specifically, I see no reason why you couldn't drop the proxy class definition and use the original class to receive the results of the SOAP call. It must already be doing reflection under the hood, it seems a shame to do it twice. ","pontos":3},{"corpo":"Danny is mostly right. a. unsigned decimal, minimum 4 characters, space padded b. floating point, minimum 16 digits before the decimal (0 padded), 1 digit after the decimal c. hex, minimum 4 characters, 0 padded, letters are printed in upper case d. same as above, but minimum 2 characters e. e is assumed to be an int, converted to an unsigned char and printed f. same as e g. This is likely a typo, the 4 has no effect. If it were \"%.4s\", then a maximum of 4 characters from the string would be printed. It is interesting to note that in this case, the string does not need to be null terminated. Edit: jj33 points out 2 errors in b and g above here. ","pontos":5},{"corpo":"@Jason Day, I think the 4 in the last %4s is significant if there are fewer than 4 characters. If there are more than 4 you are right, %4s and %s would be the same, but with fewer than 4 chars in g %s would be left justified and %4s would be right-justified in a 4 char field. b is actually minimum 16 chars for the whole field, including the decimal and the single digit after the decimal I think (16 total chars vs 18 total chars) ","pontos":5},{"corpo":"To draw a centered text: TextRenderer.DrawText(g, \"my text\", Font, Bounds, ForeColor, BackColor, TextFormatFlags.HorizontalCenter | TextFormatFlags.VerticalCenter | TextFormatFlags.GlyphOverhangPadding); Determining optimal font size to fill an area is a bit more difficult. One working soultion I found is trial-and-error: start with a big font, then repeatedly measure the string and shrink the font until it fits. Font FindBestFitFont(Graphics g, String text, Font font, Size proposedSize, TextFormatFlags flags) { // Compute actual size, shrink if needed while (true) { Size size = TextRenderer.MeasureText(g, text, font, proposedSize, flags); // It fits, back out if ( size.Height = proposedSize.Height size.Width = proposedSize.Width) { return font; } // Try a smaller font (90% of old size) Font oldFont = font; font = new Font(font.FontFamily, (float)(font.Size * .9)); oldFont.Dispose(); } } You'd use this as: Font bestFitFont = FindBestFitFont(g, text, someBigFont, sizeToFitIn, flags); // Then do your drawing using the bestFitFont // Don't forget to dispose the font (if/when needed) ","pontos":4},{"corpo":"Here you go. I started with ScottGu's explanation/examples and went from there: http://weblogs.asp.net/scottgu/archive/2007/05/19/using-linq-to-sql-part-1.aspx ","pontos":1},{"corpo":"Actually nlucaroni, your case isn't quite right. Your example doesn't include double-quotes, so id,age,name,... 1,23,phil, won't match my regex. It requires the format \"XXX,XXX\". I can't think of an example of when it will match incorrectly. All the following example won't include the deliminator in the regex: \"111,111\",234 234,\"111,111\" \"111,111\",\"111,111\" Please let me know if you can think of a counter-example. Cheers! ","pontos":0},{"corpo":"If you understand the process of retain/release then there are two golden rules that are \"duh\" obvious to established Cocoa programmers, but unfortunately are rarely spelled out this clearly for newcomers. **1) If a function which returns an object has 'alloc', 'create' or 'copy' in its name then the object is yours. You must call [object release] when you are finished with it. Or CFRelease(object) if it's a Core-Foundation object. 2) If it does NOT have one of these words in its name then the object belongs to someone else. You must call [object retain] if you wish to keep the object after the end of your function.** You would be well served to also follow this convention in functions you create yourself. (Nitpickers: Yes, there are unfortunately a few API calls that are exceptions to these rules but they are rare). ","pontos":8},{"corpo":"I think the best thing that extension methods replace are all those utility classes that you find in every project. At least for now, I feel that any other use of Extension methods would cause confusion in the workplace. My two bits. ","pontos":5},{"corpo":"Printing from a Windows service is really painful. It seems to work... sometimes... but finally it craches or throws an exception from time to time, without any clear reason. It's really hopeless. Officially, it's even not supported, without any explanation, nor any proposal for an alternate solution. Recently, I have been confronted to the problem and after several unsuccessful trials and experimentations, I came finally with two viable solutions: Write your own printing DLL using the Win32 API (in C/C++ for instance), then use it from your service with P/Invoke (works fine) Write your own printing COM+ component, then uses it from your service. I have chosen this solution with success recently (but it was third party COM+ component, not own written) It works absolutely fine too. ","pontos":8},{"corpo":"ORM everytime, the least I have to think about databases the better. ","pontos":4},{"corpo":"Here is a good case for regular expressions. You can run a find and replace on the data either before you import (easier) or later on if the SQL import accepted those characters (not nearly as easy). But in either case, you have any number of methods to do a find and replace, be it editors, scripting languages, GUI programs, etc. Remember that you're going to want to find and replace all of the bad characters. A typical regular expression to find the comma and quotes (assuming just double quotes) is: (Blacklist) /[,\"]/ Or, if you find something might change in the future, this regular expression, matches anything except a number or decimal point. (Whitelist) /[^0-9\\.]/ What has been discussed by the people above is that we don't know all of the data in your CSV file. It sounds like you want to remove the commas and quotes from all of the numbers in the CSV file. But because we don't know what else is in the CSV file we want to make sure that we don't corrupt other data. Just blindly doing a find/replace could affect other portions of the file. ","pontos":1},{"corpo":"I seriously doubt you're going to find a markup language for GIU's that's not tied to a specific library. For such a thing to exist, there would need to be a standardized GUI markup language, with several implementations. ","pontos":2},{"corpo":"I really like the 3 + 1 tier way of doing things. One tier for UI, one for business logic, and for persisting data. The last one you say? Domain objects and interfaces. This makes it possible to load up any one or two of the main tiers plus the domain \"tier\", and the code should work. It relies heavily on dependency injection and Inversion of Control principles. The data/persistence tier does only two things. It creates, reads, updates and deletes data, and maps it to the domain object format. The UI tier does the exact opposite. It displays and receives data in a way that the user can relate to, and maps that output/input to and from the domain object format. The business logic tier just need to know one thing. Business logic. It does not care about where the data is from, and it does not care about where the data tier is putting it. It knows that it should flag an account that was just overdrawn, how to physically do that is not part of its job really. The domain objects themselves does not have any logic, they are just containers for passing data between the tiers. This means that you can load the domain objects and interfaces without having to think at all about dependencies. At the end of the day I feel that I have a pretty clear code base with clearly separated tiers. And with some strict interfaces and good base classes most of the coding is just telling the software what to do when X happens. Just how it is supposed to be. /rant Edit: Oh, yeah. This is true for both the LINQ, SubSonic, and other ORMs. ","pontos":3},{"corpo":"This guy seems to have your answer. http://damieng.com/blog/2006/08/08/Calculating_CRC32_in_C_and_NET ","pontos":9},{"corpo":"I love the way SubSonic does the one column only thing. Either DataBaseTable.GetList(DataBaseTable.Columns.ColumnYouWant) , or: Query q = DataBaseTable.CreateQuery() .WHERE(DataBaseTable.Columns.ColumnToFilterOn,value); q.SelectList = DataBaseTable.Columns.ColumnYouWant; q.Load(); But Linq is still king when it comes to lazy loading. ","pontos":1},{"corpo":"Well, there's a reason for the fact that there is no obvious choice for a python web framework. There are quite a few, as the other guys pointed out, and none of them seem to prevail. There was some interesting project called Tesla, which worked pretty well, and had additional features that pylons miss (migrations etc.), but seems unmaintained. Even though I would agree, that the best thing for your situation would be pylons, it definitely is not the easiest frameworks to learn. There is quite a learning curve to pylons, as there is to django by the way. But, since pylons has all the rails helpers ported, I would suggest you should also check Rails and maybe merb (both written in Ruby), as they might give you (especially rails) an easy introduction to the web frameworks and sort of \"feel\" of what it is to the framework, what to expect, what's cool and so on. Anyhow, what I feel with Python web framework is that there is a pethora of choices (template systems, ORMs and so on) and the user, who has just heard of web frameworks gets lost in translation. There's just to much to choose from. I also prefer Python over Ruby, but when web frameworks are concerned I have to give to DHH - Rails framework simply rocks as far as developing code is concerned. ","pontos":0},{"corpo":"Short answer: when it's only going to happen once in a long time. Long Answer. ","pontos":3},{"corpo":"The standard is to throw the NullPointerException. The generally infallible \"Effective Java\" discusses this briefly in Item 42 (in the first edition) or Item 60 (in the second edition) \"Favor the use of standard exceptions\": \"Arguably, all erroneous method invocations boil down to an illegal argument or illegal state, but other exceptions are standardly used for certain kinds of illegal arguments and states. If a caller passes null in some parameter for which null values are prohibited, convention dictates that NullPointerException be thrown rather than IllegalArgumentException.\" ","pontos":98},{"corpo":"@Hugo regarding threadlocal: I thought about that solution. However, from experiments I found two problems with that approach: Shared thread (server connections, etc) are problematic. This can be solved though by paying special attention to these thread (they're all under my control and are pretty much isolated from the legacy code). The EDT thread is shared across all applets. I failed to find a way to force the creation of a new EDT thread for each applet. This means that the threadlocal for the EDT would be shared across the applets. This one I have no idea how to solve. Suggestions? ","pontos":0},{"corpo":"I don't get this part here: This worked okay, but there was no easy way of checking if x[3][24] was supposed to exist or not (so I couldn't raise the seasonnotfound exception) There is a way to do it - called in: x={} x[1]={} x[1][2]={} x {1: {2: {}}} 2 in x[1] True 3 in x[1] False what seems to be the problem with that? ","pontos":0},{"corpo":"Apparently this is a bug. Because they are adding it to potential rendering values, they just forgot to include it. I would recommend creating a bug on codeplex, and download the source and modify it for your needs. ","pontos":0},{"corpo":"It is very common and generally a good practice for any build process to do a 'clean' before doing any significant build. This prevents any 'artifacts' from previous builds to taint the output. A clean is essentially what you are doing by deleting the working copy. ","pontos":0},{"corpo":"That looks correct: http://dev.mysql.com/doc/refman/5.0/en/binary-log.html#option_mysqld_binlog-ignore-db. According to that reference: There are some --binlog-ignore-db rules. Does the default database match any of the --binlog-ignore-db rules? Yes: Do not write the statement, and exit. No: Write the query and exit. Since you only have ignore commands, all queries will be written to the log as long as the default (active) database doesn't match one of the ignored databases. ","pontos":6},{"corpo":"Doing a full delete before or after your build is good practice. This means that there is no chance of your build environment picking up an out of date file. Your building exactly against what is in the repository. Deleting the working copy is possible as I have done it with Nant. In Nant I would have a clean script in its own folder outwith the one I want to delete and would then invoke it from CC.net. I assume this should also be possible with a batch file. Take a look at the rmdir command http://www.computerhope.com/rmdirhlp.htm @pauldoo I prefer my CI server to do a full delete as I don't want any surprise when I go to do a release build, which should always be done from a clean state. But it should be able to handle both, no reason why not ","pontos":8},{"corpo":"There's ActiveRecord the Design Pattern and ActiveRecord the Rails ORM Library, and there's also a ton of knock-offs for .NET, and other languages. These are all different things. They mostly follow that design pattern, but extend and modify it in many different ways, so before anyone says \"ActiveRecord Sucks\" it needs to be qualified by saying \"which ActiveRecord, there's heaps?\" I'm only familiar with Rails' ActiveRecord, I'll try address all the complaints which have been raised in context of using it. @BlaM The problem that I see with Active Records is, that it's always just about one table Code: class Person belongs_to :company end people = Person.find(:all, :include = :company ) This generates SQL with , and automatically generates associated Company objects so you can do and it doesn't need to hit the database because the data is already present. @pix0r The inherent problem with Active Record is that database queries are automatically generated and executed to populate objects and modify database records Code: person = Person.find_by_sql(\"giant complicated sql query\") This is discouraged as it's ugly, but for the cases where you just plain and simply need to write raw SQL, it's easily done. @Tim Sullivan ...and you select several instances of the model, you're basically doing a \"select * from ...\" Code: people = Person.find(:all, :select= 'name, id') This will only select the name and ID columns from the database, all the other 'attributes' in the mapped objects will just be nil, unless you manually reload that object, and so on. ","pontos":83},{"corpo":"Well, it is going to go away as the answer to all these questions will be LINQ. Incidentally, we have never needed custom connection pooling for any of our applications, so I am not sure what all the noise is about. ","pontos":-2},{"corpo":"I have not yet developed using WPF.. But I would assume that its the same as most other applications in that you want to keep the UI code as light as possible.. A number of design patterns may be used in this such as the obvious MVC and Faade. I personally always try and keep the objects travelling between the UI and BL layers as light as possible, keeping them to primitives if I can. This then helps me focus on improving the UI layer without the concerns of anything going on once I throw my (primitive) data back.. I hope I understood your question correctly, and sorry I cannot offer more contextual help with WPF. ","pontos":0},{"corpo":"You can open the file, go to 0 offset relative from the bottom of the file with #define SEEKBOTTOM 2 fseek(handle, 0, SEEKBOTTOM) the value returned from fseek is the size of the file. I didn't code in C for a long time, but I think it should work. ","pontos":-2},{"corpo":"Matt's solution should work, except that it's C++ instead of C, and the initial tell shouldn't be necessary. unsigned long fsize(char* file) { FILE * f = fopen(file, \"r\"); fseek(f, 0, SEEK_END); unsigned long len = (unsigned long)ftell(f); fclose(f); return len; } Fixed your brace for you, too. ;) Update: This isn't really the best solution. It's limited to 4GB files on Windows and it's likely slower than just using a platform-specific call like or . ","pontos":15},{"corpo":"Edit my post (see footnote). Some of us are maintaining sites built in 1999. If you find an SQL injection vulnerability in ASP 3.0, maybe this will help. Don't do this: DBConn.Execute(\"UPDATE members SET photo = '\" + gblSQLSafe(fileName) + \"' WHERE memberID = \" + memberid); Here, gblSQLSafe() doubles up single quotes in the string. Instead do something like this: objCmd.CommandType = adCmdText; objCmd.CommandText = \"UPDATE members SET photo = @filename WHERE memberID = @memberID\"; objCmd.Parameters.Append(objCmd.CreateParameter(\"@memberID\", adInteger, adParamInput, 4, memberid )); objCmd.Parameters.Append(objCmd.CreateParameter(\"@filename\", adVarChar, adParamInput, 510, fileName)); objCmd.Execute(adExecuteNoRecords); gblDelobjParams(objCmd); That said, if you have 50 legacy sites with no time to actually change all the darned code on all of them, try something like UrlScan for iis6 and 7; dotDefender for pay which also covers Apache or IIS 5-7 or SQL Injection sanitation ISAPI for IIS6. Please note that my ASP 3 is rusty and this code threw an error on my db about a variable (filename) not being assigned. I'm actually testing how stackoverflow might allow someone to correct an erroneous response or improve on it. So if no one fixes or supersedes this, I'll probably delete it soon enough. ","pontos":2},{"corpo":"Ctrl+Alt+E (or Debug\\Exceptions) From there you can select which exceptions break. ","pontos":0},{"corpo":"Printing from a service is a bad idea. Network printers are connected \"per-user\". You can mark the service to be run as a particular user, but I'd consider that a bad security practice. You might be able to connect to a local printer, but I'd still hesitate before going this route. The best option is to have the service store the data and have a user-launched application do the printing by asking the service for the data. Or a common location that the data is stored, like a database. If you need to have the data printed as regular intervals, setup a Task event thru the Task Scheduler. Launching a process from a service will require knowing the user name and password, which again is bad security practice. As for the printing itself, use a third-party tool to generate the report will be the easiest. ","pontos":4},{"corpo":"Don't use . Files over 2 gigabytes in size are common as dirt these days Don't use . Files over 4 gigabytes in size are common as some slightly-less-common dirt IIRC the standard library defines as an unsigned 64 bit integer, which is what everyone should be using. We can redefine that to be 128 bits in a few years when we start having 16 exabyte files hanging around. If you're on windows, you should use GetFileSizeEx - it actually uses a signed 64 bit integer, so they'll start hitting problems with 8 exabyte files. Foolish Microsoft! :-) ","pontos":47},{"corpo":"Our build people use Mozilla Tinderbox. It seems to have some hooks for distributed testing. I'm sorry not to know the details but I thought I would at least pass on the pointer to you. It's also nice coz you can find out immediately when a build breaks, and what checkin might have been the culprit. http://www.mozilla.org/tinderbox.html ","pontos":1},{"corpo":"I sometimes use The World's Simplest Code Generator (Javascript edition). It's online, but it's just javascript - your data doesn't go anywhere. There's also an asp version though, with more features. ","pontos":8},{"corpo":"davex.dll is the legacy webdav component for Exchange server, which Entourage uses. Your first step should be investigating why the application pool crashes. My guess is that Entourage can't do anything when the dll isn't present because webdav is not responding to any requests. ","pontos":0},{"corpo":"I can't imagine drawing icons online. Nowadays icons are usually drawn as vectors, and I'm not aware of any online vector packages. In case you decide to draw off-line instead, I use Xara (www.xara.com) to draw all my computer artwork, and I use Gif Movie Gear to create .ico files. The former is a superb vector package, the latter is just something I have lying around. ","pontos":0},{"corpo":"As someone else said, 'what platform'. On Windows I've used 'blat', which is a freebie command line SMTP mailer to do this, along with a post-commit and another batch file. The post commit looks like this: (Just calls another batch file) call d:\\subversion\\repos\\rts\\hooks\\mail %1 %2 And mail.bat looked like this: copy d:\\subversion\\repos\\RTS\\hooks\\Commitmsg.txt %temp%\\commit.txt copy d:\\subversion\\repos\\RTS\\hooks\\subjbase.txt %temp%\\subject.txt svnlook info -r %2 %1 %temp%\\commit.txt echo Revision %2 %temp%\\commit.txt svnlook changed -r %2 %1 %temp%\\commit.txt svnlook author -r %2 %1 %temp%\\subject.txt c:\\utils\\blat %temp%\\commit.txt -t me@my.email.com -sf %temp%\\subject.txt -server ServerName -f \"SVN Admin svn@my.email.com \" -noh2 The biggest gotcha in writing SVN hooks is that you might have basically NO environment set-up - no exe path, no temp path, etc. Though maybe that's improved in more recent SVN builds. ","pontos":1},{"corpo":"Is this an exception that your code would actually handle if you weren't running in the debugger? ","pontos":5},{"corpo":"Unless you want to do something a little complex, using the generic views are the way to go. They are far more powerful than their name implies, and if you are just displaying model data generic views will do the job. ","pontos":1},{"corpo":"This defect (found here) points the way to the solution. The Tomcat instance that runs in JBoss is configured with emptySessionPath=\"true\", rather than \"false\", which is the default. This can be modified in ; both the HTTP and AJP connectors have this option. The feature itself is used to eliminate the context path (eg. \"foo\" in http://example.com/foo) from being included in the JSESSIONID cookie. Setting it to false will break applications that rely on cross-application authentication, which includes stuff built using some portal frameworks. It didn't negatively affect the application in question, however. ","pontos":6},{"corpo":"@Dan, Do I not need msdtc enabled for transactions to work? Only distributed transactions - Those that involve more than a single connection. Make doubly sure you are only opening a single connection within the transaction and it won't escalate - Performance will be much better too. ","pontos":4},{"corpo":"You could consider log4net. It is a robust logging framework that exists in a single DLL. It is also done in a \"non demanding\" type mode so that if a critical process is going on, it won't log until resources are freed up a bit more. You could easily setup a bunch of INFO level loggers and track all the user interaction you needed, and it wouldn't take a bug crash to send the file to yourself. You could also then log all your ERROR and FATAL code to seperate file that could easily be mailed to you for processing. ","pontos":2},{"corpo":"One thing I've done in the past - if I'm extending a class I'll try and follow their conventions. For example, when working with the Spring Framework, I'll have my MVC Controller classes in a package called com.mydomain.myapp.web.servlet.mvc If I'm not extending something I just go with what is simplest. com.mydomain.domain for Domain Objects (although if you have a ton of domain objects this package could get a bit unwieldy). For domain specific constants, I actually put them as public constants in the most related class. For example, if I have a \"Member\" class and have a maximum member name length constant, I put it in the Member class. Some shops make a separate Constants class but I don't see the value in lumping unrelated numbers and strings into a single class. I've seen some other shops try to solve this problem by creating SEPARATE Constants classes, but that just seems like a waste of time and the result is too confusing. Using this setup, a large project with multiple developers will be duplicating constants all over the place. ","pontos":0},{"corpo":"I'm not 100% sure about VS2008, but I know that the Unit Testing framework that microsoft shipped in VS2005 as part of their Team Suite was only for .NET, not C++ I've used CppUnit also and it was alright. Much the same as NUnit/JUnit/so on. If you've used boost, they also have a unit testing library The guys behind boost have some serious coding chops, so I'd say their framework should be pretty good, but it might not be the most user friendly :-) ","pontos":0},{"corpo":"I'd like to support Will Dean's answer An access violation sounds like an actual bug in your code. It's not something I'd expect the underlying C/++ Runtime to be throwing and catching internally. The 'first-chance-exceptions' feature is so you can intercept things which get 'caught' in code, using the debugger, and have a look. If there's nothing 'catching' that exception (which makes sense, why on earth would you catch and ignore access violations?), then it will trigger the debugger regardless of what options you may have set. ","pontos":4},{"corpo":"If, while writing your code, you expect this object to be in the collection, and then during runtime you find that it isn't, I would call that an exceptional case, and it is proper to use an exception. However, if you're simply testing for the existence of an object, and you find that it is not there, this is not exceptional. Using an exception in this case is not proper. The analysis of the runtime performance depends on the actual collection being used, and the method if searching for it. That shouldn't matter though. Don't let the illusion of optimization fool you into writing confusing code. ","pontos":0},{"corpo":"You can try Firebug Lite or use Visual Studio to debug the JavaScript. ","pontos":13},{"corpo":"In general, using exception handling for program flow and logic is bad practice. I personally feel that the latter option is unacceptable use of exceptions. Given the features of languages commonly used these days (such as Linq and lambdas in C# for example) there's no reason not to write your own Contains() method. As a final thought, these days most collections do have a contains method already. So I think for the most part this is a non-issue. ","pontos":0},{"corpo":"I would have to say that this is pretty bad practice. Whilst some people might be happy to say that looping through the collection is less efficient to throwing an exception, there is an overhead to throwing an exception. I would also question why you are using a collection to access an item by key when you would be better suited to using a dictionary or hashtable. My main problem with this code however, is that regardless of the type of exception thrown, you are always going to be left with the same result. For example, an exception could be thrown because the object doesn't exist in the collection, or because the collection itself is null or because you can't cast myCollect[myObject] to aObject. All of these exceptions will get handled in the same way, which may not be your intention. These are a couple of nice articles on when and where it is usally considered acceptable to throw exceptions: Foundations of Programming Throwing exceptions in c# I particularly like this quote from the second article: It is important that exceptions are thrown only when an unexpected or invalid activity occurs that prevents a method from completing its normal function. Exception handling introduces a small overhead and lowers performance so should not be used for normal program flow instead of conditional processing. It can also be difficult to maintain code that misuses exception handling in this way. ","pontos":2},{"corpo":"The IE8 beta comes with what I think is the IE Developer toolbar, but it seems to be a lot more powerful than the last time I tried the toolbar on IE7 ","pontos":0},{"corpo":"This has not been tested but I think this should work using mod_rewrite RewriteEngine On RewriteCond %{HTTPS} on RewriteRule (.*) http://%{HTTP_HOST}%{REQUEST_URI} ","pontos":65},{"corpo":"Seconded for e-texteditor. I use it daily and it's great (although not without it's share of BUGS). For the rails side of things though, I'd actually suggest a virtual machine running linux. Ubuntu works well, the only caveat is that you have to install manually, as it does not adhere to the great debian filesystem naming ideology :-( I suggest this because if you want to do \"advanced\" things, such as installing ImageMagick/RMagick, or memcached, or a number of other plugins which require native C libraries, it becomes very painful very quickly if you're on windows. A second reason is that unless you are very atypical, your production server will likely be running linux too. It's good practice to have your development environment match your deployment environment as closely as possible, to help you find and fix bugs earlier and more easily, and avoid fixing bugs that won't affect your production site (like windows specific ones) Microsoft Virtual PC and VMWare both have free options, which work well, and are plenty fast, so this is not a problem. ","pontos":2},{"corpo":"Based on NilObject's code: #include sys/stat.h off_t fsize(const char *filename) { struct stat st; if (stat(filename, st) == 0) return st.st_size; return -1; } Changes: Made the filename argument a . Corrected the definition, which was missing the variable name. Returns on error instead of , which would be ambiguous for an empty file. is a signed type so this is possible. If you want to print a message on error, you can use this: #include sys/stat.h #include string.h #include stdio.h #include errno.h off_t fsize(const char *filename) { struct stat st; if (stat(filename, st) == 0) return st.st_size; fprintf(stderr, \"Cannot determine size of %s: %s\\n\", filename, strerror(errno)); return -1; } On 32-bit systems you should compile this with the option , otherwise will only hold values up to 2 GB. See the \"Using LFS\" section of Large File Support in Linux for details. ","pontos":75},{"corpo":"In Internet Explorer, select View -> Script Debugger -> Open. That should do it. ","pontos":0},{"corpo":"I like break my classes down into packages that are related to each other. For example: Model For database related calls View Classes that deal with what you see Control Core functionality classes Util Any misc. classes that are used (typically static functions) etc. ","pontos":0},{"corpo":"Firebug lite doesn't work too well for me. The Developer Toolbar just isn't good enough. There really is no great solution. ","pontos":6},{"corpo":"Exceptions should be exceptional. Something like 'The collection is missing because the database has fallen out from underneath it' is exceptional Something like 'the key is not present' is normal behaviour for a dictionary. For your specific example of a winforms Control collection, the property has a method, which is what you're supposed to use. There's no because when dealing with dictionaries/hashtables, there's no fast way short of iterating through the entire collection, of checking if something is present, so you're really discouraged from doing that. As for WHY Exceptions should be exceptional, it's about 2 things Indicating what your code is trying to do. You want to have your code match what it is trying to achieve, as closely as possible, so it is readable and maintainable. Exception handling adds a bunch of extra cruft which gets in the way of this purpose Brevity of code. You want your code to do what it's doing in the most direct way, so it is readable and maintainable. Again, the cruft added by exception handling gets in the way of this. ","pontos":0},{"corpo":"Unless your SSL certificate is the \"wildcard\" or multi-site kind, then I don't think this will work. The rewrite will display in the browser and the name in the address bar must be valid against the certificate, or your users will see a security error (which they can always accept and continue, but that doesn't sound like what you'd like). More here. ","pontos":2},{"corpo":"awk The AWK utility is an interpreted programming language typically used as a data extraction and reporting tool. It is a standard feature of most Unix-like operating systems. AWK uses a data-driven scripting language consisting of a set of actions to be taken against textual data (either in files or data streams) for the purpose of producing formatted reports. The language extensively uses the string datatype, associative arrays (that is, arrays indexed by key strings), and regular expressions. ","pontos":0},{"corpo":"From memory SSRS has built in logging for this exact situation ","pontos":1},{"corpo":"I have to say that I don't use the hourly recurrence feature as really how many people have events that repeat in the same day? I could see if someone however was to schedule when they needed to take a particular medicine at recurring times throughout the day. I would say support full features in the application itself, but provide a warning when they go to export the calendar that all event details may not work as expected or find a way to export in a different manner for Outlook alone that does provide the hourly recurrence feature. ","pontos":1},{"corpo":"I think keep it simple and don't over think it. Don't over abstract and layer too much. Just keep it neat, and as it grows, refactoring it is trivial. One of the best features of IDEs is refactoring, so why not make use of it and save you brain power for solving problems that are related to your app, rather then meta issues like code organisation. ","pontos":0},{"corpo":"Add a second (empty) table immediately after the first. Page break after that. ","pontos":0},{"corpo":"I believe you need to add a section with Directory \"/home/other_files\" (options) /Directory to your server configuration before apache will be able to serve anything from it. For an example, my DocumentRoot is /var/www but there is this section in the default available site: Alias /doc/ \"/usr/share/doc/\" Directory \"/usr/share/doc/\" Options Indexes MultiViews FollowSymLinks AllowOverride None Order deny,allow Deny from all Allow from 127.0.0.0/255.0.0.0 ::1/128 /Directory You could then rewrite a URL to go to /doc/ and the server would know where to get the files from. ","pontos":8},{"corpo":"You can also do this [Flags] public enum MyEnum { None = 0, First = 1 0, Second = 1 1, Third = 1 2, Fourth = 1 3 } I find the bit-shifting easier than typing 4,8,16,32 and so on. It has no impact on your code because it's all done at compile time ","pontos":419},{"corpo":"I haven't used MSVC6 in years, but I remember the debugger basically being a flaky piece of crap. Things like this would regularly happen for no apparent reason because it just didn't like your code that day. In addition to the debugger being a flaky piece of crap, the rest of it was too. It's STL implementation isn't threadsafe, it doesn't support very much of the C++ standard, and the IDE is sorely lacking in niceties. I'm pretty sure you also just simply can't use any versions of the Platform SDK from the last 5 years because it's too old to grok them. Not a good thing. You'd be mad to keep using it when there is Visual C++ Express 2008 which you can download for free. ","pontos":-1},{"corpo":"What you are asking for is handled at the OS level. Once the data is in your program, it is liable to be paged out. For accessing the memory, a motivated individual can attach a hardware debugger. ","pontos":2},{"corpo":"Be sure it isn't something Google can answer though. Which also shows an issue with that --order of operations! ","pontos":26},{"corpo":"Although we all should know basic maths, the math puzzle could cause some confusion. In your example I'm sure some people would answer with \"8\" instead of \"1\". Would a simple string of text with random characters highlighted in bold or italics be suitable? The user just needs to enter the bold/italic letters as the CAPTCHA. E.g. *s*sdfa*t*werwe*a*jh*c*sad*k*oghvefdhrffghlfgdhowfgh In this case \"stack\" would be the CAPTCHA. There are obviously numerous variations on this idea. Edit: Example variations to address some of the potential problems identified with this idea: using randomly coloured letters instead of bold/italic. using every second red letter for the CAPTCHA (reduces the possibility of bots identifying differently formatted letters to guess the CAPTCHA) ","pontos":15},{"corpo":"Let's take this a bit at a time: I want to create an allocator which provides memory with the following attributes: That's fair enough. * cannot be paged to disk. That's going to be hard. As far as I am aware, you cannot disable Virtual Paging as it is handled by the OS. If there is a way, then you'll be spelunking in the bowels of the OS. * is incredibly hard to access through an attached debugger You could run it through PGP and store it encrypted in memory and unencrypt it as needed. Massive performance hit. The idea is that this will contain sensitive information (like licence information) which should be inaccessible to the user. I have done the usual research online and asked a few other people about this, but I cannot find a good place start on this problem. Keep all sensitive information off the machine. Seriously. Don't store sensitive information in memory. Write a custom delete routine that will automatically remove all data from any allocations you perform. Never allow general access to a machine with sensitive material on it. If you perform db access, make sure all access is sanitized before firing. Only people with specific log-ins are allowed to access. No general group access. On a side note, what other methods are there of accessing the memory of a process other than attaching a debugger? Taking a dump of the memory. ","pontos":5},{"corpo":"You can also try using data validation if users commit data before you use it. Doing that I found was fairly simple and cleaner than fiddling about with keys. Otherwise, you could always disable Paste too! ","pontos":1},{"corpo":" The advantage of this approach is that, for most people, the CAPTCHA won't ever be visible! I like this idea, is there not any way we can just hook into the rep system? I mean, anyone with say +100 rep is likely to be a human. So if they have rep, you need not even bother doing ANYTHING in terms of CAPTCHA. Then, if they are not, then send it, I'm sure it wont take that many posts to get to 100 and the community will instantly dive on anyone seem to be spamming with offensive tags, why not add a \"report spam\" link that downmods by 200? Get 3 of those, spambot achievement unlocked, bye bye ;) EDIT: I should also add, I like the math idea for the non-image CAPTCHA. Or perhaps a simple riddle-type-thing. May make posting even more interesting ^_^ ","pontos":42},{"corpo":"You can't really protect against memory access. You can probably prevent paging if you are running as an admin or as the system, but you cannot prevent the admin or system from reading your memory. Even if you could somehow completely block other processes from reading your memory (which you can't), another process could still actually inject a new thread into your process and read the memory that way. Even if you could somehow completely lock down your process and guarantee that the OS would never allow anyone else to access your process, you still don't have full protection. The entire OS could be running in a virtual machine, which could be paused and inspected at any time. You cannot protect memory contents from the owner of the system. Hollywood and the music industry have been aching for this for years. If it were possible, they'd already be doing it. ","pontos":16},{"corpo":"What about a honeypot captcha? ","pontos":37},{"corpo":"@graham You could run it through PGP and store it encrypted in memory and unencrypt it as needed. Massive performance hit. Then you'd have to hold the key in memory. That would make it a little harder, but definitely not impossible. Anyone motivated will still manage to get the data from memory. ","pontos":0},{"corpo":"Stop beating on VC6. It's old. The STL was updated in 1996 from HP code written in 1994. C++ was ratified in 1998. What is the code doing when you are breaking? Can you reduce the situation into a simple test. When I try that I usually find the cause. If you can do that so it still happens then I'll take a look at it for you. I too am unfortunate enough to use VC6 for my day to day work. Visual C++ Express 2008 can't be used in certain situations. ","pontos":1},{"corpo":"In your route, get rid of the {paramName} part of the URL. It should be: TestController.mvc/TestAction As that is the URL you want the request to route to. Your form will then post to that URL. Posted form values are mapped to parameters of an action method automatically, so don't worry about not having that data passed to your action method. ","pontos":3},{"corpo":"My current solution is to create an exact searcher and a prefix searcher, both sorted by reverse population, and then copy out all my hits starting from the exact hits, moving to the prefix hits. It makes paging my results slightly more annoying than I think it should be. Also I used a hash to eliminate duplicates but later changed the prefix searcher into a boolean query of a prefix search (MUST) with an exact search (MUST NOT), to have Lucene remove the duplicates. Though this seemed even more wasteful. Edit: Moved to a comment (since the feature now exists): Yuval F Thank you for your blog post ... How would the sort comparator know that the name field \"london\" exactly matches the search term \"london\" if it cannot access the search term? ","pontos":0},{"corpo":"@roo I was really hoping that is was possible, and that I just hadn't found it yet. Your example just made me realise that that is exactly what we are trying to do - only allow access to files in the context of our program and so preserve the IP. I guess I have to accept that there is no truly secure way to store someones files on another computer, especially if at some point access is allowed to that file by the owner. That's definitely the problem. You can store something securely so long as you never grant access, but as soon as you grant access, your control is gone. You can make it a little bit more difficult, but that's all. ","pontos":0},{"corpo":"Who says you have to create all the images on the server with each request? Maybe you could have a static list of images or pull them from flickr. I like the \"click on the kitten\" captcha idea. http://www.thepcspy.com/kittenauth ","pontos":3},{"corpo":"@lance Who says you have to create all the images on the server with each request? Maybe you could have a static list of images or pull them from Flickr. I like the \"click on the kitten\" CAPTCHA idea. http://www.thepcspy.com/kittenauth. If you pull from a static list of images, it becomes trivial to circumvent the CAPTCHA, because a human can classify them and then the bot would be able to answer the challenges easily. Even if a bot can't answer all of them, it can still spam. It only needs to be able to answer a small percent of CAPTCHAs, because it can always just retry when an attempt fails. This is actually a problem with puzzles and such, too, because it's extremely difficult to have a large set of challenges. ","pontos":1},{"corpo":"I believe that you can use . The lock statement just translates to a call and a block. ","pontos":30},{"corpo":"If it were my source control server, I would not want to a) pay the added cost, or b)have to drive to the colo because I can't connect to my repository. ","pontos":1},{"corpo":"I would do it the simpliest way: rename ComputeResult method to ComputeResultX rename DoSomething method to ComputeResult remove DoSomething method (which is now ComputeResult) rename ComputeResultX method back to ComputeResult Maybe VS will show some conflict because of the last rename, but ignore it. By \"rename\" I mean: overwrite the name of the method and after it use the dropdown (Shift+Alt+F10) and select \"rename\". It will replace all occurences with the new name. ","pontos":1},{"corpo":"Extension methods should be used as just that: extensions. Any crucial structure/design related code or non-trivial operation should be put in an object that is composed into/inherited from a class or interface. Once another object tries to use the extended one, they won't see the extensions and might have to reimplement/re-reference them again. The traditional wisdom is that Extension methods should only be used for: utility classes, as Vaibhav mentioned extending sealed 3rd party APIs ","pontos":10},{"corpo":"Answering the original question: ASCII is bad : I had to squint to find \"WOW\". Is this even correct? It could be \"VVOVV\" or whatever; Very simple arithmetic is good. Blind people will be able to answer. (But as Jarod said, beware of operator precedence.) I gather someone could write a parser, but it makes the spamming more costly. Trivia is OK, but you'll have to write each of them :-( I've seen pictures of animals [what is it?]. Votes for comics use a picture of a character with their name written somewhere in the image [type in name]. Impossible to parse, not ok for blind people. You could have an audio fallback reading alphanumerics (the same letters and numbers you have in the captcha). Final line of defense: make spam easy to report (one click) and easy to delete (one recap screen to check it's a spam account, with the last ten messages displayed, one click to delete account). This is still time-expensive, though. ","pontos":1},{"corpo":"ReSharper is definitely the VS 2008 plug in to have for refactoring. However it does not do this form of refactoring in one step; you will have to Refactor->rename DoSomething to ComputeResult and ignore the conflict with the real ComputeResult. Then delete the definition which was DoSomething. It's almost one step. However maybe it can do it one step. If I read that correctly. ","pontos":0},{"corpo":"Ouch. Please don't extend Interfaces. An interface is a clean contract that a class should implement, and your usage of said classes must be restricted to what is in the core Interface for this to work correctly. That is why you always declare the interface as the type instead of the actual class. IInterface variable = new ImplementingClass(); Right? If you really need a contract with some added functionality, abstract classes are your friends. ","pontos":1},{"corpo":"There are a few products available to add extra refactoring options to Visual Studio 2005 2008, a few of the better ones are Refactor! Pro and Resharper. As far as remove method, there is a description in the canonical Refactoring book about how to do this incrementally. Personally, I follow a pattern something along these lines (assume that compiling and running unit tests occurs between each step): Create the new method Remove the body of the old method, change it to call the new method Search for all references to the old method (right click the method name and select \"Find all Reference\"), change them to calls to the new method Mark the old method as [Obsolete] (calls to it will now show up as warnings during the build) Delete the old method ","pontos":1},{"corpo":"The thing about XAML is that it is fine for 'simple' programs, but sadly, it doesn't work well when you want to do things like share functions. Say you have several classes and UI's all of which had commands that were never disabled, you'd have to write a 'CanAlwaysExecute' method for each Window or UserControl! That's just not very DRY. Having read several blogs and through trying several things, I've made the choice to make XAML purely about looks, styles, animation and triggers. All my hooking up of event handlers and commanding is now down in the code-behind. :) Another gotcha by the way is Input binding, in order for them to be caught, focus must be on the object that contains the Input bindings. For example, to have a short cut you can use at any time (say, F1 to open help), that input binding must be set on the Window object, since that always has focus when your app is Active. Using the code method should make that easier, even when you start using UserControls which might want to add input bindings to their parent Window. ","pontos":3},{"corpo":"@Lars, good call on the passing around of Form references, seen it as well myself. Nasty. Never seen them passed them down to the BLL layer though! That doesn't even make sense! That could have seriously impacted performance right? If somewhere in the BLL the reference was kept, the form would stay in memory right? You have my sympathy! ;) @Ed, RE your comment about making the Forms UserControls. Dylan has already pointed out that the root form instantiates many child forms, giving the impression of an MDI application (where I am assuming users may want to close various Forms). If I am correct in this assumption, I would think they would be best kept as forms. Certainly open to correction though :) ","pontos":0},{"corpo":"I'd absolutely go for the server that's located under my roof, as long as I don't need it to be connected to the internet with a static IP. Why: It's a target for hackers, as soon as it is reachable from the net Any problems with the machine? I'd rather walk to the closet instead of calling a hotline - and probably pay for the service Connection speed (from me to the server) I can turn it off as long as I don't need it. Less power consuption, which is better for the environment. The hosting of a machine costs money all the time. Even when you don't need it. ","pontos":0},{"corpo":"@Derek Park He only said harder, not impossible. PGP would make it harder, not impossible. ","pontos":0},{"corpo":"I was going to suggest download.wikimedia.org but on looking, it seems they don't offer mysql dumps anymore, just the xml format. I can't think of any other projects off the top of my head that might offer raw data downloads. You may want to clarify what format you're looking for. Do you want the typical tab-delimited ASCII dump, or do you want the actual table files? Or something else? ","pontos":1},{"corpo":"If you want some big data sets, try some of the Wikipedia dumps. You can also go straight to the Wikimedia dump page. There are a lot of files in XML form, but a lot are available in raw SQL form. The first link also has some instructions on how to use the dumps; parsing, importing int MySQL, etc. Here's a link straight to the wikipedia dumps: http://download.wikimedia.org/enwiki/. Click any date and you'll find a lot of data in both XML and SQL form. ","pontos":3},{"corpo":"Are you sure there are no precompile directives that, say, ignores some really important code in Release mode but allows them in Debug? Also, have you implemented any logging that might point out to the precise assembly that's throwing the error? ","pontos":0},{"corpo":"It's hard to say what the problem might be without carefully inspecting the code. However... One of the differences between debug and release builds is how the function call stack frame is set up. There are certain classes of bad things you can do (like calling a function with the wrong number of arguments) that are not fatal in a debug build but crash horribly in a release build. Perhaps you could try changing the stack frame related options (I forget what they're called, sorry) in the release build to the same as the debug build and see whether that helps. Another thing might be to enable all the warnings you possibly can, and fix them all. ","pontos":2},{"corpo":"Could be a concurrency problem of two threads. The DEBUG configuration slows the execution down, so the problem does not occur. But, only a guess. ","pontos":1},{"corpo":"Interesting problem.. Are you sure you have no conditional compilation code lurking around that is not being compiled in release mode? i.e: #if (DEBUG) // Debug Code here #else // Release Code here #endif Thats the only thing I can really think of.. Never experienced anything like this myself.. ","pontos":1},{"corpo":"ActiveRecord, which is a pattern documented first (I think) in Fowler's Patterns of Enterprise Architecture. I believe it's implemented in languages other than Ruby, although it's well-known as a core technology in Rails. Whatever, it's a neat abstraction of the database, although I have to confess that I find it a bit clunky and in the findbysql area. But that may just be me. But (putting on Grumpy Old Man hat now) all the ORMs in the world are no substitute for a good knowledge of SQL, without which I really don't like to see access to an RDBMS being permitted at all. ","pontos":0},{"corpo":"Another option I was considering: rather than writing a native launcher from scratch, Eclipse comes with the source code for its own launcher, and this could perhaps be repurposed for my app. It's a shame that Sun never included anything similar in the JDK. ","pontos":0},{"corpo":"Rather than relying on your users to look at the page footer and to let you know if the value exceeds some patience threshold, it might be a better idea to log the page render times in a log file on the server. Once you have all that raw data, you can look for particular pages that tend to take longer than normal to render. With more detailed logging, you could also measure the elapsed times in database queries or whatever if your web app relies on external systems. ","pontos":1},{"corpo":"Just simple things - move messages to appropriate folders, forward some stuff to an email2sms address, move spam to spam folder. One thing I'm kind of proud of is how to mark your spam as \"read\" (this is for Courier IMAP and Maildir, where \"read\" means \"move to different folder and change the filename\"): :0 * ^X-Spam # the header our filter inserts for spam { :0 .Junk\\ E-mail/ # stores in .Junk E-mail/new/ :0 * LASTFOLDER ?? /\\/[^/]+$ # get the stored message's filename { tail=$MATCH } # and put it into $tail # now move the message TRAP=\"mv .Junk\\ E-mail/new/$tail .Junk\\ E-mail/cur/$tail:2,S\" } ","pontos":4},{"corpo":"A method that I have developed and which seems to work perfectly (although I probably don't get as much comment spam as you), is to have a hidden field and fill it with a bogus value e.g.: input type=\"hidden\" name=\"antispam\" value=\"lalalala\" / I then have a piece of JavaScript which updates the value every second with the number of seconds the page has been loaded for: var antiSpam = function() { if (document.getElementById(\"antiSpam\")) { a = document.getElementById(\"antiSpam\"); if (isNaN(a.value) == true) { a.value = 0; } else { a.value = parseInt(a.value) + 1; } } setTimeout(\"antiSpam()\", 1000); } antiSpam(); Then when the form is submitted, If the antispam value is still \"lalalala\", then I mark it as spam. If the antispam value is an integer, I check to see if it is above something like 10 (seconds). If it's below 10, I mark it as spam, if it's 10 or more, I let it through. If AntiSpam = A Integer If AntiSpam = 10 Comment = Approved Else Comment = Spam Else Comment = Spam The theory being that: A spam bot will not support JavaScript and will submit what it sees If the bot does support JavaScript it will submit the form instantly The commenter has at least read some of the page before posting The downside to this method is that it requires JavaScript, and if you don't have JavaScript enabled, your comment will be marked as spam, however, I do review comments marked as spam, so this is not a problem. Response to comments @MrAnalogy: The server side approach sounds quite a good idea and is exactly the same as doing it in JavaScript. Good Call. @AviD: I'm aware that this method is prone to direct attacks as I've mentioned on my blog. However, it will defend against your average spam bot which blindly submits rubbish to any form it can find. ","pontos":207},{"corpo":"Spring is also very much about unit testing and therefore testability of your classes. That basically means thinking about modularization, separation of concerns, referencing a class through interfaces etc. ","pontos":1},{"corpo":"Can you add the debug symbols to the release build and run it in the debugger to see where and why it crashed? ","pontos":1},{"corpo":"I'm not sure there's any value in telling users how long it took for the server to render the page. It could well be worth you logging that sort of information, but they don't care. If it takes the server 0.001 of a second to draw the page but it takes 17 seconds for them to load it (due to network, javascript, page size, their rubbish PC, etc) their perception will be the latter. Then again adding the render time might help you fend off the enquiries about any percieved slowness with a \"talk to your local network admin\" response. Given that you know the accuracy of your measurements you could have the 0.000 text be \"Rendered in less than a thousandth of a second\" ","pontos":1},{"corpo":"The stuff is compiler magic and will work without Linq. Try adding a reference to Sorry, I wasn't clear. I meant add to the web project's references, not to the page. The on the page are basically just using statements, allowing you to skip the namespace on the page. ","pontos":0},{"corpo":"Yes, you could format it this way: string.Format(\"Format number to: {0 : #.00}\", number); string.Format(\"Format date to: {0 : MM/dd/yyyy}\", date); ","pontos":4},{"corpo":"I think doing something like this is against Microsoft recommended practices. What are you trying to do that requires emptying the Recycle Bin from a Windows service? ","pontos":2},{"corpo":"The best method I've used for debugging JavaScript in Internet Explorer is through the Microsoft Script Editor. The debugger is full featured and very easy to use. The article bellow teaches how to install the Microsoft Script Editor and configure it. HOW-TO: Debug JavaScript in Internet Explorer for Safari, sorry no answer... ","pontos":1},{"corpo":"Syntax is irrelevant, readability is not! ","pontos":0},{"corpo":"Ok, here's the deal: In silverlight, you can't bind values from one UI element to another declaratively. The only way to do what I was trying to do here would be in the C# code. I had a reference for this yesterday, but now I guess you'll just have to take my word for it :) ","pontos":1},{"corpo":"I use it very little for actual dev work. I've used it to setup virtual directories automatically and execute a scipt that sets up IIS with the same settings on all our dev machines ","pontos":1},{"corpo":"It's never come in use as part of my development role, but every now and then I get a task that I'd write a small program to automate, which I now force myself to do in powershell and it takes less time. For example, I recently moved hundredsthousands of files from one server to another using xcopy and forgot to set the attribute to preserve the creation dates on the files. Powershell to the rescue. Within ten minutes I had a script written and tested that copied the creation dates over without having to re-copy the files. ","pontos":3},{"corpo":"Back with .Net 1.1 obfuscation was essential: decompiling code was easy, and you could go from assembly, to IL, to C# code and have it compiled again with very little effort. Now with .Net 3.5 I'm not at all sure. Try decompiling a 3.5 assembly; what you get is a long long way from compiling. Add the optimisations from 3.5 (far better than 1.1) and the way anonymous types, delegates and so on are handled by reflection (they are a nightmare to recompile). Add lambda expressions, compiler 'magic' like Linq-syntax and , and C#2 functions like (which results in new classes with unreadable names). Your decompiled code ends up a long long way from compilable. A professional team with lots of time could still reverse engineer it back again, but then the same is true of any obfuscated code. What code they got out of that would be unmaintainable and highly likely to be very buggy. I would recommend key-signing your assemblies (meaning if hackers can recompile one they have to recompile all) but I don't think obfuscation's worth it. ","pontos":37},{"corpo":"The only way I can think of doing this without a second run through the data would be by creating some formulas to do running totals per group. The problem I assume you are running into with the existing running totals is that they are intended to follow each of the groups that they are totaling. Since you seem to want the subtotals to follow after all of the 'raw' data this won't work. If you create your own formulas for each group that simply adds on the total from those rows matching the group you should be able to place them at the end of the report. The downside to this approach is that the resulting subtotals will not be dynamic in relationship to the groups. In other words if you had a new 'source' it would not show up in the subtotals until you added it or if you had no 'dog walking' data you would still have a subtotal for it. ","pontos":1},{"corpo":"Is it specific to the app you're working on or do all breakpoints in any app break the debugger? Is anything different if you attach the debugger manually after launching the app normally? ","pontos":0},{"corpo":"Check out GIT. A talk on it here. ","pontos":0},{"corpo":" I like the idea of not needing to compile the programs each time we make a change. I understand that the interpreted languages probably wont hit the same performance we currently get. This is the biggest issue; can you live with the performance hit. You could try to use Python and extending it with your current C++ modules for the performance heavy parts. Still, switching your entire system seems like a big effort if the only reason is the lack of C++ talent. Hiring people who know C++ seems like the cheaper option. ","pontos":15},{"corpo":"Hopefully you can't. A service running as the local machine should not be clearing my Recycle bin, ever. You could promote the service to run as an Admin account then it would have the right (and be a security risk), but why do you want to do this? It sounds like the sort of think Viruses try to do. ","pontos":3},{"corpo":"This looks good, but unfortunately it's being licensed under GPLv3, so I'm actually a bit afraid to start looking at that code. The framework I either need to find, or develop if needs be, must be able to be used as part of a commercial program, without having to license the entire program different. Commercial libraries are fine, I just haven't found any I can demo yet, presumably because I could just then steal all the code if I wanted to. Guess I'll look further, thanks for the link though. Edit: Clarification. I'd be fine with the requirement to share the source to the web framework part for the iPhone, if someone wanted it, but since this framework is all source, I'm afraid that incorporating bits of it into an existing web application (to make a skin for iPhone), I'd be making the whole web application liable for GPL license, which is totally out of the question. Even sharing all the files related to the iPhone pages is out of the question, since they will contain proprietary code. ","pontos":0},{"corpo":"It's possible to open multiple databases at once in Sqlite, but it's doubtful if can be done when working from Flex/AIR. In the command line client you run and then you can refer to tables in that database as just as in MySQL or SQL Server. Tables in an attached database can be referred to using the syntax database-name.table-name. ATTACH DATABASE documentation at sqlite.org ","pontos":1},{"corpo":"When you say \"10Gb C drive\", do you mean it's a 10-gig disk or a partition? If the former, you should really be looking at replacing the drive - it's old, and I'd be starting to worry about how much longer it has to live. If the latter, then assuming that the C: drive restriction can't easily be worked around, then I'd look at increasing the size of the C: partition. Depending on how full the remainder of the drive is, this can take a while. I'd also be considering spending some tens of dollars ($40 or $50, I'd guess) on a partition manager from someone such as Acronis or Paragon. Kick it off just before you finish work for the day - it may take several hours, especially if the disk's fairly full. ","pontos":0},{"corpo":"Yeah, those bastard crashes are the hardest to fix. Fortunatly, there are some steps you can do that will give you clues before you resort to manually looking at the code and hope to find the needle. When does it crash? At every test? At a specific test? What does that test does that the others don't? What's the error? If it's an access violation, is there a pattern to where it happens? If the addresses are low, it might mean there is an uninitialised pointer somewhere. Is the program crashing with Debug configuration but without the debugger attached? If so, it's most likely a thread synchronisation problem as John Smithers pointed out. Have you tried running the code through an analyser such as Purify? It's slow but it's usually worth the wait. Try to debug the release configuration anyway. It will only dump assemblies but it can still give you an indication of what happens such as if the code pointer jumps in the middle of garbage or hits a breakpoint in an external library. Are you on an Intel architecture? If not, watch for memory alignement errors, they hard crash without warning on some architectures and those codec algorithm tend to create those situations a lot since they are overly optimized. ","pontos":1},{"corpo":"Any language looks a lot harder when one doesn't use the common indentation conventions of a language. When one follows them of Lisp, one sees how it expresses a syntax-tree structure quite readily (note, this isn't quite right because the preview lies a little; the r's should align with the fns in the recursive quicksort argument): (defun quicksort (lis) (if (null lis) nil (let* ((x (car lis)) (r (cdr lis)) (fn (lambda (a) ( a x)))) (append (quicksort (remove-if-not fn r)) (list x) (quicksort (remove-if fn r)))))) ","pontos":5},{"corpo":"Recording the database calls, the gross timing and the number of records (bytes) returned in the application is useful, but it's not going to give you all the information you need. It might show you usage patterns you were not expecting. It might show where your using \"row-by-row\" access instead of \"set based\" operations. The best tool to use is SQL Profiler and analyse the number of \"Reads\" vs the CPU and duration. You want to avoid high CPU queries, high Read's and long durations (duh!). The \"group by reads\" is a useful feature to bring to the top the nastiest queries. ","pontos":1},{"corpo":"Try using the \"ant\" task instead of the \"antcall\" task, which runs the imported build directly instead of importing it into the current build file. It has a \"dir\" parameter: the directory to use as a basedir for the new Ant project. Defaults to the current project's basedir, unless inheritall has been set to false, in which case it doesn't have a default value. This will override the basedir setting of the called project. So you could do: ant antfile=\"${baseDirUpOne}/utils/build/build.xml\" dir=\"../utils/build\" / or something like that. ","pontos":6},{"corpo":"@Jay Mooney: A generic Dictionary class in .NET is actually a hash table, just with fixed types. The code you've shown shouldn't convince anyone to use Hashtable instead of Dictionary, since both code pieces can be used for both types. For hashtable: foreach(object key in h.keys) { string keyAsString = key.ToString(); // btw, this is unnecessary string valAsString = h[key].ToString(); System.Diagnostics.Debug.WriteLine(keyAsString + \" \" + valAsString); } For dictionary: foreach(string key in d.keys) { string valAsString = d[key].ToString(); System.Diagnostics.Debug.WriteLine(key + \" \" + valAsString); } And just the same for the other one with KeyValuePair, just use the non-generic version for Hashtable, and the generic version for Dictionary. So it's just as easy both ways, but Hashtable uses Object for both key and value, which means you will box all value types, and you don't have type safety, and Dictionary uses generic types and is thus better. ","pontos":2},{"corpo":"One thing that would really help is if the SharePoint team provided interfaces for the SP-specific workflow services needed to run SP workflows. This would allow you to mock those interfaces and run the workflows outside of SP proper. AFAIK, you can't do that today. I've personally found SharePoint extremely painful to develop against... not just with workflows, but overall. I understand the administrative wins and the end user productivity, but it's a fairly dreadful experience for Joe .NET Developer. ","pontos":2},{"corpo":"Use something like this: class Tree T : Dictionary T, IList Tree T { } It's ugly, but I think it will give you what you want. Too bad KeyValuePair is sealed. ","pontos":1},{"corpo":"Monitoring web and DB access logs should alert you to things like this, but if you want a more fully featured alert system I would suggest some kind of IDS/IPS. You'll need a spare machine though, and a switch that can do port mirroring. If you have those then an IDS is a cheap way of monitoring your traffic for many intrusion attempts (there will be lots). Snort (www.snort.org) based IDSes are excellent, and there are some free fully packaged versions available. One I have used is StrataGuard (http://sgfree.stillsecure.com/), and it can be configured as an IDS (Intrusion Detection System) or as an IPS (Intrusion Prevention System). It's free to use if your traffic does not exceed 5Mbps. If you do go with an IDS/IPS I'd advise you to let it run as a simple IDS for a month or so, before you allow it to prevent attacks. This may be overkill, but if you have a spare machine lying around it can't hurt to have an IDS running passively. ","pontos":0},{"corpo":"Depending on how complicated you want to get, you can use a generic linking table. For one of my applications there are several reports where the user might pick, for instance a list of customers to run the report on rather than just a single customer from a combo box. I have a separate table with 2 fields: UniqueID (guid) ItemID The psuedo-code looks like this: GUID guid = GenerateGUID() try for each customer in customerList { INSERT(guid, customerId) } ExecuteSQLPocedure(guid) --the procedure can inner-join to the list table to get the list finally DELETE WHERE UniqueID=guid ","pontos":1},{"corpo":"Timer classes can start behaving strangely when the timer 'tick' event code is not finished executing by the time the next 'tick' occurs. One way to combat this is to disable the timer at the beginning of the tick event, then re-enable it at the end. However, this approach is not suitable in cases where the execution time of the 'tick' code is not acceptable error in the timing of the tick, since the timer will be disabled (not counting) during that time. If disabling the timer is an option, then you can also achieve the same effect by creating a separate thread that executes, sleeps for x milliseconds, executes, sleeps, etc... ","pontos":0},{"corpo":"Null is case insensitive. From the documentation: There is only one value of type null, and that is the case-insensitive keyword NULL. ","pontos":67},{"corpo":"I agree with using events for this. Since I suspect that you're building an MDI-application (since you create many child forms) and creates windows dynamically and might not know when to unsubscribe from events, I would recommend that you take a look at Weak Event Patterns. Alas, this is only available for framework 3.0 and 3.5 but something similar can be implemented fairly easy with weak references. However, if you want to find a control in a form based on the form's reference, it's not enough to simply look at the form's control collection. Since every control have it's own control collection, you will have to recurse through them all to find a specific control. You can do this with these two methods (which can be improved). public static Control FindControl(Form form, string name) { foreach (Control control in form.Controls) { Control result = FindControl(form, control, name); if (result != null) return result; } return null; } private static Control FindControl(Form form, Control control, string name) { if (control.Name == name) { return control; } foreach (Control subControl in control.Controls) { Control result = FindControl(form, subControl, name); if (result != null) return result; } return null; } ","pontos":0},{"corpo":"I think I found the reason. While trying to get this work, I think I installed another version of the package that removed or deactivated my current version. The control I was dropping on the form belonged to the older version that had no assemblies referenced. I removed all installations of ActiveReports, installed the last version and cleaned up the toolbox. I added the latest version of the WebViewer to toolbox and dropped it on the form. It worked. ","pontos":2},{"corpo":"I've never heard of such a thing. A few years ago, many hosts (Brinkster, etc) offered some minimal database capacity with their free web hosting accounts, but I think you'd find it difficult to find something like that now. Even if you could, most hosts no longer allow you to connect to a database (even on an account you're paying for) outside of a web application running on their server. My advice would be to cobble together an old computer and use that as a database server that you run out of your house (coupled with no-ip or some similar service, probably). If you're going to need more horsepower/bandwidth than that, you'll probably just have to suck it up and pay for something. ","pontos":1},{"corpo":"In general, it depends :) I haven't had a lot of problems when the application side has just been updating the data through the forms. You can get warnings/errors when the same row has been updated by more than one user; but Access seems to be constantly updating its live record sets all the time. Problems can happen if Alice is already working with record 365, and the Bob updates it, and then Alice tries to update it with her changes. As I recall, Alice will get a cryptic error message. It would be easier for the users if you trap these errors and at least give them a friendlier error message. I've had more problems when I was editing records in the VB code through RecordSets, especially when combined with editing the same data on forms. That's not necessarily a multi user problem; however, you have almost the same situation because you have one user with multiple connections to the same data. ","pontos":1},{"corpo":"Are you sure that the 32-bit version doesn't just run on 64-bit Windows, without modification? Most things do. Failing that, have you actually tried just compiling it for 64-bit? A brief scan of a few Google Groups etc where people asked this same question suggests that that may be exactly the solution to this. I think you're probably overestimating the difference between 32-bit and 64-bit Windows (at least as far as compiling a native application goes). ","pontos":0},{"corpo":"The Visual Studio 2008 and .NET 3.5 Framework Service Pack 1 has gone out of beta, maybe you can see if this bug still occurs? ","pontos":2},{"corpo":"Use a custom FxCop rule that flags undesirable usage of . ","pontos":1},{"corpo":"Primitives appear to be specified in the enumeration: Perhaps there is a way to find out if an object contains the without having to cast it to an specific object or call or ? Update It was right under my nose. The code sample there shows this: static void WriteObjectInfo(object testObject) { TypeCode typeCode = Type.GetTypeCode( testObject.GetType() ); switch( typeCode ) { case TypeCode.Boolean: Console.WriteLine(\"Boolean: {0}\", testObject); break; case TypeCode.Double: Console.WriteLine(\"Double: {0}\", testObject); break; default: Console.WriteLine(\"{0}: {1}\", typeCode.ToString(), testObject); break; } } } It's still an ugly switch. But it's a good place to start! ","pontos":28},{"corpo":"Have a look at this answer: Storing Images in DB - Yea or Nay? Essentially, the space and performance hit can be quite big, depending on the number of users. Also, keep in mind that Web servers are cheap and you can easily add more to balance the load, whereas the database is the most expensive and hardest to scale part of a web architecture usually. There are some opposite examples (e.g., Microsoft Sharepoint), but usually, storing files in the database is not a good idea. Unless possibly you write desktop apps and/or know roughly how many users you will ever have, but on something as random and unexpectable like a public web site, you may pay a high price for storing files in the database. ","pontos":52},{"corpo":"I occasionally get this in Visual Studio 2005. A method I use to get the controls back, is to switch the web page between code view and design view. I know it's not a fix but it's a little quicker than restarting Visual Studio. ","pontos":0},{"corpo":"Unfortunately, the \"full\" Sharepoint Experience is limited to running Internet Explorer 6/7 and Office 2007. On the Mac, I recommend using Firefox (Camino?) which seems to work a bit better than Safari. Edit: When you say \"Similar experience\", what exactly are you missing? I don't have any Mac here, but I was under the impression that Office 2008 will have a working integration with Sharepoint as well. ","pontos":1},{"corpo":"The overhead of having to parse a blob (image) into a byte array and then write it to disk in the proper file name and then reading it is enough of an overhead hit to discourage you from doing this too often, especially if the files are rather large. ","pontos":1},{"corpo":"No because you need to select them. However you can create a stored proc wrapper, which may defeat the point of having a table function. ","pontos":18},{"corpo":"It doesn't need to be WIA. I was mostly looking at the WIA setup because it offers the same basic interface for different scanners. I've got 3 scanners on this machine and the TWAIN drivers/software for all of them suck (like blocking the screen during scanning). For document management, I'm really looking for simple 200dpi grayscale scans, so most of the stuff in the TWAIN drivers is overkill. That said, asking here was part of my last attempt to figure out how to do it in WIA before moving on to TWAIN. ","pontos":0},{"corpo":" ?? - coalescing operator using (statement / directive) - great keyword that can be used for more than just calling Dispose readonly - should be used more netmodules - too bad there's no support in Visual Studio ","pontos":104},{"corpo":"My goodness, if the question was about Microsoft SQL Server then we'd have been in business! Sybase, sadly, is a whole 'nother database these days, since about 1997, in fact, give or take a year. If the input format simply has to be 'DD-MON-YYYY' and no exceptions, then I think a fair amount of validation was be achieved by slicing the input using SUBSTR(), after first doing some simple things, such as checking length. I thought that recent releases of Sybase (SQL Anywhere 11, for example) have regular expression support, however, although it's been a while since I've had to suffer T-SQL. Some googling leaves me in rather more doubt. ","pontos":1},{"corpo":"I vaguely recall having this happen to me when I had Office 2007 installed first before VS 2008. I don't remember what options that I had installed for Office 2007. Update: I remember now it had to do with the fact that I had Visual Studio Tools for Office already installed. When I upgraded my computer I did a clean install of everything without problems by installing VS 2008 before installing Office 2007 and VSTO. So most likely you have to uninstall whatever is causing VS 2008 to want to go to a specific drive. Even if you do get it to switch drives it still is going to put a lot of stuff on the system drive. ","pontos":0},{"corpo":" TransactionScope and DependentTransaction in System.Transactions is a lightweight way to use transaction processing in .NET - it's not just for Database transactions either String.IsNullOrEmpty is one that I am surprised to learn a lot of developers don't know about List.ForEach - iterate through your generic list using a delegate method There are more, but that is the three obvious ones of the top of my head... ","pontos":68},{"corpo":"We've used both http://jatha.sourceforge.net and http://www.jboss.com/products/rules. They're both pretty good, but for the most part, JBoss rules seems to me to be overkill for a lot of what people do. They're both Java based. It's worth remembering Greenspun's Tenth Rule of Programming and skip ahead to importing it :) ","pontos":1},{"corpo":"Regions must never be used inside methods. They may be used to group methods but this must be handled with extreme caution so that the reader of the code does not go insane. There is no point in folding methods by their modifiers. But sometimes folding may increase readability. For e.g. grouping some methods that you use for working around some issues when using an external library and you won't want to visit too often may be helpful. But the coder must always seek for solutions like wrapping the library with appropriate classes in this particular example. When all else fails, use folding for improving readibility. ","pontos":2},{"corpo":"I think that it's a useful tool, when used properly. In many cases, I feel that methods and enumerations and other things that are often folded should be little black boxes. Unless you must look at them for some reason, their contents don't matter and should be as hidden as possible. However, I never fold private methods, comments, or inner classes. Methods and enums are really the only things I fold. ","pontos":1},{"corpo":"Try this article - I have some code at work that will erm, work if this doesn't... ","pontos":5},{"corpo":"I have often come across the need to have a generic parameter-object persisted into the viewstate in a base class. public abstract class BaseListControl ListType,KeyType,ParameterType : UserControl where ListType : BaseListType ParameterType : BaseParameterType, new { private const string viewStateFilterKey = \"FilterKey\"; protected ParameterType Filters { get { if (ViewState[viewStateFilterKey] == null) ViewState[viewStateFilterKey]= new ParameterType(); return ViewState[viewStateFilterKey] as ParameterType; } set { ViewState[viewStateFilterKey] = value; } } } Usage: private void SomeEventHappened(object sender, EventArgs e) { Filters.SomeValue = SomeControl.SelectedValue; } private void TimeToFetchSomeData() { GridView.DataSource = Repository.GetList(Filters); } This little trick with the \"where ParameterType : BaseParameterType, new\" is what makes it really work. With this property in my baseclass, I can automate handling of paging, setting filter values to filter a gridview, make sorting really easy, etc. I am really just saying that generics can be an enormously powerful beast in the wrong hands. ","pontos":15},{"corpo":"It seems you're going to be stuck rolling your own. You could probably use this as a starting point. ","pontos":1},{"corpo":"Bartosz/To clarify \"This worked okay, but there was no easy way of checking if x[3][24] was supposed to exist or not\" would return season 3, episode 24 of \"some show\". If there was no season 3, I want the pseudo-dict to raise tvdbseasonnotfound, if \"some show\" doesn't exist, then raise tvdbshownotfound The current system of a series of classes, each with a - Show checks , the Season class checks and so on. It works, but it there seems to be a lot of repeated code (each class is basically the same, but raises a different error) ","pontos":0},{"corpo":"I've hit this before. It has to do with the fact that lucene, under the covers, turns many (all?) things into boolean queries when you call Query.rewrite() From: http://lucene.apache.org/java/2_2_0/api/org/apache/lucene/search/Query.html#rewrite(org.apache.lucene.index.IndexReader) public Query rewrite(IndexReader reader) throws IOException Expert: called to re-write queries into primitive queries. For example, a PrefixQuery will be rewritten into a BooleanQuery that consists of TermQuerys. Throws: IOException ","pontos":5},{"corpo":"I definitely see the value in using SQL Profiler while you're app is running, and EXPLAIN or SET STATISTICS will give you information about individual queries, but does anyone routinely put measurement points into their code to gather information about database queries ongoing - that would pick up on for example, a query on a table that performs fine initially, but as the number of rows grows, becomes slower and slower. If you're using MySQL or Postgre there's various tools for seeing query activity in real time, but I haven't found a tool as good as the SQL Profiler for measuring query performance over time. I'm wondering if there is (or should be?) something similar to ELMAH in the way it just plugs in and gives you information without much additional effort? ","pontos":0},{"corpo":"Here's a useful one for regular expressions and file paths: \"c:\\\\program files\\\\oldway\" @\"c:\\program file\\newway\" The @ tells the compiler to ignore any escape characters in a string. ","pontos":146},{"corpo":"To the best of my knowledge, there isn't. You can do something like: SELECT col1, col2, col3, col4 FROM tbl and manually choose the columns you want. However, if you want a lot of columns, then you might just want to do a: SELECT * FROM tbl and just ignore what you don't want. In your particular case, I would suggest: SELECT * FROM tbl unless you only want a few columns. If you only want four columns, then: SELECT col3, col6, col45, col 52 FROM tbl would be fine, but if you want 50 columns, then any code that makes the query would become (too?) difficult to read. ","pontos":18},{"corpo":"Aside from ObjC, you can use the PyObjC or RubyCocoa bindings to access it also. If you're not picky about which language, I'd say use Ruby, as PyObjC is horribly badly documented (even the official Apple page on it refers to the old version, not the one that came with OS X Leopard) Quartz Composer is probably the easiest way to access it, and .quartz files can be embed in applications pretty easily (and the data piped out to ObjC or such) Also, I suppose there should be an example or two of this in the /Developer/Examples/ ","pontos":0},{"corpo":" Is there any option besides using the hidden iframe trick? Unfortunately, no, not now. Otherwise the microsummary code you point to would use it instead. And if not, what is the best way to do the iframe trick so that your code works outside the context of any currently open tabs (so that closing tabs won't screw up code, etc)? The code you quoted uses the recent browser window, so closing tabs won't affect parsing. Closing that browser window will abort your load, but you can deal with it (detect that the load is aborted and restart it in another window for example) and it doesn't happen very often. You need a DOM window for the iframe to work properly, so there's no clean solution at the moment (if you're keen on using the mozilla parser). ","pontos":1},{"corpo":"Or should try to store your parsing rules on a database instead of leaving them hard-coded inside your code. As Ken Downs rightly quoted, minimize code, maximize data. This way you would not need to recompile everytime a tiny rule changes. ","pontos":0},{"corpo":"I hate to say this, but f you want something that your incoming developers are going to be familiar with, go with Java. Java is the language that most recent graduates will be most familiar with. You still have to compile, but compile times will be shorter than C++. It'll run on Linux and pretty much anywhere else. It's got a good garbage collector. It's pretty fast. And did I mention your developers will be familiar with it? No, it's not \"cool\" like Python, but it's a very tried-and-true language. Honestly, I doubt that you've got a lot of incoming developers who suck with C++ but would be awesome with Python anyway. The people who use Python well tend to be fine with manual memory management. The people who are bad with memory management actually tend to be bad with all languages. I do find it worrisome that you've got developers who are so bad with memory management that you want to switch languages. That's a sign indicating a problem, but I'm not sure that the problem is with the language. ","pontos":2},{"corpo":"If it's always the same one column, then you can create a view that doesn't have it in it. Otherwise, no I don't think so. ","pontos":1},{"corpo":"I think that this is one of these issues that cause quasi-religious debates, and its almost futile to talk about. I would just say use what you prefer. In 99% of systems it will no matter which type of key you use, so the benefits (stated in the other posts) of using one sort over the other will never be an issue. ","pontos":0},{"corpo":"Try this article but short answer is ","pontos":3},{"corpo":"This sounds pretty strange. Here's what I would check next: Check that there's nothing lingering in your Properties/AssemblyInfo.cs file. Check that there's nothing lingering in your SuperUI.csproj file. Delete all references and re-add them. ","pontos":0},{"corpo":"Since it's a compiler error, there must be a reference or use of SuperException somewhere in the project. Do a find/replace in the entire project or solution for that type and remove every reference (it's possible you already did this). If you reference any types that inherits from SuperException (even if the type defined in another assembly), you need a reference to the assembly that SuperException is defined in. Take the line that the compiler is showing the error on and start tracing the inheritance tree of the objects used on that line, you might find the source of it that way. ","pontos":1},{"corpo":"I'd like to add some further notes in my response. All other non-Microsoft operating systems we have tested do not suffer from this problem. Linux, FreeBSD, and Mac OS X (this final one on different hardware) all degrade much more gracefully in terms of aggregate bandwidth when moving from one thread to two. Linux for example degraded from ~45 MiB/sec to ~42 MiB/sec. These other operating systems must be reading larger chunks of the file between each seek, and therefor not spending nearly all their time waiting on the disk to seek. Our solution for Windows is to pass the flag to and use large (~16MiB) reads in each call to . This is suboptimal for several reasons: Files don't get cached when read like this, so there are none of the advantages that caching normally gives. The constraints when working with this flag are much more complicated than normal reading (alignment of read buffers to page boundaries, etc). (As a final remark. Does this explain why swapping under Windows is so hellish? Ie, Windows is incapable of doing IO to multiple files concurrently with any efficiency, so while swapping all other IO operations are forced to be disproportionately slow.) Edit to add some further details for Will Dean: Of course across these different hardware configurations the raw figures did change (sometimes substantially). The problem however is the consistent degradation in performance that only Windows suffers when moving from one thread to two. Here is a summary of the machines tested: Several Dell workstations (Intel Xeon) of various ages running Windows 2000, Windows XP (32-bit), and Windows XP (64-bit) with single drive. A Dell 1U server (Intel Xeon) running Windows Server 2003 (64-bit) with RAID 1+0. An HP workstation (AMD Opteron) with Windows XP (64-bit), and Windows Server 2003, and hardware RAID 5. My home unbranded PC (AMD Athlon64) running Windows XP (32-bit), FreeBSD (64-bit), and Linux (64-bit) with single drive. My home MacBook (Intel Core1) running Mac OS X, single SATA drive. My home Koolu PC running Linux. Vastly underpowered compared to the other systems but I demonstrated that even this machine can outperform a Windows server with RAID5 when doing multi-threaded disk reads. CPU usage on all of these systems was very low during the tests and anti-virus was disabled. I forgot to mention before but we also tried the normal Win32 API with the flag set. This flag didn't fix the problem. ","pontos":4},{"corpo":" Exit Visual Studio Delete the bin and obj Folders in your solution directory Restart and see what happens ","pontos":2},{"corpo":"jQuery is the way i'd deal with this personally. css support is minimal, images are too fiddly, to be able to select the elements you want to have round corners in jQuery makes perfect sense to me even though some will no doubt argue otherwise. Theres a plugin I recently used for a project at work here: http://plugins.jquery.com/project/jquery-roundcorners-canvas ","pontos":7},{"corpo":"My approach tends to be to ensure I can completely validate on all pages, however I still send the page as text/html instead of application/xhtml+xml so there are no ugly XML errors in the event I have missed something. ","pontos":1},{"corpo":"It does seem a little strange that you see no difference across quite a wide range of windows versions and nothing between a single drive and hardware raid-5. It's only 'gut feel', but that does make me doubtful that this is really a simple seeking problem. Other than the OS X and the Raid5, was all this tried on the same machine - have you tried another machine? Is your CPU usage basically zero during this test? What's the shortest app you can write which demonstrates this problem? - I would be interested to try it here. ","pontos":1},{"corpo":"At first I thought you could use regular expressions, but as I've been reading the MYSQL docs it seems you can't. If I were you I would use another language (such as PHP) to generate a list of columns you want to get, store it as a string and then use that to generate the SQL. ","pontos":3},{"corpo":"It's important to follow security best practices wherever possible, but you don't want to make things unduly difficult for yourself or lose sleep worrying about keeping up with the latest exploits. In my experience, there are two key things that can help keep your personal server secure enough to throw up on the internet while retaining your sanity: 1) Security through obscurity Needless to say, relying on this in the 'real world' is a bad idea and not to be entertained. But that's because in the real world, baddies know what's there and that there's loot to be had. On a personal server, the majority of 'attacks' you'll suffer will simply be automated sweeps from machines that have already been compromised, looking for default installations of products known to be vulnerable. If your server doesn't offer up anything enticing on the default ports or in the default locations, the automated attacker will move on. Therefore, if you're going to run a ssh server, put it on a non-standard port (>1024) and it's likely it will never be found. If you can get away with this technique for your web server then great, shift that to an obscure port too. 2) Package management Don't compile and install Apache or sshd from source yourself unless you absolutely have to. If you do, you're taking on the responsibility of keeping up-to-date with the latest security patches. Let the nice package maintainers from Linux distros such as Debian or Ubuntu do the work for you. Install from the distro's precompiled packages, and staying current becomes a matter of issuing the occasional apt-get update apt-get -u dist-upgrade command, or using whatever fancy GUI tool Ubuntu provides. ","pontos":5},{"corpo":"Here is an article about IL debugging. It says you can't do it and then talks about ways to do it. There is also some info in the comments about doing it also. ","pontos":0},{"corpo":"A little more info on the connection pooling thing... you're using it already with SqlClient, but only if your connection string is identical for each new connection you open. My understanding is that the framework will pool connections automatically when it can, but if the connection string varies even slightly from one connection to the next, then the new connection won't come from the pool - it gets created anew (so it's more expensive). You can use the Performance Monitor app with XP/Vista to watch SQL connections and you'll see pretty quickly whether or not pooling is being used. Look under the \".NET CLR Data\" category\" in Performance Monitor. ","pontos":2},{"corpo":"2TB is chump change nowadays. Look into hard-drive based hot-swappable backup machines, and rent a box at your local bank: http://www.high-rely.com/ (there are many more products such as this, but my Google-time is limited). ","pontos":2},{"corpo":"I second Keith; if you're calling a stored procedure 30,000 times, you have far bigger problems than connection pooling. ","pontos":0},{"corpo":"This is a classic problem - separating your domain model from your database model. There are several ways to attack it, it really depends on the size of your project in my opinion. You could use the repository pattern as others have said. If you are using .net or java you could use NHibernate or Hibernate. What I do is use Test Driven Development so I write my UI and Model layers first and the Data layer is mocked, so the UI and model is build around domain specific objects, then later I map these object to what ever technology I'm using the the Data Layer. Is a very bad idea to let the database determine the design of your app, write the app first and think about the data later. ps the title of the question is a little mis-leading ","pontos":5},{"corpo":"You can buy external eSATA RAID boxes in the 8TB capacity range for $2600. I'm not saying that particular product is the right choice, but that's the kind of box that will do 6TB in RAID5 and still be portable enough to buy a couple of them and rotate them through the bank, like Stu says. Obviously if you have to have to keep 7 individual days worth, a 14 day, 30 and 90 day snapshot, etc. then things are going to be much more expensive, but it's certainly doable if what you're after is just disaster recovery. The biggest thing to make sure is part of your plan is actually testing the restoration from the backup. That seems to get overlooked WAY too often and turns out to be the weakest link in nearly all of the strategies. You should plan for scheduled restorations as often as is reasonable where you actually dump the real data and restore from the backup. Without that, you don't know that it will work when you NEED it too. I've lost track of the number of times I've been in a company where there's a big rack full of backup tapes/drives, all dutifully made according to the schedule only to find out that NONE of them have valid data when the server gets wiped out. The more ways you can verify the integrity of the backups the better, but nothing substitutes for doing an actual dump/load from one of your backups to really test the setup. ","pontos":8},{"corpo":"I agree with the other comments here.. There is a reference, in plain text somewhere ! I have had similar problems in the past where searching through the project files returned nothing, turns out it was in some other file that wasn't automatically picked up in the search. I don't think that creating a new project is the solution here.. You need to be positive that NONE of the references in your dependency tree use SuperException.. NONE I have never experienced this to the point where I have needed to literally wipe the project, I have always found the reference somewhere. Ensure you are searching every file. EDIT: Just a point to add, if the location pointed to by the error seems random, that can often mean there is a mismatch between the compiled source and the source code file.. Is this a ASP.NET application? I have had it before where the compiled DLL's haven't been replaced on a rebuild in the ASP.NET temp folder causing things to get.. Interesting when debugging :) ","pontos":2},{"corpo":" If you reference any types that inherits from SuperException (even if the type defined in another assembly), you need a reference to the assembly that SuperException is defined in. Seconded on that. You might not be referencing , but you might be referencing , which is derived from, or somehow otherwise uses - your grep of the project for won't be catching it though. Try have a hack with the trial of NDepend ","pontos":0},{"corpo":"Ahh, one of the Perforce classics :) Yes, it really sucks that there is STILL no easy way for this built into the default commands. The easiest way is to run a command to find all files under your clients root, and then attempt to add them to the depot. You'll end up with a changelist of all new files and existing files are ignored. E.g dir /s /b /A-D | p4 -x - add (use 'find . -type f -print' from a nix command line). If you want a physical list (in the console or file) then you can pipe on the results of a diff (or add if you also want them in a changelist). If you're running this within P4Win you can use $r to substitute the client root of the current workspace. ","pontos":10},{"corpo":"On linux, or if you have gnu-tools installed on windows: find . -type f -print0 | xargs -0 p4 fstat /dev/null This will show an error message for every unaccounted file. If you want to capture that output: find . -type f -print0 | xargs -0 p4 fstat /dev/null 2 mylogfile ","pontos":48},{"corpo":"Avoid checking for null event handlers Adding an empty delegate to events at declaration, suppressing the need to always check the event for null before calling it is awesome. Example: public delegate void MyClickHandler(object sender, string myValue); public event MyClickHandler Click = delegate {}; // add empty delegate! Let you do this public void DoSomething() { Click(this, \"foo\"); } Instead of this public void DoSomething() { // Unnecessary! MyClickHandler click = Click; if (click != null) // Unnecessary! { click(this, \"foo\"); } } Please also see this related discussion and this blog post by Eric Lippert on this topic (and possible downsides). ","pontos":314},{"corpo":"You really have to assess the true value of your data. If you lost it tomorrow what impact would it have on your business? We use offsite backups, it isn't cheap, but if we were to lose our data the business would cease to trade withing 2-3 days. We considered on-site backups as a possible cost saver but in my experience with data centres/computer rooms over the last ten years (as both an employee and a customer) I've seen fires, fire suppression system malfunctions (wet), hardware theft and one day a car crashed through an external wall right into the suite. Add to that our last DC was located at Heathrow, right next to the runways....you never know what strange things can happen (remember the BA 777 that got caught short of the runway on landing?). My advice, assess the value of the data then decide if $12k is too rich to keep it safe. ","pontos":3},{"corpo":"That's not what map does. You really want Array.filter. Or if you really want to remove the elements from the original list, you're going to need to do it imperatively with a for loop. ","pontos":8},{"corpo":"int indexVal = 0; Regex re = new Regex(@\"Index: (\\d*)\") Match m = re.Match(s) if(m.Success) indexVal = int.TryParse(m.Groups[1].toString()); I might have the group number wrong, but you should be able to figure it out from here. ","pontos":7},{"corpo":"The three big downsides to using fields instead of properties are: You can't databind to a field whereas you can to a property If you start off using a field, you can't later (easily) change them to a property There are some attributes that you can add to a property that you can't add to a field ","pontos":38},{"corpo":"I use auto-properties all the time. Before C#3 I couldn't be bothered with all the typing and just used public variables instead. The only thing I miss is being able to do this: public string Name = \"DefaultName\"; You have to shift the defaults into your constructors with properties. tedious :-( ","pontos":3},{"corpo":"I've had a problem like this (tho not the same) in the past where my control was in a different namespace to my form even tho it was in the same project. To fix it I had to add a using My.Other.Namespace; to the top of the designer generated code file. The annoying thing was it kept getting blown away when the designer regenerated the page. ","pontos":5},{"corpo":"I don't have any VPN connections on my current computer but somewhere in the TCP/IP properties for the connection there's a checkbox to indicate that you use the remote host as a gateway or something like that. This once caused me alot of issues since all my traffic would go over the VPN and then back again, even when I wanted to do something locally. ","pontos":0},{"corpo":"If the second dropdown is initially enabled through javascript (I'm assuming this is during a javascript onchange, since you didn't specify), then clicking the back button to reload the previous postback will never enable it. Mixing ASP.NET with classic javascript can be hairy. You might want to have a look at ASP.NET's Ajax implementation (or the third-party AjaxPanel control if you're forced to use an older ASP.NET version). Those will give you the behaviour that you want through pure C#, without forcing you to resort to javascript hackery-pokery. ","pontos":2},{"corpo":"To detect changed files, you could try fam (file alteration monitor) or inotify. The latter is linux-specific, fam has a bsd port which might work on OS X. Both have userspace tools that could be used in a script together with rsync. ","pontos":3},{"corpo":"It seems like perhaps you're solving the wrong problem. If you're trying to edit files on a remote computer then you might try using something like the ftp plugin for jedit. http://plugins.jedit.org/plugins/?FTP This ensures that you have only one version of the file so it can't ever be out of sync. ","pontos":1},{"corpo":"it cannot be done through explorer.exe ","pontos":2},{"corpo":"We use log4net, and normally write both to log files and the database. However, when we've been tracking down a particularly difficult problem, we've enabled the email appender, so that critical log messages went straight to a developer's email account. This allowed us to figure out what was happening more immediately. In addition, our infrastructure team has several tools they use to monitor system uptime, event logs, etc., to give them early warning when something is about to go down. We've also helped them implement custom monitoring scripts that test specific functionality of our code. ","pontos":2},{"corpo":"Using ASP.NET MVC just whipped up a quick bit of code using the .NET XML generation library and then just passed that to a view page that had an XML control on it. In the code-behind I tied the control with the ViewData. This seemed to override the default behaviour of view pages to present a different header. ","pontos":0},{"corpo":"Thanks Phil, You got me to switch tracks and think about time in terms of an array of dates rather than calling a function to redefine time each button click. I'm writing a daily task log/timesheet. After playing with different UI ideas, I think I've realized all I need are a way to get to \"last monday\" where I begin filling out my timesheet, and the next four days of the week as links to readout each of those day's worth of things I've done. That's alot less than needing to iterate through many possible dates. ","pontos":0},{"corpo":"The only problem I have with them is that they don't go far enough. The same release of the compiler that added automatic properties, added partial methods. Why they didnt put the two together is beyond me. A simple \"partial On PropertyName Changed\" would have made these things really really useful. ","pontos":2},{"corpo":" The @ tells the compiler to ignore any escape characters in a string. Just wanted to clarify this one... it doesn't tell it to ignore the escape characters, it actually tells the compiler to interpret the string as a literal. If you have string s = @\"cat dog fish\" it will actually print out as (note that it even includes the whitespace used for indentation): cat dog fish ","pontos":221},{"corpo":"I don't know a lot about ASP.NET, but why not write a custom function for the onload event that in turn calls both functions for you? If you've got two functions, call them both from a third script which you register for the event. ","pontos":1},{"corpo":"Try this: window.attachEvent(\"onload\", myOtherFunctionToCall); function myOtherFunctionToCall() { // do something } edit: hey, I was just getting ready to log in with Firefox and reformat this myself! Still doesn't seem to format code for me with IE7. ","pontos":2},{"corpo":"I use m_ for member variables, but I'm increasingly becoming tempted to just using lowerCamelCase like I do for method parameters and local variables. Public stuff is in UpperCamelCase. This seems to be more or less accepted convention across the .NET community. ","pontos":-3},{"corpo":"The tools look nice (especially Resharper but at $200-350 ouch!) but I ended up just recording a macro and assigning it to ctrl+alt+[ Macro came out like this: Sub FunctionBraces() DTE.ActiveDocument.Selection.NewLine DTE.ActiveDocument.Selection.Text = \"{}\" DTE.ActiveDocument.Selection.CharLeft DTE.ActiveDocument.Selection.NewLine(2) DTE.ActiveDocument.Selection.LineUp DTE.ActiveDocument.Selection.Indent End Sub Edit: I used the macro recorder to make this and it wasn't too bad ","pontos":6},{"corpo":"C#3 and .Net 3.5 adds new assemblies, but the IL is unchanged. This means that with .Net 2 assemblies you can compile and use C#3, as long as you don't use Linq or anything else that references System.Linq or System.Core , , lambda syntax, anon types and initialisers are all compiler cleverness. The IL they produce is cross-compatible. If you can reference the new assemblies for 3.5 it should all just work. There is no new version of ASP.Net - it should still be 2.0.50727 - but you should still compile for 3.5 ","pontos":6},{"corpo":"I never use underscores in my variable names. I've found that anything besides alpha (sometimes alphanumeric) characters is excessive unless demanded by the language. ","pontos":0},{"corpo":"A hook to notify the bug/issue management system of changes to repository. Ie. the commit message has issue:546 or similar tag in it that is parsed and fed to the bug management system. ","pontos":0},{"corpo":"I came through VB and have held onto the control type prefix for controls. My private members use lower-camel case (firstLetterLowercase) while public members use Pascal/upper-camel case (FirstLetterUppercase). If there are too many identifiers/members/locals to have a 90% chance of remembering/guessing what it is called, more abstraction is probably necessary. I have never been convinced that a storage type prefix is useful and/or necessary. I do, however, make a strong habit of following the style of whatever code I am using. ","pontos":1},{"corpo":"Paul - saw the update. Very interesting. It would be interesting to try it on Vista or Win2008, as people seem to be reporting some considerable I/O improvements on these in some circumstances. My only suggestion about a different API would be to try memory mapping the files - have you tried that? Unfortunately at 2GB per file, you're not going to be able to map multiple whole files on a 32-bit machine, which means this isn't quite as trivial as it might be. ","pontos":0},{"corpo":"It's called a full outer join and it's not supported natively in MySQL, judging from its docs. You can work around this limitation using UNION as described in the comments to the page I linked to. [edit] Since others posted snippets, here you go. You can see explanation on the linked page. SELECT * FROM A LEFT JOIN B ON A.id = B.id UNION ALL SELECT * FROM A RIGHT JOIN B ON A.id = B.id WHERE A.id IS NULL ","pontos":5},{"corpo":"I don't think SVG is a good choice for the future. From Wikipedia: \"The most common IE plugin was produced by Adobe. Adobe, however, are planning to withdraw this product at the beginning of 2009\" \"... Internet Explorer which will also not support SVG in the upcoming version IE8\" \"...all have incomplete support for the SVG 1.1...\" \"The Corel SVG Viewer plugin was once offered from Corel. Its development has stopped.\" ","pontos":0},{"corpo":"You're correct, you can't actually get access to the enumerations. Just a wee nitpick, this constant doesn't need to be an object, you can make it an int32 - Const ADSGROUPTYPEGLOBALGROUP As Object = H2 ","pontos":0},{"corpo":"The 'default' keyword in generic types: T t = default(T); results in a 'null' if T is a reference type, and 0 if it is an int, false if it is a boolean, etcetera. ","pontos":255},{"corpo":"Thanks for the resource. It certainly helped me test out the webservice, but it didn't much help with using the WCF service in my .net 2.0 application. What I eventually ended up doing was going back to the architects and explaining that the 3.0 dll's that I needed to reference got compiled back to run on the 2.0 CLR. We don't necessarily like the solution, but we're going to go with it for now as there doesn't seem to be too many viable alternatives ","pontos":0},{"corpo":"We've been running an application using Hibernate talking to multiple remote MSQL Server instances for a few years now and we also switched to the jTDS driver early on after a few issues with the M$ driver. Since the switch we haven't had any issues at all. However, it's not a complicated application so it doesn't use any LOB's. Hope that helps. ","pontos":1},{"corpo":"Generally no. By the time you've got confirmation that a Window is valid another process/thread my come along and remove it for you. ","pontos":3},{"corpo":"If you needed to sort it, then you could implement a sort that also removes duplicates. Kills two birds with one stone, then. ","pontos":9},{"corpo":"I thought they were - I'm not sure of the point of the lock in your example unless you're also doing something to s_Provider at the same time - then the lock would ensure that these calls happened together. Does that comment cover creating s_Provider? For instance private static void Initialize() { if (s_Initialized) return; lock(s_lock) { s_Provider = new MembershipProvider ( ... ) s_Initialized = true; } } Otherwise that static property-get's just going to return null anyway. ","pontos":0},{"corpo":"The Initialize function is faulty. It should look more like this: private static void Initialize() { if(s_initialized) return; lock(s_lock) { if(s_Initialized) return; s_Initialized = true; } } Without the second check inside the lock it's possible the initialisation code will be executed twice. So the first check is for performance to save you taking a lock unnecessarily, and the second check is for the case where a thread is executing the initialisation code but hasn't yet set the flag and so a second thread would pass the first check and be waiting at the lock. ","pontos":2},{"corpo":"What you're asking is whether accessing a field in a method multiple times atomic -- to which the answer is no. In the example above, the initialise routine is faulty as it may result in multiple initialization. You would need to check the flag inside the lock as well as outside, to prevent a race condition in which multiple threads read the flag before any of them actually does the initialisation code. E.g., private static void Initialize() { if (s_Initialized) return; lock(s_lock) { if (s_Initialized) return; s_Provider = new MembershipProvider ( ... ) s_Initialized = true; } } ","pontos":0},{"corpo":"\"I guess you could use your favourite image editor and pick the colors from a screen grab.\" This is essentially what I'm doing at the moment, and I've defined a list of constants from which I pull out the colours. Doesn't seem very elegant though! ","pontos":0},{"corpo":"I'm not a lawyer, but - is that even legal? It's normal that they own anything you do while working for them or on their machines, but when you're home after work, using your machine, they normally are not able to own anything you do. ","pontos":0},{"corpo":"I think you're asking if could be in an unstable state when read outside the lock. The short answer is no. A simple assignment/read will boil down to a single assembly instruction which is atomic on every processor I can think of. I'm not sure what the case is for assignment to 64 bit variables, it depends on the processor, I would assume that it is not atomic but it probably is on modern 32 bit processors and certainly on all 64 bit processors. Assignment of complex value types will not be atomic. ","pontos":1},{"corpo":"Ack, nevermind... as pointed out, this is indeed incorrect. It doesn't prevent a second thread from entering the \"initialize\" code section. Bah. You could also decorate s_Initialized with the volatile keyword and forego the use of lock entirely. ","pontos":-2},{"corpo":" I'm not a lawyer, but - is that even legal? Unfortunately yes!! It shouldn't be but it still is. One of the best examples is that Steve Wozniak worked for HP at the time he designed the Apple I... as such he was required to give them \"first rights\" to his design! Fortunately for him and Jobs, they thought it was crap!! Some companies really do stretch the limits of this, and the laws definitely need to change. But what they are trying to do is cover themselves legally in the case that you did do something on company time and release it under your name, but they can't prove that you did it on their time...so by owning everything you do, they've covered that issue. Personally I wouldn't work for a company that does this...I've got too many side projects that I enjoy working on and would not want to give up. And it's not far from slavery in my mind. I've actually tried to simply cross out those sections on a contract in the past (which is entirely legal and if they sign it that way it is binding) but they would not sign it without those sections intact... so I walked. Even if you have signed it...go to them and tell them that you have researched it more and have concerns. They may be willing to work out a deal with you, you never know unless you ask. Edit: One thing to keep in mind...to CYA, never work on anything that is your own while at work or on their computer...even it you are at home with your company laptop. Even if the company doesn't have these rules, like mine, if you release something and they then find out that you did use company resources, whatever you created is theirs...and possibly even anything you created in the past. It can be real mess. Oh, and make your whatever you do is in a very different business segment from your work...anti-compete laws can be a bitch. ","pontos":22},{"corpo":"Like the recent case involving non-competes, these kinds of \"agreements\" aren't necessarily legal, but proving so will often require a lawsuit and trial in front of a judge. As a more practical way to resolve the situation, I know of many people who have had a lawyer draft up an amendment to that agreement. The amendment specifically exempts work done offsite, using all personal equipment and none of the employer's existing intellectual property. In most of those cases, the employer was OK with the amendment. In a few cases, they also insisted on something of a non-compete clause so that the employee couldn't launch a competing product. I personally have avoided signing by pointing out the absurdity and asking for explicit permission to own the short stories, poetry, photography, songs, paintings and the novel I dabble with on the weekends. I got the reaction of \"Well, that's not what we meant.\" I replied, \"That's fine, but what you mean and what this contract state are apparently 2 different things then.\" They let me stay on without agreeing to it. Of course, I also know of a lot of people who work in such companies who manage to \"forget\" to sign the paperwork about IP ownership long enough that everyone just moves on. ","pontos":9},{"corpo":"You may need to install (reinstall) VS 2005 SP1, since a security update from Microsoft (KB928365) on July 10 may have caused the issue. ","pontos":3},{"corpo":"I hope they pay you like you're Bill Gates, because that policy is just plain out retarded. Why you cannot work for open source projects just blows my mind. Are they afraid you'll use some for loop somewhere in an open source project ? They actually should pay you more just because you take the effort to contribute and train yourself at home... I don't know, it's your call of course, but I would strongly object to those policies... Just my 2 cc ;) ","pontos":1},{"corpo":"What specifically does that question mean? Does reverse mean setting 1's to 0's and vice versa? Or does it mean 00001100 --> 00110000 where you reverse their order in the byte? Or perhaps just reversing the part that is from the first 1 to the last 1? ie. 00110101 --> 00101011? Assuming it means reversing the bit order in the whole byte, here's an x86 assembler version: ; al is input register ; bl is output register xor bl, bl ; clear output ; first bit rcl al, 1 ; rotate al through carry rcr bl, 1 ; rotate carry into bl ; duplicate above 2-line statements 7 more times for the other bits not the most optimal solution, a table lookup is faster. ","pontos":4},{"corpo":"Sorry for that.. Thought a similar thread would appear in the related questions. There is already a thread: link text ","pontos":0},{"corpo":"NOTE : NOT tested! string[] test(string[] myStringArray) { List String myStringList = new List string (); foreach (string s in myStringArray) { if (!myStringList.Contains(s)) { myStringList.Add(s); } } return myStringList.ToString(); } Might do what you need... EDIT Argh!!! beaten to it by rob by under a minute! ","pontos":1},{"corpo":"The first option you describe is essentially a pessimistic locking model whilst the second is an optimistic model. Which one to choose really comes down to a number of factors but essentially boils down to how the business wants to work. For example, would it unduly inconvenience the users if a document they needed to edit was locked by another user? What happens if a document is locked and someone goes on holiday with their client connected? What is the likely contention for each document - i.e. how likely is it that the same document will be modified by two users at the same time?, how localised are the modifications likely to be within a single document? (If the same section is modified regularly then performing a merge may take longer than simply making the changes again). Assuming the contention is relatively low and/or the size of each change is fairly small then I would probably opt for an optimistic model that resolves conflicts using an automatic or manual merge. A version number or a checksum of the document's contents can be used to determine if a merge is required. ","pontos":1},{"corpo":" You could also decorate s_Initialized with the volatile keyword and forego the use of lock entirely. That is not correct. You will still encounter the problem of a second thread passing the check before the first thread has had a chance to to set the flag which will result in multiple executions of the initialisation code. ","pontos":1},{"corpo":"Sorry, no link, but one advice. Because we support Oracle and SQL Server, I know that getting fixes for the 'normal' Oracle database, is not something what I call fun. You have to pay for it, and if you have no tool which updates your Oracle system for you, it's a pain in the a.., if you ask me. Check out how the Oracle XE is supported with updates/fixes. I don't know, I only use the 'normal' Oracle (Developer) database. ","pontos":2},{"corpo":"I don't really like the flvPlayback-component, it's hard to handle both implementation wise and somewhat tricky to skin nicely and it's also quite bloated. So I'd opt to use either the JW Flash Media Player as recommended by Michael above or rolling my own entirely. ","pontos":1},{"corpo":"Delivering email can be like black magic sometimes. The reverse DNS is really important. I have found it to be very helpful to carefully track NDRs. I direct all of my NDRs to a single address and I have a windows service parsing them out (Google ListNanny). I put as much information from the NDR as I can into a database, and then I run reports on it to see if I have suddenly started getting blocked by a certain domain. Also, you should avoid sending emails to addresses that were previously marked as NDR, because that's generally a good indication of spam. If you need to send out a bunch of customer service emails at once, it's best to put a delay in between each one, because if you send too many nearly identical emails to one domain at a time, you are sure to wind up on their blacklist. Some domains are just impossible to deliver to sometimes. Comcast.net is the worst. Make sure your IPs aren't listed on sites like http://www.mxtoolbox.com/blacklists.aspx. ","pontos":7},{"corpo":"The problem isn't the number of days in the month, it's how many weeks it spans over. February in a non-leap year will have 28 days, and if the first day of the month is a monday, february will span exactly 4 week numbers. However, if the first day of the month is a tuesday, or any other day of the week, february will span 5 week numbers. A 31 day month can span 5 or 6 weeks the same way. If the month starts on a monday, the 31 days gives you 5 week numbers. If the month starts on saturday or sunday, it will span 6 week numbers. So the right way to obtain this number is to find the week number of the first and last days of the month. Edit #1: Here's how to calculate the number of weeks a given month spans: Edit #2: Fixed bugs in code public static Int32 GetWeekForDateCurrentCulture(DateTime dt) { CultureInfo culture = Thread.CurrentThread.CurrentCulture; Calendar cal = culture.Calendar; return cal.GetWeekOfYear(dt, culture.DateTimeFormat.CalendarWeekRule, culture.DateTimeFormat.FirstDayOfWeek); } public static Int32 GetWeekSpanCountForMonth(DateTime dt) { DateTime firstDayInMonth = new DateTime(dt.Year, dt.Month, 1); DateTime lastDayInMonth = firstDayInMonth.AddMonths(1).AddDays(-1); return GetWeekForDateCurrentCulture(lastDayInMonth) - GetWeekForDateCurrentCulture(firstDayInMonth) + 1; } ","pontos":0},{"corpo":"On another note; setting the wmode to transparent has a few kinks. For instance it can break the scrolling (the flash stays in the same place disregarding the scroll) in some older versions of Firefox (pre 2.0). I've also had issues with ALT-key combinations in textfields not working when wmode is transparent. Also, if you need to place html-content above flash-content (not a good idea generally, but there are cases when it's useful) wmode=transparent is the way to go. ","pontos":2},{"corpo":"Currently documents are published by a limited group of people, each of them working on a separate subject. So, the inconvenience introduced by locks is minimized. People mostly extend existing documents and correct mistakes in them. Speaking about the pessimistic model, the 'left client connected for N days' scenario could be avoided by setting lock expire date to, say, one day before lock start date. Because documents edited are by no means mission critical, and are modified by multiple users quite rarely, that could be enough. Now consider the optimistic model. How should the differences be detected, if the documents have some regular (say, hierarchical) structure? If not? What are the chances of successful automatic merge in these cases? The situation becomes more complicated, because some of the documents (edited by the 'admins' user group) contain important configuration information (document global index, user roles, etc.). To my mind, locks are more advantageous for precisely this kind of information, because it's not changed on everyday basis. So some hybrid solution might be acceptable. What do you think? ","pontos":0},{"corpo":"Here's what I do for paging: All of my big queries that need to be paged are coded as inserts into a temp table. The temp table has an identity field that will act in a similar manner to the row_number() mentioned above. I store the number of rows in the temp table in an output parameter so the calling code knows how many total records there are. The calling code also specifies which page it wants, and how many rows per page, which are selected out from the temp table. The cool thing about doing it this way is that I also have an \"Export\" link that allows you to get all rows from the report returned as CSV above every grid in my application. This link uses the same stored procedure: you just return the contents of the temp table instead of doing the paging logic. This placates users who hate paging, and want to see everything, and want to sort it in a million different ways. ","pontos":0},{"corpo":"1) Premature optimization is evil. Implement your \"expensive stuff\" in C# and see if you need to refactor it. Or, at least set up a test that will allow you to determine this. 2) Yowch. Cross platform UI. I wouldn't put up with the \"may\" stuff. Nail the weasels down; how can you possibly make design decisions without knowing what you're designing? If you go with a pure .NET implementation, will they complain if you have to (at a minimum) refactor it to work in Mono? If you create it in Java, will they be annoyed that it looks ugly as hell and users complain that they can't find their .exe file amongst all those .jars? ","pontos":3},{"corpo":" List String myStringList = new List string (); foreach (string s in myStringArray) { if (!myStringList.Contains(s)) { myStringList.Add(s); } } This is O(n^2), which won't matter for a short list which is going to be stuffed into a combo, but could be rapidly be a problem on a big collection. ","pontos":2},{"corpo":"Could be oodles of things. For example, I've seen (yes, actually seen) this happen after: Domain controller reboot Exchange server reboot Router outage Service account changes SQL Server running out of disk space So until it happens again, I wouldn't freak out over it. ","pontos":1},{"corpo":"No, it does not make sense to do the \"expensive stuff\" in C/C++. The potential (and most likely minor) performance improvements never, ever outweigh your productivity being an abject, sick joke when compared to C#. Really. It's not even close. Read through this (and all posts referenced within): http://blogs.msdn.com/ricom/archive/2005/05/10/416151.aspx ","pontos":2},{"corpo":"1) Not necessarily. I think it would be more correct to say that it's probably worthwhile writing your backend code in C++, regardless of the performance implications. Even though you can't tie your higher-ups down on the platform switch, it would be prudent of you to make preparations for that eventuality, since management types tend to change their mind alot without good reason (or warning); even if they decide not to switch now, that doesn't mean that they won't decide to switch six months from now. Writing your logic in C++ now, knowing that it's a possibility, though more difficult, may make your life significantly easier later. 2) Not really. There are \"solutions\" like wxWindows and GTK#, but often they're buggy, or difficult to get working properly, or they lack something important on one platform or another. They also usually lock you into a lowest-common-denominator UI (ie, general controls work fine but you can forget about ever doing something interesting -- WPF, for example -- with it). UIs are easy to write, so I think if you write your logic in something that's portable, it should be a trivial matter to knock together several platform-specific UIs. ","pontos":3},{"corpo":" What specifically does that question mean? Good question. If reversing the \"ON\" bits means reversing only the bits that are \"ON\", then you will always get 0, no matter what the input is. If it means reversing all the bits, i.e. changing all 1s to 0s and all 0s to 1s, which is how I initially read it, then that's just a bitwise NOT, or complement. C-based languages have a complement operator, , that does this. For example: unsigned char b = 102; /* 0x66, 01100110 */ unsigned char reverse = ~b; /* 0x99, 10011001 */ ","pontos":14},{"corpo":"My advice would be not to worry about it (although as was already said, don't do this on company time/equipment under ANY circumstances), and if you're questioned or they attempt to assert ownership over something that yours, make a giant pain of yourself and they'll more likely just go away and leave you alone. There are lots of ways to do this. My personal favourite is dumping a bunch of code that's out of order on them, or which I worked on with someone else (which means I can give them, at most, 50% of the actual code I have), or to print everything out in 36-point font and give them a mile-high stack of paper. They may be able to force you to give them your intellectual property. However, in my experience, most companies neglect to specify HOW you have to give it to them, and it's always just assumed that you'll give it to them in a coherent form that they can use... except that this is never stated, which gives you a BIG out. ","pontos":1},{"corpo":"Just as a side question and following up on my 'ego trip' comment: why would you take anything on the web to be 'true'? IME printed submissions, while not necessarily accurate, tend to be slightly less, erm... exaggerated than web submissions. Do those responding\\viewing ever hire? I wouldn't google for a candidate. I might ego surf for a respondent, but would ignore CVs. Rounding back to the OP, I would suggest that you need to SHOW what you're good at - participate in Open Source projects and POST on their forums, link to projects you can post details of and generally try to show what a Good Employee you could be. Just telling me that you're good at [insert latest trend here] means diddly. ","pontos":1},{"corpo":"Lucida Console every time. I've never found a font that can pack as many lines of code onto the screen at the same point size without looking cramped. And it looks nice too. ","pontos":1},{"corpo":"When compiling I use Ant and have full control over that from TextMate, what I want is to be able to launch the debugger and the profiler. The command line debugger is unusable and there is no other profiler available than the one in FlexBuilder. ","pontos":1},{"corpo":"I remember doing this a few years ago - so I'm talking Office XP or 2003 days, not 2007. Obviously a better solution for automation these days is to use the new XML format that describes docx etc using the System.IO.Packaging namespace. Back then, I used to notice that whenever MSWord had kicked the bucket and had had enough, a process called \"Dr. Watson\" was running on the machine. This was my first clue that Word had tripped and fallen over. Sometimes I might see more than one WINWORD.EXE, but my code just used to scan for the good Doctor. Once I saw that (in code), I killed all WINWORD.EXE processes the good Doctor himself, and restarted the process of torturing Word :-) Hope that gives you some clues as to what to look for. All the best, Rob G P.S. I might even be able to dig out the code in my archives if you don't come right! ","pontos":1},{"corpo":"@aib is unfortunately incorrect. Assuming strict mode (the default compiler mode) it is not possible to modify the prototype of non-dynamic class types in ActionScript 3. I'm not even sure that it's possible in non-strict mode. Is wrapping an option? Basically you create a class that takes one of the objects you get from the web service and just forwards all method calls to that, but also has methods of its own: public class FooWrapper extends Foo { private var wrappedFoo : Foo; public function FooWrapper( foo : Foo ) { wrappedFoo = foo; } override public function methodFromFoo( ) : void { wrappedFoo.methodFromFoo(); } override public function anotherMethodFromFoo( ) : void { wrappedFoo.anotherMethodFromFoo(); } public function newMethodNotOnFoo( ) : String { return \"Hello world!\" } } When you want to work with a , but also have the extra method you need you wrap the instance in a and work with that object instead. It's not the most convenient solution, there's a lot of typing and if the generated code changes you have to change the class by hand, but unless you can modify the generated code either to include the method you want or to make the class dynamic I don't see how it can be done. Another solution is to add a step to your build process that modifies the source of the generated classes. I assume that you already have a step that generates the code from a WSDL, so what you could do is to add a step after that that inserts the methods you need. ","pontos":1},{"corpo":"I agree with keeping everything in source control and manually scripting all changes. Changes to the schema for a single release go into a script file created specifically for that release. All stored procs, views, etc should go into individual files and treated just like .cs or .aspx as far as source control goes. I use a powershell script to generate one big .sql file for updating the programmability stuff. I don't like automating the application of schema changes, like new tables, new columns, etc. When doing a production release, I like to go through the change script command by command to make sure each one works as expected. There's nothing worse than running a big change script on production and getting errors because you forgot some little detail that didn't present itself in development. I have also learned that indexes need to be treated just like code files and put into source control. And you should definitely have more than 2 databases - dev and live. You should have a dev database that everybody uses for daily dev tasks. Then a staging database that mimics production and is used to do your integration testing. Then maybe a complete recent copy of production (restored from a full backup), if that is feasible, so your last round of installation testing goes against something that is as close to the real thing as possible. ","pontos":0},{"corpo":"There's a command line utility called that does more or less what you want to do. You could probably get the code from the developer (his e-mail address is in the readme you get when you download the utility). ","pontos":1},{"corpo":"Is arithabort on or off from ASP.net 2.0 ","pontos":1},{"corpo":"This is what I've learned so far from my research. .NET sends in connection settings that are not the same as what you get when you log in to management studio. Here is what you see if you sniff the connection with Sql Profiler: -- network protocol: TCP/IP set quoted_identifier off set arithabort off set numeric_roundabort off set ansi_warnings on set ansi_padding on set ansi_nulls off set concat_null_yields_null on set cursor_close_on_commit off set implicit_transactions off set language us_english set dateformat mdy set datefirst 7 set transaction isolation level read committed I am now pasting those setting in above every query that I run when logged in to sql server, to make sure the settings are the same. For this case, I tried each setting individually, after disconnecting and reconnecting, and found that changing arithabort from off to on reduced the problem query from 90 seconds to 1 second. The most probable explanation is related to parameter sniffing, which is a technique Sql Server uses to pick what it thinks is the most effective query plan. When you change one of the connection settings, the query optimizer might choose a different plan, and in this case, it apparently chose a bad one. But I'm not totally convinced of this. I have tried comparing the actual query plans after changing this setting and I have yet to see the diff show any changes. Is there something else about the arithabort setting that might cause a query to run slowly in some cases? The solution seemed simple: Just put set arithabort on into the top of the stored procedure. But this could lead to the opposite problem: change the query parameters and suddenly it runs faster with 'off' than 'on'. For the time being I am running the procedure 'with recompile' to make sure the plan gets regenerated each time. It's Ok for this particular report, since it takes maybe a second to recompile, and this isn't too noticeable on a report that takes 1-10 seconds to return (it's a monster). But it's not an option for other queries that run much more frequently and need to return as quickly as possible, in just a few milliseconds. ","pontos":17},{"corpo":"I've really fallen in love with Droid Sans Mono. ","pontos":84},{"corpo":"The SQLite API has a function called something like which takes one statement and prepares it for execution, essentially parsing the SQL and storing it in memory. This means that the SQL only has to be sent once to the database engine even though the statement is executed many times. Anyway, a statement is a single SQL query, that's just the rule. The AIR SQL API doesn't allow sending raw SQL to SQLite, only single statements, and the reason is, likely, that AIR uses the function when it talks to SQLite. ","pontos":7},{"corpo":"I just looked at the AIR SQL API, and there's an method on it looks exactly what you need. I haven't tested this, but according to the documentation it should work: var connection : SQLConnection = new SQLConnection(); connection.open(firstDbFile); connection.attach(secondDbFile, \"otherDb\"); var statement : SQLStatement = new SQLStatement(); statement.connection = connection; statement.text = \"INSERT INTO main.myTable SELECT * FROM otherDb.myTable\"; statement.execute(); There may be errors in that code snipplet, I haven't worked much with the AIR SQL API lately. Notice that the tables of the database opened with are available using , any attached database can be given any name at all ( in the example above). ","pontos":6},{"corpo":"I've been using the following snipplet to parse UTC date strings: private function parseUTCDate( str : String ) : Date { var matches : Array = str.match(/(\\d\\d\\d\\d)-(\\d\\d)-(\\d\\d) (\\d\\d):(\\d\\d):(\\d\\d)Z/); var d : Date = new Date(); d.setUTCFullYear(int(matches[1]), int(matches[2]) - 1, int(matches[3])); d.setUTCHours(int(matches[4]), int(matches[5]), int(matches[6]), 0); return d; } Just remove the time part and it should work fine for your needs: private function parseDate( str : String ) : Date { var matches : Array = str.match(/(\\d\\d\\d\\d)-(\\d\\d)-(\\d\\d)/); var d : Date = new Date(); d.setUTCFullYear(int(matches[1]), int(matches[2]) - 1, int(matches[3])); return d; } No idea about the speed, I haven't been worried about that in my applications. 50K iterations in significantly less than a second on my machine. ","pontos":17},{"corpo":"I didn't see a native way for WCF to do compression when doing a WCF project recently. I just used the System.IO.Compression namespace and made a quick compressor. Here's the code i used public static class CompressedSerializer { /// summary /// Decompresses the specified compressed data. /// /summary /// typeparam name=\"T\" /typeparam /// param name=\"compressedData\" The compressed data. /param /// returns /returns public static T Decompress T (byte[] compressedData) where T : class { T result = null; using (MemoryStream memory = new MemoryStream()) { memory.Write(compressedData, 0, compressedData.Length); memory.Position = 0L; using (GZipStream zip= new GZipStream(memory, CompressionMode.Decompress, true)) { zip.Flush(); var formatter = new System.Runtime.Serialization.Formatters.Binary.BinaryFormatter(); result = formatter.Deserialize(zip) as T; } } return result; } /// summary /// Compresses the specified data. /// /summary /// typeparam name=\"T\" /typeparam /// param name=\"data\" The data. /param /// returns /returns public static byte[] Compress T (T data) { byte[] result = null; using (MemoryStream memory = new MemoryStream()) { using (GZipStream zip= new GZipStream(memory, CompressionMode.Compress, true)) { var formatter = new System.Runtime.Serialization.Formatters.Binary.BinaryFormatter(); formatter.Serialize(zip, data); } result = memory.ToArray(); } return result; } } then i just had my services take in a byte array as an input, like such void ReceiveData(byte[] data); Worked out well for me. ","pontos":11},{"corpo":"Sorry to follow up with a question, but does prefixing interfaces with \"I\" qualify as hungarian notation? If that is the case, then yes, a lot of people are using it in the real world. If not, ignore this. ","pontos":3},{"corpo":"Where do your desktops live now? If they follow a pattern like: C:\\Foo\\*username*\\bar\\desktop you could use Environment.UserName and strings instead. ","pontos":0},{"corpo":"If the column name is \"StatusID\", and there is a \"Status\" table, with \"StatusID\" and \"Name\" fields, I think it should be painfully obvious. Also, buy a bigger printer. Nothing like a 36\" printer to get that poster-sized schema on the wall. Also, read up on extended properties. They seem to be what you want -- although, as stated, it should not be needed. Start here: Using Extended Properties on Database Objects ","pontos":0},{"corpo":"What's wrong is mixing standards. What's right is making sure that everyone does the same thing. int Box = iBottom * nVerticleSide ","pontos":1},{"corpo":"I'm probably misremembering, but I thought that Joel's question was about counting the \"on\" bits rather than reversing them. ","pontos":1},{"corpo":"I recommend people write code that is fascist in the development environment and benevolent in production. During development you want to catch bad data/logic/code as early as possible to prevent problems either going unnoticed or resulting in later problems where the root cause is hard to track. In production handle problems as gracefully as possible. If something really is a non-recoverable error then handle it and present that information to the user. As an example here's our code to Normalize a vector. If you feed it bad data in development it will scream, in production it returns a safety value. inline const Vector3 Normalize( Vector3arg vec ) { const float len = Length(vec); ASSERTMSG(len 0.0f \"Invalid Normalization\"); return len == 0.0f ? vec : vec / len; } ","pontos":1},{"corpo":"Your UI isn't updating because all the work is happening in the user interface thread. Your call to: this.BeginInvoke((MethodInvoker)delegate() {update.Action.Run(); }) is saying invoke update.Action.Run() on the thread that created \"this\" (your form), which is the user interface thread. Application.DoEvents() will indeed give the UI thread the chance to redraw the screen, but I'd be tempted to create new delegate, and call BeginInvoke on that. This will execute the update.Action.Run() function on a seperate thread allocated from the thread pool. You can then keep checking the IAsyncResult until the update is complete, querying the update object for its progress after every check (because you can't have the other thread update the progress bar/UI), then calling Application.DoEvents(). You also are supposed to call EndInvoke() afterwards otherwise you may end up leaking resources I would also be tempted to put a cancel button on the progress dialog, and add a timeout, otherwise if the update gets stuck (or takes too long) then your application will have locked up forever. ","pontos":5},{"corpo":"Have you turned on ASP.NET tracing yet? I've had an instance where it wasn't the SQL stored procedure itself that was the problem, it was the fact that the procedure returned 5000 rows and the app was attempting to create databound ListItems with those 5000 items that was causing the problem. You might look into the execution times between the web app functions as well through the trace to help track things down. ","pontos":2},{"corpo":"I dont know regex syntax very well but could you not do: [any alpha numeric]*:[any alphanumeric]* I think something like that should work no? ","pontos":0},{"corpo":"When you hover over the type of the field. For instance create a new bug and hover over the \"rank\" and you should see \"Stack rank used to prioritize work\" ","pontos":2},{"corpo":"Match on :? I think the question isn't clear enough, because the answer is so obvious: if(Regex.Match(\":\", input)) // reject ","pontos":1},{"corpo":"Actually, LINQ has Skip and Take methods which can be combined to choose which records are fetched. Check those out. For DB: Pagination In SQL Server 2005 ","pontos":1},{"corpo":"@Justin: When executing a macro, it's a little different... incremental searches will just happen once, and you will have to execute the macro again if you want to search again. You can do more powerful and complex things though, such as search for a keyword, jump to the beginning of the line, mark, go to end of the line, M-w (to copy), then jump to another buffer, then C-y (paste), then jump back to the other buffer and end your macro. Then, each time you execute the macro you will be copying a line to the next buffer. The really cool thing about emacs macros is it will stop when it sees the bell... which happens when you fail to match an incremental search (among other things). So the above macro, you can do C-u 1000 C-x e which will execute the macro 1000 times... but since you did a search, it will only copy 1000 lines, OR UNTIL THE SEARCH FAILS! Which means if there are 100 matches, it will only execute the macro 100 times. EDIT: Check out C-hf highlight-lines-matching-regexp which will show the help of a command that highlights everything matching a regex... I don't know how to undo the highlighting though... anyways you could use a stored macro to highlight all matching the regex, and then another macro to find the next one...? FURTHER EDIT: M-x unhighlight-regexp will undo the highlighting, you have to enter the last regex though (but it defaults to the regex you used to highlight) ","pontos":1},{"corpo":"I am thinking that a generic framework would need to specify between two things: 1. What are the delimiting characters. 2. Under what condition do those characters not count (such as when they are between quotes). I think it may just be better off writing custom logic for every time you need to do something like this. ","pontos":0},{"corpo":"I am not aware of any framework, but a simple state machine works: State 1: Read every char until you hit a \" or a , In case of a \": Move to State 2 In case of a ,: Move to State 3 In case of the end of file: Move to state 4 State 2: Read every char until you hit a \" In case of a \": Move to State 1 In case of the end of the file: Either Move to State 4 or signal an error because of an unterminated string State 3: Add the current buffer to the output array, move the cursor forward behind the , and back to State 1. State 4: this is the final state, does nothing except returning the output array. ","pontos":2},{"corpo":"I use String and not string, Int32 instead of int, so that my syntax highlighting picks up on a string as a Type and not a keyword. I want keywords to jump out at me. ","pontos":0},{"corpo":"Yes, it depends on language, since string storage differs between languages. Pascal-type strings: Length = 0. C-style strings: [0] == 0. .NET: .IsNullOrEmpty. Etc. ","pontos":15},{"corpo":"I might be mistaken, but I'm pretty sure IE6 and less just don't do transparency with PNG files. I have two \"solutions\" that I use. Either create GIF files with transparency and use those everywhere, or just use them for IE 6 and older with conditional style sheets. The second really only works if you are using them as backgrounds, etc. ","pontos":-1},{"corpo":" And again, let me emphasize, the C++ stuff is veerrrryyyy expensive. Would it make sense to do what I mentioned above? (.NET forms hiding heavy lifting C++) As noted before, I personally haven't noticed any system wide slow downs due to WinForms in applications written in both VB.NET and C#. However, if the application is truly performance intensive then you might notice a slight slow down if you wrote everything in C# due to it being complied into CIL (http://www.cl.cam.ac.uk/research/srg/han/hprls/orangepath/timestable-demo/). As such, writing the GUI in a language such as C# will likely make that part of the development a bit easier which would give you more time to work on the critical parts of the code. The only catch-22 here is might notice some slow downs due to the calls to the C/C++ code from the C# code; however, this is likely very unlikely. ","pontos":1},{"corpo":"Two things to consider. 1. How long will it take to process a record? If record processing is very quick, the overhead of handing off records to threads can become a bottleneck. In this case, you would want to bundle records so that you don't have to hand them off so often. If record processing is reasonably long-running, the difference will be negligible, so the simpler approach (1 record per thread) is probably the best. 2. How many threads are you planning on starting? If you aren't using a threadpool, I think you either need to manually limit the number of threads, or you need to break the data into big chunks. Starting a new thread for every record will leave your system thrashing if the number of records get large. ","pontos":2},{"corpo":"When you're going to perform an operation that is going to take a long time, or perhaps a continuous background thread. I guess you could always push the amount of threads available in the pool up but there would be little point in incurring the management costs of a thread that is never going to be given back to the pool. ","pontos":1},{"corpo":"Its the MVC framework. Without 3.5, there is no MVC. Without MVC, ASP.NET is a PITA. ","pontos":1},{"corpo":"In Java 1.6, the String class has a new method isEmpty There is also the Jakarta commons library, which has the isBlank method. Blank is defined as a string that contains only whitespace. ","pontos":1},{"corpo":"I might be misunderstanding the issue, but if it is a network monitoring system, why isn't it written as a \"dedicated\" Windows service? VB.NET shouldn't be much slower than C#. I'm not 100% certain if there is any big differences in the generated IL-code, but the only advantage (and justifiable reason to rewrite it in C#) I could think of (except that C# have a nicer syntax and some other goodies) is the use of unsafe code block that could speed things up a little. ","pontos":0},{"corpo":"@ jsmorris I once had the senior developer and \"architect\" berate me and a tester(it was my first job out of college) in email for not staying late and finishing such an \"easy\" task the night before. We had been at it all day and called it quits at 7pm, I had been thrashing since 11am before lunch that day and had pestered every member our team for help at least twice. I responded and cc'd the team with: \"I've been disappointed in you for a month now. I never get help from the team. I'll be at the coffee shop across the street if you need me. I'm sorry i couldn't debug the 12 parameter, 800 line method that just about everything is dependent on.\" After cooling off at the coffee shop for an hour, i went back in the office, grabbed my crap and left. After a few days they called me asking if I was coming in, I said I would but I had an interview, maybe tomorrow. \"So your quitting then?\" ","pontos":1},{"corpo":" In this case, directly checking the length is faster, because it avoids the overhead of constructing the new empty string. @DerekPark: That's not always true. \"\" is a string literal so, in Java, it will almost certainly already be interned. ","pontos":0},{"corpo":"For C strings, if (s[0] == 0) will be faster than either if (strlen(s) == 0) or if (strcmp(s, \"\") == 0) because you will avoid the overhead of a function call. ","pontos":0},{"corpo":" In languages that use C-style (null-terminated) strings, comparing to \"\" will be faster Actually, it may be better to check if the first char in the string is '\\0': char *mystring; /* do something with the string */ if ((mystring != NULL) (mystring[0] == '\\0')) { /* the string is empty */ } In Perl there's a third option, that the string is undefined. This is a bit different from a NULL pointer in C, if only because you don't get a segmentation fault for accessing an undefined string. ","pontos":2},{"corpo":"Maybe there is a design problem in your tests. Usually each test must not depend on any other tests, so they can run in any order. Each test needs to instantiate and destroy everything it needs to run, that would be the perfect approach, you should never share objects and states between tests. Can you be more specific about why you need the same object for N tests? ","pontos":35},{"corpo":"I don't think the MVC Framework is quite ready for prime time yet, though I definitely plan to use it sometime next year. I love the clean URLs, clean XHTML (web forms can really spew out some nasty HTML) and the ability to create controller actions with no associated view. I've been using Master Pages since they were released and they've been a big help. I do really dislike the way the master pages add the nasty prefixes to the control IDs. It makes for some ugly CSS. I think the MVC Framework may eliminate this problem though. Any other killer features? ","pontos":0},{"corpo":"One thing to keep in mind with using log4net or similar tool is that they change the timing of the application and can often hide the underlying race conditions. We had some poorly written code to debug and introduced logging and this actually removed race conditions and deadlocks (or greatly reduced their frequency). ","pontos":1},{"corpo":" 1) does it make sense to do a GUI in winforms but the expensive stuff in native, unmanaged C/C++ ? Most likely not. Unless you're communicating with a lot of other native C dlls or so on, C# is likely to be between 5% slower to 5% faster than C++ (std::string really kills you if you're using it) 2) any recommendations for a good cross platform windowing kit that would fit for the scenario described above? If it's just some simple forms with buttons, mono will likely be able to run them unmodified. It's support for .NET WinForms is pretty good these days. It is however, butt ugly :-) ","pontos":1},{"corpo":"As a rule, if you have to ask this question, it is a bad idea. ","pontos":1},{"corpo":"I don't like using underscores as prefixes for any identifiers, because C and C++ both reserve certain underscore prefixes for use by the implementation. I think using \"self.variable\" is ugly. In general, I use unadorned identifiers (that is, no prefixes nor suffixes) for instance variables. If your class is so complicated that you can't remember the instance variables, you're in trouble. So for your example, I'd use \"rect\" as the name of the instance variable and \"newRect\" or \"aRect\" as the parameter name. ","pontos":1},{"corpo":"Personally, I follow the Cocoa naming conventions, using camel-casing for functions and variables, and capitalized camel-casing for object names (without the leading NS of course). I find type prefixing makes code more opaque to anyone who didn't write it (since everyone invariably uses different prefixes), and in a modern IDE it's not really that difficult to figure out something's type. ","pontos":2},{"corpo":"I'd focus on the shared memory locks first (the mutexes and semaphores) as they are most likely to cause issues. Look at which state is being protected by locks and then determine which state is under the protection of several locks. This will give you a sense of potential conflicts. Look at situations where code that holds a lock calls out to methods (don't forget virtual methods). Try to eliminate these calls where possible (by reducing the time the lock is held). Given the list of mutexes that are held and a rough idea of the state that they protect, assign a locking order (i.e., mutex A should always be taken before mutex B). Try to enforce this in the code. See if you can combine several locks into one if concurrency won't be adversely affected. For example, if mutex A and B seem like they might have deadlocks and an ordering scheme is not easily done, combine them to one lock initially. It's not going to be easy but I'm for simplifying the code at the expense of concurrency to get a handle of the problem. ","pontos":3},{"corpo":"It is so that you don't have two things trying to update the control at the same time. (This could happen if the CPU switches to the other thread in the middle of a write/read) Same reason you need to use mutexes (or some other synchronization) when accessing shared variables between multiple threads. Edit: In other languages such as C++ you are free to try and do this (without an exception being thrown as in WinForms), but you'll end up learning the hard way! Ahh yes...I switch between C/C++ and C# and therefore was a little more generic then I should've been, sorry... He is correct, you can do this in C/C++, but it will come back to bite you! ","pontos":1},{"corpo":"Your example works in Ruby - I just tried it. irb(main):001:0 require 'stringio' = true irb(main):002:0 s = StringIO.new = # StringIO:0x2ced9a0 irb(main):003:0 s 'foo' = # StringIO:0x2ced9a0 irb(main):004:0 s 'bar' = # StringIO:0x2ced9a0 irb(main):005:0 s.string = \"foobar\" Unless I'm missing the reason you're using to_s - that just outputs the object id. ","pontos":10},{"corpo":"Because you can easily end up with a deadlock (among other issues). For exmaple, your secondary thread could be trying to update the UI control, but the UI control will be waiting for a resource locked by the secondary thread to be released, so both threads end up waiting for each other to finish. As others have commented this situation is not unique to UI code, but is particularly common. In other languages such as C++ you are free to try and do this (without an exception being thrown as in WinForms), but your application may freeze and stop responding should a deadlock occur. Incidentally, you can easily tell the UI thread that you want to update a control, just create a delegate, then call the (asynchronous) BeginInvoke method on that control passing it your delegate. E.g. myControl.BeginInvoke(myControl.UpdateFunction); This is the equivalent to doing a C++/MFC PostMessage from a worker thread ","pontos":11},{"corpo":"Check the error console (Tools Menu > Error Console in Firefox 3) to make sure that there isn't another error happening that you're not seeing, which is stopping your script from working. ","pontos":1},{"corpo":"@Eric, I'm going to have to agree with Dean. Threads are expensive. You can't assume that your program is the only one running. When everyone is greedy with resources, the problem multiplies. I prefer to create my threads manually and control them myself. It keeps the code very easy to understand. That's fine when it's appropriate. If you need a bunch of worker threads, though, all you've done is make your code more complicated. Now you have to write code to manage them. If you just used a thread pool, you'd get all the thread management for free. And the thread pool provided by the language is very likely to be more robust, more efficient, and less buggy than whatever you roll for yourself. Thread t = new Thread(new ThreadStart(DoSomething)); t.Start(); t.Join(); I hope that you would normally have some additional code in between and . Otherwise, the extra thread is useless, and you're wasting resources for no reason. People are way too afraid of the resources used by threads. I've never seen creating and starting a thread to take more than a millisecond. There is no hard limit on the number of threads you can create. RAM usage is minimal. Once you have a few hundred threads, CPU becomes an issue because of context switches, so at that point you might want to get fancy with your design. A millisecond is a long time on modern hardware. That's 3 million cycles on a 3GHz machine. And again, you aren't the only one creating threads. Your threads compete for the CPU along with every other program's threads. If you use not-quite-too-many threads, and so does another program, then together you've used too many threads. Seriously, don't make life more complex than it needs to be. Don't use the thread pool unless you need something very specific that it offers. Indeed. Don't make life more complex. If your program needs multiple worker threads, don't reinvent the wheel. Use the thread pool. That's why it's there. Would you roll your own string class? ","pontos":26},{"corpo":"Can you provide some markup that reproduce the error? Your situation must have something to do with your code since I can get this to work on IE, FF3 and Opera 9.5: html head script function show() { var d = document.getElementById('testdiv'); d.style.display = 'block'; } /script /head body div id=\"testdiv\" style=\"position: absolute; height: 20px; width: 20px; display:none; background-color:Red;\" /div a href=\"javascript:show();\" Click me /a /body /html ","pontos":7},{"corpo":" Master Pages (of course, these are in there from version 2.0) Nested master pages are new in 3.5. I haven't used them yet, but I can only imagine they could turn into a hidious nightmare if not used very carefully. You only have to look at the order in which the events are fired in a page that uses a master page to think 'urgh'. ","pontos":1},{"corpo":"There would also be the need to implement synchronization within update functions that are sensitive to being called simultaneously. Doing this for UI elements would be costly at both application and OS levels, and completely redundant for the vast majority of code. Some APIs provide a way to change the current thread ownership of a system so you can temporarily (or permanently) update systems from other threads without needing to resort to inter-thread communication. ","pontos":1},{"corpo":"@Eric @Derek, I don't exactly agree with the scenario you use as an example. If you don't know exactly what's running on your machine and exactly how many total threads, handles, CPU time, RAM, etc, that your app will use under a certain amount of load, you are in trouble. Are you the only target customer for the programs you write? If not, you can't be certain about most of that. You generally have no idea when you write a program whether it will execute effectively solo, or if it will run on a webserver being hammered by a DDOS attack. You can't know how much CPU time you are going to have. Assuming your program's behavior changes based on input, it's rare to even know exactly how much memory or CPU time your program will consume. Sure, you should have a pretty good idea about how your program is going to behave, but most programs are never analyzed to determine exactly how much memory, how many handles, etc. will be used, because a full analysis is expensive. If you aren't writing real-time software, the payoff isn't worth the effort. In general, claiming to know exactly how your program will behave is far-fetched, and claiming to know everything about the machine approaches ludicrous. And to be honest, if you don't know exactly what method you should use: manual threads, thread pool, delegates, and how to implement it to do just what your application needs, you are in trouble. I don't fully disagree, but I don't really see how that's relevant. This site is here specifically because programmers don't always have all the answers. If your application is complex enough to require throttling the number of threads that you use, aren't you almost always going to want more control than what the framework gives you? No. If I need a thread pool, I will use the one that's provided, unless and until I find that it is not sufficient. I will not simply assume that the provided thread pool is insufficient for my needs without confirming that to be the case. I'm not speaking as someone with only theoretical knowledge here. I write and maintain high volume applications that make heavy use of multithreading, and I generally don't find the thread pool to be the correct answer. Most of my professional experience has been with multithreading and multiprocessing programs. I have often needed to roll my own solution as well. That doesn't mean that the thread pool isn't useful, or appropriate in many cases. The thread pool is built to handle worker threads. In cases where multiple worker threads are appropriate, the provided thread pool should should generally be the first approach. ","pontos":-1},{"corpo":"I think this is a brilliant question - and I think there is need of a better answer. Surely the only reason is that there is something in a framework somewhere that isn't very thread-safe. Is it a problem with .NET or Win32 - and why isn't there a push to fix the source instead of enforcing what, to me, feels like a nasty work-around? Anyone know where the real underlying issue is? ","pontos":0},{"corpo":" I'm not speaking as someone with only theoretical knowledge here. I write and maintain high volume applications that make heavy use of multithreading, and I generally don't find the thread pool to be the correct answer. Ah, argument from authority - but always be on the look out for people who might be on the Windows kernel team. Neither of us were arguing with the fact that if you have some specific requirements then the .NET ThreadPool might not be the right thing. What we're objecting to is the trivialisation of the costs to the machine of creating a thread. The significant expense of creating a thread at the raison d'etre for the ThreadPool in the first place. I don't want my machines to be filled with code written by people who have been misinformed about the expense of creating a thread, and don't, for example, know that it causes a method to be called in every single DLL which is attached to the process (some of which will be created by 3rd parties), and which may well hot-up a load of code which need not be in RAM at all and almost certainly didn't need to be in L1. The shape of the memory hierarchy in a modern machine means that 'distracting' a CPU is about the worst thing you can possibly do, and everybody who cares about their craft should work hard to avoid it. ","pontos":2},{"corpo":"Interesting... I have the opposite problem - Not being able to get the authentication to be passed from the client browser, through the webserver and onto the database within a large corporate network over firewalls. I also feel that \"end to end user\" authentication to the database is a bad idea and a potential security risk. There is nothing to stop the end user from loading up SQL Query and connecting directly to your database, so you'd better have your schema locked down! @Esteban - Clarified my not very useful in helping you answer. ","pontos":0},{"corpo":"I'm going to continue my habit of going against the grain and say that you should question why you are building all these horribly complex object layers. I think many developers think of the database as a simple persistence layer for their objects, and are only concerned with the CRUD operations that those objects need. Too much effort is being put into the \"impedence mismatch\" between object and relational models. Here's an idea: stop trying. Write stored procedures to encapsulate your data. Use results sets, DataSet, DataTable, SqlCommand (or the java/php/whatever equivalent) as needed from code to interact with the database. You don't need those objects. An excellent example is embedding a SqlDataSource into a .ASPX page. You shouldn't try to hide your data from anyone. Developers need to understand exactly how and when they are interacting with the physical data store. Object-relational mappers are the devil. Stop using them. Building enterprise applications is often an exercise in managing complexity. You have to keep things as simple as possible, or you will have an absolutely un-maintainable system. If you are willing to allow some coupling (which is inherent in any application anyway), you can do away with both your business logic layer and your data access layer (replacing them with stored procedures), and you won't need any of those interfaces. ","pontos":0},{"corpo":"prior to SVN 1.5 (which has been out all of a month or so), it didn't track merges at all, so the bits where branches 'reconnect' to the trunk are impossible for it to do anyway ","pontos":2},{"corpo":"Although it sounds reasonable Johns answer isn't correct. In fact even when using Invoke you're still not safe not running into dead-lock situations. When dealing with events fired on a background thread using Invoke might even lead to this problem. The real reason has more to do with race conditions and lays back in ancient Win32 times. I can't explain the details here, the keywords are message pumps, WM_PAINT events and the subtle differences between \"SEND\" and \"POST\". Further information can be found here here and here. ","pontos":7},{"corpo":" I might be mistaken, but I'm pretty sure IE6 and less just don't do transparency with PNG files. You sort of are, and you sort of aren't. IE6 has no support natively for them. However, IE has support for crazy custom javascript/css and COM objects (which is how they originally implemented XmlHttpRequest) All of these hacks basically do this: Find all the png images Use a directx image filter to load them and produce a transparent image in some kind of format IE understands Replace the images with the filtered copy. ","pontos":0},{"corpo":"I've messed with trying to make a site with .pngs and it just isn't worth it. The site becomes slow, and you use hacks that don't work 100%. Here's a good article on some options, but my advice is to find a way to make gifs work until you don't have to support IE6. Or just give IE6 a degraded experience. ","pontos":2},{"corpo":"If you want to learn by getting thrown in the deep end... DasKeyboard ultimate will have you touch typing in no time :) ","pontos":2},{"corpo":"Mavis Beacon. Although not nearly as fun as Typing of the Dead! ","pontos":7},{"corpo":"I tend to focus more on readability of my tests than speed. However, I still try to make them reasonably fast. I think if they run on the order of milliseconds, you are fine. If they run a second or more per test... then you might be doing something that should be optimized. Slow tests only become a problem as the system matures and causes the build to take hours, at which point you are more likely running into an issue of a lot of kind of slow tests rather than one or 2 tests that you can optimize easily... thus you should probably pay attention RIGHT AWAY if you see lots of tests running hundreds of milliseconds each (or worse, seconds each), rather than wait till it gets to the hundreds of tests taking that long point (at which point it is going to be really hard to solve the problem). Even so, it will only reduce the time between when your automated build issues errors... which is ok if it is an hour later (or even a few hours later), I think. The problem is running them before you check in, but this can be avoided by selecting a small subset of tests to run that are related to what you are working on. Just make sure to fix the build if you check in code that breaks tests you didn't run! ","pontos":1},{"corpo":"If we're talking strictly unit tests, I'd aim more for completeness than speed. If the run time starts to cause friction, separate the test into different project/classes etc., and only run the tests related to what you're working on. Let the Integration server run all the tests on checkin. ","pontos":3},{"corpo":"For linux: $ strace sqlplus -L scott/tiger@orcl 2 1| grep -i 'open.*tnsnames.ora' shows something like this: open(\"/opt/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora\",O_RDONLY)=7 Changing to $ strace sqlplus -L scott/tiger@orcl 2 1| grep -i 'tnsnames.ora' will show all the file paths that are failing. ","pontos":10},{"corpo":"I judge my unit tests on a per test basis, not by by # of tests per second. The rate I aim for is 500ms or less. If it is above that, I will look into the test to find out why it is taking so long. When I think a test is to slow, it usually means that it is doing too much. Therefore, just refactoring the test by splitting it up into more tests usually does the trick. The other times that I have noticed my tests running slow is when the test shows a bottleneck in my code, then a refactoring of the code is in order. ","pontos":0},{"corpo":"Based on your comment, \"Showing that the design becomes simpler\" I'm assuming you guys practice TDD. Doing a code review after the fact is not going to work. The whole thing about TDD is that it's a design and not a testing philosophy. If he didn't write the tests as part of the design, you aren't going to get a lot of benefit from writing tests after the fact - especially from a junior developer. He'll end up missing a whole lot of corner cases and his code will still be crappy. Your best bet is to have a very patient senior developer to sit with him and do some pair programming. And just keep at it until he learns. Or doesn't learn, in which case you need to reassign him to a task he is better suited to because you will just end up frustrating your real developers. Not everyone has the same level of talent and/or motivation. Development teams, even agile ones, are made up of people on the \"A-Team\" and people on \"B-Team\". A-Team members are the one who architect the solution, write all the non-trivial production code, and communicate with the business owners - all the work that requires thinking outside the box. The B-Team handle things like configuration management, writing scripts, fixing lame bugs, and doing maintenance work - all the work that has strict procedures that have small consequences for failure. ","pontos":0},{"corpo":"@Nathan: I've upmodded the Common Lisp links, because you asked about Lisp (especially with reference to Emacs Lisp). However, Common Lisp is very different from Scheme. A program written for one is unlikely to run on the other. As you mentioned, SICP is for learning Scheme, not Lisp (or at least, not Common Lisp and not Emacs Lisp). There are some overlap in principles, however you can't simply cut and paste code from SICP and expect it to run on any Common Lisp or Emacs Lisp system. :-) ","pontos":1},{"corpo":"Here's basically what I did to solve this: ($x_str, $y_str, $remainder) = split(/ and /, $str, 3); if ($x_str !~ /x=(.*)/) { # error } $x = $1; if ($y_str !~ /y=(.*)/) { # error } $y = $1; I've omitted some additional validation and error handling. This technique works, but it's not as concise or pretty as I would have liked. I'm hoping someone will have a better suggestion for me. ","pontos":0},{"corpo":"Another good dialect of lisp is cmucl. They used to love to brag about being the \"fastest\" lisp. ","pontos":0},{"corpo":"One of the major sticking points I've had with IIS is the lack of Apache's mod_rewrite. There are other work-arounds and work-alikes depending on what you're doing, but just keep in mind that you'll need to change things up a bit to work with IIS if you're using mod rewrite extensively. ","pontos":0},{"corpo":"Is it just me or are your parameters the wrong way around? Also, do you have the right number of parameters? I could be missing something though, so sorry if you've already checked this stuff: The documentation says: dispatcher.executeDispatch(document, \".uno:Paste\", \"\", 0, Array()) Which would indicate to me that you need to have your parameter list defined as object[] paramlist = new object[5] {objframe, \".uno:Paste\", \"\", 0, null}; ","pontos":1},{"corpo":"And here's a version directly cut and pasted from OpenJDK, which is interesting because it involves no loop. On the other hand, unlike the Scheme version I posted, this version only works for 32-bit and 64-bit numbers. :-) 32-bit version: public static int reverse(int i) { // HD, Figure 7-1 i = (i 0x55555555) 1 | (i 1) 0x55555555; i = (i 0x33333333) 2 | (i 2) 0x33333333; i = (i 0x0f0f0f0f) 4 | (i 4) 0x0f0f0f0f; i = (i 24) | ((i 0xff00) 8) | ((i 8) 0xff00) | (i 24); return i; } 64-bit version: public static long reverse(long i) { // HD, Figure 7-1 i = (i 0x5555555555555555L) 1 | (i 1) 0x5555555555555555L; i = (i 0x3333333333333333L) 2 | (i 2) 0x3333333333333333L; i = (i 0x0f0f0f0f0f0f0f0fL) 4 | (i 4) 0x0f0f0f0f0f0f0f0fL; i = (i 0x00ff00ff00ff00ffL) 8 | (i 8) 0x00ff00ff00ff00ffL; i = (i 48) | ((i 0xffff0000L) 16) | ((i 16) 0xffff0000L) | (i 48); return i; } ","pontos":2},{"corpo":"I'm not the best at regular expressions, but this seems pretty close to what you're looking for: /x=(.+) and y=([^ ]+)( and (.*))?/ Except you use $1, $2, and $4. In use: my @strs = (\"x=1 and y=abc and z=c4g and w=v4l\", \"x=yes and y=no\", \"z=nox and w=noy\"); foreach (@strs) { if ($_ =~ /x=(.+) and y=([^ ]+)( and (.*))?/) { $x = $1; $y = $2; $remainder = $4; print \"x: $x; y: $y; remainder: $remainder\\n\"; } else { print \"Failed.\\n\"; } } Output: x: 1; y: abc; remainder: z=c4g and w=v4l x: yes; y: no; remainder: Failed. This of course leaves out plenty of error checking, and I don't know everything about your inputs, but this seems to work. ","pontos":2},{"corpo":"I've had difficulty getting git to cooperate with wordpad, KomodoEdit and pretty much every other editor I give it. Most open for editing, but git clearly doesn't wait for the save/close to happen. As a crutch, I've just been doing i.e. git commit -m \"Fixed the LoadAll method\" to keep things moving. Tends to keep my commit messages a little shorter than they probably should be, but clearly there's some work to be done on the Windows version of git. The GitGUI also isn't that bad. It takes a little bit of orientation, but after that, it works fairly well. ","pontos":3},{"corpo":"I think the anti-aliasing blur on Consolas is caused by monitors which do not have ClearType enabled. Consolas was designed for ClearType. [Jeff A: indeed, you can see screenshots of this in a post I wrote on this topic.] ","pontos":6},{"corpo":"If you would like to use JavaScript then it has built in date validation functions. However, if you do not want to go the JavaScript route, you could change the UI to dropdown controls which would limit the users ability to enter invalid data. You would still need to check server side to ensure nobody submits Feb 30th. ","pontos":3},{"corpo":"I think one of the major things to watch out is that versions prior to MySQL 5.0 did not have Views, Triggers, and Stored Procedures. More of this is explained in the MySQL 5.0 Download page ","pontos":2},{"corpo":" I think one of the major things to watch out is that versions prior to MySQL 5.0 did not have Views, Triggers, and Stored Procedures. Anyone have any good experience with a \"port\" of a database from SQL Server to MySQL? I use views all the time - it surprises me that MySQL did not support it until 5.0. I'd be curious as to people's experience with Stored Procedures, Views, Triggers, Constraints, Etc in MySQL? ","pontos":0},{"corpo":"Could be PowerShell's default security level, which (IIRC) will only run signed scripts. Try typing this: set-executionpolicy remotesigned That will tell PowerShell to allow local (that is, on a local drive) unsigned scripts to run. Then try executing your script again. ","pontos":66},{"corpo":"I have used AQtime and it has never let me down. I am sure there is a trial version. ","pontos":4},{"corpo":"Matasano Chargen had a good post a while back on porting some debugging code to OS X, which included learning how to read and write memory in another process (among other things). It has to work, otherwise GDB wouldn't: It turns out Apple, in their infinite wisdom, had gutted ptrace(). The OS X man page lists the following request codes: PT_ATTACH  to pick a process to debug PT_DENY_ATTACH  so processes can stop themselves from being debugged [...] No mention of reading or writing memory or registers. Which would have been discouraging if the man page had not also mentioned PT_GETREGS, PT_SETREGS, PT_GETFPREGS, and PT_SETFPREGS in the error codes section. So, I checked ptrace.h. There I found: PT_READ_I  to read instruction words PT_READ_D  to read data words PT_READ_U  to read U area data if youre old enough to remember what the U area is [...] Theres one problem solved. I can read and write memory for breakpoints. But I still cant get access to registers, and I need to be able to mess with EIP. ","pontos":9},{"corpo":"You should use if possible. is nonstandard and less common. For example, it's not available on OS X. Kernel.org - : This function comes from SunOS 4, but is also present in libc4, libc5 and glibc. It no longer occurs in Solaris (SunOS 5). Avoid this function, and use the standard atexit(3) instead. ","pontos":16},{"corpo":"If you use rails it automatically logs all the SQL queries, and the time they took to execute, in your development log file. I find this very useful because if you do see one that's taking a while, it's one step to just copy and paste it straight off the screen/logfile, and put 'explain' in front of it in mysql. You don't have to go digging through your code and reconstruct what's happening. Needless to say this doesn't happen in production as it'd run you out of disk space in about an hour. ","pontos":0},{"corpo":"According to this link I found, it seems there are a few differences. will let you pass in an argument that is passed in to the function when it is called... which might let you set up some pointers to do some cleanup work on when it is time to exit. Furthermore, it appears that was a SunOS specific function that may not be compatible on all platforms... so you may want to stick with atexit, despite it being more restrictive. ","pontos":7},{"corpo":"Data Point -- Python Regression Tests Here are the numbers on my laptop for running \"make test\" for Python 2.5.2: number of tests: 3851 (approx) execution time: 9 min, 6 sec execution rate: 7 tests / sec ","pontos":1},{"corpo":"I'm probably going to get flamed for this, but you really should try and avoid using cursors as they incur a serious performance hit. If you must use it, you should keep it open the absolute minimum amount of time possible so that you free up the resources being blocked by the cursor ASAP. ","pontos":8},{"corpo":"plain text? If they're on your server, I would hope the server is secure enough not to allow unauthorised access. If people can access your config files on the server, something has gone wrong much earlier. ","pontos":1},{"corpo":"I've used RCS, CVS, SCCS, SourceSafe, Vault, perforce, subversion, and git. I've evaluated BitKeeper, Dimensions, arch, bazaar, svk, ClearCase, PVCS, and Synergy. If I had to start a new repository today, I'd choose git. Hands down. It's free, fast, and under active development. And you can use it as a client of any subversion repository using git-svn. It rocks. ","pontos":7},{"corpo":"Unit testing is testing against a unit of work or a block of code if you like. Usually performed by a single developer. Integration testing refers to the test that is performed, preferably on an integration server, when a developer commits their code to a source control repository. Integration testing might be performed by utilities such as Cruise Control. So you do your unit testing to validate that the unit of work you have built is working and then the integration test validates that whatever you have added to the repository didn't break something else. ","pontos":1},{"corpo":"You can bake a symmetric encryption key into your binary, and have that binary read an encrypted username/password from a file on disk when it starts up. However, this is not really much more than obfuscation, since your code is likely to be stored in some source repository somewhere. I would suggest that you would be better served to control access to your servers both physically and over the network using a firewall and a private network bubble, and store the passwords in the clear (or base-64 encoded) on disk with permissions locked down to the run user for your web app. You can also lock down the database server to only accept connections from your web app machines by IP. Ultimately, your problem is that the key (your DB username/password pair) needs to be available for programmatic, unattended use by your web apps. ","pontos":0},{"corpo":"ApexSQL, spendy but nice when migrations are down or just not in at all. ","pontos":14},{"corpo":"I do the same - I call them all unit tests, but at some point I have a \"unit test\" that covers so much I often rename it to \"..IntegrationTest\" - just a name change only, nothing else changes. I think there is a continuation from \"atomic tests\" (testing one tiny class, or a method) to unit tests (class level) and integration tests - and then functional test (which are normally covering a lot more stuff from the top down) - there doesn't seem to be a clean cut off. If your test sets up data, and perhaps loads a database/file etc, then perhaps its more of an integration test (integration tests I find use less mocks and more real classes, but that doesn't mean you can't mock out some of the system). ","pontos":2},{"corpo":"@Nathan First, see if there is another API call to determine exit status... a quick glance and I don't see one, but I am not well versed in the standard C API. An easy alternative is to have a global variable that stores the exit status... the default being an unknown error cause (for if the program terminates abnormally). Then, when you call exit, you can store the exit status in the global and retrieve it from any atexit functions. This requires storing the exit status diligently before every exit call, and clearly is not ideal, but if there is no API and you don't want to risk not being on the platform... it might be the only option. ","pontos":0},{"corpo":"You should switch to And when IronRuby gets mature enough to run it, you can run Then one day in the future it'll get upgraded, and you can run That's way cooler than ants and builds :-) (ahhh I'm tired, sorry guys :-) ) ","pontos":-1},{"corpo":" @superjoe30 What about using source control on your own computer, if you're the sole programmer? Is this good practice? Are there related tips or tricks? I find git is actually easier for this as you don't need a server or worry about entering URL's and so on. Your version-control stuff just lives in the directory inside your project and you just go ahead and use it. 5 second intro (assuming you have installed it) cd myproject git init git add * # add all the files git commit Next time you do some changes git add newfile1 newfile2 # if you've made any new files since last time git commit -a As long as you're doing that, git has your back. If you mess up, your code is safe in the nice git repository. It's awesome Note: You may find getting things OUT of git a bit harder than getting them in, but it's far more preferable to have that problem than to not have the files at all! ","pontos":5},{"corpo":"In most cases, I believe it is sufficient to obfuscate the password in a plain text file (eg. with base64). You cannot completely protect a stored password against a determined sysadmin with root access, so there's not really any need to try. Simple obfuscation, however, protects against accidentally revealing the password to a shoulder surfer. A more complex alternative is to set up a dedicated secure password server that either: provides a password decryption service actually stores the passwords for use by other less secure servers Depending on the network protocols used, this may not protect against a rogue sysadmin with tcpdump. And it probably won't protect against a determined sysadmin with a debugger, either. At that point, it might be time to look at something like Kerberos tickets. ","pontos":1},{"corpo":"@Nathan, I can't find any function that will return the exit code for the current running process. I expect that it isn't set yet at the point when is called, anyway. By this I mean that the runtime knows what it is, but probably hasn't reported it to the OS. This is pretty much just conjecture, though. It looks like you will either need to use or structure your program so that the exit code doesn't matter. It would not be unreasonable to have the last statement in your main function flip a global variable to true. In the function you register with , you could check this variable to determine how the program exited. This will only give you two states, but I expect that would be sufficient for most needs. You could also expand this type of scheme to support more exit states if necessary. ","pontos":1},{"corpo":"Thanks for the help but that's not exactly what I was asking. I can catch unhandled exceptions in the Error event of the page, but I can't get the reference to the UserControl that caused the exception so I could hide just that control. Even if I could get that information somehow through the stack trace (which would be awful way to do it) the execution of the Page is halted and no subsequent controls would render. Maybe someone knows how DotNetNuke handles that, because this is a similar solution... ","pontos":2},{"corpo":"This is an interesting problem.. I am still pretty fresh when it comes to custom controls etc, but here are my thoughts (feel free to comment/correct people!).. (I am kinda thinking/writing out loud here!) If an error occurs during rendering, in some cases, would it not be too late? (since some of the controls HTML may have already been sent to the Writer and output). Therefore, would it not be best to wrap the user control's Render method, but rather than passing it the reference to the \"Live\" HtmlTextWriter, you pass your own, trap any Exceptions raised in this little safety \"bubble\", if all goes well, you then pass your resultant HTML to the actual HtmlTextWriter? This logic could probably be slung to a generic wrapper class which you would use to dynamically load/render the controls at run time.. If any errors do occur, you have all the information you need at your disposal! (i.e control references etc). Just my thoughts, flame away! :D ;) ","pontos":4},{"corpo":"Shorten the timeout on the connection string and execute something trivial. The wait should be about the same as the timeout. You would still need a second or two though. ","pontos":2},{"corpo":"You haven't mentioned what database you are connecting to, however. In SQL Server 2005, from .NET, you can specify a connection timeout in your connection string like so: server= server ;database= database ;uid= user ;password= password ;Connect Timeout=3 This will try to connect to the server and if it doesn't do so in three seconds, it will throw a timeout error. ","pontos":7},{"corpo":"SELECT * FROM table1 WHERE CONVERT(varchar(10),columnDatetime,121) = CONVERT(varchar(10),CONVERT('14 AUG 2008' ,smalldatetime),121) This will convert the datatime and the string into varchars of the format \"YYYY-MM-DD\". This is very ugly, but should work ","pontos":0},{"corpo":"Manipulating a process's memory behind its back is a Bad Thing and is fraught with peril. That's why Mac OS X (like any Unix system) has protected memory, and keeps processes isolated from one another. Of course it can be done: There are facilities for shared memory between processes that explicitly cooperate. There are also ways to manipulate other processes' address spaces as long as the process doing so has explicit right to do so (as granted by the security framework). But that's there for people who are writing debugging tools to use. It's not something that should be a normal  or even rare occurrence for the vast majority of development on Mac OS X. ","pontos":1},{"corpo":"If you're using Sybase 12.5 or earlier then you can't use functions. A workaround might be to populate a temporary table with the values and read them from there. ","pontos":2},{"corpo":"It's not that they were deliberately not allowed on DataTables, it's just that DataTables pre-date the IQueryable and generic IEnumerable constructs on which Linq queries can be performed. Both interfaces require some sort type-safety validation. DataTables are not strongly typed. This is the same reason why people can't query against an ArrayList, for example. For Linq to work you need to map your results against type-safe objects and query against that instead. ","pontos":20},{"corpo":"In applications wherein we use NHibernate, the answer becomes \"somewhere in between\", in that, while the XML mapping definitions (they specify which table belongs to which object and which columns belong to which field, etc) are clearly in the business object tier. They are passed to a generic data session manager which is not aware of any of the business objects; the only requirement is that the business objects passed to it for CRUD have to have a mapping file. ","pontos":0},{"corpo":"There is the Type attribute which allows you to change the numbering style, however, you cannot change the full stop after the number/letter. ol type=\"a\" li Turn left on Maple Street /li li Turn right on Clover Court /li /ol ","pontos":1},{"corpo":"Better late than never... The latest issue of C-Vu turned up and guess what was in it: That's right, iterators that do exactly what you wanted. Unfortunately you need to become a member of the ACCU to view the magazine (the article references the Overload article from 2000 that David links to). But for a measly price a year you get a nice magazine to read, conferences and user groups. When you become a member you can view PDF's of the back issues so what are you waiting for? ","pontos":2},{"corpo":" Anyone have any good experience with a \"port\" of a database from SQL Server to MySQL? This should be fairly painful! I switched versions of MySQL from 4.x to 5.x and various statements wouldn't work anymore as they used to. The query analyzer was \"improved\" so statements which previously were tuned for performance would not work anymore as expected. The lesson learned from working with a 500GB MySQL database: It's a subtle topic and anything else but trivial! ","pontos":2},{"corpo":" only works on .net 2.0 and above, for .net 1/1.1, I tend to use: if (inputString == null || inputString == String.Empty) { // String is null or empty, do something clever here. Or just expload. } I use String.Empty as opposed to \"\" because \"\" will create an object, whereas String.Empty wont - I know its something small and trivial, but id still rather not create objects when I dont need them! (Source) ","pontos":1},{"corpo":"I have a hack to workaround this, which works but isn't ideal: Add a new class to the project that inherits the form with its simple name. internal class MyGenericForm: MyGenericForm object { } This means that although the designer is still wrong the expected simple type (i.e without ) is still found. ","pontos":0},{"corpo":"I concur with the WPF sentiment. Tag/XML based UI would seem to be a bit more portable than WinForms. I guess too you have to consider your team, if there is not a lot of current C# skills, then that is a factor, but going forward the market for MFC developers is diminishing and C# is growing. Maybe some kind of piecemeal approach would be possible? I have been involved with recoding legacy applications to C# quite a bit, and it always takes a lot longer than you would estimate, especially if you are keeping some legacy code, or your team isn't that conversant with C#. ","pontos":0},{"corpo":"@Keith Can you show me a simple code sample of your idea, i'm not sure I understood you completely? As I see it, if I inherit from the base class and override the usercontrols Page_Load event, I think my base class code wouldn't even fire... @Rob Thanks for the comments. That's an interesting idea that might work, but it requires that each UserControl implements some additional logic, and it is not under my control. I will load customly developed user controls, which will implement some interfaces, but I can't control how they will render their output. Bottom linem, my project is something similar to Dot Net Nuke project. I load controls which are developed by other people, and I would like to make sure that error in one control doesn't affect other controls or the entire page. ","pontos":0},{"corpo":"You could try running a big list of realistic operations and looking at IO queues for the different actions. There are a lot of variables that govern it, such as the size of each row and the number of writes vs reads. Basically: high fill factor = quicker read, low = quicker write. However it's not quite that simple, as almost all writes will be to a subset of rows that need to be looked up first. For instance: set a fill factor to 10% and each single-row update will take 10 times as long to find the row it's changing, even though a page split would then be very unlikely. Generally you see fill factors 70% (very high write) to 95% (very high read). It's a bit of an art form. I find that a good way of thinking of fill factors is as pages in an address book - the more tightly you pack the addresses the harder it is to change them, but the slimmer the book. I think I explained it better on my blog. ","pontos":12},{"corpo":"I call unit tests those tests that white box test a class. Any dependencies that class requires is replaced with fake ones (mocks). Integration tests are those tests where multiple classes and their interactions are tested at the same time. Only some dependencies in these cases are faked/mocked. I wouldn't call Controller's integration tests unless one of their dependencies is a real one (i.e. not faked) (e.g. IFormsAuthentication). Separating the two types of tests is useful for testing the system at different levels. Also, integration tests tend to be long lived, and unit tests are supposed to be quick. The execution speed distinction means they're executed differently. In our dev processes, unit tests are run at check-in (which is fine cos they're super quick), and integration tests are run once/twice per day. I try and run integration tests as often as possible, but usually hitting the database/writing to files/making rpc's/etc slows. That raises another important point, unit tests should avoid hitting IO (e.g. disk, network, db). Otherwise they slow down alot. It takes a bit of effort to design these IO dependencies out - i can't admit I've been faithful to the \"unit tests must be fast\" rule, but if you are, the benefits on a much larger system become apparent very quickly. ","pontos":0},{"corpo":"Visual Studio 2008 can do JavaScript debugging, you have to go to IE's Tools->Internet Options->Advanced and uncheck 'Disable Script Debugging (Internet Explorer)' in order for the browser to bubble up the errors it detects. Once you're in Visual Studio you basically have it's entire debugging arsenal at your disposal. It's not as integrated as Firebug, but it is way better than anything we used to have. ","pontos":1},{"corpo":"@Lance: if you have access to Visual FoxPro command line window, type: SET TABLEVALIDATE 11 USE \"YourTable\" EXCLUSIVE If the table is damaged VFP must display an error here PACK To reindex the table and deleted \"marked\" records PACK MEMO If you have memo fields After doing that, the structure of the table must ve valid, if you want to see fields with invalid data, you can try: SELECT * FROM YourTable WHERE EMPTY(YourField) All records with YourField empty SELECT * FROM YourTable WHERE LEN(YourMemoField) 200 All records with a long memo field, there can be corrupted data etc. ","pontos":0},{"corpo":"The first step is to lookup the Fail code's hex value (E.G. E_FAIL 0x80004005). I've had really good luck with posting that value in Google to get a sense of what the error code means. Then, I just use trial and error to try to isolate the location in code that's failing, and the root cause of the failure. ","pontos":2},{"corpo":"We just started using ILMerge in our solutions that are redistributed and used in our other projects and so far so good. Everything seems to work okay. We even obfuscated the packaged assembly directly. We are considering doing the same with the MS Enterprise Library assemblies. The only real issue I see with it is versioning of individual assemblies from the package. ","pontos":0},{"corpo":"You could overload new for Foo and make it private. This would mean that the compiler would moan... unless you're creating an instance of Foo on the heap from within Foo. To catch this case, you could simply not write Foo's new method and then the linker would moan about undefined symbols. class Foo { private: void* operator new(size_t size); }; PS. Yes, I know this can be circumvented easily. I'm really not recommending it - I think it's a bad idea - I was just answering the question! ;-) ","pontos":7},{"corpo":"Not sure if this offers any compile-time opportunities, but have you looked at overloading the 'new' operator for your class? ","pontos":-1},{"corpo":"If you just want a really quick way to find out what the error code means, you could use the \"Error Lookup\" tool packaged with Visual Studio (details here). Enter the hex value, and it will give you the string describing that error code. Of course, once you know that, you've still got to figure out why it's happening. ","pontos":1},{"corpo":"@pix0r That actually annoyed the hell out of me too and nothing came close to Apache mod_rewrite. Because they all have this overly complex XML structure. So I actually took the time and wrote my own rewriter for IIS 6.0 and IIS 7.0. Non-.NET applications only works in IIS 7.0. http://www.managedfusion.com/products/url-rewriter/ http://www.codeplex.com/urlrewriter ","pontos":1},{"corpo":"No this syntax stems from the days before joins were in the language. Not sure of the problems associated with it, but there are definitely language constructs that are more supported for jointing tables. ","pontos":2},{"corpo":"Definitely upgrade to TFS 2008 and Visual Studio 2008, as it is the \"v2\" version of Team System in every way. Fixes lots of small and medium sized problems. As for \"things being randomly checked out\" this is almost always due to Visual Studio deciding to edit files on your behalf. Try getting latest from the Team Explorer, with nothing open in Visual Studio, and see if that behavior persists. I bet it won't! Multiple TFS servers is a bad idea. Make sure your proxy is configured correctly, as it caches repeated GETs. That said, TFS is a server connected model, so it'll always be a bit slower than true \"offline\" source control systems. Also, if you could edit your question to contain more specific complaints or details, that would help -- right now it's awfully vague, so I can't answer very well. ","pontos":2},{"corpo":"I just want to say that this kind of joining is the devils work. Just think about it; the conditions for joining and filtering gets mixed together in the where statement. What happens when you need to join across 20 tables and filter on 15 values? Again, just my $.02 ","pontos":1},{"corpo":"In Microsoft SQL the query plans for these two queries are identical - they are executed in the same way. ","pontos":1},{"corpo":"I like long explicit table names (it's not uncommon to be more than 100 characters) because I use many tables and if the names aren't explicit, I might get confused as to what each table stores. So when I write a query, I tend to use shorter aliases that make sense within the scope of the query and that makes the code much more readable. ","pontos":1},{"corpo":"Microsoft SQL's query optimiser benefits from using either fully qualified names or aliases. Personally I prefer aliases, and unless I have a lot of tables they tend to be single letter ones. --seems pretty readable to me ;-) select a.Text from Question q inner join Answer a on a.QuestionId = q.QuestionId There's also a practical limit on how long a Sql string can be executed - aliases make this limit easier to avoid. ","pontos":9},{"corpo":"If I write a query myself (by typing into the editor and not using a designer) I always use aliases for the table name just so I only have to type the full table name once.I really hate reading queries generated by a designer with the full table name as a prefix to every column name. ","pontos":4},{"corpo":"I guess you could just use a short to store them. Not very efficient, but really the only option besides some herculean effort that I have seen. ","pontos":-1},{"corpo":"When reading any single value from the array copy it into something like a short or an int and manually convert the negative number into the positive value it should be. byte[] foobar = ..; int value = foobar[10]; if (value 0) value += 256 // Patch up the 'falsely' negative value You can do a similar conversion when writing into the array. ","pontos":15},{"corpo":"It doesn't really matter, as long as you're consistent with it. There does seem to be a tendency to demand sameness within a single statement, i.e. if there's brackets in one branch, there's brackets everywhere. The Linux kernel coding standards, for one, mandate that. ","pontos":2},{"corpo":"This is filthy, evil legacy syntax. You write this as Select * -- Oh, and don't ever use *, either From A Inner Join B On A.ID = B.ID Inner Join C On B.ID = C.ID ","pontos":2},{"corpo":"We use TFS with a somewhat distributed team - they aren't too far away but connect via a slow and unreliable VPN. For your first issue, get latest on checkout is not the default behaviour. (Here's an explanation) There is an add-in that will do it for you, though. Here's the workflow that works for us: Get latest Build and verify nothing's broken Work (changes pended) Get latest again Deal with merge conflicts Build and verify nothing's broken Check in [edit] OK looks like you rephrased this part of the question. Yes, Jeff's right, VS decides to check some files out \"for you,\" like sln and proj files. It also automatically checks out any source file that you edit (that's what you want though, right? although you can change that setting in tools > options > source control) The proxy apparently takes a while to get ramped up (we don't use it) but once it has cached most of the tree it's supposed to be pretty quick. Can you do some monitoring and find the bottleneck(s)? Anything else giving you trouble, other than get-latest-on-checkout and speed? ","pontos":1},{"corpo":"I tend to use braces at all times. You can get some subtle bugs where you started off with something like: if(something) DoOneThing(); else DoItDifferently(); and then decide to add another operation to the clause and forget to wrap it in braces: if(something) DoOneThing(); else DoItDifferently(); AlwaysGetsCalled(); will always get called, and if you're sitting there at 3am wondering why your code is behaving all strange, something like that could elude you for quite some time. For this reason alone, I always use braces. ","pontos":8},{"corpo":"I would strongly advocate always using braces, even when they're optional. Why? Take this chunk of C++ code: if (var == 1) doSomething(); doSomethingElse(); Now, someone comes along who isn't really paying enough attention and decides that something extra needs to happen if (var == 1), so they do this: if (var == 1) doSomething(); doSomethingExtra(); doSomethingElse(); It's all still beautifully indented but it won't do what was intended. By always using braces, you're more likely to avoid this sort of bug. ","pontos":2},{"corpo":"I tend to agree with Joel Spolsky on that one with that article (Making Wrong Code Look Wrong) with the following code example : if (i != 0) bar(i); foo(i); Foo is now unconditionnal. Wich is real bad! I always use brackets for decision statements. It helps code maintainability and it makes the code less bug prone. ","pontos":0},{"corpo":"Yes, results are the ONLY thing that matters. The real chore is writing a framework that allows your generated code to run independently... spend your time there. ","pontos":0},{"corpo":"Have you considered using .RTF as an alternative? It supports embedding images and tables as well as text, opens by default using Microsoft Word and whilst it's featureset is more limited (count out any advanced formatting) for something that looks and feels and opens like a Word document it's not far off. Your end users probably won't notice. ","pontos":9},{"corpo":"I don't have the time to Google too much for this, but I know that either Larry Osterman or Raymond Chen blogged about a similar situation. I'll check back later when I have more time to see if this question is still open. ","pontos":2},{"corpo":"Didn't see your database diagram whilst I was writing. ?xml version=\"1.0\" encoding=\"utf-8\" ? hibernate-mapping default-cascade=\"save-update\" xmlns=\"urn:nhibernate-mapping-2.2\" class lazy=\"false\" name=\"Namespace.Customer, Namespace\" table=\"Customer\" id name=\"Id\" type=\"Int32\" unsaved-value=\"0\" column name=\"customer_id\" length=\"4\" sql-type=\"int\" not-null=\"true\" unique=\"true\" index=\"CustomerPK\"/ generator class=\"native\" / /id bag name=\"AcceptedOffers\" inverse=\"false\" lazy=\"false\" cascade=\"all-delete-orphan\" key column=\"accepted_offer_id\"/ one-to-many class=\"Namespace.AcceptedOffer, Namespace\"/ /bag /class /hibernate-mapping ?xml version=\"1.0\" encoding=\"utf-8\" ? hibernate-mapping default-cascade=\"save-update\" xmlns=\"urn:nhibernate-mapping-2.2\" class lazy=\"false\" name=\"Namespace.AcceptedOffer, Namespace\" table=\"Accepted_Offer\" id name=\"Id\" type=\"Int32\" unsaved-value=\"0\" column name=\"accepted_offer_id\" length=\"4\" sql-type=\"int\" not-null=\"true\" unique=\"true\" / generator class=\"native\" / /id many-to-one name=\"Plan\" class=\"Namespace.Plan, Namespace\" lazy=\"false\" cascade=\"save-update\" column name=\"plan_id\" length=\"4\" sql-type=\"int\" not-null=\"false\"/ /many-to-one /class /hibernate-mapping Should probably do the trick (I've only done example mappings for the collections, you'll have to add other properties). ","pontos":1},{"corpo":"If the shell scripts are normally run on a telnet session then you could screen scrape and parse the responses. There are commercial COM components out there such as the Dart telnet library: http://www.dart.com/pttel.aspx that would let you do this. Either that or you could roll your own using AspSock http://www.15seconds.com/component/pg000300.htm ","pontos":0},{"corpo":"Since setting the properties with javascript never seemed to work, but setting using Firebug's inspect did, I started to suspect that the javascript ID selector was broken - maybe there were multiple items in the DOM with the same ID? The source didn't show that there were, but looping through all divs using javascript I found that that was the case. Here's the function I ended up using to show the popup: function openPopup(popupID) { var divs = getObjectsByTagAndClass('div','popupDiv'); if (divs != undefined divs != null) { for (var i = 0; i divs.length; i++) { if (divs[i].id == popupID) divs[i].style.display = 'block'; } } } (utility function getObjectsByTagAndClass not listed) Ideally I'll find out why the same item is being inserted multiple times, but I don't have control over the rendering platform, just its inputs. So when debugging issues like this, remember to check for duplicate IDs in the DOM, which can break getElementById. To everyone who answered, thanks for your help! ","pontos":4},{"corpo":"You could use an external method: var results = from rec in GetSomeRecs() where ConditionalCheck(rec) select rec; ... bool ConditionalCheck( typeofRec input ) { ... } This would work, but can't be broken down into expression trees, which means Linq to SQL would run the check code against every record. Alternatively: var results = from rec in GetSomeRecs() where (!filterBySeverity || rec.Severity == severity) (!filterByUser|| rec.User == user) select rec; That might work in expression trees, meaning Linq to SQL would be optimised. ","pontos":0},{"corpo":"You can't run a .Net app without the .Net framework. The framework takes care of some of the more tedious background tasks so you couldn't run the app without the framework. ","pontos":2},{"corpo":"Are you using only the dragEnter method? If you are trying to reject the drag while still dragging over the same component you need to use both the dragEnter and dragOver methods. Check out this example: ?xml version=\"1.0\" encoding=\"utf-8\"? mx:Application xmlns:mx=\"http://www.adobe.com/2006/mxml\" layout=\"absolute\" mx:Script ![CDATA[ import mx.core.DragSource; import mx.managers.DragManager; import mx.events.DragEvent; private function onDragEnter(e:DragEvent):void { if ( e.target == lbl ) { if ( e.localX lbl.width/2 ) { trace(\"accept\"); DragManager.acceptDragDrop(this); } else { DragManager.acceptDragDrop(null); } } } private function doStartDrag(e:MouseEvent):void { if ( e.buttonDown ) { var ds:DragSource = new DragSource(); ds.addData(\"test\", \"text\"); DragManager.doDrag(btn, ds, e); } } ]] /mx:Script mx:Label id=\"lbl\" text=\"hello world!\" left=\"10\" top=\"10\" dragEnter=\"onDragEnter(event)\" dragOver=\"onDragEnter(event)\" / mx:Button id=\"btn\" x=\"47\" y=\"255\" label=\"Button\" mouseMove=\"doStartDrag(event)\"/ /mx:Application ","pontos":5},{"corpo":"Currently adobe is not supporting opening files in there default applications. Passing it off to the browser seems to be the only way to make it work. You could however use a FileStream and write a small html file with some javascript that sets the location of an iframe to the file, then after 100ms or so calls window.close(). Then open that file in the browser. ","pontos":0},{"corpo":"You can still develop applications for the windows desktop using C/C++, eliminating the requirement to the .NET framework, but you'll need to make sure the necessary libraries are already on the system or installed. The nice thing about the .NET framework is that Windows XP SP2 and Vista has the 3.0 framework runtime installed by default. In a lot of ways, this is Microsoft's \"development standard\" and has been that way for a while. This allows you to not worry about having a bunch of libraries tacked onto your application. If you're sticking to all of the .NET provided libraries, you wind up only have to worry about deploying your executable, which is a big headache reliever. When you have a bunch of libraries you have to deploy as well, then you start to run into hassles when you write updates, because you have to make sure those updates are pushed out in your existing installer and to all the existing installed apps out there. As for \"preferred\", that always tends to ruffle feathers at times, but there are more and more .NET developers wanted for the web and the desktop at the job hunt sites I tend to visit. 8^D EDIT: Many thanks to Orion for pointing out my confusion on the frameworks. You get 3.0 \"out the gate if you're on XP SP2 or Vista. Everything else is going to require a simple download or run of Windows Update. ","pontos":9},{"corpo":"Last epoch is when 1970 GMT? SELECT DATEDIFF(s,'19700101 05:00:00:000',lastModified) See also Epoch Date ","pontos":2},{"corpo":"I guess what I'm trying to say is that when I look at system requirements for certain software I rarely ever see the .NET Framework as being a requirement. So, I always wonder how they get by without it being a requirement (if they developed the software in .NET). So, I just assume that most commercial software is not written in .NET so that's why I'm asking this question. Hope that cleared some things up. ","pontos":1},{"corpo":"Basically the thing that crops up 90% of the time is just analyzing loops. Do you have single, double, triple nested loops? The you have O(n), O(n^2), O(n^3) running time. Very rarely (unless you are writing a platform with an extensive base library (like for instance, the .NET BCL, or C++'s STL) you will encounter anything that is more difficult than just looking at your loops (for statements, while, goto, etc...) ","pontos":4},{"corpo":"Mono Has a Windows release, if you absolutely have to avoid dependency on .NET. Any way you look at it, though, you are going to need a .NET compatible runtime on any computer that your application is running on. So if you want to completely avoid .NET, you will probably have to distribute the Mono runtime along with your application. ","pontos":1},{"corpo":"If you are running on *nux you might consider dumping the unittest framework in favor of a bash script or makefile. on windows you might consider building a shell app/function that runs the generator and then uses the code (as another process) and unittest that. A third option would be to generate the code and then build an app from it that includes nothing but a unittest. Again you would need a shell script or whatnot to run this for each input. As to how to encode the expected behavior, it occurs to me that it could be done in much the same way as you would for the C++ code just using the generated interface rather than the C++ one. ","pontos":0},{"corpo":"You could use a combination of JQuery with JSON calls to consume REST services from the client or if you need to interact with the REST services from the ASP layer you can use MSXML2.ServerXMLHTTP like: Set HttpReq = Server.CreateObject(\"MSXML2.ServerXMLHTTP\") HttpReq.open \"GET\", \"Rest_URI\", False HttpReq.send ","pontos":20},{"corpo":"I would go with MSMQ/event table. Polling is only dirty if you do it wrong. One thing to keep in mind: you say you want multiple WF servers for high availability, but both of them use the same SQL backend? High availability only works if you remove all single points of failure, not just some of them. ","pontos":0},{"corpo":" I guess what I'm trying to say is that when I look at system requirements for certain software I rarely ever see the .NET Framework as being a requirement. So, I always wonder how they get by without it being a requirement (if they developed the software in .NET). So, I just assume that most commercial software is not written in .NET so that's why I'm asking this question. Hope that cleared some things up. I don't have any numbers, but I'm going to guess that since the majority of folks out there are running XP and Vista on their desktops, listing the .NET framework is moot, especially if they are targeting the 2.0 framework in the application itself. Back in the day, how many applications did you see that said \"requires vbrun50.dll\" or something to that regard since it was put into the Windows installs by default? Plus it is a little less \"scary\" for those that aren't terribly computer saavy. All they want to do is download, install, and run the app. A couple of the apps I have out there require the 2.0 framework and I do get some folks asking what is that and how do I get it and does it cost me anything? The typical answer I give them is \"If you're running XP or Vista, there's nothing to worry about\" and they seem to like that. ","pontos":1},{"corpo":"I've definitely been fighting with unmanaged issues in a C# managed app for a while -- it's not easy. What I've found to be most helpful is to have a regular output to a text log file. For example you can print the output of GlobalMemoryStatus every couple of minutes along with logging every time you load a new form. From there you can at least see that either memory gradually erodes, or a huge chunks of memory disappeared at specific times of the day. For us, we found a gradual memory loss all day as long as the device was being used. From there we eventually found that the barcode scanning device was being initialized for no particular reason in our Form base class (I blame the previous developer! :-) Setting up this logging may be a small hassle, but for us it paid huge dividends in the long run especially with the device in live use we can get real data, instrumentation, stack traces from exceptions, etc. ","pontos":1},{"corpo":"Anything but FlexLM. It will get you nothing but instant hatred with the intensity of a thousand blazing suns. ","pontos":1},{"corpo":"It turns out there was a very simple solution in my case. The vendor project gathers several header files into one monolithic header file, which is then d by the vendor sources. But the make rule that builds the monolithic header accidentally included the generated . The presence of the PACKAGE, VERSION, etc. config variables in the monolithic header is what was causing the redefinition warnings. It turns out that the vendor's was irrelevant, because \"config.h\" always resolved to . I believe this is the way it's supposed to work. By default a subproject should be including the enclosing project's instead of its own, unless the subproject explicitly includes its own, or manipulates the INCLUDE path so that its own directory comes before , or otherwise manipulates the header files as in my case. ","pontos":1},{"corpo":"@Pascal, sadly I'm not aware of any F/OSS alternatives. We usually just buy in these types of libraries provided that they're not hugely expensive, and more often than not the cost is built into the customer's overall project cost. If you had .NET on the server, you could build a COM wrapped component to do the heavy lifting around System.Net.Sockets.TcpClient. Just a thought. ","pontos":0},{"corpo":"Nick's answer is a good starting point, but incomplete, as you actually need to overload: private: void* operator new(size_t); // standard new void* operator new(size_t, void*); // placement new void* operator new[](size_t); // array new void* operator new[](size_t, void*); // placement array new (Good coding practice would suggest you should also overload the delete and delete[] operators -- I would, but since they're not going to get called it isn't really necessary.) Pauldoo is also correct that this doesn't survive aggregating on Foo, although it does survive inheriting from Foo. You could do some template meta-programming magic to HELP prevent this, but it would not be immune to \"evil users\" and thus is probably not worth the complication. Documentation of how it should be used, and code review to ensure it is used properly, are the only ~100% way. ","pontos":18},{"corpo":"Have you looked at CollectionViewSource and ICollectionView? With those classes, you're able to customize grouping, sorting and filtering. I'm not sure if it applies to CompositeCollections, though. ","pontos":0},{"corpo":"Besides Stack Overflow of course, here are mine. Many have already mentioned Hanselminutes. Some have already mentioned .NET Rocks! Not quite as many have mentioned RunAs Radio. I can't believe the size of some of these lists. With podcasts, I like to keep the list short and the quality high. As such, I tend to skip the aggregates like ITConversations et. al. ","pontos":8},{"corpo":"My advice would be that you don't push your friend too hard. If you're going to suggest they take up programming, only mention it casually. Suggesting recreational computer programming to someone \"unenlightened\" could be taken about the same way as suggesting they do some recreational mathematics, or stamp collecting (no offense to any philatelists out there!). ","pontos":3},{"corpo":"I'll follow up on Carl Russmann's comments by suggesting that you shouldn't push too hard on your friend. Most readers of this site find programming to be interesting and fun, but we are really weird. For most people, learning programming would be very hard work, with little short-term benefit. Most people have no aptitude for programming, and would find it to be as much fun as doing their income taxes. That's a big Con. ","pontos":1},{"corpo":"<p>I don't think you have anything to worry about. If <code>System.totalMemory</code> goes down you can relax. It may very well be the OS that doesn't reclaim the newly freed memory (in anticipation of the next time Flash Player will ask for more memory). Try doing something else that is very memory intensive and I'm sure that you'll notice that the memory allocated to Flash Player will decrease and be used for the other process instead.</p> <p>As I've understood it, memory management in modern OS's isn't intuitive from the perspective of looking at the amounts allocated to each process, or even the total amount allocated. When I've used my Mac for 5 minutes 95% of my 3 GB RAM is used, and it will stay that way, it never goes down. That's just the way the OS handles memory. As long as it's not needed elsewhere even processes that have quit still have memory assigned to them (this can make them launch quicker the next time, for example).</p> ","pontos":14},{"corpo":"ProFont. Am I the only one still using it? ","pontos":14},{"corpo":"You need local-name(): http://www.w3.org/TR/xpath#function-local-name To crib from http://jcooney.net/archive/2005/08/09/6517.aspx: foo xmlns='urn:foo' bar asdf/ /bar /foo This expression will match the bar element: //*[local-name()='bar'] This one won't: //bar ","pontos":10},{"corpo":"In some situations, it's faster and more convenient to not draw using the paint event, but getting the Graphics object from the control/form and painting \"on\" that. This may give some troubles with opacity/anti aliasing/text etc, but could be worth the trouble in terms of not having to repaint the whole shabang. Something along the lines of: private void AnimationTimer_Tick(object sender, EventArgs args) { // First paint background, like Clear(Control.Background), or by // painting an image you have previously buffered that was the background. animationControl.CreateGraphics().DrawImage(0, 0, animationImages[animationTick++])); } I use this in some Controls myself, and have buffered images to \"clear\" the background with, when the object of interest moves or need to be removed. ","pontos":8},{"corpo":"That syntax has its uses though ... there are times when you find you need to join two tables on more than one field ","pontos":-1},{"corpo":" I'm probably misremembering, but I thought that Joel's question was about counting the \"on\" bits rather than reversing them. Here you go: #include stdio.h int countBits(unsigned char byte); int main(){ FILE* out = fopen( \"bitcount.c\" ,\"w\"); int i; fprintf(out, \"#include stdio.h \\n#include stdlib.h \\n#include time.h \\n\\n\"); fprintf(out, \"int bitcount[256] = {\"); for(i=0;i 256;i++){ fprintf(out, \"%i\", countBits((unsigned char)i)); if( i 255 ) fprintf(out, \", \"); } fprintf(out, \"};\\n\\n\"); fprintf(out, \"int main(){\\n\"); fprintf(out, \"srand ( time(NULL) );\\n\"); fprintf(out, \"\\tint num = rand() %% 256;\\n\"); fprintf(out, \"\\tprintf(\\\"The byte %%i has %%i bits set to ON.\\\\n\\\", num, bitcount[num]);\\n\"); fprintf(out, \"\\treturn 0;\\n\"); fprintf(out, \"}\\n\"); fclose(out); return 0; } int countBits(unsigned char byte){ unsigned char mask = 1; int count = 0; while(mask){ if( mask byte ) count++; mask = 1; } return count; } ","pontos":3},{"corpo":"This changed in gcc-3.4. The C++ parser got much more strict in that release -- per the spec but still kinda annoying for people with legacy or multi-platform code bases. ","pontos":10},{"corpo":"You need to create your own exchange message sink to do this. Here's a classic VB example from MS KB: http://support.microsoft.com/kb/317327 and a VB Script one: http://support.microsoft.com/kb/317680 And lots of goodness from MSDN about Exchange 2003 Transport Event Sinks: http://msdn.microsoft.com/en-us/library/ms526223(EXCHG.10).aspx If you're running Exchange 2007 then you can use Transport Rules: http://msexchangeteam.com/archive/2006/12/12/431879.aspx http://www.msexchange.org/tutorials/Using-Transport-Rules-Creating-Disclaimers-Exchange-Server-2007.html ","pontos":2},{"corpo":"David Joyner had the history, here is the reason. The problem when compiling B is that its base class A is unknown from the compiler, being a template class, so no way for the compiler to know any members from the base class. Earlier versions did some inference by actually parsing the base template class, but ISO C++ stated that this inference can lead to conflicts where there should not be. The solution to reference a base class member in a template is to use this (like you did) or specifically name the base class: template typename T class A { public: T foo; }; template typename T class B: public A T { public: void bar() { cout A T ::foo endl; } }; More information in gcc manual. ","pontos":31},{"corpo":"I've always found the custom dialogs in visual studio setup projects to be woefully limited and barely functional. By contrast, I normally create custom actions that display winforms gui's for any remotely difficult tasks during setup. Works really well and you can do just about anything you want by creating a custom action and passing a few parameters across. In the dayjob we built a collection of common custom actions for tasks like application config and database creation / script execution to get around custom dialog limitations. ","pontos":11},{"corpo":"Well it is a little bland, but I would vote for Get-Help. ","pontos":1},{"corpo":"I would recommend using drop-downs for dates, as indicated above. I can't really think of any reason not to--you want the user to choose from pre-defined data, not give you something unique that you can't anticipate. You can avoid February 30 with a little bit of Javascript (make the days field populate dynamically based on the month). ","pontos":1},{"corpo":"The default wiki included with Sharepoint doesn't support common wiki features well at all. There is no way to edit a single section of a page, and no way to link directly to a particular section on another page. The backend is in HTML so you lose the ability to edit in plaintext using simple syntax. The diff feature can't span multiple versions. Poor cross browser support of WYSIWYG editing. No way to auto-insert a table of contents... There are, however, other wiki add-ins for Sharepoint which I can't categorically dismiss, for instance Confluence makes an add-in for Sharepoint. I haven't evaluated this software myself, and Confluence is somewhat expensive ($1,200 for 25 user license) although if you are already on Sharepoint I sense large corporate coffers :P. There also appear to be some free add-ins like CKS Enhanced Wiki but that appears to have a lot of the same problems mentioned above. ","pontos":14},{"corpo":"My company rolled out sharepoint recently, and I have to say my user experience was Very Bad. And I'm not just saying I was apprehensive to using it: I went in with an open mind and tried it, and many things just felt like they didn't really work right. The reasons Luke mentioned more or less cover it. Why wouldn't you consider using something else like Screwturn Wiki which Jeff donated to a short while ago? I haven't used Screwturn myself, but it is free and open source, and may be a faster lightweight solution for what you need. ","pontos":3},{"corpo":"I would say no. I have used both, and they are different for very good reason (warning, history lesson) The Dvorak keyboard is optimal, the qwerty layout was designed so that the pegs on a typewrier would not collide (so letters that often come next to each other are split up) Because these are so different, its really not possible to be really good on both. You will find that even if you look at the keyboard while typing you eventually develop muscle memory that allows you to know where the keys are. This will get ALL messed up if you start moving where the keys are. ","pontos":0},{"corpo":"Aside from trying out Visual AssistX, the only other one I've tried is ReSharper (which I highly recommend). If you do decide to go for ReSharper, you'll likely notice that it's missing a spell checker for code though - however the Agent Smith plugin fixes that. ","pontos":4},{"corpo":"@Thomas Owens - the person in that cafe after you is going to be proper befuddled :-D I guess to be good on both you'd have to alternate all the time. I have enough trouble switching between my laptop and desktop keyboards :-) ","pontos":0},{"corpo":"Chalk this one to lack of experience, but during my seven-year stint as a code monkey I've never actually seen anyone make the mistake of not adding braces when adding code to a block that doesn't have braces. That's precisely zero times. And before the wisecrackers get to it, no, the reason wasn't \"everyone always uses braces\". So, an honest question -- I really would like to get actual replies instead of just downvotes: does that ever actually happen? (Edit: I've heard enough outsourcing horror stories to clarify a bit: does it ever actually happen to competent programmers?) ","pontos":3},{"corpo":"As you already mentioned, those terms mean different things in different stacks - there is no one right generic answer for web services. ","pontos":1},{"corpo":"If the inner loop code is a reasonable length, I don't see any reason you can't post it. I think Stack Overflow is intended to encompass both general and specific questions. ","pontos":0},{"corpo":"Here are some caveats I came across that will vanish if you use a wiki other than Sharepoint. Sharepoint lets you create tons of separate wikis, but I'd recommend having one big wiki for everything. My company made a bunch of little wikis for each project/feature, but only admins can create the individual wikis, so if I want to write about something that isn't doesn't match one of the predefined categories, I have to find a manager to create the wiki first. Secondly, if you use Sharepoint make sure everyone on your staff only uses IE, since Firefox doesn't support the WYSIWIG editor. This is a good thing for most wikis, but makes collaborating difficult in Sharepoint. Imagine editing auto-generated HTML in a tiny little box all day. Third, try to write up your project documentation in the wiki and resist the temptation to upload Word docs to the Sharepoint library. No point in writing up all your docs twice and watching things get more and more out of sync. Finally, image support in Sharepoint wikis is terrible. You have to add a file to a document library somewhere and type in the URL. My images were forever getting deleted because they don't seem to make much sense out of context. ","pontos":20},{"corpo":"You're not allowed (by the C++ standard) to overload std::swap, however you are specifically allowed to add template specializations for your own types to the std namespace. E.g. namespace std { template void swap(my_type lhs, my_type rhs) { // ... blah } } then the usages in the std containers (and anywhere else) will pick your specialization instead of the general one. Also note that providing a base class implementation of swap isn't good enough for your derived types. E.g. if you have class Base { // ... stuff ... } class Derived : public Base { // ... stuff ... } namespace std { template void swap(Base lha, Base rhs) { // ... } } this will work for Base classes, but if you try to swap two Derived objects it will use the generic version from std because the templated swap is an exact match (and it avoids the problem of only swapping the 'base' parts of your derived objects). NOTE: I've updated this to remove the wrong bits from my last answer. D'oh! (thanks puetzk and j_random_hacker for pointing it out) ","pontos":48},{"corpo":"I find the MVC pattern really useful to isolate your model logic, which can than be reused or worked on without too much trouble. It also helps de-coupling your classes and makes unit testing easier. I wrote about it recently (yes, shameless plug here...) Also, I've recently used a factory pattern from a base class to generate and return the proper DataContext class that I needed on the fly, using LINQ. Bridges are used when trying when trying to glue together two different technologies (like Cocoa and Ruby on the Mac, for example) I find, however, that whenever I implement a pattern, it's because I knew about it before hand. Some extra thought generally goes into it as I find I must modify the original pattern slightly to accommodate my needs. You just need to be careful not to become and architecture astronaut! ","pontos":0},{"corpo":"Have you tried these tips? http://weblogs.asp.net/haroonwaheed/archive/2008/06/30/ASP.NET-Performance-Tips.aspx ","pontos":1},{"corpo":"If you change \"*\" to just the parameters the cache should vary on (PostID?) you can do something like this: //add dependency string key = \"post.aspx?id=\" + PostID.ToString(); Cache[key] = new object(); Response.AddCacheItemDependency(key); and when someone adds a comment... Cache.Remove(key); I guess this would work even with VaryByParam *, since all requests would be tied to the same cache dependency. ","pontos":1},{"corpo":"In MS SQL Server Management Studio on the object explorer, right click on the database. In the context menu that follows select 'Tasks -> Take Offline' ","pontos":5},{"corpo":"In my opinion, the question: \"Do you use design pattern?\", alone is a little flawed because the answer is universally YES. Let me explain, we, programmers and designers, all use design patterns... we just don't always realise it. I know this sounds clich, but you don't go to patterns, patterns come to you. You design stuff, it might look like an existing pattern, you name it that way so everyone understand what you are talking about and the rationale behind your design decision is stronger, knowing it has been discussed ad nauseum before. I personally use patterns as a communication tool. That's it. They are not design solutions, they are not best practices, they are not tools in a toolbox. Don't get me wrong, if you are a beginner, books on patterns will show you how a solution is best solved \"using\" their patterns rather than another flawed design. You will probably learn from the exercise. However, you have to realise that this doesn't mean that every situation needs a corresponding pattern to solve it. Every situation has a quirk here and there that will require you to think about alternatives and take a difficult decision with no perfect answer. That's design. Anti-pattern however are on a totally different class. You actually want to actively avoid anti-patterns. That's why the name anti-pattern is so controversial. To get back to your original question: \"Do I use design patterns?\", Yes! \"Do I actively lean toward design patterns?\", No. ","pontos":8},{"corpo":"Are you talking about a dumb case insensitive compare or a full normalized Unicode compare? A dumb compare will not find strings that might be the same but are not binary equal. Example: U212B (ANGSTROM SIGN) U0041 (LATIN CAPITAL LETTER A) + U030A (COMBINING RING ABOVE) U00C5 (LATIN CAPITAL LETTER A WITH RING ABOVE). Are all equivalent but they also have different binary representations. That said, Unicode Normalization should be a mandatory read especially if you plan on supporting Hangul, Tha and other asian languages. Also, IBM pretty much patented most optimized Unicode algorithms and made them publicly available. They also maintain an implementation : IBM ICU ","pontos":44},{"corpo":"Apart from syntax not that much any more. They both compile to exactly the same IL, so you can compile something as VB and reflect it into C#. Most of the apparent differences are syntactic sugar. For instance VB appears to support dynamic types, but really they're just as static as C#'s - the VB compiler figures them out. Visual Studio behaves differently with VB than with C# - it hides lots of functionality but adds background compiling (great for small projects, resource hogging for large ones) and better snippet support. With more and more compiler 'magic' in C#3 VB.Net has really fallen behind. The only thing VB now has that C# doesn't is the keyword - and that's of debatable benefit. @Tom - that really useful, but a little out of date - VB.Net now supports XML docs too with @Luke - VB.Net still doesn't have anon-methods, but does now support lambdas. ","pontos":1},{"corpo":"There is no way you can have a MOSS 2007/WSS 3.0 development for free but a Microsoft Action Pact is so cheap to get. :) There is a nice blog to read to get the requirements and the steps to get a full MOSS 2007 image up and running here : How to Create a MOSS 2007 VPC Image: The Whole 9 Yards. ","pontos":3},{"corpo":"If you are on a POSIX system, you can use strcasecmp. This function is not part of standard C, though, nor is it available on Windows. This will perform a case-insensitive comparison on 8-bit chars, so long as the locale is POSIX. If the locale is not POSIX, the results are undefined (so it might do a localized compare, or it might not). A wide-character equivalent is not available. Failing that, a large number of historic C library implementations have the functions stricmp() and strnicmp(). Visual C++ on Windows renamed all of these by prefixing them with an underscore because they arent part of the ANSI standard, so on that system theyre called _stricmp or _strnicmp. Some libraries may also have wide-character or multibyte equivalent functions (typically named e.g. wcsicmp, mbcsicmp and so on). C and C++ are both largely ignorant of internationalization issues, so there's no good solution to this problem, except to use a third-party library. Check out IBM ICU (International Components for Unicode) if you need a robust library for C/C++. ICU is for both Windows and Unix systems. ","pontos":32},{"corpo":"This is because the font used in the tooltip doesn't include the characters you are trying to display. Try installing a font pack that includes those characters. I'm affraid you can't do much for your site's visitors other than implementating a tooltip yourself using javascript. ","pontos":5},{"corpo":"The main reason C++ cannot assume anything here is that the base template can be specialized for a type later. Continuing the original example: template class A int {}; B int x; x.bar();//this will fail because there is no member foo in A int ","pontos":8},{"corpo":"Clippy noticed that you have sensitive information in your files and automatically encrypted them. Are you sure it's for EFS? I've had things prompt me to backup my keys before, but I didn't know exactly what they were to. I was assuming it was like a DRM protected file or something. It was a while ago so i don't remember exactly what the specific details were. I never backed it up and haven't been locked out of anything. ","pontos":0},{"corpo":" Just write your file parser, using whatever techniques come to mind Write lots of unit tests for it to make sure all your edge cases are covered Once you've done this, you will actually have a reasonable idea of the problem/solution. Right now you just have theories floating around in your head, most of which will turn out to be misguided. Step 3: Refactor mercilessly. Your aim should be to delete about half of your code You'll find that your code at the end will either resemble an existing design pattern, or you'll have created a new one. You'll then be qualified to answer this question :-) ","pontos":18},{"corpo":"Can you sanitize the alt text so that it doesn't have the characters in it, preferably by replacing the entire text with something useful (rather than just filtering the string)? That's not ideal, but neither is displaying broken characters, or telling your users to install a new font pack. ","pontos":0},{"corpo":"I was involved in a Scrum team at my last company, and it really has nothing to do with the development environment. It is a process for developing software, and often there is little technology in using the process itself (though a good spreadsheet tool will help with tracking progress). So... I would say your worries of tools are perhaps misplaced, unless I am misunderstanding the question. ","pontos":3},{"corpo":"Really all you need is a piece of bug tracking software to keep track of hot issues for the current sprint. It could even be a spreadsheet (don't use a spreadsheet). SCRUM is a methodology, http://en.wikipedia.org/wiki/Scrum_(development) and doesn't really require team system so much as it requires good project manager and a comitted team. ","pontos":9},{"corpo":"It's worth noting in light of a wide spread SQL Injection attempts that disallowing your webapp's db user account from querying the system tables (in MS SQL Server it's sysobjects and syscolumns) is a good idea. It's so little effort and makes a lot of sense. Alternatively if you could set everything to be read only, do so. ","pontos":1},{"corpo":"If you could go back and modify your app code, I'd suggest getting log4j/log4net integrated into the application. From there you could write code that would check a form field or URL (say at the global.asax level for .NET apps) and make a log entry when malicious code is detected. The nice thing about log4j/log4net is that you can configure an e-mail/pager/SMS type appender so as soon as the malicious attempt was caught, you would be notified. I'm in the process of merging some log4net code into our CMS system we have and I'm looking to do just this in light of the influx of ASPRox attacks that have been coming our way. ","pontos":2},{"corpo":"You're probably out of luck, to be honest. Looking at the MySQL C API (http://dev.mysql.com/doc/refman/5.0/en/mysql-fetch-row.html, http://dev.mysql.com/doc/refman/5.0/en/c-api-datatypes.html, look at MYSQL_ROW) there doesn't seem to be a mechanism for returning data in its actual type... the joys of using structs I guess. You could always implement a wrapper which checks against the MYSQL_ROW's type attribute (http://dev.mysql.com/doc/refman/5.0/en/c-api-datatypes.html) and returns a C union, but that's probably poor advice; don't do that. ","pontos":1},{"corpo":"Yes it's EFS: [Window Title] Encrypting File System [Main Instruction] Back up your file encryption certificate and key [Content] Creating this backup file helps you avoid permanently losing access to your encrypted files if the original certificate and key are lost or corrupted. [Back up now (recommended)] [Back up later] [Never back up] [Cancel] [Footer] Why should I backup the certificate and key? ","pontos":0},{"corpo":"There are two approaches that I know of. The first and simplest is to register the special Windows message \"QueryCancelAutoPlay\" and simply return 1 when the message is handled. This only works for the current window, and not a background application. The second approach requires inserting an object that implements the COM interface COM interface into the Running Object Table. ","pontos":3},{"corpo":"Have you tried ? You can basically chained up all your calls. It acts like a decorator: each new method adds a new layer of functionality and passes the control onto the \"overridden\" method to do the rest. ","pontos":2},{"corpo":"Where's your Japanese input coming from? It could be that it's in a non-unicode (e.g. http://en.wikipedia.org/wiki/JIS_X_0208) encoding, whereas your file is in unicode so the browser attempts to interpret the non-unicode characters as unicode and gets confused. I tried throwing together an example to reproduce your problem: img src=\"test.png\" alt=\"\" / The tooltip displays properly under IE7 with the Japanese language pack installed. ","pontos":1},{"corpo":"Another option would be to use something like the PredicateBuilder discussed here. It allows you to write code like the following: var newKids = Product.ContainsInDescription (\"BlackBerry\", \"iPhone\"); var classics = Product.ContainsInDescription (\"Nokia\", \"Ericsson\") .And (Product.IsSelling()); var query = from p in Data.Products.Where (newKids.Or (classics)) select p; Note that I've only got this to work with Linq 2 SQL. EntityFramework does not implement Expression.Invoke, which is required for this method to work. I have a question regarding this issue here. ","pontos":2},{"corpo":" @Nick DeVore wrote: If 2 is true, then that seems bad if someone is using that specific page or DLL and it gets overwritten. It's not really an issue if you're using ASP.NET stack (Webforms, MVC or rolling your own) because all your aspx files get compiled and therefore not touched by webserver. /bin/ folder is completely shadowed somewhere else, so libraries inside are not used by webserver either. IIS will wait until all requests are done (however there is some timeout though) and then will proceed with compilation (if needed) and restart of AppDomain. If only a few files have changed, there won't even be AppDomain restart. IIS will load new assemblies (or compiled aspx/asmx/ascx files) into existing AppDomain. @Nick DeVore wrote: Help me understand this a little bit more. Point me to the place where this is explained from Microsoft. Thanks! Try google for \"IIS AppDomain\" keywords. I found What ASP.NET Programmers Should Know About Application Domains. ","pontos":2},{"corpo":"Not to promote reinventing the wheel, but I originally wrote my own web SVN browser by using the svn log --xml command and then just an XML parser in whatever language i was using. I don't use .Net, but it shouldn't be too hard. ","pontos":3},{"corpo":"FolderBrowserDialog class? http://msdn.microsoft.com/en-us/library/system.windows.forms.folderbrowserdialog.aspx ","pontos":47},{"corpo":"Yes, this is to be expected, or at least, its exactly what happens when our crypto routines get non-decryptable data ","pontos":1},{"corpo":"I do remember reading something a while ago which said that this would be the case, but possibly only in release mode. I'm not sure. ","pontos":0},{"corpo":"No, empty methods are never optimized out. Here are a couple reasons why: The method could be called from a derived class, perhaps in a different assembly The method could be called using Reflection (even if it is marked private) Edit: Yes, from looking at that (exellent) code project doc the JITer will eliminate calls to empty methods. But the methods themselves will still be compiled and part of your binary for the reasons I listed. ","pontos":1},{"corpo":"@Jon Limjap: We already know the C# compiler doesn't optimize empty methods out. Since what you're decompiling with ildasm was generated by the C# compiler... no help there. ","pontos":0},{"corpo":"@Chris: Makes sense, but it could optimize out calls to the method. So the method would still exist, but static calls to it could be removed (or at least inlined...) @Jon: That just tells me the language compiler doesn't do anything. I think what I need to do is run my dll through ngen and look at the assembly. ","pontos":0},{"corpo":"A lot of computers at my company use Win2k, so we couldn't really drop support. It all depends on the client base. ","pontos":0},{"corpo":" is an inline element. The term hanging indent is meaningless unless you're talking about a paragraph (which generally means a block element). You can, of course, change the margins on or or any other block element to get rid of extra vertical space between paragraphs. You may want something like , where the tag will become either block or inline depending on context... sadly, this is not yet universally supported by browsers. ","pontos":11},{"corpo":"I use Warehouse, as Lubos already pointed out, and it works very well. I looked at one point for a .Net version, but I was never able to find one. I was also at a point where I wanted to better myself as a programmer by learning a new language and I ventured into learning Ruby and Ruby on Rails. Now, I program in both .NET and Ruby. Anyway, that is how I ran into Warehouse. I have Warehouse installed on a Linux machine running the Ubuntu server edition, nginx for the HTTP server, and mongrel cluster. I never even tried to install it on windows and glad that I didn't. Warehouse requires the svn-ruby bindings to work and this poor guy found out the hard way. Well, I know you are looking for a .NET application, but I thought I would give my two cents on Warehouse and I hope you don't dismiss it just because it doesn't run in .Net. I also wanted to inform you not to install Warehouse on Windows, if you did decide to give it a shot. ","pontos":3},{"corpo":"I somewhat disagree with secretGeek's comment: That's already happening for you -- it's called tcp/ip ;-) Re-implementing that could be overkill. There are times when you may want to do just this, but really only from a UI perspective. If you implement some way to either stream the data to the client (via something like a pushlets mechanism), or chunk it into pages as you suggest, you can then load some really small subset on the client and then slowly build up the UI with the full amount of data. This makes for a slicker, speedier UI (from the user's perspective), but you have to evaluate if the extra effort will be worthwhile... because I don't think it will be an insignificant amount of work. ","pontos":0},{"corpo":"The purpose of a Singleton is to ensure a class has only one instance, and provide a global point of access to it. Most of the time the focus is on the single instance point. Imagine if it were called a Globalton. It would sound less appealing as this emphasizes the (usually) negative connotations of a global variable. Most of the good arguments against singletons have to do with the difficulty they present in testing as creating test doubles for them is not easy. ","pontos":25},{"corpo":"To echo what Kevin said, in .net web services if you have a byte array it is sent as a base64 encoded string by default. You can also specify the encoding of the byte array beforehand. Obviously, once it gets to the server (or client) you need to manually decode the string back into a byte array as this isn't done automagically for you unfortunately. ","pontos":0},{"corpo":"We encountered an issue like this and found that it was a group policy issue. There's a group policy setting for debugging that needs to be enabled. It overrides the fact that you are in the right group. ","pontos":1},{"corpo":"Sometimes it's worth giving up the ideal for the realistic. If it's going to cause a massive problem to \"do it right\" with no real benefit, then I would do it wrong. With that said, I often think it's worth taking the time to do it right, because unnecessary multiple inheritance increases complexity, and it can contribute to the system being less maintainable. You really have to decide what's best for your circumstance. One option would be to have these objects implement a interface, rather than inheriting from . This way, a person has-a damage counter, but is damageable. (I often find interfaces make a lot more sense as adjective than nouns.) Then you could have a consistent damage interface on objects, and not expose that a damage counter is the underlying implementation (unless you need to). If you want to go the template route (assuming C++ or similar), you could do this with mixins, but that can get ugly really quickly if done poorly. ","pontos":0},{"corpo":"This question is really confusing :/ Your question in bold is very open-ended and has an answer of \"it depends\", but your example doesn't really give much information about the context from which you are asking. These lines confuse me; sets of data that should all be processed in a similar way What way? Are the sets processed by a function? Another class? Via a virtual function on the data? In particular, different objects would ideally act the same, which would be very easily achieved with polymorphism The ideal of \"acting the same\" and polymorphism are absolutely unrelated. How does polymorphism make it easy to achieve? ","pontos":0},{"corpo":"@Kevin Normally when we talk about 'is a' vs 'has a' we're talking about Inheritance vs Composition. Um...damage counter would just be attribute of one of your derived classes and wouldn't really be discussed in terms of 'A person is a damage counter' with respect to your question. Having the damage counter as an attribute doesn't allow him to diverse objects with damage counters into a collection. For example, a person and a car might both have damage counters, but you can't have a or a or anything similar in most languages. If you have a common Object base class, then you can shove them in that way, but then you can't access the method generically. That was the essence of his question, as I read it. \"Should I violate and for the sake of treating certain objects as if they are the same, even though they aren't?\" ","pontos":0},{"corpo":"The first question that you need to ask yourself is how fast is the network you client and server exist in. If both are inside the same network and it is your standard corporate LAN then you are likely looking at 100 Mbit/s. Most people aren't even going to notice the network delay in these cases so I would say that it is nothing to worry about. .NET should throw an exception if something goes wrong, once again network speeds come in to play here as you might be able to just re-download the data without the user noticing. You might want to examine the data to make sure you are only getting the data that you need, but if you need all of the data to do the task at hand, I don't see why there would be an issue with the size. You might also want to look into compression to see if there are any ways to make it a bit smaller if size and speed are a major issue. ","pontos":-1},{"corpo":"A singleton is just a bunch of global variables in a fancy dress. Global variables have their uses, as do singletons, but if you think you're doing something cool and useful with a singleton instead of using a yucky global variable (everyone knows globals are bad mmkay), you're unfortunately misled. ","pontos":30},{"corpo":" Yes I have tried running PS and the regular command prompt as administrator. The same error message comes up. Another possible solution could be that you need to give your user account access to the key container located at C:\\Documents and Settings\\All Users\\Application Data\\Microsoft\\Crypto\\RSA\\MachineKeys ","pontos":18},{"corpo":"Google has a Singleton Detector for Java that I believe started out as a tool that must be run on all code produced at Google. The nutshell reason to remove Singletons: because they can make testing difficult and hide problems with your design For a more explicit explanation see 'Why Singletons Are Controversial' from Google. ","pontos":37},{"corpo":"I can definitely tell you to steer clear of any of the lower end vista installs, because you'll lose: Ability to do simple backups to a disc not physically connected to your machine; Term serv access to your machine from any other; Like Fry says, you'll lose RAM. I have 4, vista only \"sees\" 3. I'm talking out of the box at least. I want to go x64 but really dreading having to reinstall everything. ","pontos":1},{"corpo":"This may be considered syntax, but VB.NET is case insensitive while C# is case sensitive. ","pontos":3},{"corpo":"It's supposed to work via FastCGI. But I haven't had great success (using Vista). I can get PHP to run, but it crashes after a page loads (FastCGI does). So I'm modding you up. I'd like to see a reliable answer myself. ","pontos":0},{"corpo":"@Brian: I don't know how things work in Java, but in .net objects get serialized down to XML, not base64 strings. The webservice publishes a wsdl file that contains the method and object definitions required for your webservice. I would hope that nobody creates webservices that simply create a base64 string ","pontos":1},{"corpo":"Why not fire up sysinternals Process Monitor too see what you can see, it's the first thing I always do when I get any kind of access denied message? http://technet.microsoft.com/en-us/sysinternals/bb896645.aspx ","pontos":3},{"corpo":"Not sure how your controller looks, the error seems to be pointing to the fact that it can't find the controller. Did you inherit off of Controller after creating the PageController class? Is the PageController located in the Controllers directory? Here is my route in the Global.asax.cs routes.MapRoute( \"Page\", \"{Page}.aspx\", new { controller = \"Page\", action = \"Index\", id = \"\" } ); Here is my controller, which is located in the Controllers folder: using System.Web.Mvc; namespace MvcApplication1.Controllers { public class PageController : Controller { public void Index() { Response.Write(\"Page.aspx content.\"); } } } ","pontos":0},{"corpo":"When it gets to IL its all just bits. That case insensitivity is just a precompiler pass. But the general consensus is, vb is more verbose. If you can write c# why not save your eyes and hands and write the smaller amount of code to do the same thing. ","pontos":0},{"corpo":"if you do web, iis 7 rocks the house, being able to have multiple hosts on one box has been a life saver for me, I don't know how to go back to xp anymore. If I had to go back, server 2003 is the least I would accept, not having a real functional web server is just not an option. ","pontos":0},{"corpo":"On one of Rob Conery's MVC Storefront screencasts, he encounters this exact issue. It's at around the 23 minute mark if you're interested. ","pontos":1},{"corpo":"@ChanChan, I don't think you can claim to be only interested in freedom when you ask if you should \"Pay for vmware.\" I'm forced to assume you are talking about money there, not about freedom. :p Nonetheless, I gave you a poor link. VMware Server is free (as in beer) and will run Windows VMs just fine. For what it's worth, I've also used Xen, and it's perfectly good, too. Edit: I reread this and it sounds really obnoxious and rude. So, I'd just like to apologize, ChanChan, for not taking more care with my reply. (I would have apologized in a private message, but we don't have those yet.) ","pontos":3},{"corpo":"So I ran a little experiment with MSSQL server. I created a table and added a row with the current localized timezone (Australia). Then I changed my datetime to be GMT and added another row. Even tho those rows were added around 10 seconds apart, they appear in SQL server as tho they're 10 hours apart. If nothing else, it at least tells me that I should be storing dates in a conisitent manner, which for me, adds weight to the argument for storing them as GMT. ","pontos":1},{"corpo":"Looks like there's a bug with 1.2.2. Just roll back to 1.2.1 with: gem install sqlite3-ruby -v=1.2.1 and that will fix the problem. ","pontos":2},{"corpo":"Try something like this: (echo oldpasswd; echo newpasswd) | smbpasswd -s ","pontos":7},{"corpo":"Matthew: Yes, that is what I meant by \"I can get my internet IP using a service on a website.\" Sorry about being glib. Brian/Nick: Traceroute would be fine except for the fact that lots of these routers have ICMP disabled and thus it always stalls. I think a combination of traceroute and uPnP will work out. That is what I was planning on doing, I as just hoping I was missing something obvious. Thank you everyone for your comments, so it sounds like I'm not missing anything obvious. I have begun implementing some bits of uPnP in order to discover the gateway. ","pontos":0},{"corpo":"Java doesn't make this as pleasant as other languages, unfortunately. Here's what I did: import java.io.*; import java.util.*; public class ExecTest { public static void main(String[] args) throws IOException { Process result = Runtime.getRuntime().exec(\"traceroute -m 1 www.amazon.com\"); BufferedReader output = new BufferedReader(new InputStreamReader(result.getInputStream())); String thisLine = output.readLine(); StringTokenizer st = new StringTokenizer(thisLine); st.nextToken(); String gateway = st.nextToken(); System.out.printf(\"The gateway is %s\\n\", gateway); } } This presumes that the gateway is the second token and not the third. If it is, you need to add an extra to advance the tokenizer one more spot. ","pontos":3},{"corpo":"Thanks to Mark I found the answer: (echo newpassword; echo confirmNewPassword) | smbpasswd -s BTW: (echo oldpasswd; echo newpasswd) | smbpasswd -s does not work. ","pontos":13},{"corpo":"From my experience with windows/apache it's just a matter of install MySQL, I can't Imagine that IIS/Apache has anything to do with this. ","pontos":0},{"corpo":"I think what I would do in this case is test the code that actually executes when the timer ticks, rather than the entire sequence. What you really need to decide is whether it is worthwhile for you to test the actual behaviour of the application (for example, if what happens after every tick changes drastically from one tick to another), or whether it is sufficient (that is to say, the action is the same every time) to just test your logic. Since the timer's behaviour is guaranteed never to change, it's either going to work properly (ie, you've configured it right) or not; it seems to be to be wasted effort to include that in your test if you don't actually need to. ","pontos":3},{"corpo":"Modify your constructor to the following so that it calls the base class constructor properly: public class MyExceptionClass : Exception { public MyExceptionClass(string message, string extrainfo) : base(message) { //other stuff here } } Note that a constructor is not something that you can call anytime within a method. That's the reason you're getting errors in your call in the constructor body. ","pontos":741},{"corpo":"What I have done is to mock the timer, and also the current system time, that my events could be triggered immediately, but as far as the code under test was concerned time elapsed was seconds. ","pontos":9},{"corpo":"mmilic, following on from your response to my previous idea.. No additional logic required! That's the point, your doing nothing to the classes in question, just wrapping them in some instantiation bubble-wrap! :) OK, I was going to just bullet point but I wanted to see this work for myself, so I cobbled together some very rough code but the concept is there and it seems to work. APOLOGIES FOR THE LONG POST The SafeLoader This will basically be the \"bubble\" I mentioned.. It will get the controls HTML, catching any errors that occur during Rendering. public class SafeLoader { public static string LoadControl(Control ctl) { // In terms of what we could do here, its down // to you, I will just return some basic HTML saying // I screwed up. try { // Get the Controls HTML (which may throw) // And store it in our own writer away from the // actual Live page. StringWriter writer = new StringWriter(); HtmlTextWriter htmlWriter = new HtmlTextWriter(writer); ctl.RenderControl(htmlWriter); return writer.GetStringBuilder().ToString(); } catch (Exception) { string ctlType = ctl.GetType().Name; return \" span style=\\\"color: red; font-weight:bold; font-size: smaller;\\\" \" + \"Rob + Controls = FAIL (\" + ctlType + \" rendering failed) Sad face :( /span \"; } } } And Some Controls.. Ok I just mocked together two controls here, one will throw the other will render junk. Point here, I don't give a crap. These will be replaced with your custom controls.. BadControl public class BadControl : WebControl { protected override void Render(HtmlTextWriter writer) { throw new ApplicationException(\"Rob can't program controls\"); } } GoodControl public class GoodControl : WebControl { protected override void Render(HtmlTextWriter writer) { writer.Write(\" b Holy crap this control works /b \"); } } The Page OK, so lets look at the \"test\" page.. Here I simply instantiate the controls, grab their html and output it, I will follow with thoughts on designer support etc.. Page Code-Behind protected void Page_Load(object sender, EventArgs e) { // Create some controls (BadControl will throw) string goodHtml = SafeLoader.LoadControl(new BadControl()); Response.Write(goodHtml); string badHtml = SafeLoader.LoadControl(new GoodControl()); Response.Write(badHtml); } Thoughts OK, I know what you are thinking, \"these controls are instantiated programatically, what about designer support? I spent freaking hours getting these controls nice for the designer, now you're messing with my mojo\". OK, so I havent really tested this yet (probably will do in a min!) but the idea here is to override the CreateChildControls method for the page, and take the instance of each control added on the form and run it through the SafeLoader. If the code passes, you can add it to the Controls collection as normal, if not, then you can create erroneous literals or something, up to you my friend. Finally.. Again, sorry for the long post, but I wanted to get the code here so we can discuss this :) I hope this helps demonstrate my idea :) Update Tested by chucking a control in on the designer and overriding the CreateChildControls method with this, works fine, may need some clean up to make things better looking, but I'll leave that to you ;) protected override void CreateChildControls() { // Pass each control through the Loader to check // its not lame foreach (Control ctl in Controls) { string s = SafeLoader.LoadControl(ctl); // If its bad, smack it downnnn! if (s == string.Empty) { ctl.Visible = false; // Prevent Rendering string ctlType = ctl.GetType().Name; Response.Write(\" b Problem Occurred Rendering \" + ctlType + \" '\" + ctl.ID + \"'. /b \"); } } } Enjoy! ","pontos":10},{"corpo":"See my answer here to a similar question. I don't think it's really needed anymore in .Net 3.5 ","pontos":1},{"corpo":"The problem here is that the browsers specifically work to block anything that changes the basic file upload input control. You can't change it with javascript for instance. The reason is security - if I could script it I could build a page that when you visited it sent me various files from your hard disk. Not nice. There are various workarounds at the moment, but they're different between IE and FX (I don't know about Safari, Opera, etc). Look at what http://www.gmail.com does in IE and FX when you attach something to an e-mail. I want to see that rubbish \"Browse\" button - it tells me that I'm not letting anything unexpected in. ","pontos":1},{"corpo":"Rather than use table prefixes instead have an application user that belongs to a (in MS Sql 2005 or above). This means that instead of: select * from dbo.clientAProduct select * from dbo.clientBroduct You have: select * from clientA.Product select * from clientB.Product ","pontos":1},{"corpo":"I guess it really comes down to what your Java code is for, how it's distributed and who your clients are. We don't obfuscate anything, as we've never found one that was particularly good and it tends to be more trouble than it's worth. If someone has access to our JAR files and has the knowledge to be able to sniff around inside them, then there's far more worrying things that they can do than rip off our source code. ","pontos":6},{"corpo":"I'm not a lawyer but all licenses mentioned are okay to be used in commercial products as long as you don't make any changes and claim the code is yours. I think if you don't wanna risk anything you should consult a lawyer. ","pontos":-2},{"corpo":"I found out from the event log that there was a security issue with the user making the call to AzMan from a remote computer. The user did not belong the local Users group on the computer running ADAM/AzMan. When I corrected that everything worked again. ","pontos":2},{"corpo":"Try this: @filtered = map {s/ //g; $_} @outdata; The problem is the s operator in perl modifies $_ but actually returns the number of changes it made. So, the extra $_ at the end causes perl to return the modified string for each element of @outdata. ","pontos":10},{"corpo":"The business about _svn vs. .svn was an issue with Visual Studio web projects only (and I'm fairly sure it was fixed in VS2005 anyway), it's not a general \"_svn works better with VS\" thing. It's also only a working-copy issue, not a repository issue - i.e. it doesn't matter if some users of SVN are using clients set up to do _svn and some are using .svn - the repository won't know or care - (unless somehow you end-up with a load of these _svn/.svn files actually checked-into the repository which would be confusing in the extreme.) Unless you have absolute concrete evidence that .SVN is causing you problems, then I would stick with that wherever you can. ","pontos":6},{"corpo":"Maybe outside of the scope but, to sometimes its useful to do an to make the gui parts react to user input, such as pressing the cancel-button on a status bar dialog. ","pontos":0},{"corpo":" Looks like CMFCVisualManager offers several methods for getting color information, e.g. CMFCVisualManager::GetSmartDockingBaseGuideColors() CMFCVisualManager::GetToolbarHighlightColor() Take a look at the MSDN docs for CMFCVisualManager. Good suggestion, but unfortunately they just return various shades of grey, when currently I'm running my application with the style CMFCVisualManagerOffice2007::Office2007_LunaBlue Annoyingly the msdn help is \"under construction\" so doesn't even tell you what they are supposed to be doing! ","pontos":1},{"corpo":"The delay is because, having been unable to find the custom serializer dll, the system is building the equivalent code (which is very time-consuming) on the fly. The way to avoid the delay is to have the system build the DLL, and make sure it's available to the .EXE - have you tried this? ","pontos":4},{"corpo":"A junior DBA meant to do: delete from [table] where [condition] Instead they typed: delete [table] where [condition] Which is valid T-Sql but basically ignores the where [condition] bit completely (at least it did back then on MSSQL 2000/97 - I forget which) and wipes the entire table. That was fun :-/ ","pontos":4},{"corpo":"I discovered I didn't understand Oracle redo log files (terminology? it was a long time ago) and lost a weeks' trade data, which had to be manually re-keyed from paper tickets. There was a silver lining - during the weekend I spent inputting, I learned a lot about the useability of my trade input screen, which improved dramatically thereafter. ","pontos":0},{"corpo":"I think my worst mistake was truncate table Customers truncate table Transactions I didnt see what MSSQL server I was logged into, I wanted to clear my local copy out...The familiar \"OH s**t\" when it was taking significantly longer than about half a second to delete, my boss noticed I went visibily white, and asked what I just did. About half a mintue later, our site monitor went nuts and started emailing us saying the site was down. Lesson learned? Never keep a connection open to live DB longer than absolutly needed. Was only up till 4am restoring the data from the backups too! My boss felt sorry for me, and bought me dinner... ","pontos":11},{"corpo":"Worst case scenario for most people is production data loss, but if they're not running nightly backups or replicating data to a DR site, then they deserve everything they get! @Keith in T-SQL, isn't the FROM keyword optional for a DELETE? Both of those statements do exactly the same thing... ","pontos":0},{"corpo":"My favourite is the global:: keyword to escape namespace hell with some of our 3rd party code providers... Example: global::System.Collections.Generic.List global::System.String myList = new global::System.Collections.Generic.List global::System.String (); ","pontos":33},{"corpo":"I'm guessing now. but: The system might be generating a serializer for the whole of mscorlib, which could be very slow. You could probably avoid this by wrapping the system type in your own type and serialising that instead - then you'd get a serializer for your own assembly. You might be able to build the serializer for mscorlib with sgen.exe, which was the old way of building serializer dlls before it got integrated into VS. ","pontos":2},{"corpo":"I'm not sure that this is the best way to do it, but when I'm deploying Ruby GUI apps (not Python, but has the same \"problem\" as far as .exe's are concerned) on Windows, I just write a short launcher in C# that calls on my main script. It compiles to an executable, and I then have an application executable. ","pontos":2},{"corpo":"I did this: public class MySettings { public static double Setting1 { get { return SettingsCache.Instance.GetDouble(\"Setting1\"); } } public static string Setting2 { get { return SettingsCache.Instance.GetString(\"Setting2\"); } } } I put this in a separate infrastructure module to remove any issues with circular dependencies. Doing this I am not tied to any specific configuration method, and have no strings running havoc in my applications code. ","pontos":0},{"corpo":"This is something that annoys me about MSSQL (rant on my blog). I wish MSSQL supported . @Dillie-O's code is a good way in older SQL versions (+1 vote), but it still is basically two IO operations (the and then the or ) There's a slightly better way on this post, basically: --try an update update tablename set field1 = 'new value', field2 = 'different value', ... where idfield = 7 --insert if failed if @@rowcount = 0 and @@error = 0 insert into tablename ( idfield, field1, field2, ... ) values ( 7, 'value one', 'another value', ... ) This reduces it to one IO operations if it's an update, or two if an insert. MS Sql2008 introduces from the SQL:2003 standard: merge tablename as target using (values ('new value', 'different value')) as source (field1, field2) on target.idfield = 7 when matched then update set field1 = source.field1, field2 = source.field2, ... when not matched then insert ( idfield, field1, field2, ... ) values ( 7, source.field1, source.field2, ... ) Now it's really just one IO operation, but awful code :-( ","pontos":30},{"corpo":"Hang about -- the question that is in the title is definitely not the real question that Rory is asking. The titular question has the simple answer of \"No\" -- but this is no help at all, when you see the real question -- which i don't think anyone has given a simple answer to. The real question Rory asks is presented much later and is more pertinent to the example he gives. Why is the s_Initialized field read outside of the lock? The answer to this is also simple, though completely unrelated to the atomicity of variable access. The s_Initialized field is read outside of the lock because locks are expensive. Since the s_Initialized field is essentially \"write once\" it will never return a false positive. It's economical to read it outside the lock. This is a low cost activity with a high chance of having a benefit. That's why it's read outside of the lock -- to avoid paying the cost of using a lock unless it's indicated. If locks were cheap the code would be simpler, and omit that first check. (edit: nice response from rory follows. Yeh, boolean reads are very much atomic. If someone built a processor with non-atomic boolean reads, they'd be featured on the DailyWTF.) ","pontos":11},{"corpo":"@Rob Cooper Having had some discussions with my manager at work, he said he doesn't obfuscate, but does NGEN on install, apparantly that should be enough to stop Reflector working on your assemblies, but I have no idea if this is true and to what extent, so please don't take it as gospel :) This doesn't offer any kind of protection against disassembly. First I imagine its quite possible to extract raw files from any installation package like an MSI or a CAB file. But more importantly, Ngen runs on the client machine after the assembly has been installed. Ngen just forces the assembly to compile now instead of later using the JIT. The original assembly remains and is unmodified and it must remain because Ngen might not be able to compile the entire assembly. Ngen is for performance, not security, and does nothing to prevent disassembly or make it even slightly more difficult. ","pontos":4},{"corpo":"I have had the unfortunate task of testing threaded code and it is definately the hardest tests I have ever written. When writing my tests, I used a combination of delegates and events. Basically it is all about using PropertyNotifyChanged events with a WaitCallback or some kind of ConditionalWaiter that polls. I am not sure if this was the best approach, but it has worked out for me. ","pontos":1},{"corpo":"@Gaius foreign key (thing_id, thing_type) - problems.id or solutions.id Be careful with these kinds of \"multidirectional\" foreign keys. My experience has shown that query performance suffers dramatically when your join condition has to check the type before figuring out which table to join on. It doesn't seem as elegant but nullable problem_id and solution_id will work much better. Of course, query performance will also suffer with an MVCC design when you have to add the check to get the latest version of a record. The tradeoff is that you never have to worry about contention with updates. ","pontos":1},{"corpo":"The worst thing that happened to me was that a Production server consume all the space in the HD. I was using SQL Server so I see the database files and see that the log was about 10 Gb so I decide to do what I always do when I want to trunc a Log file. I did a Detach the delete the log file and then attach again. Well I realize that if the log file is not close properly this procedure does not work. so I end up with a mdf file and no log file. Thankfully I went to the Microsoft site I get a way to restore the database as recovery and move to another database. ","pontos":0},{"corpo":"Tough one indeed! In my (C++) unit tests, I've broken this down into several categories along the lines of the concurrency pattern used: Unit tests for classes that operate in a single thread and aren't thread aware -- easy, test as usual. Unit tests for Monitor objects (those that execute synchronized methods in the callers' thread of control) that expose a synchronized public API -- instantiate multiple mock threads that exercise the API. Construct scenarios that exercise internal conditions of the passive object. Include one longer running test that basically beats the heck out of it from multiple threads for a long period of time. This is unscientific I know but it does build confidence. Unit tests for Active objects (those that encapsulate their own thread or threads of control) -- similar to #2 above with variations depending on the class design. Public API may be blocking or non-blocking, callers may obtain futures, data may arrive at queues or need to be dequeued. There are many combinations possible here; white box away. Still requires multiple mock threads to make calls to the object under test. As an aside: In internal developer training that I do, I teach the Pillars of Concurrency and these two patterns as the primary framework for thinking about and decomposing concurrency problems. There's obviously more advanced concepts out there but I've found that this set of basics helps keep engineers out of the soup. It also leads to code that is more unit testable, as described above. ","pontos":33},{"corpo":"@Leon I see your point - the way I've asked, and then commented on, the question allows it to be taken in a couple of different ways. To be clear, I wanted to know if it was safe to have concurrent threads read and write to a boolean field without any explicit synchronization code, i.e., is accessing a boolean (or other primitive-typed) variable atomic. I then used the Membership code to give a concrete example, but that introduced a bunch of distractions, like the double-check locking, the fact that s_Initialized is only ever set once, and that I commented out the initialization code itself. My bad. ","pontos":1},{"corpo":"@Herms What I really meant was to stick to the recommended way software should store configuration values for any given platform. What you often get then is also the recommended ways these should/can be modified. Like a configuration menu in a program or a configuration panel in a \"system prefs\" application (for system services softwares ie). Not letting the end users modify them directly via RegEdit or NotePad... Why? The end users (=customers) are used to their platforms System for backups can better save \"safe setups\" etc @ninesided About \" choice of library \", try to link in (static link) any selected library to lower the risk of getting into a version-conflict-war on end users machines. ","pontos":1},{"corpo":"What needs explaining, Reflector isn't open source, Lutz decided to obfuscate to protect his IP. Fair game. ","pontos":2},{"corpo":"It would have been kind of ironic if it weren't ;-) ","pontos":9},{"corpo":"I suppose there's Option 4: the hybrid Move the common Thing attributes into a single-inheritance table, then add an table. This makes foreign-keys simpler, reduces duplication, and allows flexibility. It doesn't solve the problems of type-safety for the additional attributes. It also adds a little complexity since there are two ways for a Thing to have an attribute now. If and other large fields stay in the Things table, though, it also doesn't solve the duplication-space problem. table things int id | int type | string name | text description | datetime created_at | other common fields... foreign key type - thing_types.id table custom_attributes int id | int thing_id | string name | string value foreign key thing_id - things.id ","pontos":0},{"corpo":"@Jeff var ts = new TimeSpan(DateTime.UtcNow.Ticks - dt.Ticks); Doing a subtraction on returns a anyway. So you can just do (DateTime.UtcNow - dt).TotalSeconds I'm also surprised to see the constants multiplied-out by hand and then comments added with the multiplications in. Was that some misguided optimisation? ","pontos":3},{"corpo":"Place two rectangles, one inside the other. Place your table inside the inner rectangle and set it to always be visible. Set the inner rectangle's Page Break to Insert After Rectangle. Set the outer rectangle's visibility to use your conditional expression. The page break and the conditional visibility are now separated, and the inner rectangle's page break won't be processed if it is not visible, but it will if it is visible. Edit: When I tried this, it did not appear to work in the Preview tab in Visual Studio, but it did work in the Print Preview and when I exported the report to PDF. ","pontos":6},{"corpo":"Categorization of templates depends on settings (for example, if you choose \"C#\" settings, all of a sudden all other languages move to an \"other languages\" tree). What folder is your template in? ","pontos":0},{"corpo":"The problem with ActiveRecord is that the queries it automatically generates for you can cause performance problems. You end up doing some unintuitive tricks to optimize the queries that leave you wondering if it would have been more time effective to write the query by hand in the first place. ","pontos":0},{"corpo":"SIMILIE Timeline would probably suit your needs. http://simile.mit.edu/timeline/ Timeline .NET: http://www.codeplex.com/timelinenet Oh, i guess i should ask... for personal use or for display to end users? that might change what i would suggest, but this could work for internal purposes too i suppose. ","pontos":6},{"corpo":"Instead of joining an open source project, find an itch you want to scratch. I find my first year with a language is almost always throw away code (or at least, it should be). Find a problem you (personally) want to solve. Use ruby to do it. You'll learn a lot. ","pontos":7},{"corpo":"I once managed to write an updating cursor that never exited. On a 2M+ row table. The locks just escalated and escalated until this 16-core, 8GB RAM (in 2002!) box actually ground to a halt (of the blue screen variety). ","pontos":3},{"corpo":"Another reason to avoid setting objects to null when you are done with them is that it can actually keep them alive for longer. e.g. void foo() { var someType = new SomeType(); someType.DoSomething(); // someType is now eligible for garbage collection // ... rest of method not using 'someType' ... } will allow the object referred by someType to be GC'd after the call to \"DoSomething\" but void foo() { var someType = new SomeType(); someType.DoSomething(); // someType is NOT eligible for garbage collection yet // because that variable is used at the end of the method // ... rest of method not using 'someType' ... someType = null; } may sometimes keep the object alive until the end of the method. The JIT will usually optimized away the assignment to null, so both bits of code end up being the same. ","pontos":21},{"corpo":"Using Linq and .Net 3.5: //this will now be an enumeration, rather than a read only collection Dim children = SiteMap.CurrentNode.ChildNodes.Where( _ Function (x) x.Url \"/Registration.aspx\" ) RepeaterSubordinatePages.DataSource = children Without Linq, but using .Net 2: Function IsShown( n as SiteMapNode ) as Boolean Return n.Url \"/Registration.aspx\" End Function ... //get a generic list Dim children as List(Of SiteMapNode) = _ New List(Of SiteMapNode) ( SiteMap.CurrentNode.ChildNodes ) //use the generic list's FindAll method RepeaterSubordinatePages.DataSource = children.FindAll( IsShown ) Avoid removing items from collections as that's always slow. Unless you're going to be looping through multiple times you're better off filtering. ","pontos":1},{"corpo":"If you need a timeline from RSS Feeeds give xTimeline a try. I just used it http://lifehacker.com/software/rss/create-a-timeline-from-rss-feeds-with-xtimeline-283098.php ","pontos":1},{"corpo":"My advice is just the opposite - Avoid MSBuild like the plague. NANT is far far easier to set up your build to do automatic testing, deploy to multiple production environments, integrate with cruisecontrol for an entry environment, integrate with source control. We've gone through so much pain with TFS/MSBuild (Using TFSDeployer, custom powershell scripts, etc) to get it to do what we were able to do with NANT out of the box. Don't waste your time. ","pontos":26},{"corpo":"According to the MSDN documentation of System.Type [1] you should be able to serialize the System.Type object. However, as the error is explicitly referring to System.Text.StringBuilder, that is likely the class that is causing the serialization error. [1] Type Class (System) - http://msdn.microsoft.com/en-us/library/system.type.aspx ","pontos":2},{"corpo":"For starters, always remember that is not a SQL keyword; it is merely a batch separator that is (generally) implemented/recognized by the client, not the server. So, depending on context and client, there really is no guarantee that the current database is preserved between batches. ","pontos":1},{"corpo":"Are you allowed to reflect it according to the EULA (if any) ? I would guess not, and not surprised that you can't. ","pontos":0},{"corpo":"Problem solved! Although the error message said The specified module could not be found, this is a little misleading -- it's not that it couldn't find php_curl.dll, but rather it couldn't find a module that php_curl.dll required. The 2 DLLs it requires are libeay32.dll SSLeay32.dll. So, you have to put those 2 DLLs somewhere in your PATH (e.g., C:\\Windows\\system32). That's all there is to it. HOWEVER, even that did not work for me initially. So I downloaded the Windows zip of the latest version of PHP, which includes all the necessary DLLs. I didn't reinstall PHP, I just copied all of the DLLs in the \"ext\" folder to my PHP extensions folder (as specified in the extension_dir variable in php.ini), and I copied the versions of libeay32.dll and SSLeay32.dll from the PHP download into my System32 directory. I also did an iisreset, but I don't know if that was necessary. ","pontos":12},{"corpo":"You can hate Powershell, and yet it can still be incredibly useful to you. I use it for small but important one-liner types of things or in very minor scripts. It really can't compare to C# so as soon as there is any complexity or significant potential reuse at all I switch to C#. Also, importantly, Powershell is so funky that I WANT to recreate solutions from scratch every time, otherwise I forget the quirks, of which there are many. I have heard other people say this too! Examples of what it's really good for: Ad hoc text processing. Occasionally people hand me a large data or SQL file, and they want it manipulated into a different form, sometimes in really complicated ways. This alone has saved me incredible amounts of time. It often involves lots of adhoc one-liners and intermediate files. Now that people know I can do this, they tend to hand such projects off to me. Or in some cases they are so wowed that they learn Powershell for themselves. When I'm at a customer site and desperately need to automate something, and it's the only tool I can and/or am allowed to get my hands on. Little scripts to log into web sites and navigate to whatever page I'm interested in or working on. I never manually log into a web site that I'm developing anymore. Trivial, but that's one less annoying repeating brain dead task I need to worry about. One-liners to copy files and projects around and search and replace. Little scripts to do builds, if there are any unusual complications involved. Etc. You are bound to have little quirks in your system, where you need to stop/start a service to fix something else, or whatever. ","pontos":6},{"corpo":"If you're using Cocoa it's fairly easy with NSString. Just load the UTF16 data in using -initWithBytes:length:encoding: (or perhaps -initWithCString:encoding:) and then get a UTF8 version by calling UTF8String on the result. Then, just call fopen with your new UTF8 string as the param. You can definitely call fopen with a UTF-8 string, regardless of language - can't help with C++ on OSX though - sorry. ","pontos":0},{"corpo":"If you don't want to (or can't) implement IDisposable on your class, you can force garbage collection like this (but it's slow) - GC.Collect(); ","pontos":0},{"corpo":"Have you tried DBUnit? It's designed to unit test your database, and just your database, without needing to go through your C# code. ","pontos":11},{"corpo":"It's always been the case that its been obfuscated. It was one of the first things I tried with it years ago ;). ","pontos":4},{"corpo":"IDisposable has nothing to do with freeing memory. IDisposable is a pattern for freeing unmanaged resources -- and memory is quite definitely a managed resource. The links pointing to GC.Collect() are the correct answer, though use of this function is generally discouraged by the Microsoft .NET documentation. Edit: Having earned a substantial amount of karma for this answer, I feel a certain responsibility to elaborate on it, lest a newcomer to .NET resource management get the wrong impression. Inside a .NET process, there are two kinds of resource -- managed and unmanaged. \"Managed\" means that the runtime is in control of the resource, while \"unmanaged\" means that it's the programmer's responsibility. And there really is only one kind of managed resource that we care about in .NET today -- memory. The programmer tells the runtime to allocate memory and after that it's up to the runtime to figure out when the memory can freed. The mechanism that .NET uses for this purpose is called garbage collection and you can find plenty of information about GC on the internet simply by using Google. For the other kinds of resources, .NET doesn't know anything about cleaning them up so it has to rely on the programmer to do the right thing. To this end, the platform gives the programmer three tools: The IDisposable interface and the \"using\" statement in VB and C# Finalizers The IDisposable pattern as implemented by many BCL classes The first of these allows the programmer to efficiently acquire a resource, use it and then release it all within the same method. using (DisposableObject tmp = DisposableObject.AcquireResource()) { // Do something with tmp } // At this point, tmp.Dispose() will automatically have been called // BUT, tmp may still a perfectly valid object that still takes up memory If \"AcquireResource\" is a factory method that (for instance) opens a file and \"Dispose\" automatically closes the file, then this code cannot leak a file resource. But the memory for the \"tmp\" object itself may well still be allocated. That's because the IDisposable interface has absolutely no connection to the garbage collector. If you did want to ensure that the memory was freed, your only option would be to call to force a garbage collection. However, it cannot be stressed enough that this is probably not a good idea. It's generally much better to let the garbage collector do what it was designed to do, which is to manage memory. What happens if the resource is being used for a longer period of time, such that its lifespan crosses several methods? Clearly, the \"using\" statement is no longer applicable, so the programmer would have to manually call \"Dispose\" when he or she is done with the resource. And what happens if the programmer forgets? If there's no fallback, then the process or computer may eventually run out of whichever resource isn't being properly freed. That's where finalizers come in. A finalizer is a method on your class that has a special relationship with the garbage collector. The GC promises that -- before freeing the memory for any object of that type -- it will first give the finalizer a chance to do some kind of cleanup. So in the case of a file, we theoretically don't need to close the file manually at all. We can just wait until the garbage collector gets to it and then let the finalizer do the work. Unfortunately, this doesn't work well in practice because the garbage collector runs non-deterministically. The file may stay open considerably longer than the programmer expects. And if enough files are kept open, the system may fail when trying to open an additional file. For most resources, we want both of these things. We want a convention to be able to say \"we're done with this resource now\" and we want to make sure that there's at least some chance for the cleanup to happen automatically if we forget to do it manually. That's where the \"IDisposable\" pattern comes into play. This is a convention that allows IDispose and a finalizer to play nicely together. You can see how the pattern works by looking at the official documentation for IDisposable. Bottom line: If what you really want to do is to just make sure that memory is freed, then IDisposable and finalizers will not help you. But the IDisposable interface is part of an extremely important pattern that all .NET programmers should understand. ","pontos":78},{"corpo":"I am assuming that you want unit testing in MSSQL. Looking at DBUnit there are some limitations in it's support for MSSQL. It doesn't support NVarChar for instance. Here are some real users and their problems with DBUnit. ","pontos":4},{"corpo":"Would it be appropriate to also mention that dispose doesn't always refer to memory? I dispose resources such a references to files more often than memory. GC.Collect() directly relates to the CLR garbage collector and may or may not free memory (in Task Manager). It will likely impact your application in negative ways (eg performance). At the end of the day why do you want the memory back immediately? If there is memory pressure from elsewhere the OS will get you memory in most cases. ","pontos":14},{"corpo":"You can't really force a GC to clean up an object when you want, although there are ways to force it to run, nothing says it's clean up the all the object you want/expect. It's best to call dispose in a try catch ex finally dispose end try (VB.NET rulz) way. But Dispose is for cleaning up system resources (memory, handles, db connections, etc. allocated by the object in deterministic way. Dispose doesn't (and can't) clean up the memory used by the object itself, only the the GC can do that. ","pontos":2},{"corpo":"About 7 years ago, I was generating a change script for a client's DB after working late. I had only changed stored procedures but when I generated the SQL I had \"script dependent objects\" checked. I ran it on my local machine and all appeared to work well. I ran it on the client's server and the script succeeded. Then I loaded the web site and the site was empty. To my horror, the \"script dependent objects\" setting did a for every table that my stored procedures touched. I immediately called the lead dev and boss letting them know what happened and asking where the latest backup of the DB could be located. 2 other devs were conferenced in and the conclusion we came to was that no backup system was even in place and no data could be restored. The client lost their entire website's content and I was the root cause. The result was a $5000 credit given to our client. For me it was a great lesson, and now I am super-cautious about running any change scripts, and backing up DBs first. I'm still with the same company today, and whenever the jokes come up about backups or database scripts someone always brings up the famous \"DROP TABLE\" incident. ","pontos":3},{"corpo":"You can only dispose instances that implement the IDisposable interface. To force a garbage collect to free up the (unmanaged) memory immediately: GC.Collect(); GC.WaitForPendingFinalizers(); This is normally bad practice, but there is for example a bug in the x64-version of the .NET framework that makes the GC behave strange in some scenarios, and then you might want to do this. I don't know if the bug have been resolved yet. Does anyone know? To dispose a class you do this: instance.Dispose(); or like this: using(MyClass instance = new MyClass()) { // Your cool code. } that will translate at compile-time to: MyClass instance = null; try { instance = new MyClass(); // Your cool code. } finally { if(instance != null) instance.Dispose(); } You can implement the IDisposable interface like this: public class MyClass : IDisposable { private bool disposed; /// summary /// Construction /// /summary public MyClass() { } /// summary /// Destructor /// /summary ~MyClass() { this.Dispose(false); } /// summary /// The dispose method that implements IDisposable. /// /summary public void Dispose() { this.Dispose(true); GC.SuppressFinalize(this); } /// summary /// The virtual dispose method that allows /// classes inherithed from this one to dispose their resources. /// /summary /// param name=\"disposing\" /param protected virtual void Dispose(bool disposing) { if (!disposed) { if (disposing) { // Dispose managed resources here. } // Dispose unmanaged resources here. } disposed = true; } } ","pontos":19},{"corpo":"I thought I was working in the testing DB (which wasn't the case apparently), so when I finished 'testing' I run a script to reset all data back to the standard test data we use... ouch! Luckily this happened on a database that had backups in place, so after figuring out I did something wrong we could easily bring back the original database. However this incident did teach the company I worked for to realy seperate the production and the test environment. ","pontos":1},{"corpo":"I think the \"what is a memory leak\" and \"what are the effects\" questions have been answered well already, but I wanted to add a few more things on the other questions... How to understand whether your application leaks One interesting way is to open perfmon and add traces for # bytes in all heaps and # Gen 2 collections , in each case looking just at your process. If exercising a particular feature causes the total bytes to increase, and that memory remains allocated after the next Gen 2 collection, you might say that the feature leaks memory. How to prevent Other good opinions have been given. I would just add that perhaps the most commonly overlooked cause of .NET memory leaks is to add event handlers to objects without removing them. An event handler attached to an object is a form of reference to that object, so will prevent collection even after all other references have gone. Always remember to detach event handlers (using the syntax in C#). Does the leak go away when the process exits, and what about COM interop? When your process exits, all memory mapped into its address space is reclaimed by the OS, including any COM objects served from DLLs. Comparatively rarely, COM objects can be served from separate processes. In this case, when your process exits, you may still be responsible for memory allocated in any COM server processes that you used. ","pontos":20},{"corpo":"Yeah, looks like Entity Framework doesn't support this, nor could i jerry-rig a way to get it to evaluate in a way that would work. ","pontos":0},{"corpo":"I would guess that possibly those don't happen because they would break the build for existing code, but that's just a guess on my part. Here's my logic: First, EF is supposed to be more than 1:1 table mapping, so it's quite possible that just because you are deleting a column from table A doesn't mean that for that entity, there shouldn't be a property Description. You might just map that property to another table. Second, changing a type could just break builds. that's the only rationale there. ","pontos":5},{"corpo":"As mentioned in the question, has a method: IEnumerable DataRow query = from order in orders.AsEnumerable() where order.Field DateTime (\"OrderDate\") new DateTime(2001, 8, 1) select order; // Create a table from the query. DataTable boundTable = query.CopyToDataTable DataRow (); Why won't that work for you? ","pontos":42},{"corpo":"We use DataFresh to rollback changes between each test, then testing sprocs is relatively easy. What is still lacking is code coverage tools. ","pontos":1},{"corpo":"Remember, obfuscation is not encryption. IMHO, if somebody perceives value in reverse-engineering your code, they will do it. That's true for managed code or native code, obfuscated or not. Sure, obfuscation deters the casual observer, but is your business actually threatened by such people? Every .NET obfuscation method I've seen makes your life as a developer harder. There are services that offer true encryption, such as SLPS from Microsoft. See http://www.microsoft.com/slps/default.aspx ","pontos":8},{"corpo":"IDisposable interface is really for classes that contain unmanaged resources. If your class doesn't contain unmanaged resources, why do you need to free up resources before the garbage collector does it? Otherwise, just ensure your object is instantiated as late as possible and goes out of scope as soon as possible. ","pontos":0},{"corpo":"Obsfucation is limited in it's effectiveness, it might keep the casual guy away. The most effective obsfucation is making only the smallest amount of code available to the user. If you can, make your app run depend heavily on a fat server. ","pontos":0},{"corpo":"This is probably coming from a Response.Redirect call. Check this link for an explanation: http://dotnet.org.za/armand/archive/2004/11/16/7088.aspx (In most cases, calling Response.Redirect(url, false) fixes the problem) ","pontos":18},{"corpo":"I was faced with the same problem, and ended up moving my Outlook archive.pst and the windows.edb (the new live search index file) over to D: to make room instead of trying to cram a square peg into a round hole with SP1 splitting drives. A huge help in this regard is WinDirStat, which scans a drive of your choice and identifies the size of every folder and file so that you can reveal some random large entities and move them if you can. ","pontos":2},{"corpo":"Without an actual CAPTCHA as your first line of defense, aren't you still vulnerable to spammers scripting the browser (trivial using VB and IE)? I.e. load the page, navigate the DOM, click the submit button, repeat... ","pontos":2},{"corpo":"The strict answer is \"you can't\", as the very concept of a folder is not truly cross-platform. On MS platforms you can use _findfirst, _findnext and _findclose for a 'c' sort of feel, and FindFirstFile and FindNextFile for the underlying Win32 calls. Here's the C-FAQ answer: http://c-faq.com/osdep/readdir.html ","pontos":12},{"corpo":"There are a lot of RSS feed readers out there that people are used to using, and most importantly, RSS is very well known and has been around much longer. Why mess with something if it works? ","pontos":0},{"corpo":"Because the developers of sed sights got reemed from their marketing manager that they were \"excluding\" people by not providing rss. Since Mr. Marketing has never heard of Atom, you just provide both. If you are restfully implementing it, its not a big deal to just do both and not get yelled at by other departments. ","pontos":0},{"corpo":"The same reason that people are HTML 4 loose, strict, XHTML transitional, XHTML strict, etc. Legacy code / working with what you already know. Besides, both formats have their merits. Better to support a couple different formats than have one be-all-end-all-subscribe-to-everything feed that becomes bloated. ","pontos":1},{"corpo":" will return the version number. RTM of v1 is 1.0.0.0 Couldn't honestly tell you what the latest version of the previews are because I haven't had a chance to play yet. ","pontos":2},{"corpo":" So, CAPTCHA is mandatory for all users except moderators. [1] That's incredibly stupid. So there will be users who can edit any post on the site but not post without CAPTCHA? If you have enough rep to downvote posts, you have enough rep to post without CAPTCHA. Make it higher if you have to. Plus there are plenty of spam detection methods you can employ without image recognition, so that it even for unregistered users it would never be necessary to fill out those god-forsaken CAPTCHA forms. ","pontos":27},{"corpo":"Unit-testing is the testing of a unit of code (e.g. a single function) without the need for the infrastructure that that unit of code relies on. i.e. test it in isolation. If, for example, the function that you're testing connects to a database and does an update, in a unit test you might not want to do that update. You would if it were an integration test but in this case it's not. So a unit test would exercise the functionality enclosed in the \"function\" you're testing without side effects of the database update. Say your function retrieved some numbers from a database and then performed a standard deviation calculation. What are you trying to test here? That the standard deviation is calculated correctly or that the data is returned from the database? In a unit test you just want to test that the standard deviation is calculated correctly. In an integration test you want to test the standard deviation calculation and the database retrieval. ","pontos":1},{"corpo":"There's a couple out there. They all hook into the windows API to log item clicks, and then reproduce them to test. We're now mostly web based (using WatiN), but we used to use Mercury Quicktest. Don't use Quicktest, it's awful for a tremendously long list of reasons. ","pontos":0},{"corpo":"This is not possible without using the result to select the day yourself. For one thing the textual representation of the day is locale-dependent. For another the returned value depends upon the 'datefirst' setting. ","pontos":0},{"corpo":"The notion of tuples are highly expressive: Pragmatically, they are great for packing and unpacking values (). In combination with dictionaries (hash tables), they allow forms of mapping that would otherwise require many levels of association. For example, consider marking that (x,y) has been found. // PHP if (!isset($found[$x])) { $found[$x] = Array(); $found[$x][$y] = true; } else if (!isset($found[$x][$y])) { $found[$x][$y] = true; } # Python found[(x,y)] = True # parens added for clarity Lists should be used with the expectation of operations on its contents (hence the various mentions of immutability). One will want to pop, push, splice, slice, search, insert before, insert after, etc with a list. Tuples should be a low-level representation of an object, where simple comparisons are made, or operations such as extracting the n'th element or n elements in a predictable fashion, such as the coordinates example given earlier. Lastly, lists are not hashable, so the type of mapping done with dictionaries (hash tables in Perl, associative arrays in PHP) must be done with tuples. Here's a simple example of tuples and dictionaries, together at last: \"\"\" couple is a tuple of two people doesLike is a dictionary mapping couples to True or False \"\"\" couple = \"john\", \"jane\" doesLike = dict() doesLike[couple] = True doesLike[\"jane\", \"john\"] = False # unrequited love :'( ","pontos":6},{"corpo":"We were trying to fix a busted node on an Oracle cluster. The storage management module was having problems, so we clicked the un-install button with the intention of re-installing and copying the configuration over from another node. Hmm, it turns out the un-install button applied to the entire cluster, so it cheerfully removed the storage management module from all the nodes in the system. Causing every node in the production cluster to crash. And since none of the nodes had a storage manager, they wouldn't come up! Here's an interesting fact about backups... the oldest backups get rotated off-site, and you know what your oldest files on a database are? The configuration files that got set up when the system was installed. So we had to have the offsite people send a courier with that tape, and a couple of hours later we had everything reinstalled and running. Now we keep local copies of the installation and configuration files! ","pontos":2},{"corpo":"Though they're mostly targeted at automating administration tasks or shortcuts for users, Autohotkey and AutoIT let you automate nearly anything you want as far as mouse/keyboard interaction. Some of the mouse stuff can get tricky when the only way to really tell it what you want to click is an X,Y coordinate, but for automating entirely arbitrary tasks on a Windows machine, it does the trick. Like I said, they're not necessarily intended for testing purposes, so they're not instrumented for unit test conventions. However, I use them all of the time to automate stuff that isn't testing related. ","pontos":6},{"corpo":"Vincent, I'm not suggesting that anyone rewrite existing RSS feeds just for the sake of it, that would be a big waste of time! In terms of RSS being the acronym that defines the category, I'm guessing that most users now identify with the orange feed icon, rather than the specific flavour of XML behind it. ","pontos":1},{"corpo":"Don't waste too much time trying to think of every boundry condition. Your tests won't be able to catch every bug first time around. The idea is to have tests that are pretty good, and then each time a bug does surface, write a new test specifically for that bug so that you never hear from it again. Another note I want to make about code coverage tools. In a language like C# or Java where your have many get/set and similar methods, you should not be shooting for 100% coverage. That means you are wasting too much time writing tests for trivial code. You only want 100% coverage on your complex business logic. If your full codebase is closer to 70-80% coverage, you are doing a good job. If your code coverage tool allows multiple coverage metrics, the best one is 'block coverage' which measures coverage of 'basic blocks'. Other types are class and method coverage (which don't give you as much information) and line coverage (which is too fine grain). ","pontos":8},{"corpo":"You can pull it in from Alexa. For example all sites linking to Yahoo would be: http://www.alexa.com/data/ds/linksin/yahoo.com?q=link:yahoo.com/ So just replace \"yahoo.com\" in the 2 spots with your site and it should work. You can then parse the HTML to get any info you want. Or you can look into Alexa's API, but they are not free. ","pontos":1},{"corpo":"There is no magic solution, and attempting to provide generic solutions could well just be a waste of time. Where are your bottlenecks? For example are your scripts processor/database/memory intensive? Have you performed any profiling? ","pontos":3},{"corpo":"Profile. Profile. Profile. I'm not sure if there is anything out there for PHP, but it should be simple to write a little tool to insert profiling information in your code. You will want to profile function times and SQL query times. So where you have a function: function foo($stuff) { ... return ...; } I would change it to: function foo($stuff) { trace_push_fn('foo'); ... trace_pop_fn('foo'); return ...; } (This is one of those cases where multiple returns in a function become a hinderance.) And SQL: function bar($stuff) { trace_push_fn('bar'); $query = ...; trace_push_sql($query); mysql_query($query); trace_pop_sql($query); trace_pop_fn('bar'); return ...; } In the end, you can generate a full trace of the program execution and use all sorts of techniques to identify your bottlenecks. ","pontos":14},{"corpo":"The fundamental thing that the Atom creators didn't understand (and that the Atom supporters still don't understand), is that Atom isn't somehow separate from RSS. There's this idea that RSS fractured, and that somehow Atom fixes that problem. But it doesn't. Atom is just another RSS splinter. A new name doesn't change the fact that it's just one more standard competing to do the same job, a job for which any of the competing standards are sufficient. No one outside a fairly small group of people care at all which standard is used. They just want it to work. Atom, RSS 2.0, RSS 1.0, RSS 401(k), whatever. As long as it works, the users are happy. The RSS \"brand\" very much defines the entire feed category, though, so on the rare occasion that someone does know enough to choose, they will tend to choose RSS, because it's got \"the name.\" They will also tend to choose RSS 2.0, because it's got the bigger number. RSS, and especially RSS 2.0, are very much entrenched in the feed \"industry.\" Atom hasn't taken off because it doesn't bring much except a new name. Why switch away from RSS when it works just fine? And why even bother using Atom on new projects if RSS is sufficient? Switching to a new feed format mostly means extra time spent learning the new format. If nothing else Apple's exclusive use of RSS 2.0 for podcasts means that RSS 2.0 is here for the foreseeable future. ","pontos":106},{"corpo":"@Frank Krueger: It wouldn't work well. What if no one clicked on the link pointing to your page? It means no referrer and it won't show in the logs. ","pontos":0},{"corpo":"If all else fails, you could always use NetShareEnum and call NetShareGetInfo on each. ","pontos":3},{"corpo":"There is no need for this sort of stuff to be the subject of tedious workplace debates, because the source code for the framework is available, and with a minuscule amount of work you can download the whole lot onto your machine. http://www.codeplex.com/NetMassDownloader With another tiny bit of work, you can make a VS project which contains all the framework source, which makes it even easier to look through. ","pontos":1},{"corpo":"@vincent: Standard C function accepts UTF-8 Is that all functions? Where did you read this? That has big implications (in terms of convenience) for people porting to OS X but I've not read it anywhere else. ","pontos":0},{"corpo":"Yes. You can do it. The doctest module documentation and Wikipedia has an example of it. x Traceback (most recent call last): ... NameError: name 'x' is not defined ","pontos":33},{"corpo":"I think they are working on throttling. It would make more sense just to disable CAPTCHA for users with 500+ rep and reset the rep for attackers. ","pontos":1},{"corpo":"I would say start with the ical standard. If you use it as your model, then you'll be able to do everything that google calendar, outlook, mac ical (the program), and get virtually instant integration with them. From there, time to bone up on your ajax and javascript cuz you can't have a flashy web ui with drag drop and multiple calendars without a ton of ajax and javascript. ","pontos":3},{"corpo":"I think I understand your second paragraph to mean you are considering a second events table that has a row for each occurrence of an event. I would avoid that. Re-occurring events should have a start date and a stop date (which could be Null for events that continue every X days \"forever\") You'll have to decide what kinds of frequency you want to allow -- every X days, the Nth day of each month, every given weekday, etc. I'd probably tend toward two tables - one for one time events and a second for recurring events. You'll have to query and display the two separately. If I were going to tackle this (and I'd try as hard as I can to avoid reinventing this wheel) I'd look for open-source libraries or, at the very least, open source projects with Calendars that you can look at. Any recommendations guys? ","pontos":0},{"corpo":"I've had to implement that type of security a couple of times. Unfortunately I don't know of any really good articles that provide examples. My implementations were mainly piecing together the parts through trial and error. However, I did come across this link on MSDN: http://msdn.microsoft.com/en-us/library/52kd59t0(VS.71).aspx It has some of the concepts. After my original post, I did some more research. I found this article: http://www.aspfree.com/c/a/C-Sharp/Implementing-Role-Based-Security-using-CSharp/ it seems pretty promising, I didn't go through all the details, but it at least guides you through the high-level topics. ","pontos":1},{"corpo":"A more philosophical answer: Unix (in all flavors) is built on a single big idea: Difficult problems can be solved by solving easy problems first. You might recognize this as the Bottom-Up approach. But Unix takes this philosophy to an extreme. It's like living in a foreign country: you need to enculturate. For instance, suppose you are working on a system that requires three separate servers. Every morning, you type in three different commands to start them up. At some point (hopefully on day two), you decide it's silly to type those same three commands each time you want to start work. You might be tempted to write an application that controls those servers, but that's not the Unix way. Instead, you should put those three commands in a script and move on. Later, when you are ready to go into production, you want to show the startup process to your customer. It's a bit embarrassing to show off the startup script, so you write a little GUI that has a startup button for the customer to press. That button simply calls the script you wrote back on day two. Problem solved! If that scenario strikes you as odd or horrifying, you are still thinking like a Windows programmer. And in some ways it is horrifying: a little helper script has become part of production code almost by accident. But this sort of thing happens all the time on Unix systems and it mostly works. There's not much point in listing commands that you need. If you use the command line long enough, you'll figure out what you need fairly quickly. Instead, I'd focus on trying to do everything in the shell for a while. (I use ksh exclusively for writing scripts and bash for my interactive shell. They're similar, but geared toward slightly different uses.) I don't believe anyone who does not understand pipelines can be said to be a Unix programmer. A fairly common idiom that I found helpful to grokking pipelines was the output of find piped into xargs. Right now, for instance, I need to remove a bunch of files that I own. First I find the files: $ find . -user jericson Then I pipe the results to xargs to remove them: $ find . -user jericson | xargs rm Be sure to look at the -i option for xargs as well. Note that I broke the problem into two smaller problems and solved each one separately. I actually ran the find command by itself to be sure I was looking at correct files. Then I piped the results to the second command as input. Using the pipeline avoids an intermediary file. ","pontos":1},{"corpo":"@GateKiller I hadn't thought of the case where you edit individual occurrences. It makes sense you would store the occurrences separately in that case. When you do that, though, how far in the future do you store events? Do you pick an arbitrary date? Do you auto-generate the new occurrences the first time a user browses out into future months/years? Also, how do you handle the case where the user wants to edit the whole series. \"We've had a meeting every Tuesday morning at 10:30 but we're going to start meeting on Wednesday at 8\" ","pontos":1},{"corpo":"Darren, That is how I have designed my events table actually, but when thinking about it, say I have 100K users who have create events, this table will be hit pretty hard, especially if I am going to be sending out emails to remind people of their events (events can be for specific times of the day also!), so I could be polling this table every 15 minutes potentially! This is why I wanted to create another table that would expand out all the events/re-occuring events, this way I can simple hit that table and get the users months view of events without doing any complicated querying and business logic, AND it will make polling much more effecient also. The question is, should this secondary table be for the next day or month? What makes more sense? Since the maximum a user can view is a months view, I am leaning towards a table that writes out all the events for a given month. (ofcourse I will have to maintain this secondary table for any edits the user might make to the original events table). ChanChan, I have designed it with the same sort of functionality actually, but I am just referring to how I will go about storing events, specifically how to handle re-occurring events. ","pontos":2},{"corpo":"should use a functional language imo. Trees are harder to represent and manipulate in OO languages. ","pontos":0},{"corpo":"Use; SHGetFileInfo with SHGFI_ATTRIBUTES upon return check the dwAttributes flag for SFGAO_SHARE. I'm not sure how to find the actual path tho. ","pontos":0},{"corpo":"Have you tried a two way data binding between the two dependency properties? ","pontos":0},{"corpo":"Matt Berseth had some thoughts in this, might help: http://mattberseth.com/blog/2008/07/aspnet_file_upload_with_realti_1.html @Dan - Apologies mate, I coulda sworn Matt's article was about Silverlight, but it's quite clearly not. Blame it on those two big glasses of Chilean red I just downed. :-) ","pontos":0},{"corpo":"Does this work for you? select user_name(),suser_sname() Doh! I forgot to escape my code. ","pontos":2},{"corpo":" Or maybe this is the real question: how can you represent (2) as a BST? That is the part that is tripping me up. Recursion. ","pontos":0},{"corpo":"Thanks, problem I can see with the article is that its not talking about Silverlight, and Silverlight has limited functions, for some reason they have removed some necessary events and methods for binary transfers for no reason. I need to use Silverlight as I need/want to upload multiple files and HTML does not allow for a multiple file upload. ","pontos":0},{"corpo":" The problem, I think, is that we need to parse perentheses, and yet they are not a binary operator? Should we take (2) as a single token, that evaluates to 2? The parens don't need to show up in the expression tree, but they do affect its shape. E.g., the tree for (1+2)+3 is different from 1+(2+3): + / \\ + 3 / \\ 1 2 versus + / \\ 1 + / \\ 2 3 The parentheses are a \"hint\" to the parser (e.g., per superjoe30, to \"recursively descend\") ","pontos":3},{"corpo":"Attempting to store each instance of every event seems like it would be really problematic and, well, impossible. If someone creates an event that occurs \"every thursday, forever\", you clearly cannot store all the future events. You could try to generate the future events on demand, and populate the future events only when necessary to display them or to send notification about them. However, if you are going to build the \"on-demand\" generation code anyway, why not use it all the time? Instead of pulling from the event table, and then having to use on-demand event generation to fill in any new events that haven't been added to the table yet, just use the on-demand event generation exclusively. The end result will be the same. With this scheme, you only need to store the start and end dates and the event frequency. I don't see any way that you can avoid having on-demand event generation, so I can't see the utility in the event table. If you want it for the sake of caching, then I think you're taking the wrong approach. First, it's a poor cache because you can't avoid on-demand event generation anyway. Second, you should probably be caching at a higher level anyway. If you want to cache, then cache generated pages, not events. As far as making your polling more efficient, if you are only polling every 15 minutes, and your database and/or server can't handle the load, then you are already doomed. There's no way your database will be able to handle users if it can't handle much, much more frequent polling without breaking a sweat. ","pontos":4},{"corpo":"Sorry, but I'm confused. You can't call an ascx directly, so... Is your modal code that you are calling from within the same page, like a hidden panel, etc; Or is it another aspx page that you are calling on a click event? ","pontos":0},{"corpo":"From a coworker who used to work at TIBCO: TIBCO is a complicated, hard to use system because it's used for complicated, hard to solve problems. ","pontos":2},{"corpo":"Unless you plan on making the app cross-platform, using the Windows API calls would be the best way to go. Just ignore the note in the API documentation about being provided only for 16-bit app compatibility. ","pontos":2},{"corpo":"Re: Justin I think the tree would look something like this: + / \\ 2 ( ) | 2 Basically, you'd have an \"eval\" node, that just evaluates the tree below it. That would then be optimized out to just being: + / \\ 2 2 In this case the parens aren't required and don't add anything. They don't add anything logically, so they'd just go away. ","pontos":1},{"corpo":"I recently (can't remember where) saw a system that showed a bunch of pictures. Each of the pictures had a character assigned to it. The user was then asked to type in the characters for some pictures that showed examples of some category (cars, computers, buildings, flowers and so on). The pictures and characters changed each time as well as the categories to build the CAPTCHA string. The only problem is the higher bandwidth associated with this approach and you need a lot of pictures that are classified in categories. There is no need to waste much resources generating the pictures. ","pontos":1},{"corpo":"The attribute you want is OperationContract (on interface) / Operation Behavior (on method) [ServiceContract] public interface ITableProvider { [OperationContract] DataTable GetTbl(); } [OperationBehavior] public DataTable GetTbl(){ DataTable tbl = new DataTable(\"testTbl\"); //populate table with sql query return tbl; } Also, in the... i think service configuration... you want to specify that errors can be sent, you might be hitting an error that is something like the message size is to big, etc. You can fix that by fudging w/ the reader quotas and such. By default wsHttpBinding has a receive size quota of like 65k, so if the serialized data table's xml is more than that, it would throw an error (and i'm 95% sure the data table is more than 65k with data in it) You can change the settings for the reader quotas and such in the web.config / app.config or you can set it on a binding instance in code. But yeah, that's probably what your problem is, if you haven't changed it by default. WSHttpBindingBase Members - Look at ReaderQuotas property as well as the MaxReceivedMessageSize property ","pontos":3},{"corpo":"I don't believe there is anything builtin to do it. For more than you ever wanted to see on the subject, see Perlmonks on Detecting Numeric ","pontos":2},{"corpo":"Ok, it's working here. I'm seeing my windows credentials when I update my tables. So, I bet we missed a step. Let me put together a 1,2,3 sequence of what I did and maybe we can track down where this is breaking for you. Create a new MSAccess database (empty) Click on the tables section Select external data Pick ODBC database Pick Link to the datasource by creating a linked table Select Machine datasource Pick New... System Datasource Pick SQL Server from the list and click Next, Finish. Give the new datasource a name and description, and select (local) for the server. Click Next. Pick \"With Windows NT authentication using the network login ID\". Click Next. Check Change the default database to, and pick the DB. Click Next. Click Finish. Test the datasource. Pick the table that the Trigger is associated with and click OK. Open the table in Access and modify one of the entries (the trigger doesn't fire on Insert, just Update) Select * from your audit table ","pontos":2},{"corpo":"I'd suggest you move your repository to somewhere a little safer, maybe \"c:\\SVNRepo\". I'd hesitate to put the Repository in \"Documents and Settings\". Is your repository actually called \"my_repository\"? ","pontos":0},{"corpo":"I've followed the instructions given at the Collabnet site: http://svn.apache.org/repos/asf/subversion/trunk/notes/windows-service.txt They use the windows SC to create the service (which runs svnserve). This has worked for me without any problems (using svn 1.4 and 1.5) ","pontos":1},{"corpo":"The User Documentation is primarily written by our Communications department, who also write up Feature Requests and talk with the Clients about bugs and other problems. Anything on the System or Code level is written by the Developers responsible for the code if it needs any explaining. ","pontos":2},{"corpo":"I think svnservice is obsolete, because since 1.4, svnserve itself has been able to run as a Windows service. (svnserve comes as a part of the normal SVN binary distribution) http://svn.apache.org/repos/asf/subversion/trunk/notes/windows-service.txt contains the details of how to set it up. And the binaries you want are here: http://subversion.tigris.org/servlets/ProjectDocumentList?folderID=91 But as others have said, there are now more friendly packages containing the svn stuff - VisualSVN Server (so badly named it makes me weep) and the Collabnet distribution - the later is Apache only, and is hand rolled on the thighs of virgins, which means that it always seems to appear about three weeks later than everyone else. ","pontos":1},{"corpo":"The latest CTP is CTP2 released on 05/02/08 and can be found here. Remoting requires WinRM to be installed on both the calling machine and the target machine. Included in the CTP is a script to configure WS-Management called Configure-WSMan.ps1. This command should get you the version number of PowerShell that you have installed. Get-Command \"$PSHome\\powershell.exe\" | Format-List FileVersionInfo V1.0 is 6.0.5430.0 CTP2 is 6.1.6585.1 I don't have the version number for the first CTP on hand, but I can find it if you really need it. ","pontos":1},{"corpo":"Yes - MVC doesn't utilize the ASP.NET view state junk. ","pontos":2},{"corpo":"An SVN server doesn't really 'attach' to a repository, it just needs to be able to see its files. The repository itself doesn't know or care if it's being accessed via svnserve, Apache mod_svn or direct file:// URLs ","pontos":3},{"corpo":" undefined wrote: this table will be hit pretty hard, especially if I am going to be sending out emails to remind people of their events (events can be for specific times of the day also!), so I could be polling this table every 15 minutes potentially! Create a table for the notifications. Poll only it. Update the notification table when events (recurring or otherwise) are updated. EDIT: A database View might not violate normal forms, if that's a concern. But, you'll probably want to track which notifications were sent and which have not yet been sent somewhere anyway. ","pontos":0},{"corpo":"If you're going to do this, spend a bit of money and at the least buy a dedicated router/firewall with a separate DMZ port. You'll want to firewall off your internal network from your server so that when (not if!) your web server is compromised, your internal network isn't immediately vulnerable as well. ","pontos":1},{"corpo":"From the experience I've had, the .NET DataTables and TableAdapters work better with DBNull. It also opens up a few special methods when strongly typed, such as DataRow.IsFirstNameNull when in place. I wish I could give you a better technical answer than that, but for me the bottom line is use DBNull when working with the database related objects and then use a \"standard\" null when I'm dealing with objects and .NET related code. ","pontos":3},{"corpo":"Use . We encouintered some sort of problems when using null. If I recall correctly you cannot INSERT a null value to a field, only DBNull. Could be Oracle related only, sorry, I do not know the details anymore. ","pontos":1},{"corpo":"I'm responsible for a large reporting system and we track the slowest reports kind of like that. I fire a unique key into the db when the report starts and then when it finishes I can determine how long it took. I'm using the database because that way I can detect when pages timeout (which happens a lot more than I'd like) ","pontos":0},{"corpo":"One reasonable technique that can easily be pulled off the shelf is caching. A vast amount of time tends to go into generating resources for clients that are common between requests (and even across clients); eliminating this runtime work can lead to dramatic speed increases. You can dump the generated resource (or resource fragment) into a file outside the web tree, and then read it back in when needed. Obviously, some profiling will be needed to ensure this is actually faster than regeneration - forcing the web server back to disk regularly can be detrimental, so the resource really does need to have heavy reuse. You might also be surprised how much time is spent inside badly written database queries; time common generated queries and see if they can be rewritten. The amount of time spent executing actual PHP code is generally pretty limited, unless you're using some sub-optimal algorithms. Neither of these are limited to PHP, though some of the PHP \"magicy\" approaches/functions can over-protect one from thinking about these concerns. For example, I recently updated a script that was using array_search to use a binary search over a sorted array, and gained the expected exponential speedup. ","pontos":4},{"corpo":"The best answer I have ever heard about using the provided type aliases in C# comes from Jeffrey Richter in his book CLR Via C#. Here are his 3 reasons: I've seen a number of developers confused, not knowing whether to use string or String in their code. Because in C# the string (a keyword) maps exactly to System.String (an FCL type), there is no difference and either can be used. In C#, long maps to System.Int64, but in a different programming language, long could map to an Int16 or Int32. In fact, C++/CLI does in fact treat long as an Int32. Someone reading source code in one language could easily misinterpret the code's intention if he or she were used to programming in a different programming language. In fact, most languages won't even treat long as a keyword and won't compile code that uses it. The FCL has many methods that have type names as part of their method names. For example, the BinaryReader type offers methods such as ReadBoolean, ReadInt32, ReadSingle, and so on, and the System.Convert type offers methods such as ToBoolean, ToInt32, ToSingle, and so on. Although it's legal to write the following code, the line with float feels very unnatural to me, and it's not obvious that the line is correct: BinaryReader br = new BinaryReader(...); float val = br.ReadSingle(); // Ok, but feels unnatural Single val = br.ReadSingle(); // OK and feels good So there you have it. I think these are all really good points. I however, don't find myself using Jeffrey's advice in my own code. Maybe I am too stuck in my C# world but I end up trying to make my code look like the framework code. ","pontos":197},{"corpo":"This was pretty much what I was doing, the problem I was getting was that my UI was getting locked up. As you suggested what I was doing already, I presumed the problem was somewhere else so I used the old divide and conquer to narrow down the problem and it wasnt the actual update code, it was my attempt to Dispatch a request to update my progress bar during the upload stream code. Thanks for the advice. ","pontos":0},{"corpo":"When \"waiting for lock on repository\", delete the repository file: .hg/store/lock When deleting the lock file, you must make sure nothing else is accessing the repository. (If the lock is a string of zeros, this is almost certainly true). ","pontos":214},{"corpo":"You could go out and buy a bunch of books and start reading them and quickly get overwhelmed in the seemingly massive learning curve it takes to go from nowhere, which is where it appears you are, to a rich internet entrepreneur, which is where you want to be. Alternatively, and what I would suggest is, you could define a problem you want to solve, and then go about finding the solution to that problem. Start with something small. \"I have a problem: I don't have a web site about myself.\". Define what you need to do to solve that problem, learn the basics, and do it. Then, define a new problem, which probably relies on the solution to the first problem, find what you need to do, and do it. This is how all technology professionals evolve. My first website was a personal site with nothing but text. Then I added some jokes and some movie quotes. Then I got tired of man-handling all the updates to I learned how to put them into a database and retrieve them from the database for display. It goes on and on. Call me when you've got more money from your financial windfall than you know what to do with. ","pontos":2},{"corpo":"I know this might sound a little arcanine but why not just stat the directory that contains the database. ","pontos":0},{"corpo":"Source: http://searchsqlserver.techtarget.com/tip/0,289483,sid87_gci1313431,00.html Works with SQL2000,2005,2008 USE master; GO IF OBJECT_ID('dbo.sp_SDS', 'P') IS NOT NULL DROP PROCEDURE dbo.sp_SDS; GO CREATE PROCEDURE dbo.sp_SDS @TargetDatabase sysname = NULL, -- NULL: all dbs @Level varchar(10) = 'Database', -- or \"File\" @UpdateUsage bit = 0, -- default no update @Unit char(2) = 'MB' -- Megabytes, Kilobytes or Gigabytes AS /************************************************************************************************** ** ** author: Richard Ding ** date: 4/8/2008 ** usage: list db size AND path w/o SUMmary ** test code: sp_SDS -- default behavior ** sp_SDS 'maAster' ** sp_SDS NULL, NULL, 0 ** sp_SDS NULL, 'file', 1, 'GB' ** sp_SDS 'Test_snapshot', 'Database', 1 ** sp_SDS 'Test', 'File', 0, 'kb' ** sp_SDS 'pfaids', 'Database', 0, 'gb' ** sp_SDS 'tempdb', NULL, 1, 'kb' ** **************************************************************************************************/ SET NOCOUNT ON; IF @TargetDatabase IS NOT NULL AND DB_ID(@TargetDatabase) IS NULL BEGIN RAISERROR(15010, -1, -1, @TargetDatabase); RETURN (-1) END IF OBJECT_ID('tempdb.dbo.##Tbl_CombinedInfo', 'U') IS NOT NULL DROP TABLE dbo.##Tbl_CombinedInfo; IF OBJECT_ID('tempdb.dbo.##Tbl_DbFileStats', 'U') IS NOT NULL DROP TABLE dbo.##Tbl_DbFileStats; IF OBJECT_ID('tempdb.dbo.##Tbl_ValidDbs', 'U') IS NOT NULL DROP TABLE dbo.##Tbl_ValidDbs; IF OBJECT_ID('tempdb.dbo.##Tbl_Logs', 'U') IS NOT NULL DROP TABLE dbo.##Tbl_Logs; CREATE TABLE dbo.##Tbl_CombinedInfo ( DatabaseName sysname NULL, [type] VARCHAR(10) NULL, LogicalName sysname NULL, T dec(10, 2) NULL, U dec(10, 2) NULL, [U(%)] dec(5, 2) NULL, F dec(10, 2) NULL, [F(%)] dec(5, 2) NULL, PhysicalName sysname NULL ); CREATE TABLE dbo.##Tbl_DbFileStats ( Id int identity, DatabaseName sysname NULL, FileId int NULL, FileGroup int NULL, TotalExtents bigint NULL, UsedExtents bigint NULL, Name sysname NULL, FileName varchar(255) NULL ); CREATE TABLE dbo.##Tbl_ValidDbs ( Id int identity, Dbname sysname NULL ); CREATE TABLE dbo.##Tbl_Logs ( DatabaseName sysname NULL, LogSize dec (10, 2) NULL, LogSpaceUsedPercent dec (5, 2) NULL, Status int NULL ); DECLARE @Ver varchar(10), @DatabaseName sysname, @Ident_last int, @String varchar(2000), @BaseString varchar(2000); SELECT @DatabaseName = '', @Ident_last = 0, @String = '', @Ver = CASE WHEN @@VERSION LIKE '%9.0%' THEN 'SQL 2005' WHEN @@VERSION LIKE '%8.0%' THEN 'SQL 2000' WHEN @@VERSION LIKE '%10.0%' THEN 'SQL 2008' END; SELECT @BaseString = ' SELECT DB_NAME(), ' + CASE WHEN @Ver = 'SQL 2000' THEN 'CASE WHEN status 0x40 = 0x40 THEN ''Log'' ELSE ''Data'' END' ELSE ' CASE type WHEN 0 THEN ''Data'' WHEN 1 THEN ''Log'' WHEN 4 THEN ''Full-text'' ELSE ''reserved'' END' END + ', name, ' + CASE WHEN @Ver = 'SQL 2000' THEN 'filename' ELSE 'physical_name' END + ', size*8.0/1024.0 FROM ' + CASE WHEN @Ver = 'SQL 2000' THEN 'sysfiles' ELSE 'sys.database_files' END + ' WHERE ' + CASE WHEN @Ver = 'SQL 2000' THEN ' HAS_DBACCESS(DB_NAME()) = 1' ELSE 'state_desc = ''ONLINE''' END + ''; SELECT @String = 'INSERT INTO dbo.##Tbl_ValidDbs SELECT name FROM ' + CASE WHEN @Ver = 'SQL 2000' THEN 'master.dbo.sysdatabases' WHEN @Ver IN ('SQL 2005', 'SQL 2008') THEN 'master.sys.databases' END + ' WHERE HAS_DBACCESS(name) = 1 ORDER BY name ASC'; EXEC (@String); INSERT INTO dbo.##Tbl_Logs EXEC ('DBCC SQLPERF (LOGSPACE) WITH NO_INFOMSGS'); -- For data part IF @TargetDatabase IS NOT NULL BEGIN SELECT @DatabaseName = @TargetDatabase; IF @UpdateUsage 0 AND DATABASEPROPERTYEX (@DatabaseName,'Status') = 'ONLINE' AND DATABASEPROPERTYEX (@DatabaseName, 'Updateability') 'READ_ONLY' BEGIN SELECT @String = 'USE [' + @DatabaseName + '] DBCC UPDATEUSAGE (0)'; PRINT '*** ' + @String + ' *** '; EXEC (@String); PRINT ''; END SELECT @String = 'INSERT INTO dbo.##Tbl_CombinedInfo (DatabaseName, type, LogicalName, PhysicalName, T) ' + @BaseString; INSERT INTO dbo.##Tbl_DbFileStats (FileId, FileGroup, TotalExtents, UsedExtents, Name, FileName) EXEC ('USE [' + @DatabaseName + '] DBCC SHOWFILESTATS WITH NO_INFOMSGS'); EXEC ('USE [' + @DatabaseName + '] ' + @String); UPDATE dbo.##Tbl_DbFileStats SET DatabaseName = @DatabaseName; END ELSE BEGIN WHILE 1 = 1 BEGIN SELECT TOP 1 @DatabaseName = Dbname FROM dbo.##Tbl_ValidDbs WHERE Dbname @DatabaseName ORDER BY Dbname ASC; IF @@ROWCOUNT = 0 BREAK; IF @UpdateUsage 0 AND DATABASEPROPERTYEX (@DatabaseName, 'Status') = 'ONLINE' AND DATABASEPROPERTYEX (@DatabaseName, 'Updateability') 'READ_ONLY' BEGIN SELECT @String = 'DBCC UPDATEUSAGE (''' + @DatabaseName + ''') '; PRINT '*** ' + @String + '*** '; EXEC (@String); PRINT ''; END SELECT @Ident_last = ISNULL(MAX(Id), 0) FROM dbo.##Tbl_DbFileStats; SELECT @String = 'INSERT INTO dbo.##Tbl_CombinedInfo (DatabaseName, type, LogicalName, PhysicalName, T) ' + @BaseString; EXEC ('USE [' + @DatabaseName + '] ' + @String); INSERT INTO dbo.##Tbl_DbFileStats (FileId, FileGroup, TotalExtents, UsedExtents, Name, FileName) EXEC ('USE [' + @DatabaseName + '] DBCC SHOWFILESTATS WITH NO_INFOMSGS'); UPDATE dbo.##Tbl_DbFileStats SET DatabaseName = @DatabaseName WHERE Id BETWEEN @Ident_last + 1 AND @@IDENTITY; END END -- set used size for data files, do not change total obtained from sys.database_files as it has for log files UPDATE dbo.##Tbl_CombinedInfo SET U = s.UsedExtents*8*8/1024.0 FROM dbo.##Tbl_CombinedInfo t JOIN dbo.##Tbl_DbFileStats s ON t.LogicalName = s.Name AND s.DatabaseName = t.DatabaseName; -- set used size and % values for log files: UPDATE dbo.##Tbl_CombinedInfo SET [U(%)] = LogSpaceUsedPercent, U = T * LogSpaceUsedPercent/100.0 FROM dbo.##Tbl_CombinedInfo t JOIN dbo.##Tbl_Logs l ON l.DatabaseName = t.DatabaseName WHERE t.type = 'Log'; UPDATE dbo.##Tbl_CombinedInfo SET F = T - U, [U(%)] = U*100.0/T; UPDATE dbo.##Tbl_CombinedInfo SET [F(%)] = F*100.0/T; IF UPPER(ISNULL(@Level, 'DATABASE')) = 'FILE' BEGIN IF @Unit = 'KB' UPDATE dbo.##Tbl_CombinedInfo SET T = T * 1024, U = U * 1024, F = F * 1024; IF @Unit = 'GB' UPDATE dbo.##Tbl_CombinedInfo SET T = T / 1024, U = U / 1024, F = F / 1024; SELECT DatabaseName AS 'Database', type AS 'Type', LogicalName, T AS 'Total', U AS 'Used', [U(%)] AS 'Used (%)', F AS 'Free', [F(%)] AS 'Free (%)', PhysicalName FROM dbo.##Tbl_CombinedInfo WHERE DatabaseName LIKE ISNULL(@TargetDatabase, '%') ORDER BY DatabaseName ASC, type ASC; SELECT CASE WHEN @Unit = 'GB' THEN 'GB' WHEN @Unit = 'KB' THEN 'KB' ELSE 'MB' END AS 'SUM', SUM (T) AS 'TOTAL', SUM (U) AS 'USED', SUM (F) AS 'FREE' FROM dbo.##Tbl_CombinedInfo; END IF UPPER(ISNULL(@Level, 'DATABASE')) = 'DATABASE' BEGIN DECLARE @Tbl_Final TABLE ( DatabaseName sysname NULL, TOTAL dec (10, 2), [=] char(1), used dec (10, 2), [used (%)] dec (5, 2), [+] char(1), free dec (10, 2), [free (%)] dec (5, 2), [==] char(2), Data dec (10, 2), Data_Used dec (10, 2), [Data_Used (%)] dec (5, 2), Data_Free dec (10, 2), [Data_Free (%)] dec (5, 2), [++] char(2), Log dec (10, 2), Log_Used dec (10, 2), [Log_Used (%)] dec (5, 2), Log_Free dec (10, 2), [Log_Free (%)] dec (5, 2) ); INSERT INTO @Tbl_Final SELECT x.DatabaseName, x.Data + y.Log AS 'TOTAL', '=' AS '=', x.Data_Used + y.Log_Used AS 'U', (x.Data_Used + y.Log_Used)*100.0 / (x.Data + y.Log) AS 'U(%)', '+' AS '+', x.Data_Free + y.Log_Free AS 'F', (x.Data_Free + y.Log_Free)*100.0 / (x.Data + y.Log) AS 'F(%)', '==' AS '==', x.Data, x.Data_Used, x.Data_Used*100/x.Data AS 'D_U(%)', x.Data_Free, x.Data_Free*100/x.Data AS 'D_F(%)', '++' AS '++', y.Log, y.Log_Used, y.Log_Used*100/y.Log AS 'L_U(%)', y.Log_Free, y.Log_Free*100/y.Log AS 'L_F(%)' FROM ( SELECT d.DatabaseName, SUM(d.T) AS 'Data', SUM(d.U) AS 'Data_Used', SUM(d.F) AS 'Data_Free' FROM dbo.##Tbl_CombinedInfo d WHERE d.type = 'Data' GROUP BY d.DatabaseName ) AS x JOIN ( SELECT l.DatabaseName, SUM(l.T) AS 'Log', SUM(l.U) AS 'Log_Used', SUM(l.F) AS 'Log_Free' FROM dbo.##Tbl_CombinedInfo l WHERE l.type = 'Log' GROUP BY l.DatabaseName ) AS y ON x.DatabaseName = y.DatabaseName; IF @Unit = 'KB' UPDATE @Tbl_Final SET TOTAL = TOTAL * 1024, used = used * 1024, free = free * 1024, Data = Data * 1024, Data_Used = Data_Used * 1024, Data_Free = Data_Free * 1024, Log = Log * 1024, Log_Used = Log_Used * 1024, Log_Free = Log_Free * 1024; IF @Unit = 'GB' UPDATE @Tbl_Final SET TOTAL = TOTAL / 1024, used = used / 1024, free = free / 1024, Data = Data / 1024, Data_Used = Data_Used / 1024, Data_Free = Data_Free / 1024, Log = Log / 1024, Log_Used = Log_Used / 1024, Log_Free = Log_Free / 1024; DECLARE @GrantTotal dec(11, 2); SELECT @GrantTotal = SUM(TOTAL) FROM @Tbl_Final; SELECT CONVERT(dec(10, 2), TOTAL*100.0/@GrantTotal) AS 'WEIGHT (%)', DatabaseName AS 'DATABASE', CONVERT(VARCHAR(12), used) + ' (' + CONVERT(VARCHAR(12), [used (%)]) + ' %)' AS 'USED (%)', [+], CONVERT(VARCHAR(12), free) + ' (' + CONVERT(VARCHAR(12), [free (%)]) + ' %)' AS 'FREE (%)', [=], TOTAL, [=], CONVERT(VARCHAR(12), Data) + ' (' + CONVERT(VARCHAR(12), Data_Used) + ', ' + CONVERT(VARCHAR(12), [Data_Used (%)]) + '%)' AS 'DATA (used, %)', [+], CONVERT(VARCHAR(12), Log) + ' (' + CONVERT(VARCHAR(12), Log_Used) + ', ' + CONVERT(VARCHAR(12), [Log_Used (%)]) + '%)' AS 'LOG (used, %)' FROM @Tbl_Final WHERE DatabaseName LIKE ISNULL(@TargetDatabase, '%') ORDER BY DatabaseName ASC; IF @TargetDatabase IS NULL SELECT CASE WHEN @Unit = 'GB' THEN 'GB' WHEN @Unit = 'KB' THEN 'KB' ELSE 'MB' END AS 'SUM', SUM (used) AS 'USED', SUM (free) AS 'FREE', SUM (TOTAL) AS 'TOTAL', SUM (Data) AS 'DATA', SUM (Log) AS 'LOG' FROM @Tbl_Final; END RETURN (0) GO ","pontos":6},{"corpo":"You might also want to consider selecting into a temporary table and then performing queries on that temporary table. This would avoid the need to rejoin your tables for every single query you issue (assuming that you can use the temporary table for numerous queries, of course). This basically gives you denormalized data, but if you are only doing select calls, there's no concern about data consistency. ","pontos":0},{"corpo":"Unfortunately I'm usually stuck using notepad. ","pontos":2},{"corpo":"I agree that you should definitely put this logic behind the clean interface of: public String lookupDays(String group, String date); but maybe you should stick the data in a properties file. I'm not against hardcoding this data in your source files but, as you noticed, Java can be pretty wordy when it comes to nested Collections. Your file might looks like: A.Summer=M A.Spring=tTS B.Summer=T Usually I don't like to move static data like this to an external file because it increases the \"distance\" between the data and the code that uses it. However, whenever you're dealing with nested Collections, especially maps, things can get real ugly, real fast. If you don't like this idea, maybe you can do something like this: public class WaterScheduler { private static final Map String, String GROUP2SEASON = new HashMap String, String (); static { addEntry(\"A\", \"Summer\", \"M\"); addEntry(\"A\", \"Spring\", \"tTS\"); addEntry(\"B\", \"Summer\", \"T\"); } private static void addEntry(String group, String season, String value) { GROUP2SEASON.put(group + \".\" + season, value); } } You lose some readability but at least the data is closer to where it's going to be used. ","pontos":0},{"corpo":"I'm totally at a loss as to why some of you seem to think that throwing gobs of objects at the code is the way to go. For example, there are exactly four seasons, and they don't do or store anything. How does it simplify anything to make them objects? Wing is quite right that these should probably be constants (or maybe enums). What Bruce needs, at it's heart, is simply a lookup table. He doesn't need a hierarchy of objects and interfaces; he needs a way to look up a schedule based on a season and a group identifier. Turning things into objects only makes sense if they have responsibilities or state. If they have neither, then they are simply identifiers, and building special objects for them just makes the codebase larger. You could build, e.g., objects that each contain a set of schedule strings (one for each season), but if all the object does is provide lookup functionality, then you've reinvented the lookup table in a much less intuitive fashion. If he has to look up the group, and then lookup the schedule, all he has is a two-step lookup table that took longer to code, is more likely to be buggy, and will be harder to maintain. ","pontos":1},{"corpo":"Depending on how much of your PHP code is actually executed and how long that execution takes they can be a really big win. It certainly isn't going to hurt, but the gain you see will very much depend on where your time is currently spent. btw mmcache has been rolled into a different project now, I forget the name but Google will tell you. ","pontos":1},{"corpo":"I get the same problem after there's been an active connection sitting idle for a while. I solve it by restarting sql developer every once in a while. I also have Toad for Oracle running on a vmware XP session, and it works great. If you don't mind the money, try that. ","pontos":1},{"corpo":"It may have been obfuscated by tools such as Xenocode or Dotfuscator. Or as someone said, Lutz may know a lot about IL. ","pontos":1},{"corpo":"The answer to this will vary depending on the database server you are using to do this. Edit: Sorry, maybe i need to learn to look at the tags and not just the question - i can see you tagged this as sqlserver. ","pontos":0},{"corpo":"I like the house address analogy, but I've always thought of the address being to the mailbox itself. This way you can visualize the concept of dereferencing the pointer (opening the mailbox). For instance following a linked list: 1) start with your paper with the address 2) Go to the address on the paper 3) Open the mailbox to find a new piece of paper with the next address on it In a linear linked list, the last mailbox has nothing in it (end of the list). In a circular linked list, the last mailbox has the address of the first mailbox in it. Note that step 3 is where the dereference occurs and where you'll crash or go wrong when the address is invalid. Assuming you could walk up to the mailbox of an invalid address, imagine that there's a black hole or something in there that turns the world inside out :) ","pontos":3},{"corpo":"That's the difference between block and inline elements. is a block level element. It's not legal to put it inside a tag, which can only contain inline content. Because browsers have to support whatever godawful tag soup they might find on the real web, Firefox tries to do what you mean. IE happens to handle it differently, which is fine by the spec; behavior in that case is unspecified, because it should never happen. Could you instead replace the element with the ? (Because of the block/inline issue, technically that should only work if the elements are inside an element with \"flow\" content, but the browsers might do what you want anyway.) Why is it a element in the first place, if you want 's behavior? You could also give the element 's whitespace preserving power with the CSS , but apparently IE 6 only honors that in Strict Mode. ","pontos":10},{"corpo":" That is how I have designed my events table actually, but when thinking about it, say I have 100K users who have create events, this table will be hit pretty hard, especially if I am going to be sending out emails to remind people of their events (events can be for specific times of the day also!), so I could be polling this table every 15 minutes potentially! Databases do exception jobs of handling sets of data, so i wouldn't be too worried about that. What you should do is use this as your primary table, and then as events expire then move them into another table (like an archive). The next thing is you want to try is to query the db as little as possible, so move the information into a caching tier (like velocity) and just persist data to the database. Then, you can partition the information across multiple databases for scaling purposes. ie users 1-10000 calendars exist on server 1, 10001 - 20000 exist on server 2, etc. That's how i would scale a solution like this, but i still think the original solution i proposed is the way to go, it's just how you scale it that becomes the question. ","pontos":0},{"corpo":"Which users and/or groups are in your \"Debug programs\" right (under User Rights Assignment)? Maybe that setting got overridden by group policy (Daniel's answer), or just got out of whack for some reason. It should, obviously, include the \"Debug Users\" group. ","pontos":2},{"corpo":" Darren wrote: I'd do a hybrid. I would use an object like this... Interesting idea... passing a serialized version of the object instead of the (wsdl-ed) object itself. In a way, I like its elegance, but in another way, it seems to defeat the purpose of exposing your web service to potential third parties or partners or whatever. How would they know what to pass? Would they have to rely purely on documentation? It also loses some of the \"heterogeneous client\" aspect, since the serialization is very .Net specific. I don't mean to be critical, I'm just wondering if what you're proposing is also meant for these types of use cases. I don't see anything wrong with using it in a closed environment though. I should look into WCF... I've been avoiding it, but maybe it's time. ","pontos":1},{"corpo":"yeah, ive been able to write a basic parser, based off that rfc and some other basic tutorials. but its the multipart mime nested boundaries that keep messing me up. i found out that MMS (not SMS) messages sent from my phone are just standard emails, so i have a system that reads the incoming email, checks the from (to only allow from my phone), and uses the body part to run different commands on my server. its sort of like a remote control by email. because the system is designed to send pictures, its got a bunch of differently encoded parts. a mms.smil.txt part, a text/plain (which is useless, just says 'this is a html message'), a application/smil part (which the part that phones would pic up on), a text/html part with a advertisement for my carrier, then my message, but all wrapped in html, then finally a textfile attachment with my plain message (which is the part i use) (if i shove an image as an attachment in the message, its put at attachment 1, base64 encoded, then my text portion is attached as attachment 2) i had it working with the exact mail format from my carrier, but when i ran a message from someone elses phone through it, it failed in a whole bunch of miserable ways. i have other projects i'd like to extend this phone->mail->parse->command system to, but i need to have a stable/solid/generic parser to get the different parts out of the mail to use it. my end goal would be to have a function that i could feed the raw piped mail into, and get back a big array with associative sub-arrays of headers var:val pairs, and one for the body text as a whole string the more and more i search on this, the more i find the same thing: giant overdeveloped mail handling packages that do everything under the sun thats related to mails, or useless (to me, in this project) tutorials. i think i'm going to have to bite the bullet and just carefully write something my self. ","pontos":0},{"corpo":"oh, for sure, i only do this when i'm the consumer of the webservice or if you have some sort of controller that they request an object from and then you handle the serialization and sending rather than them directly consuming the web service. But really, if they are directly consuming the webservice, then they wouldn't need or necessarily have the assembly that would have the type in it in the first place, and should be using the objects that wsdl generates. And yes, what i put forth is very .NET specific because i don't like to use anything else. The only other time i consume webservices outside of .net was in javascript, but now i only use json responses instead of xml webservice responses :) ","pontos":1},{"corpo":"Most PHP sites should have a file (I call it a header) that you include on every single page of the site. If you put that first line of code in the header file, then include it like this on every page: include 'header.php'; you won't have to use the global keyword or anything, the second line of code you wrote should work. Edit: Oh sorry, that won't work inside functions... now I see your problem. Edit #2: Ok, take my original advice with the header, but use a define() rather than a variable. Those work inside functions after being included. ","pontos":5},{"corpo":"I've done some work with the Wikimedia download sets, which are huge XML files. Unfortunately, their download server appears to be currently having disk space issues so many of the data sets aren't available. But when it's available, the entire English Wikipedia data set with full history is 2.8 TB (18 GB compressed). ","pontos":2},{"corpo":"Not sure. But will the Forest Extension work for you? ","pontos":1},{"corpo":"The only tool that I've ever encountered is the svn-graph.pl perl script from the svn tools. It spits out a graphviz dot file which can be rendered in a variety of image formats. This could be wrapped up in a cgi script to form a basic web graph tool. ","pontos":4},{"corpo":"In .NET the struct and class declarations differentiate between reference types and value types. When you pass round a reference type there is only one actually stored. All the code that accesses the instance is accessing the same one. When you pass round a value type each one is a copy. All the code is working on its own copy. This can be shown with an example: struct MyStruct { string MyProperty { get; set; } } void ChangeMyStruct(MyStruct input) { input.MyProperty = \"new value\"; } ... // Create value type MyStruct testStruct = new MyStruct { MyProperty = \"initial value\" }; ChangeMyStruct(testStruct); // Value of testStruct.MyProperty is still \"initial value\" // - the method changed a new copy of the structure. For a class this would be different class MyClass { string MyProperty { get; set; } } void ChangeMyClass(MyClass input) { input.MyProperty = \"new value\"; } ... // Create reference type MyClass testClass = new MyClass { MyProperty = \"initial value\" }; ChangeMyClass(testClass); // Value of testClass.MyProperty is now \"new value\" // - the method changed the instance passed. Classes can be nothing - the reference can point to a null. Structs are the actual value - they can be empty but never null. For this reason structs always have a default constructor with no parameters - they need a 'starting value'. ","pontos":13},{"corpo":"Boxing unboxing is the process of converting a primitive value into an object oriented wrapper class (boxing), or converting a value from an object oriented wrapper class back to the primitive value (unboxing). For example, in java, you may need to convert an value into an (boxing) if you want to store it in a because primitives can't be stored in a , only objects. But when you want to get it back out of the you may want to get the value as an and not an so you would unbox it. Boxing and unboxing is not inherently bad, but it is a tradeoff. Depending on the language implementation, it can be slower and more memory intensive than just using primitives. However, it may also allow you to use higher level data structures and achieve greater flexibility in your code. These days, it is most commonly discussed in the context of Java's (and other language's) \"autoboxing/autounboxing\" feature. Here is a java centric explanation of autoboxing. ","pontos":61},{"corpo":"In .Net: Often you can't rely on what the type of variable a function will consume, so you need to use an object variable which extends from the lowest common denominator - in .Net this is . However is a class and stores its contents as a reference. List int notBoxed = new List int { 1, 2, 3 }; int i = notBoxed[1]; // this is the actual value List object boxed = new List object { 1, 2, 3 }; int j = (int) boxed[1]; // this is an object that can be 'unboxed' to an int While both these hold the same information the second list is larger and slower. Each value in the second list is actually a reference to an that holds the . This is called boxed because the is wrapped by the . When its cast back the is unboxed - converted back to it's value. For value types (i.e. all ) this is slow, and potentially uses a lot more space. For reference types (i.e. all ) this is far less of a problem, as they are stored as a reference anyway. A further problem with a boxed value type is that it's not obvious that you're dealing with the box, rather than the value. When you compare two then you're comparing values, but when you compare two then (by default) you're comparing the reference - i.e. are these the same instance? This can be confusing when dealing with boxed value types: int a = 7; int b = 7; if(a == b) // Evaluates to true, because a and b have the same value object c = (object) 7; object d = (object) 7; if(c == d) // Evaluates to false, because c and d are different instances It's easy to work around: if(c.Equals(d)) // Evaluates to true because it calls the underlying int's equals if(((int) c) == ((int) d)) // Evaluates to true once the values are cast However it is another thing to be careful of when dealing with boxed values. ","pontos":18},{"corpo":" How do you know when you are 'done' capturing test cases? You don't.You can't get to 100% except for the most trivial cases. Also 100% coverage (of lines, paths, conditions...) doesn't tell you you've hit all boundary conditions. Most importantly, the test cases are not write-and-forget. Each time you find a bug, write an additional test. Check it fails with the original program, check it passes with the corrected program and add it to your test set. An excerpt from The Art of Software Testing by Glenford J. Myers: If an input condition specifies a range of values, write test cases for the ends of the range, and invalid-input test cases for situations just beyond the ends. If an input condition specifies a number of values, write test cases for the minimum and maximum number of values and one beneath and beyond these values. Use guideline 1 for each output condition. Use guideline 2 for each output condition. If the input or output of a program is an ordered set focus attention on the first and last elements of the set. In addition, use your ingenuity to search for other boundary conditions (I've only pasted the bare minimum for copyright reasons.) Points 3. and 4. above are very important. People tend to forget boundary conditions for the outputs. 5. is OK. 6. really doesn't help :-) Short exam This is more difficult than it looks. Myers offers this test: The program reads three integer values from an input dialog. The three values represent the lengths of the sides of a triangle. The program displays a message that states whether the triangle is scalene, isosceles, or equilateral. Remember that a scalene triangle is one where no two sides are equal, whereas an isosceles triangle has two equal sides, and an equilateral triangle has three sides of equal length. Moreover, the angles opposite the equal sides in an isosceles triangle also are equal (it also follows that the sides opposite equal angles in a triangle are equal), and all angles in an equilateral triangle are equal. Write your test cases. How many do you have? Myers asks 14 questions about your test set and reports that highly qualified professional programmes average 7.8 out of a possible 14. ","pontos":6},{"corpo":"This article \"Parameter passing in C#\" is the most complete explanation I've read so far. ","pontos":1},{"corpo":"The .NET FCL generic collections: List T Dictionary TKey, UValue SortedDictionary TKey, UValue Stack T Queue T LinkedList T were all designed to overcome the performance issues of boxing and unboxing in previous collection implementations. For more, see chapter 16, CLR via C# (2nd Edition). ","pontos":2},{"corpo":"Just a tip for syntax highlighting: Don't highlight the whole text view at once - it's very slow. Also don't highlight the last edited text using -editedRange - it's very slow too if the user pastes a large body of text into the text view. Instead you need to highlight the visible text which is done like this: NSRect visibleRect = [[[textView enclosingScrollView] contentView] documentVisibleRect]; NSRange visibleRange = [[textView layoutManager] glyphRangeForBoundingRect:visibleRect inTextContainer:[textView textContainer]]; Then you feed visibleRange to your highlighting code. ","pontos":10},{"corpo":"Are you using PHP5? If you define the __autoload() function and use a class with some constants, you can call them where you need them. The only aggravating thing about this is that you have to type something a little longer, like MyClass::MY_CONST The benefit is that if you ever decide to change the way that you handle new lines, you only have to change it in one place. Of course, a possible negative is that you're calling including an extra function (__autoload()), running that function (when you reference the class), which then loads another file (your class file). That might be more overhead than it's worth. If I may offer a suggestion, it would be avoiding this sort of echoing that requires echoing tags (like ). If you could set up something a little more template-esque, you could handle the nl's without having to explicitly type them. So instead of echo \"Blah Blah Blah\\n br / \\n\"; try: ?php if($condition) { ? p Blah blah blah br / /p ?php } ? It just seems to me like calling up classes or including variables within functions as well as out is a lot of work that doesn't need to be done, and, if at all possible, those sorts of situations are best avoided. ","pontos":1},{"corpo":"Instances of classes are stored on the managed heap. All variables 'containing' an instance are simply a reference to the instance on the heap. Passing an object to a method results in a copy of the reference being passed, not the object itself. Structures (technically, value types) are stored wherever they are used, much like a primitive type. The contents may be copied by the runtime at any time and without invoking a customised copy-constructor. Passing a value type to a method involves copying the entire value, again without invoking any customisable code. The distinction is made better by the C++/CLI names: \"ref class\" is a class as described first, \"value class\" is a class as described second. The keywords \"class\" and \"struct\" as used by C# are simply something that must be learned. ","pontos":14},{"corpo":"I used Zend Accelerator a little back in the day (2004-ish). It certainly gave some significant performance wins on code it could work with, but unfortunately the system I was using was designed to quite often dynamically load code and then eval it, which Zend Accelerator couldn't do much with at the time (and I'd guess still can't). On the down side, we certainly saw some caching issues (where the code would be changes, but the compiled version sync with the change for one reason or another). I imagine those problems have likely been ironed out by now. Anyway, I don't have any hard comparison numbers, and certainly didn't write the same system in different environments for comparison, but for the vast majority of systems, PHP isn't going to kill you performance wise. ","pontos":0},{"corpo":"One additional note about ref vs. out: The distinction between the two is enforced by the C# compiler. The CLR does not distinguish between between out and ref. This means that you cannot have two methods whose signatures differ only by an out or ref void foo(int value) {} // Only one of the following would be allowed // valid to overload with ref void foo(ref int value) {} // OR with out void foo(out int value) {} ","pontos":6},{"corpo":"PostgreSQL also supports indexing the results of a function: CREATE INDEX mytable_lower_col1_idx ON mytable (lower(col1)); The only other option I can think of is to de-normalize your data a bit by creating another column to hold the upper-case version (updated by triggers) and index that. Blech! ","pontos":0},{"corpo":"I wouldn't bother about that extra variable, really. If you want, though, you could also remove it from memory after you've used it: $variable = array('a','b','c'); echo $variable[$key]; unset($variable); Or, you could write a small function: function indexonce( $ar, $index) { return $ar[$index]; } and call this with: $something = indexonce(array('a', 'b', 'c'), 2); The array should be destroyed automatically now. ","pontos":13},{"corpo":"Just be aware that there currently is a bug if you call Html.RenderAction(..) on an Action that is marked to be cached. Instead of the specific action being cached, the entire page gets cached. I reported this on codeplex already and it seems to be a known issue: Calling % HTML.RenderAction ...>(...); %> to an Action with [OutputCache(..)] causes entire page to cache. ","pontos":1},{"corpo":"I just download the Emacs source from the GNU site and build it myself. I don't like too many Mac-specific features, because I want Emacs behavior to be consistent on all the platforms I use. ","pontos":3},{"corpo":"To debug in Visual Studio 2005, make sure that \"disable script debugging\" is unchecked. Then load your webpage in Internet Explorer. From the debug menu inside of Visual Studio 2005, select \"Attach to process\" and pick the instance of Internet Explorer that has your web page loaded. Alternatively, the Firebug team has been working on a \"lite\" version that you can include either as a script in your page or by launching it via a bookmarklet from your browser. It doesn't provide the full debugger that Firebug does, but it gives you a console and a command line from which you can inspect variables and log things to the console. ","pontos":5},{"corpo":"Even if you capture the keydown/keyup event, those are the only events that the tab key fires, you still need some way to prevent the default action, moving to the next item in the tab order, from occurring. In Firefox you can call the \"preventDefault()\" method on the event object passed to your event handler. In IE, you have to return false from the event handle. The JQuery library provides a preventDefault method on it's event object that works in IE and FF. body input type=\"text\" id=\"myInput\" script type=\"text/javascript\" var myInput = document.getElementById(\"myInput\"); if(myInput.addEventListener ) { myInput.addEventListener('keydown',this.keyHandler,false); } else if(myInput.attachEvent ) { myInput.attachEvent('onkeydown',this.keyHandler); /* damn IE hack */ } function keyHandler(e) { var TABKEY = 9; if(e.keyCode == TABKEY) { this.value += \" \"; if(e.preventDefault) { e.preventDefault(); } return false; } } /script /body ","pontos":52},{"corpo":"I'm not sure how to physically combine them into a single file, however you could employ abstraction of a sorts and just include a singe \"AllMyLibs.a/h\" which in turn includes everything you want. You could also put this into the location that your compiler searches for libraries, so it would work for any project. P.S. - Out of curiousity, why do you dislike including single libs? ","pontos":0},{"corpo":"The latest version of WinRAR still supports Windows 95. Think about it, why is that? It's because WinRAR solves a extremely common problem - of unpacking a file. People still use older systems not because they like them, but because they are forced to by the hardware. If you're making a video game, sure, drop support for anything below XP SP2, but if you're making a program that solves a specific task, like converting an RTF to PDF, I don't see a reason not to support other systems. ","pontos":1},{"corpo":"Don't do: try { // some code } catch (Exception ex) { throw ex; } As this will lose the stack trace. Instead do: try { // some code } catch (Exception ex) { throw; } Just the throw will do, you only need to pass the exception variable if you want it to be the inner exception on a new custom exception. ","pontos":2},{"corpo":"SVN is very difficult to get setup in the Windows environment, at least if you want hosted SVN, a local repository is different. My suggestion is stick with the company or search out a cheaper SVN that will not cost as much money. They are not difficult to setup, but you would hate to lose all your source code because of an improper backup. ","pontos":-7},{"corpo":"For simple security requirements, setting up Subversion with svnserve is almost trivial. Even getting it running under Apache for more extensive security needs is not overly difficult. This is a good walk-through: http://donie.homeip.net:8080/pebble/Steve/2006/02/27/1141079943879.html ","pontos":2},{"corpo":"A ThreadStateException is thrown because you're trying to start a thread that's not in a startable state. The most likely situations would be that it's already running, or that it has fully exited. There are potentially a couple things that might be happening. First is, the thread might have transitioned from Running to StopRequested, which isn't fully stopped yet, so your logic doesn't create a new thread, and you're trying to start a thread which has just finished running or is about to finish running (neither of which is a valid state for restarting). The other possibility is that the thread was aborted. Threads which are aborted go to the Aborted state, not the Stopped state, and of course are also not valid for restarting. Really, the only kind of thread that is still alive that can be \"restarted\" is one that's suspended. You might want to use this conditional instead: ","pontos":1},{"corpo":"It's possible for a thread to be in more than one state at once therefore the ThreadState property is actually a bitmap of possible states. So testing for equality with just one state will not give you the right result. You would need to do something like: if((mThread.ThreadState ThreadState.Running) != 0) However, checking thread state is the wrong to do anything. I'm not entirely clear what you're trying to achieve but I will guess that you're waiting for a thread to terminate before restarting it. In that case you should do: mThread.Join(); mThread = new Thread(new ParameterizedThreadStart(Monitor)); if(check) mThread.Start(60000); else mThread.Start(0); Although if you describe the problem you're trying to solve in more detail I'm almost certain there will be a better solution. Waiting around for a thread to end just to restart it again doesn't seem that efficient to me. Perhaps you just need some kind of inter-thread communication? John. ","pontos":6},{"corpo":"Are you sure the temporary file is being created correctly when running as a cron job? The working directory for your script will either be specified in the HOME environment variable, or the /etc/passwd entry for the user that installed the cron job. If deploy does not have write permissions for the directory in which it is executing, then you could specify an absolute path for the dump file to fix the problem. ","pontos":2},{"corpo":"We had been hacked from same guys apparently! Or bots, in our case. They used SQL injection in URL on some old classic ASP sites that nobody maintain anymore. We found attacking IPs and blocked them in IIS. Now we must refactor all old ASP. So, my advice is to take a look at IIS logs first, to find if problem is in your site's code or server configuration. ","pontos":0},{"corpo":"Some are not recognized, because the UserAgent has been messed with or a new browser is being used. Such as Opera Mobile 9.5. To fix this you need to create a Browser (*.browser) file specifically for defining this. I had to do it for the new Mozilla based UserAgent that is being sent from Google. ","pontos":2},{"corpo":"Wordpress has a field in the wp_posts table for the slug. When you create the post, it creates a slug from the post title (if that's how you have it configured), replacing spaces with dashes (or I think you can set it to underscores). It also takes out the apostrophes, commas, or whatnot. I believe it also limits the overall length of the slug, too. So, in short, it isn't dynamically decoding the URL into the post's title--there's a field in the table that matches the URL version of the post name directly. ","pontos":1},{"corpo":"The problem is that you have code that first checks if it should create a new thread object, and another piece of code that determines wether to start the thread object. Due to race conditions and similar things, your code might end up trying to call .Start on an existing thread object. Considering you don't post the details behind the check variable, it's impossible to know what might trigger this behavior. You should reorganize your code so that .Start is guaranteed to only be called on new objects. In short, you should put the Start method into the same if-statement as the one that creates a new thread object. Personally, I would try to reorganize the entire code so that I didn't need to create another thread, but wrap the code inside the thread object inside a loop so that the thread just keeps on going. ","pontos":3},{"corpo":"The definitions from the links to the two exceptions above are IllegalArgumentException: Thrown to indicate that a method has been passed an illegal or inappropriate argument. NullPointerException: Thrown when an application attempts to use null in a case where an object is required. The big difference here is the IllegalArgumentException is supposed to be used when checking that an argument to a method is valid. NullPointerException is supposed to be used whenever an object being \"used\" when it is null. I hope that helps put the two in perspective. ","pontos":-1},{"corpo":"A good way to look up error (hresult) codes is HResult Plus or welt.exe (Windows Error Lookup Tool). I use logging internally in the COM-classes to see what is going on. Also, once the COM-class is loaded by the executable, you can attach the VS debugger to it and debug the COM code with breakpoints, watches, and all that fun stuff. ","pontos":1},{"corpo":"I've really come to like Maven's Standard Directory Layout. One of the key ideas for me is to have two source roots - one for production code and one for test code like so: MyProject/src/main/java/com/acme/Widget.java MyProject/src/test/java/com/acme/WidgetTest.ava (here, both src/main/java and src/test/java are source roots). Advantages: Your tests have package (or \"default\") level access to your classes under test. You can easily package only your production sources into a JAR by dropping src/test/java as a source root. One rule of thumb about class placement and packages: Generally speaking, well structured projects will be free of circular dependencies. Learn when they are bad (and when they are not), and consider a tool like JDepend or SonarJ that will help you eliminate them. ","pontos":12},{"corpo":"It depends on how far you want to consider this issue. If you want to install a Subversion server on your own, it looks like you have two options: Apache Subversions own protocol In either case, the problem isn't what the two do, but what the two unintentionally do. If there are bugs in Apache that allows an outside attacker to gain access to your data, then that is bad. If there are bugs in Subversions own server that allows the same, that is bad. What you need to do is consider risk and consequences for the scenarios, and come up with a server setup that meets your requirements, if possible. The cases you would at least have to consider would be: Bug in either system that allows an attacker to sink your server (example: something which makes your server use an inordinate amount of CPU time) Bug in either system that allows an attacker access to the data on that server Bug in either system that allows an attacker access to your domain (ie. all your servers and machines available from that public server) Personally I have considered how many are hosting subversion servers through Apache now, and installed VisualSVN Server to host my own source code without a doubt. ","pontos":2},{"corpo":" Write a unit test Watch it fail, then make it pass Repeat until the problem is solved Seriously though, just keep adding layers of abstraction until things 'just work'. If I'm in over my head I just ask someone smarter than me how they would solve the problem. ","pontos":5},{"corpo":"I redefine over and over again. And again. Then I break it into the smallest chunks that I can. When coding I use many variables and don't do more than one step on a line. If I have to add five numbers and multiply then get a percentage I'll do each step on it's own line. Later on, after I know I've got it I will combine lines together, but not until I'm SURE that the problem is solved. This helps when debugging, too, since I can inspect each step to know it did what I wanted it to do. ","pontos":2},{"corpo":"I generally don't start coding right away. I break down the problem, and take notes on it until I get to a spot where I know what I need to do in terms of code. I use emacs org-mode files and occasionally pen-and-paper depending on the type of problem. Spending a bit thinking about the problem before I put any actual code down generally leads to me writing a much more elegant solution than I would have otherwise. ","pontos":1},{"corpo":"I'm not sure, if Derek's approach works. You haven't mark it as best answer yet. If not: with SQL Server 2005 it should be possible, I guess. There they introduced exceptions (which I've not used yet). So drop the table, catch the exception, if one occurs and try the next table till they are all gone. You can store the list of tables in a temp-table and use a cursor to traverse it, if you want to. ","pontos":0},{"corpo":"With respect to (1), most of the hard to debug errors are due to not closing open handles (Dispose() in managed-land). I'm curious where you heard (2). ","pontos":0},{"corpo":"I switch the computer off, get the rods out and spend a few hours fishing. It's an amazing activity for clearing your mind and worrying at those niggling problems. The best thing is, the fewer fish you catch the more problems you can work out! ","pontos":1},{"corpo":"Anecdotal evidence #1: I have used GDI+ for on-the-fly image creation within ASP.NET with no problems. I'm not sure what the problems would even be. ","pontos":1},{"corpo":"maybe these are things to consider too: do the annoying tasks first do not repeat yourself know when to stop review your code with a co-worker ","pontos":2},{"corpo":"To answer some of my own questions: The current team I'm on does only does gross task estimation, so it's hard to track hours per days. I would say that, for my career, the time spent coding has been anywhere between 25% (mostly management) to 85%+ (working from home 4 days a week, get together for a meeting for half a day once a week). If I had to guess, though, the average is probably somewhere in the vicinity of 60%. The biggest influence for me in time spent coding is the presence or absence of meetings. When I worked on agile projects with everybody in the same room, meetings tended to be ad-hoc and very short, so the time spent coding was very high. I also felt I spent less time -- sometimes a lot less time -- doing non-coding things when I was in a team room, because it's much easier to waste time, accidentally or otherwise, when nobody has a clear view of your monitor. :) ","pontos":2},{"corpo":"Well, what if one of your clients tells you to restore to an earlier version of their data due to some botched import job or similar? Imagine how your clients would feel if you told them \"you can't do that, since your data is shared between all our clients\" or \"Sorry, but your changes were lost because client X demanded a restore of the database\". ","pontos":7},{"corpo":"It's annoying when I drag a window to another monitor, and then if the application generates a popup dialog, or spawns another window, if that popup/dialog gets displayed back on the primary monitor. I haven't developed for multi-monitors, but I think this can be better handled if you position child windows/dialogs centered on their parent window, rather than on the desktop center (which I'm guessing is what happens in the case I describe above). ","pontos":4},{"corpo":"If the locked repo was the original, I can't imagine it was modifying it to clone it, so it was only preventing you from changing it in the middle and messing up the clone. It should be fine after removing the lock. The new cloned copy (if it was a local clone) could be in any sort of malformed state, though, so you should throw it out and start it over. (If it was a remote clone, I would hope it failed and already threw out the incomplete copy.) ","pontos":2},{"corpo":"As a general rule, I would say overriding the standard behavior of the TAB key would be a bad idea. Maybe you can do something like disabling the 3rd text box until a valid entry is made in the 2nd text box. Now, having said this, I've also broken this rule at the request of the customer. We made the enter key function like the tab key, where the enter key would save the value in a text field, and advance the cursor to the next field. ","pontos":3},{"corpo":"Before: Read everything you can find about the problem domain. Don't skip topics that you think won't be relevant. Repeat step 1 and 2. During: Split large problems into the smaller tasks. Define your fitness criteria (write the tests). Ater: Do a post-mortem of the solution/project. Try new languages, learn new techniques. Practise, practise, practise. ","pontos":0},{"corpo":"I'm not 100% sure if this is what you are looking for but you should check out the VisualStyleRenderer in the System.Windows.Forms.VisualStyles-namespace. VisualStyleRenderer class (MSDN) How to: Render a Visual Style Element (MSDN) VisualStyleElement.ComboBox.DropDownButton.Disabled (MSDN) Since VisualStyleRenderer won't work if the user don't have visual styles enabled (he/she might be running 'classic mode' or an operative system prior to Windows XP) you should always have a fallback to the ControlPaint class. // Create the renderer. if (VisualStyleInformation.IsSupportedByOS VisualStyleInformation.IsEnabledByUser) { renderer = new VisualStyleRenderer( VisualStyleElement.ComboBox.DropDownButton.Disabled); } and then do like this when drawing: if(renderer != null) { // Use visual style renderer. } else { // Use ControlPaint renderer. } Hope it helps! ","pontos":7},{"corpo":" Avoid creating links within long blocks of text. Prefer shorter text that can act as a logically complete and independent link. Generally, it will lead to fewer problems. Sometimes you have to compromise your UI design to accommodate localization; sometimes you need to compromise your localization process to accommodate the UI. Any time a developer manually manipulates post-translation strings is a source of potentially expensive bugs. Cutting/pasting or string editing can result in character corruption, misplaced strings, etc. A translation defect needs the participation of outside parties to fix which involves cost and takes time. Thinking on it, something like this might be less ugly: p Please update your address and contact information. br / a href=\"/address.do\" update address /a br / a href=\"/contact.do\" update contact information /a /p ...but I'm no UI designer. ","pontos":2},{"corpo":"I had to use a CSV parser in .NET for a project this summer and settled on the Microsoft Jet Text Driver. You specify a folder using a connection string, then query a file using a SQL Select statement. You can specify strong types using a schema.ini file. I didn't do this at first, but then I was getting bad results where the type of the data wasn't immediately apparent, such as IP numbers or an entry like \"XYQ 3.9 SP1\". One limitation I ran into is that it cannot handle column names above 64 characters; it truncates. This shouldn't be a problem, except I was dealing with very poorly designed input data. It returns an ADO.NET DataSet. This was the best solution I found. I would be wary of rolling my own CSV parser, since I would probably miss some of the end cases, and I didn't find any other free CSV parsing packages for .NET out there. EDIT: Also, there can only be one schema.ini file per directory, so I dynamically appended to it to strongly type the needed columns. It will only strongly-type the columns specified, and infer for any unspecified field. I really appreciated this, as I was dealing with importing a fluid 70+ column CSV and didn't want to specify each column, only the misbehaving ones. ","pontos":0},{"corpo":"I'm going to have to a give a nod in dbkk's direction as they captured a couple of the major points that you need to remember. Also, I would suggestion paying attention to how you use dual monitors and try to keep that in mind as you are developing. Generally you should try to avoid doing the things that applications you work do that annoy you. Also, don't assume that just because the user has dual monitors that they are going to want to work with your application on dual monitors. The biggest thing that I would stress is keeping track of where the focus is in the application and making sure that any pop-ups occur within that region, one of the things that people seem to dislike the most is having a window pop-up in a different window then the one they are working on. ","pontos":4},{"corpo":"I work a 37.5 hour week. 30 of those hours (80%) I am supposed to be billing our clients. In reality I find that I use about 60% coding on actual client systems, 20% experimenting with new techniques and reading blogs, and 20% is wasted on office politics and \"socializing\". Am I happy about it? Do I wish that I could stare at the screen 30 hours a week coding on my given assignments? Well. Since 20% of the time is used bettering myself at my craft, in the 60% that is effective coding I probably produce more than I would in 90% of my time if I didn't. Then again, try to explain that fact to the higher ups ;) ","pontos":4},{"corpo":"There are a couple of meanings of \"database\" the hardware box the running software (e.g. \"the oracle\") the particular set of data files the particular login or schema It's likely Joel means one of the lower layers. In this case, it's just a matter of software configuration management... you don't have to patch 1000 software servers to fix a security bug, for example. I think it's a good idea, so that a software bug doesn't leak information across clients. Imagine the case with an errant where clause that showed me your customer data as well as my own. ","pontos":0},{"corpo":"To keep it simple. You can be sure that your client is only seeing their data. The client with fewer records doesn't have to pay the penalty of having to compete with hundreds of thousands of records that may be in the database but not theirs. I don't care how well everything is indexed and optimized there will be queries that determine that they have to scan every record. ","pontos":10},{"corpo":"Small correction to Jedi: it's VisualSVN Server from http://www.visualsvn.com/server/ ","pontos":6},{"corpo":" Well, I generally come in at least fifteen minutes late, ah, I use the side door - that way Lumbergh can't see me, heh heh - and, uh, after that I just sorta space out for about an hour. ...Yeah, I just stare at my desk; but it looks like I'm working. I do that for probably another hour after lunch, too. I'd say in a given week I probably only do about fifteen minutes of real, actual, work. For me, switching between projects is a big cause of procrastination. When I've just finished a project I tend to procrastinate on kicking off the next requirement assigned to me. My mind feels still like in coding mode, but I then have to estimate the expenses for creating a spec first. So I have to switch from coding to calling customers and the like, which feels uncomfortable. What helps me most in being productive is to cut away any distraction in the first hours of the day and starting immediately with the day's most important task. I need to get into the flow as early as possible. I recommend having a look at The Programmers Stone: We know that stress impairs some cognitive functions. The loss of those functions can precisely explain why programming is hard, and show us many other opportunities to improve the ways we organize things. The consequences roll out to touch language, logic and cultural norms. Click here for the Introduction... ","pontos":6},{"corpo":"For me it depends upon what the problem is - if I am working on trying to solve a new problem, odds are the first thing I'm going to do is either find a white-board and start sketching out some concepts, or find a notepad and start sketching out some concepts. Usually, to solve a problem I first have to understand what the problem is and why it is a problem, once that is out of the way things move on to coding and the usual processes associated with coding. Debugging on the other hand, is an entirely different issue. When debugging I usually try and figure out what is going on in the code (i.e. step through it and watch variables), figure out what it is intended to be doing, and try to fix it. Usually, there is a \"step out of the room and get something to drink\" between each of those steps as well. One trick I have found with debugging is to try and stay calm, and if that doesn't work, ignore the problem for awhile and work on something else. Most of the time it takes longer to solve the problem though dedicated - stressed - work then it does by taking a break. ","pontos":0},{"corpo":"I am currently a full time freelancer working for a single client. If I want to get a full 40 hours of pay, then every minute I spend coding needs to be accounted for on the approved project plan. Or at least it has to go towards some sort of realistic maintenance task. I guess you could say this is one of the disadvantages of contracting... there's really no room for slack or being idle. You just have to keep going and going on the task at hand. It can be quite draining, but then again I kinda like how it keeps me accountable. And of course the pay is a bit better than usual. That said, I would love to have slack time available for working on pet projects, but no client would ever agree to pay for that. Anyway, I just thought I'd point out how this exemplifies some of the big differences between freelancing and full time employment. ","pontos":8},{"corpo":"Apache is a major pain to get running in Vista. And II7 (and 6) are suppose to run PHP fine. So why bother with Apache? ","pontos":0},{"corpo":"I would definitely choose SVN over CVS, if only because people who learned source control using CVS, tend to use \"\" then \"\" instead of \"\". Which makes it harder to find all of the previous revisions of a specific file. And you can always upgrade to using git-svn. I personally think it is easier to learn than hg, but really the main reason to use SVN is it has largely become the de-facto version control system of Open Source Software. If you ever plan on learning / using D it is almost mandatory to access the third party repositories, like DSource. ","pontos":0},{"corpo":"Please Please Please. If you remember window positions for multiple monitors. Please detect if the second monitor is connected. I have a laptop that is sometimes docked. It is very annoying when I try to open a window and it opens off screen. ","pontos":7},{"corpo":"Even if you don't branch, you may find it useful to use tags to mark releases. Imagine that you rolled out a new version of your software yesterday and have started making major changes for the next version. A user calls you to report a serious bug in yesterday's release. You can't just fix it and copy over the changes from your development trunk because the changes you've just made the whole thing unstable. If you had tagged the release, you could check out a working copy of it and use it to fix the bug. Then, you might choose to create a branch at the tag and check the bug fix into it. That way, you can fix more bugs on that release while you continue to upgrade the trunk. You can also merge those fixes into the trunk so that they'll be present in the next release. ","pontos":1},{"corpo":"I don't think it has any purpose. But because RegEx is almost impossible to understand/decompose, people rarely point out errors. That is probably why no one else pointed it out. ","pontos":1},{"corpo":"@Rob: I disagree. To enforce what you are asking for I think you would need to use negative-look-behind, which is possible but is certainly not related to use {1}. Neither version of the regexp address that particular issue. To let the code speak: tibook 0 /home/jj33/swap cat text Text this is http://example.com text this is Text this is http://http://example.com text this is tibook 0 /home/jj33/swap cat p #!/usr/bin/perl my $re1 = '((mailto\\:|(news|(ht|f)tp(s?))\\://){1}\\S+)'; my $re2 = '((mailto\\:|(news|(ht|f)tp(s?))\\://)\\S+)'; while ( ) { print \"Evaluating: $_\"; print \"re1 saw \\$1 = $1\\n\" if (/$re1/); print \"re2 saw \\$1 = $1\\n\" if (/$re2/); } tibook 0 /home/jj33/swap cat text | perl p Evaluating: Text this is http://example.com text this is re1 saw $1 = http://example.com re2 saw $1 = http://example.com Evaluating: Text this is http://http://example.com text this is re1 saw $1 = http://http://example.com re2 saw $1 = http://http://example.com tibook 0 /home/jj33/swap So, if there is a difference between the two versions, it's doesn't seem to be the one you suggest. ","pontos":3},{"corpo":"@Jeff Atwood, your interpretation is a little off - the {1} means match exactly once, but has no effect on the \"capturing\" - the capturing occurs because of the parens - the braces only specify the number of times the pattern must match the source - once, as you say. I agree with @Marius, even if his answer is a little terse and may come off as being flippant. Regular expressions are tough, if one's not used to using them, and the {1} in the question isn't quite error - in systems that support it, it does mean \"exactly one match\". In this sense, it doesn't really do anything. Unfortunately, contrary to a now-deleted post, it doesn't keep the regexp from matching , since the \\S+ at the end will match one or more non-whitespace characters, including the in (verified using Python 2.5, just in case my regexp reading was off). So, the regexp given isn't really the best. I'm not a URL expert, but probably something limiting the appearance of \":\"s and \"//\"s after the first one would be necessary (but hardly sufficient) to ensure good URLs. ","pontos":1},{"corpo":"I don't think the {1} has any valid function in that regex. (mailto\\:|(news|(ht|f)tp(s?))\\://){1} You should read this as: \"capture the stuff in the parens exactly one time\". But we don't really care about capturing this for use later, eg $1 in the replacement. So it's pointless. ","pontos":2},{"corpo":"from the RegexBuddy library: URL: Find in full text The final character class makes sure that if an URL is part of some text, punctuation such as a comma or full stop after the URL is not interpreted as part of the URL. ","pontos":8},{"corpo":"@Bernard Dy: I have spent probably 30% of my career in corporate settings (am not at the moment). Usually its after some failed (or not failed, but fizzled) start up idea, or some kind of burnout/change. Its ok for a little bit, it is nice to meet people from totally different backgrounds (who would have thought that lawyers and actuaries could be so much fun to hang out with), but in the end, I just find it too hard to get up in the morning with motivation (or after a holiday dread going back) - probably for reasons like you define (just a lack of care). But its good experience and a source of ideas at the least. And you can meet brilliant people everywhere (its not just programmers who are smart - I always tried to seek out who the real brains were behind a business). Interestingly the only time I have practiced strict agile/XP was in a corporate setting - in that case probably 7 hours a day was actual hands on code (in a pair) - I have never been so exhausted after a day of that. not sure if that is a good thing, perhaps I am just lazy. ","pontos":3},{"corpo":"At least for PCs, the fact that you dismiss an item does get sync'd, and fairly quickly for me. I'm not sure why phones don't seem to do it, though. Maybe the ActiveSync protocol doesn't offer that option. ","pontos":2},{"corpo":"I don't have an answer, but I feel your (and Joel's) pain every time my cell phone and my computer both buzz me within minutes of each other. ","pontos":2},{"corpo":"We just keep the production config file checked in. It's the developer's responsibility to change the file when they pull it out of source safe for staging or development. This has burnt us in the past so I wouldn't suggest it. ","pontos":0},{"corpo":"We have slack time and we try to schedule them between releases. Once a release is out, we ask our developers to spend 60% of the day fixing bugs and then the other 40% for slack time. We have policies on what you can use the slack time for though. Then when a release creeps up again, we ask all the developers to spend all day on implementing features or fixing bugs for that release. The policy lets the developer use the slack time for training, creating something new that the company could use, or just creating tools within the company to make things easier for ourselves. It has worked well for us. We think it is an awesome benefit. ","pontos":1},{"corpo":"Browser Sync is up on Google Code now. Doesn't look like anything has been done with it yet though, as far as making it hosted on personal servers/computers. ","pontos":1},{"corpo":"I'm not very experienced with such things, but I would assume that the initial compiler would have to be written in another language. I'm fairly certain that \"bootstrapping\", in reference to compilers, simply refers to writing a compiler for a language in the language it's meant to compile, not writing the first compiler for the language in the language it's meant to compile. ","pontos":-1},{"corpo":"Every example of bootstrapping a language I can think of (C, PyPy) was done after there was a working compiler. You have to start somewhere, and reimplementing a language in itself requires writing a compiler in another language first. How else would it work? I don't think it's even conceptually possible to do otherwise. ","pontos":1},{"corpo":"It's the computer science version of the chicken-and-egg paradox. I can't think of a way not to write the initial compiler in assembler or some other language. If it could have been done, I should Lisp could have done it. Actually, I think Lisp almost qualifies. Check out its Wikipedia entry. According to the article, the Lisp eval function could be implemented on an IBM 704 in machine code, with a complete compiler (written in Lisp itself) coming into being in 1962 at MIT. ","pontos":0},{"corpo":"A super interesting discussion of this is in Unix co-creator Ken Thompson's Turing Award lecture. He starts off with: What I am about to describe is one of many \"chicken and egg\" problems that arise when compilers are written in their own language. In this ease, I will use a specific example from the C compiler. and proceeds to show how he wrote a version of the Unix C compiler that would always allow him to log in without a password, because the C compiler would recognize the login program and add in special code. The second pattern is aimed at the C compiler. The replacement code is a Stage I self-reproducing program that inserts both Trojan horses into the compiler. This requires a learning phase as in the Stage II example. First we compile the modified source with the normal C compiler to produce a bugged binary. We install this binary as the official C. We can now remove the bugs from the source of the compiler and the new binary will reinsert the bugs whenever it is compiled. Of course, the login command will remain bugged with no trace in source anywhere. ","pontos":5},{"corpo":"Moving an application from one database to another isn't very common, but sooner or later you may find yourself working on another project using a different RDBMS. If you're at home with PDO then there will at least be one thing less to learn at that point. Apart from that I find the PDO API a little more intuitive, and it feels more truly object oriented. mysqli feels like it is just a procedural API that has been objectified, if you know what I mean. In short, I find PDO easier to work with, but that is of course subjective. ","pontos":57},{"corpo":"Yes, the problem is you have to build your application to profile it. At work we had a couple of projects written outside which we load-tested before putting them on our main boxes. We were quite surprised to find critical performance problems with both; one was written in CakePHP and the other was written using Drupal. I don't think this highlights a problem with any framework or CMS other than the need to do profiling and load-testing on any site which is going to get significant traffic. In both cases it was what the developer had done, rather than the characteristics of the software platform, that caused the problem. For example, there was a recursive function call the developer had created in the Cake project which instantiated the entire Cake object every recursion and this would have taken out the server had it gone live under load. In my opinion performance should not be a deciding factor in choosing a framework; the objective differences are likely to be marginal and the way you use it is likely to cause far more performance problems than the inherent performance of the framework. I believe that to scale any PHP application to run under load, you will need an opcode cache and you'll need to write in intelligent content caching using something like memcached or whatever built-in caching your framework supports. ","pontos":7},{"corpo":"it is the mvc futures project. i will probably try this http://forums.asp.net/t/1303328.aspx. I need to render menu with categories. ","pontos":1},{"corpo":"This is just personal opinion, but the problem I find with ready-made controls in cases like this is that they are extremely bloated, because they're trying to fit everybody's purpose. If all you need is a sortable list then a simple Scriptaculous list or jQuery list with a quick WebMethod callback should fit the bill quite nicely, and you can obviously stick this into your own user control. As I say, just my opinion, but I wouldn't go spending money on something that's going to add tons of overhead to my page, when I could spend (literally) 10 minutes writing one for free. ","pontos":2},{"corpo":"OffByOne. It's extremely small and fast, but only supports HTML 3.2. It's buggy, doesn't support Javascript or CSS, and downloading is very hampered, but I use it when I just want to view a page for it's text, and I want to do it as fast as I can. ","pontos":1},{"corpo":"http://www.fox-toolkit.org has an API reference, if you're looking how to work with a specific framework. Or were you more interested in general theory or something more along the lines of how to do the low-level stuff yourself? ","pontos":1},{"corpo":"Another alternative is to create a bytecode machine for your language (or use an existing one if it's features aren't very unusual) and write a compiler to bytecode, either in the bytecode, or in your desired language using another intermediate - such as a parser toolkit which outputs the AST as XML, then compile the XML to bytecode using XSLT (or another pattern matching language and tree-based representation). It doesn't remove the dependency on another language, but could mean that more of the bootstrapping work ends up in the final system. ","pontos":2},{"corpo":"As Darren told you, the easiest method is to use std::transform. But beware that in some language, like German for instance, there isn't always a one to one mapping between lower and uppercase. The \"esset\" lowercase character (look like the Greek character beta) is transformed to \"SS\" in uppercase. ","pontos":2},{"corpo":"Brad Abrams specifically warns against Enum.IsDefined in his post The Danger of Oversimplification. The best way to get rid of this requirement (that is, the need to validate enums) is to remove ways where users can get it wrong, e.g., an input box of some sort. Use enums with drop downs, for example, to enforce only valid enums. ","pontos":8},{"corpo":"Take a look at this article Implementing the Dispose pattern, IDisposable, and/or a finalizer has absolutely nothing to do with when memory gets reclaimed; instead, it has everything to do with telling the GC how to reclaim that memory. When you call Dispose() you are in no way interacting with the GC. The GC will only run when it determines the need to (called memory pressure) and then (and only then) will it deallocate memory for unused objects and compact the memory space. You could call GC.Collect() but you really shouldn't unless there is a very good reason to (which is almost always \"Never\"). When you force an out-of-band collection cycle like this you actually cause the GC to do more work and ultimately can end up hurting your applications performance. For the duration of the GC collection cycle your application is actually in a frozen state...the more GC cycles that run, the more time your application spends frozen. There are also some native Win32 API calls you can make to free your working set, but even those should be avoided unless there is a very good reason to do it. The whole premise behind a gargbage collected runtime is that you don't need to worry (as much) about when the runtime allocates/deallocates actual memory; you only need to worry about making sure the your object knows how to clean up after itself when asked. ","pontos":4},{"corpo":"If you are programming in javascript the best advice I can give is to use a javascript library instead of trying to roll your own. The libraries are well tested, and the corner cases are more likely to have been encountered. Scriptalicious - http://script.aculo.us/ jQuery - http://jquery.com/ Microsoft AJAX - http://www.asp.net/ajax/ Dojo - http://dojotoolkit.org/ Prototype - http://www.prototypejs.org/ YUI - http://developer.yahoo.com/yui/ ","pontos":3},{"corpo":"Well, as with all \"What might be faster in real life\" questions, you can't beat a real life test. function timeFunc($function, $runs) { $times = array(); for ($i = 0; $i $runs; $i++) { $time = microtime(); call_user_func($function); $times[$i] = microtime() - $time; } return array_sum($times) / $runs; } function Method1() { $foo = 'some words'; for ($i = 0; $i 10000; $i++) $t = \"these are $foo\"; } function Method2() { $foo = 'some words'; for ($i = 0; $i 10000; $i++) $t = \"these are {$foo}\"; } function Method3() { $foo = 'some words'; for ($i = 0; $i 10000; $i++) $t = \"these are \" . $foo; } print timeFunc('Method1', 10) . \"\\n\"; print timeFunc('Method2', 10) . \"\\n\"; print timeFunc('Method3', 10) . \"\\n\"; Give it a few runs to page everything in, then... 0.0035568 0.0035388 0.0025394 So, as expected, the interpolation are virtually identical (noise level differences, probably due to the extra characters the interpolation engine needs to handle). Straight up concatenation is about 66% of the speed, which is no great shock. The interpolation parser will look, find nothing to do, then finish with a simple internal string concat. Even if the concat were expensive, the interpolator will still have to do it, after all the work to parse out the variable and trim/copy up the original string. Updates By Somnath: I added Method4() to above real time logic. function Method4() { $foo = 'some words'; for ($i = 0; $i 10000; $i++) $t = 'these are ' . $foo; } print timeFunc('Method4', 10) . \"\\n\"; Results were: 0.0014739 0.0015574 0.0011955 0.001169 When you are just declaring a string only and no need to parse that string too, then why to confuse PHP debugger to parse. I hope you got my point. ","pontos":29},{"corpo":"As a fairly simple modification to Rudd's version, /^x=(.+) and y=([^ ]+)(?: and (.*))?/ will allow you to use $1, $2 and $3 (the ?: makes it a noncapturing group), and will ensure that the string starts with \"x=\" rather than allowing a \"not_x=\" to match If you have better knowledge of what the x and y values will be, this should be used to tighten the regex further: my @strs = (\"x=1 and y=abc and z=c4g and w=v4l\", \"x=yes and y=no\", \"z=nox and w=noy\", \"not-x=nox and y=present\", \"x=yes and w='there is no and y=something arg here'\"); foreach (@strs) { if ($_ =~ /^x=(.+) and y=([^ ]+)(?: and (.*))?/) { $x = $1; $y = $2; $remainder = $3; print \"x: {$x}; y: {$y}; remainder: {$remainder}\\n\"; } else { print \"$_ Failed.\\n\"; } } Output: x: {1}; y: {abc}; remainder: {z=c4g and w=v4l} x: {yes}; y: {no}; remainder: {} z=nox and w=noy Failed. not-x=nox and y=present Failed. x: {yes and w='there is no}; y: {something}; remainder: {} Note that the missing part of the last test is due to the current version of the y test requiring no spaces, if the x test had the same restriction that string would have failed. ","pontos":2},{"corpo":"I've been toying with composite indexes and have seen some real benefits...maybe I'll setup some tests to see if that can save me here..at least for a little longer. ","pontos":0},{"corpo":"This only happens with conflicts - basically svn tried to merge the change in, but (roughly speaking) saw the change as: Add 2008-08-06 Mike Stone myemail * changed_file: Details. before 2008-08-06 Someone Else their_email And it couldn't find the Someone Else line while doing the merge, so chucked that bit in for context when putting in the conflict. If it was a non-conflicting merge only the changes you expected would have been applied. ","pontos":2},{"corpo":"mod_rewrite is almost essential in today's hosting environment..but unfortunately not everyone got the message. Lots of the large php programs (I'm thinking magento, but most can cope) have a pretty-url fall back mode for when mod_rewrite isn't available. URLs end up looking like www.site.com/index.php?load-this-page They must be running some magic to grab the variable name from the $_GET variable and using it as the selector for what module/feature to execute. In a related note, I've seen lots of messed up URLs in the new facebook site where it's using the #. So links look like www.new.facebook.com/home.php#/inbox/ Clearly we're not meant to see that but it suggests that they're probably parsing the $SERVER['REQUESTURI'] variable. ","pontos":0},{"corpo":" Separating your source code into multiple projects makes only sense if you... ... More developers involved and you want to treat their work as consumable black box. (not very recommended) ... Why isn't this recommended? I've found it a very useful way to manage an application with several devs working on different portions. Makes checkins much easier, mainly by virtually eliminating merges. Very rarely will two devs have to work on the same project at the same time. ","pontos":0},{"corpo":"TortoiseSVN 1.5 has a neat hidden feature on the check in window: Select a missing file and a new file and right-click. One of the options will be \"fix move\". In TortoiseSVN 1.8 you need to select both files for the option to show up in the context menu. I tend to refactor away, and then use this to fix any files where the name has changed. ","pontos":12},{"corpo":"You should probably use a JavaScript library to do things like this. For example, MochiKit has a function removeElement, and jQuery has remove. ","pontos":0},{"corpo":"Zend framework should work without . If you can live with your URL:s looking more like \"/path/to/app/index.php/controller/action\". If you had mod_rewrite you could do away with the \"index.php\" bit, but it should work with too. It's all a matter of setting up the routes to accept the index.php part. ","pontos":4},{"corpo":"You have to remove any event handlers you've set on the node before you remove it, to avoid memory leaks in IE ","pontos":5},{"corpo":" Do you know of any differences in handling HTML tags/properties in different browsers Is this question asking for information on all differences, including DOM and CSS? Bit of a big topic. I thought the OP was asking about HTML behaviour specifically, not all this other stuff... ","pontos":1},{"corpo":" Then between the two lines, another process could easily lock the file, giving you the same problem you were trying to avoid to begin with: exceptions. However, this way, you would know that the problem is temporary, and to retry later. (E.g., you could write a thread that, if encountering a lock while trying to write, keeps retrying until the lock is gone.) The IOException, on the other hand, is not by itself specific enough that locking is the cause of the IO failure. There could be reasons that aren't temporary. ","pontos":5},{"corpo":"Dean Edwards' ie7.js makes IE6 behave (mostly) like a respectable web browser. It requires the client to have Javascript turned on, but that's a reasonable concession to make. I use that script and the script from Save the Developers on sites I create, and it makes supporting IE6 a breeze. ","pontos":0},{"corpo":"What you have to do is the following: Right click on the folder where you think it is. Choose Show Log under TortioseSVN Find the checkin that the file was deleted in Go down the list and find the file Select Revert changes for this version to undelete. ","pontos":11},{"corpo":"Did you only delete it locally, or did you commit the deletion? In the latter case, try checking out the previous revision. ","pontos":1},{"corpo":"Instead of resorting to display block, note that IE7 does some seriously odd things with whitespace; try removing the whitespace between the image and the div, and see what happens. ","pontos":1},{"corpo":"CSS Resets (like the YUI Reset CSS) are great for this kind of thing. They reset paddings, margins, and other display properties on a lot of HTML elements to minimize the display differences. ","pontos":1},{"corpo":"You are being tricked by Python's representation of the result string. The Python expression: 'This is \\\\n a test \\\\r' represents the string This is \\n a test \\r which is I think what you wanted. Try adding 'print' in front of each of your p.sub() calls to print the actual string returned instead of a Python representation of the string. mystring = r\"This is \\n a test \\r\" mystring 'This is \\\\n a test \\\\r' print mystring This is \\n a test \\r ","pontos":0},{"corpo":"Close-- The below works correctly, but I'd be interested if anyone has a deeper explanation. PS C:\\ $computers[0] | %{ \"$_.properties.name\"; \"$($_.properties.name)\" } System.DirectoryServices.SearchResult.properties.name GORILLA So it would seem that $_.properties.name doesn't deference like I expected it to. If I'm visualizing properly, the fact that the name property is multivalued causes it to return an array. Which (I think) would explain why the following works: $computers[0] | %{ $_.properties.name[0]} If \"name\" were a string this should return the first character, but because it's an array it returns the first string. ","pontos":0},{"corpo":"The idea is that I'll read in an escaped string, and unescape it (a feature notably lacking from Python, which you shouldn't need to resort to regular expressions for in the first place). Unfortunately I'm not being tricked by the backslashes... Another illustrative example: mystring = r\"This is \\n ridiculous\" print mystring This is \\n ridiculous p = re.compile( r\"\\\\(\\S)\" ) print p.sub( 'bloody', mystring ) This is bloody ridiculous print p.sub( r'\\1', mystring ) This is n ridiculous print p.sub( r'\\\\1', mystring ) This is \\1 ridiculous print p.sub( r'\\\\\\1', mystring ) This is \\n ridiculous What I'd like it to print is This is ridiculous ","pontos":0},{"corpo":"I've never heard of transactions being used in the same context as explaining what a closure is and there really aren't any transaction semantics here. It's called a closure because it \"closes over\" the outside variable (constant)--i.e., it's not just a function but an enclosure of the environment where the function was created. In the following example, calling the closure g after changing x will also change the value of x within g, since g closes over x: x = 0 def f(): def g(): x * 2 return g closure = f() print(closure()) # 0 x = 2 print(closure()) # 4 ","pontos":6},{"corpo":" The solution...display: block That question couldn't be answered properly without knowing the rendering mode that the browser was in; you need to tell people what doctype you have if you have CSS rendering issues. The image behaviour you refer to is different in quirks mode as opposed to standards mode. A minimal test case must include a full HTML document and the CSS to reproduce the problem. Please don't ask people for help without giving them the information they need to answer easily without wasting their time... ","pontos":0},{"corpo":"ls (Get-ChildItem) rm (Remove-Item) ps (Get-Process) and the rest of my familiar commands that now \"just work\" :) but seriously... New-Object would have to get my vote. With it, powershell can do ANYTHING :) ","pontos":0},{"corpo":"I like this rough, succinct definition: A function that can refer to environments that are no longer active. I'd add A closure allows you to bind variables into a function without passing them as parameters. Decorators which accept parameters are a common use for closures. Closures are a common implementation mechanism for that sort of \"function factory\". I frequently choose to use closures in the Strategy Pattern when the strategy is modified by data at run-time. In a language that allows anonymous block definition -- e.g., Ruby, C# -- closures can be used to implement (what amount to) novel new control structures. The lack of anonymous blocks is among the limitations of closures in Python. ","pontos":13},{"corpo":"The \"correct\" way to do this is to respond to the WM_SYSCOMMAND message. In C# this looks something like this: protected override void WndProc(ref Message m) { // Abort screensaver and monitor power-down const int WM_SYSCOMMAND = 0x0112; const int SC_MONITOR_POWER = 0xF170; const int SC_SCREENSAVE = 0xF140; int WParam = (m.WParam.ToInt32() 0xFFF0); if (m.Msg == WM_SYSCOMMAND (WParam == SC_MONITOR_POWER || WParam == SC_SCREENSAVE)) return; base.WndProc(ref m); } According to MSDN, if the screensaver password is enabled by policy on Vista or above, this won't work. Presumably programmatically moving the mouse is also ignored, though I have not tested this. ","pontos":11},{"corpo":"Unfortunately not - I'd rate myself as a fairly techy person and at home I use Firefox 3 and IE7, but at work (a large American Pharma) I have to use IE6, and I don't think that's going change any time soon. The company has a significant investment in an internal line of web-based apps - the business case for testing and upgrading them all against another browser (or even an upgrade) isn't compelling. ","pontos":1},{"corpo":"Ideally Stack Overflow would allow you to change your OpenID. OTOH, ideally you would have set up OpenID delegation on your own site, and used that to identify yourself. With delegation, you would need only change which service you delegate to. You'd still be identified by your own URL that you control. But that doesn't help now unless Stack Overflow lets you change it. Most sites tie OpenIDs to real accounts, and would let you switch or at least add additional OpenIDs. Doesn't seem like you could map OpenIDs to accounts 1:1 unless the result of access is totally trivial; otherwise you're in a situation like this where you lose your existing questions, answers, and reputation for switching IDs. ","pontos":16},{"corpo":"Can you clarify: Are you trying to write an installer for your app, which depends on the Client-Profile, or are you trying to write a custom installer for the client-profile? I haven't used it personally, but if it's anything like the dotnetfx 1 and 2 msi's, you basically have to just invoke it's executable yourself from your own .exe file, or from an Msi BEFORE the InstallExecuteSequence starts up - you can't \"embed\" those in your own app, MS go out of their way to tell you not to do that due to suckage of MSI. ","pontos":0},{"corpo":"It seems that if you are trying to prepare our team for a future in programming that C(++) ma be the better route. The promise of general programming languages that are built with visual building blocks has never seemed to materialize and I am beginning to wonder if they ever will. It seems that while it can be done for specific problem domains, once you get into trying to solve many general problems a text based programming language is hard to beat. At one time I had sort of bought into the idea of executable UML but it seems that once you get past the object relationships and some of the process flows UML would be a pretty miserable way to build an app. Imagine trying to wire it all up to a GUI. I wouldn't mind being proven wrong but so far it seems unlikely we'll be point and click programming anytime soon. ","pontos":0},{"corpo":"It would be nice if we could deny support for terribly non-compliant browsers. The problem is, denying IE support hurts your site, hurts your prospective users, but doesn't hurt IE. That's note exactly what we're going for. I propose a different technique. What if all anti-IE developers put a \"Please stop using your crappy browser\" splash screen for all IE(6) users accessing their web site. They could provide a few good, simple reasons to switch, that the user can't ignore, but then allow the user to access the (IE compliant) site. That way they could get the point across, without hurting themselves (much), or the user (except a little). ","pontos":0},{"corpo":"It depends on the context: When on their own, or assigning to a variable, creates arrays, and creates hashes. e.g. a = [1,2,3] # an array b = {1 = 2} # a hash can be overridden as a custom method, and is generally used to fetch things from hashes (the standard library sets up as a method on hashes which is the same as ) There is also a convention that it is used as a class method in the same way you might use a method in C# or Java. e.g. a = {1 = 2} # create a hash for example puts a[1] # same as a.fetch(1), will print 2 Hash[1,2,3,4] # this is a custom class method which creates a new hash See the Ruby Hash docs for that last example. This is probably the most tricky one - is also syntax for blocks, but only when passed to a method OUTSIDE the arguments parens. When you invoke methods without parens, Ruby looks at where you put the commas to figure out where the arguments end (where the parens would have been, had you typed them) 1.upto(2) { puts 'hello' } # it's a block 1.upto 2 { puts 'hello' } # syntax error, ruby can't figure out where the function args end 1.upto 2, { puts 'hello' } # the comma means \"argument\", so ruby sees it as a hash - this won't work because puts 'hello' isn't a valid hash ","pontos":47},{"corpo":"Isn't that what Anders' second example does? In 2.5 there's also a encoding you can apply: mystring = r\"This is \\n a test \\r\" mystring.decode('string-escape') 'This is \\n a test \\r' print mystring.decode('string-escape') This is a test ","pontos":7},{"corpo":"I'm guessing that this is a change to the cmdlet made during the configuration process Configure-Wsman.ps1. I don't have an environment setup to test right now, but I'm guessing something went wrong with the configuration. I can verify that on XP the parameter is not available (duh). I'd assume that you will find the same on Vista/08 without the configuration completed. ","pontos":0},{"corpo":"Mark; his second example requires every escaped character thrown into an array initially, which generates a KeyError if the escape sequence happens not to be in the array. It will die on anything but the three characters provided (give \\v a try), and enumerating every possible escape sequence every time you want to unescape a string (or keeping a global array) is a really bad solution. Analogous to PHP, that's using with a lambda instead of , which is utterly unnecessary in this situation. I'm sorry if I'm coming off as a dick about it, I'm just utterly frustrated with Python. This is supported by every other regular expression engine I've ever used, and I can't understand why this wouldn't work. Thank you for responding; the function is precisely what i was looking for initially. If someone has a general solution to the regex backreference problem, feel free to post it and I'll accept that as an answer as well. ","pontos":0},{"corpo":"I had to turn off the \"Silence terminal bell\" option in my active Terminal Profile in iTerm for to work. It seemed to work fine by default in Terminal. You can also use the Mac module to play the system beep: import Carbon.Snd Carbon.Snd.SysBeep(1) The Carbon modules don't have any documentation, so I had to use to see what functions were available. It seems to be a direct interface onto Carbon, so the docs on Apple Developer Connection probably help. ","pontos":4},{"corpo":"A good starting point is probably to read the source of the ParseTree library, which lets you get at and mess with the AST from ruby. ","pontos":1},{"corpo":" I considered it, but I'm not going to use XML. I am going to be writing this stuff by hand, and hand editing XML makes my brain hurt. :') Have you looked at YAML? You get the benefits of XML without all the pain and suffering. It's used extensively in the ruby community for things like config files, pre-prepared database data, etc here's an example customer: name: Orion age: 26 addresses: - type: Work number: 12 street: Bob Street - type: Home number: 15 street: Secret Road There appears to be a C# library here, which I haven't used personally, but yaml is pretty simple, so \"how hard can it be?\" :-) I'd say it's preferable to inventing your own ad-hoc format (and dealing with parser bugs) ","pontos":11},{"corpo":"I work with web and winforms apps in c# and I HATE triggers with a passion. I have never come across a situation where I could justify using a trigger over moving that logic into the business layer of the application and replicating the trigger logic there. I don't do any DTS type work or anything like that, so there might be some use cases for using trigger there, but if anyone in any of my teams says that they might want to use a trigger they better have prepared their arguments well because I refuse to stand by and let triggers be added to any database I'm working on. Some reasons why I don't like triggers: They move logic into the database. Once you start doing that, you're asking for a world of pain because you lose your debugging, your compile time safety, your logic flow. It's all downhill. The logic they implement is not easily visible to anyone. Not all database engines support triggers so your solution creates dependencies on database engines I'm sure I could think of more reasons off the top of my head but those alone are enough for me not to use triggers. ","pontos":2},{"corpo":"I'm not a fan, personally. I'll use them, but only when I uncover a bottleneck in the code that can be cleared by moving actions into a trigger. Generally, I prefer simplicity and one way to keep things simple is to keep logic in one place - the application. I've also worked on jobs where access is very compartmentalized. In those environments, the more code I pack into triggers the more people I have to engage for even the simplest fixes. ","pontos":0},{"corpo":" I think if you have to use nullable types, it's better to use Nullable .T> rather than the question mark notation. It makes it eye-achingly obvious that magic is occurring. Not sure why anyone would ever want to use Nullable .bool> though. In a VB.NET Web service where the parameter might not be passed through (because the partners request wasn't consistent or reliable), but had to pass validation against the proposed type (Boolean for \"if is search request\"). Chalk it up to \"another demand by management\"... ...and yes, I know some people think it's not the right way to do these things, but IsSearchRequest As Nullable(Of Boolean) saved me losing my mind that night! ","pontos":2},{"corpo":"I find myself bypassing triggers when doing bulk data imports. I think it's justified in such circumstances. If you end up bypassing the triggers very often though, you probably need to take another look at what you put them there for in the first place. In general, I'd vote for \"they serve a purpose in some scenarios\". I'm always nervous about performance implications. ","pontos":1},{"corpo":"Triggers can be very helpful. They can also be very dangerous. I think they're fine for house cleaning tasks like populating audit data (created by, modified date, etc) and in some databases can be used for referential integrity. But I'm not a big fan of putting lots of business logic into them. This can make support problematic because: it's an extra layer of code to research sometimes, as the OP learned, when you need to do a data fix the trigger might be doing things with the assumption that the data change is always via an application directive and not from a developer or DBA fixing a problem, or even from a different app As for having to bypass a trigger to do something, it could mean you are doing something wrong, or it could mean that the trigger is doing something wrong. The general rule I like to use with triggers is to keep them light, fast, simple, and as non-invasive as possible. ","pontos":2},{"corpo":"There should always be some developer testing. If a developer is producing too many bugs, then he/she is wasting time later on fixing those bugs. It is important that the developers don't develop the attitude which says, oh well if I leave a bug, it will be caught and I will get a chance to fix it. We try to keep a threshold for bugs produced. If this threshold is crossed during testing then the developer is answerable for it. It is up to you to decide what this threshold is (for us it can vary from project to project). Also, all unit testing is done by the developers. ","pontos":5},{"corpo":"I first used triggers a couple of weeks ago. We changed over a production server from SQL 2000 to SQL 2005 and we found that the drivers were behaving differently with NText fields (storing a large XML document), dropping off the last byte. I used a trigger as a temporary fix to add an extra dummy byte (a space) to the end of the data, solving our problem until a proper solution could be rolled out. Other than this special, temporary case, I would say that I would avoid them since they do hide what is going on, and the function they provide should be handled explictly by the developer rather then as some hidden magic. ","pontos":0},{"corpo":"You need to use to remove the observer before runs, so yes, doing it in the method of your class would work. Better than that though would be to have a deterministic point where whatever owns the object that's doing the observing could tell it it's done and will (eventually) be deallocated. That way, you can stop observing immediately when the thing doing the observing is no longer needed, regardless of when it's actually deallocated. This is important to keep in mind because the lifetime of objects in Cocoa isn't as deterministic as some people seem to think it is. The various Mac OS X frameworks themselves will send your objects and , extending their lifetime beyond what you might otherwise think it would be. Furthermore, when you make the transition to Objective-C garbage collection, you'll find that will run at very different times  and in very different contexts  than did. For one thing, finalization takes place on a different thread, so you really can't safely send to another object in a method. Stick to memory (and other scarce resource) management in and , and use a separate method to have an owner tell an object you're done with it at a deterministic point; do things like removing KVO observations there. The intent of your code will be clearer and you will have fewer subtle bugs to take care of. ","pontos":36},{"corpo":"Think of a database as a great big object - after each call to it, it ought to be in a logically consistent state. Databases expose themselves via tables, and keeping tables and rows consistent can be done with triggers. Another way to keep them consistent is to disallow direct access to the tables, and only allowing it through stored procedures and views. The downside of triggers is that any action can invoke them; this is also a strength - no-one is going to screw up the integrity of the system through incompetence. As a counterpoint, allowing access to a database only through stored procedures and views still allows the backdoor access of permissions. Users with sufficient permissions are trusted not to break database integrity, all others use stored procedures. As to reducing the amount of work: databases are stunningly efficient when they don't have to deal with the outside world; you'd be really surprised how much even process switching hurts performance. That's another upside of stored procedures: rather than a dozen calls to the database (and all the associated round trips), there's one. Bunching stuff up in a single stored proc is fine, but what happens when something goes wrong? Say you have 5 steps and the first step fails, what happens to the other steps? You need to add a whole bunch of logic in there to cater for that situation. Once you start doing that you lose the benefits of the stored procedure in that scenario. Business logic has to go somewhere, and there's a lot of implied domain rules embedded in the design of a database - relations, constraints and so on are an attempt to codify business rules by saying, for example, a user can only have one password. Given you've started shoving business rules onto the database server by having these relations and so on, where do you draw the line? When does the database give up responsibility for the integrity of the data, and start trusting the calling apps and database users to get it right? Stored procedures with these rules embedded in them can push a lot of political power into the hands of the DBAs. It comes down to how many tiers are going to exist in your n-tier architecture; if there's a presentation, business and data layer, where does the separation between business and data lie? What value-add does the business layer add? Will you run the business layer on the database server as stored procedures? Yes, I think that having to bypass a trigger means that you're \"doing it wrong\"; in this case a trigger isn't for you. ","pontos":7},{"corpo":"Do you mean actual genetic programming, as opposed to genetic algorithms in general? If so, C#/.net isn't the best language for it. LISP, for example, has always been a mainstay of GP. However, if you must, you're probably going to want to dynamically generate CIL / MSIL. You could do this using System.Reflection.Emit, however I'd recommend Mono.Cecil. It lacks good docs (as if reflection emit has them).. But it offers much better assembly emission and reflection. Another issue is that it is less than trivial to load code, and later dispose of it, in the .net framework. At least, you cannot unload assemblies. You can unload appdomains, but the whole business of loading code into a seperate appdomain, and calling it externally can get pretty messy. .NET 3.5's System.Addin stuff should make this easier. ","pontos":3},{"corpo":"Make sure event referencing elements are with in the object they are referencing, like text boxes in the form control. Or if that can't be prevented. Create a static event on a global helper class and then monitor the global helper class for events. If these two steps cannot be done try using a WeakReference, they are usually perfect for these situations, but they come with overhead. ","pontos":0},{"corpo":" As to reducing the amount of work: databases are stunningly efficient when they don't have to deal with the outside world; you'd be really surprised how much even process switching hurts performance. That's another upside of stored procedures: rather than a dozen calls to the database (and all the associated round trips), there's one. this is a little off topic, but you should also be aware that you're only looking at this from one potential positive. Bunching stuff up in a single stored proc is fine, but what happens when something goes wrong? Say you have 5 steps and the first step fails, what happens to the other steps? You need to add a whole bunch of logic in there to cater for that situation. Once you start doing that you lose the benefits of the stored procedure in that scenario. ","pontos":0},{"corpo":"This is honestly the hardest thing about Open Source, because some of the most legit projects don't look that way because their presence is only known through a poor web page constructed in 1997 and a mailing list. Other projects are very flashy but have nothing to back them up. Some projects don't know how to accept new members and don't event know how to ask. Best way to find these projects is to keep your ear to the ground and network in forums like this. ","pontos":0},{"corpo":"Check out SQL Developer: [http://sqldeveloper.solyp.com/download/index.html] ","pontos":1},{"corpo":" What about getting everyone's input? Everyone that a person is working with will have a unique insight into that person. That would work if (1) evaluation is conducted with open doors and (2) you've worked with that person on one project or even on the same module. As the person evaluating them, I couldn't judge the programmers who I didn't directly work with. One person might think someone is a slacker, while another person sees that they are spending a lot of time planning before they start coding Unfortunately, this is debatable. Someone who looks like a slacker might be in deep thoughts, or maybe not. And is someone who spend a long time planning, necessarily a bad programmer? I believe a good evaluation question would be able to answer this. ","pontos":0},{"corpo":"Triggers are generally used incorrectly, introduce bugs and therefore should be avoided. Never design a trigger to do integrity constraint checking that crosses rows in a table (e.g \"the average salary by dept cannot exceed X). Tom Kyte, VP of Oracle has indicated that he would prefer to remove triggers as a feature of the Oracle database because of their frequent role in bugs. He knows it is just a dream, and triggers are here to stay, but if he could he would remove triggers from Oracle, he would (along with the WHEN OTHERS clause and autonomous transactions). Can triggers be used correctly? Absolutely. The problem is - they are not used correctly in so many cases that I'd be willing to give up any perceived benefit just to get rid of the abuses (and bugs) caused by them. - Tom Kyte ","pontos":9},{"corpo":"(Assume $(WXWIDGETSROOT) is the root directory of your wxWidgets installation.) Open the file $(WXWIDGETSROOT)\\include\\wx\\msw\\setup.h Search and find the option wxUSE_GLCANVAS. Change its value from 0 to 1. Recompile the library. ","pontos":0},{"corpo":"I just read your blog post and I think you got a bit of misleading advice, Matt. If there is an actual memory leak here, then that is a bug in the .NET Framework, and not something you can necessarily fix in your code. What I think you (and the poster on your blog) are actually talking about here is not actually a leak, but rather an ongoing consumption of memory. That's not the same thing. To be clear, leaked memory is memory that is reserved by a program, then abandoned (ie, a pointer is left dangling), and which subsequently cannot be freed. Since memory is managed in .NET, this is theoretically impossible. It is possible, however, for a program to reserve an ever-increasing amount of memory without allowing references to it to go out of scope (and become eligible for garbage collection); however that memory is not leaked. The GC will return it to the system once your program exits. So. To answer your question, I don't think you actually have a problem here. You certainly don't have a memory leak, and from your code, I don't think you need to worry, as far as memory consumption goes either. As long as you make sure that you are not repeatedly assigning that event handler without ever de-assigning it (ie, that you either only ever set it once, or that you remove it exactly once for each time that you assign it), which you seem to be doing, your code should be fine. It seems like that's the advice that the poster on your blog was trying to give you, but he used that alarming work \"leak,\" which is a scary word, but which many programmers have forgotten the real meaning of in the managed world; it doesn't apply here. ","pontos":0},{"corpo":"Post commit scripts are useful for this. Essentially on every commit a script is called after the event, which you can use to perform an svn export to where-ever. An interesting article shows how this might be done, and this shows how hook scripts can be used with subversion ","pontos":1},{"corpo":"You want to build a script that uses the post commit hook in SubVersion. You can either have the script export from your repository and then FTP to the server, or you can just checkout from your repository into a working directory on your server and call \"svn update\" on the servers working directory in your post-commit hook script. There's more information in the Subversion FAQ ","pontos":3},{"corpo":"If you have shell access to your sever, and SVN installed on it (or the ability to install SVN), then your best bet may be just to bypass FTP entirely. How we deploy our apps is (simplified) Developers write code and check it into trunk Periodically, when trunk is stable, we will take a snapshot of it as a tag On the server, svn checkout the tag If any changes need to be made to the server (or directly on the live server itself) it is trivial to use subversion to sync the code ","pontos":3},{"corpo":"Ugh... scope it, dude: , . ","pontos":3},{"corpo":"Not everybody uses Notepad++, it's not that good. Crimson Editor ","pontos":6},{"corpo":" Values are so random within the gameplay aspects of development that it would be a far fetched idea to test for absolute values But we can test deterministic values. For example, a unit test might have Guybrush Threepwood move toward a door (pathfinding), open the door (use command), fail because he doesn't have a key in his inventory (feedback), pick the door key (pathfinding + inventory management) and then finally opening the door. All of these paths are deterministic. With this unit test, I can refactor the memory manager and if it somehow broke the inventory management routine, the unit test would fail. This is just one idea for unit testing in games. I would love to know other ideas, hence, the motivation for this post. ","pontos":2},{"corpo":"I have used UltraEdit for years... If I'm working on a project I prefer to use a real IDE, but nothing beats it for quickly making changes to source files, or especially for those small PHP projects where you're just hacking away anyway. The killer feature for me is the compare functionality. ","pontos":4},{"corpo":"It depends on your target audience and if you think you can afford to alienate users. If you are making a geeky web app and you think most users will use firefox, then don't worry about IE6. I would launch with it working in Firefox, IE7, and Safari and look at who goes to your site. If you see the need to make it work in IE6 then start working on it then. ","pontos":0},{"corpo":"I strictly use jEdit. ","pontos":4},{"corpo":"I mostly just use Notepad++, but I like BabelPad when I need to open a file in a unicode path or when I need to have more control over unicode stuff. I like EditPlus too. You can save a file as a template and create a new instance of it under the file menu. It's also pretty fast at loading moderately large files. JEDIT would be my favorite, but it's just too slow when editing even slightly big files. I can't say I'm 100% happy with Notepad++, but it bugs me the least, so... ","pontos":0},{"corpo":"It depends on your audience, and whether the cost (development, maintenance, opportunity cost of developing to a 7 year old lowest common denominator) is worth it to gain those IE6 viewers. Also worth asking - is the IE6 demographic likely to care about or use your site? I think a large amount of IE6 users don't care about new technology (duh) or are accessing the web from corporate networks which restrict browser installations. Maybe those viewers aren't worth the effort - only you can answer that. I was happy to see that Apple's Mobile Me site won't support IE6. ","pontos":5},{"corpo":"Ask your customer this: are they willing to upgrade to Vista? If they say yes, then don't support IE6. Your target customers are the people who goes \"whoa! vista. drool\". They're also the kind of people who want the fastest and most powerful computer. If your customer goes, \"huh? what's vista? I want my screensaver of cats back please\", then you need to support IE6. In short: if they have Vista, then they don't have IE6. The irony is: for web developers to finally get rid of IE6 and its legacy, they have to promote Vista or hope that Vista will be successful. ","pontos":1},{"corpo":"Notice that some users in the Enterprise have no choice. So if you target Enterprise customers, notice they are still on IE6. In general, Enterprise moves slower than consumer. ","pontos":0},{"corpo":"I'm attempting to switch to the Code::Blocks IDE for all of my C/C++ editing, but have used Visual Studio 2003, and Programmer's Notepad 2 for C/C++ projects. For Python, I currently use IDLE, but have been looking for something else that has a horozontal scroll bar. ","pontos":1},{"corpo":"@Derek Park I also use VS for most of my coding needs, but use Notepad++ for all other plain text files. I was disappointed by VS one time when it failed to open a 500 meg text file that I was hoping to change a few characters in. Seeing as it has support for viewing files in hex (ie. binary data) I was hoping that it would do a better job with large files. It seemed to want to load the whole file rather than the relevant data. Maybe I was just expecting too much from it. (Note: I wasn't able to open the file in NP++, either.) Edit - My mistake. I didn't mean to imply that Notepad++ successfully opened the file. I don't remember what I used to fix that, actually. ","pontos":0},{"corpo":"@_l0ser I also use VS for most of my coding needs, but use Notepad++ for all other plain text files. I was disappointed by VS one time when it failed to open a 500 meg text file that I was hoping to change a few characters in. Seeing as it has support for viewing files in hex (ie. binary data) I was hoping that it would do a better job with large files. It seemed to want to load the whole file rather than the relevant data. Maybe I was just expecting too much from it. If Notepad++ will open a 500meg file usably, that's a definite plus for Notepad++. Every editor I've tried to open a file that large in just thrashed and/or froze until I killed it. ","pontos":0},{"corpo":"I did something similar to your idea once and it was very successful, though I suspect it is really more of a system test than a unit test. As you suggest your random number generator must be seeded with the same value, and must produce an identical sequence each time. The game ran on 50hz cycles, so timing was not an issue. I had a system that would record mouse clicks and locations, and used this to manually generate a 'script' which could be replayed to produce the same results. By removing the timing delays and turning off the graphic generation an hour of gameplay could be replicated in a few seconds. The biggest problem was that changes to the game design would invalidate the script. If your barebones room contained logic that was independent of the general game play then it could work very well. The engine could start up without any ui and start the script as soon as initialisation is complete. Testing for crashing along the way would be simple, but more complex tests such as leaving the characters in the correct positions would be more complex. If the recording of the scripts are simple enough, which they were in my system, then they can be updated very easily, and special scripts to test specialised behavior can be set up very quickly. My system had the added advantage that it could be used during game testing, and the exact sequence of events recorded to make bug fixing easier. ","pontos":1},{"corpo":" Warning about the Wp64 setting. Turn off the /Wp64 setting which is set by default. You can find it in Project Properties -> C/C++ -> General. Warning about the compiler version. Go to the Boost trunk (online) and get the latest boost\\boost\\config\\compiler\\visualc.hpp header file. Diff it with the current file and merge the sections where MSCVER is equal to 1800. (1800 is the VC9 version number used in Boost configuration.) ","pontos":1},{"corpo":"Regardless of the persisted format, using a Regex would be the fastest way of parsing. In ruby it'd probably be a few lines of code. \\[KEY:(.*)\\] \\[SUBKEY:(.*)\\] These two would get you the Value and SubValue in the first group. Check out MSDN on how to match a regex against a string. This is something everyone should have in their kitty. Pre-Regex days would seem like the Ice Age. ","pontos":-1},{"corpo":"@Gishu Actually once I'd accommodated for escaped characters my regex ran slightly slower than my hand written top down recursive parser and that's without the nesting (linking sub-items to their parents) and error reporting the hand written parser had. The regex was a slightly faster to write (though I do have a bit of experience with hand parsers) but that's without good error reporting. Once you add that it becomes slightly harder and longer to do. I also find the hand written parser easier to understand the intention of. For instance, here is the a snippet of the code: private static Node ParseNode(TextReader reader) { Node node = new Node(); int indentation = ParseWhitespace(reader); Expect(reader, '['); node.Key = ParseTerminatedString(reader, ':'); node.Value = ParseTerminatedString(reader, ']'); } ","pontos":0},{"corpo":"The cause of this error is an older version of NVIDIA's glext.h, which still has this definition. Whereas the most recent versions of GLEW don't. This leads to compilation errors in code that you had written previously or got from the web. The GL_FRAMEBUFFER_INCOMPLETE_DUPLICATE_ATTACHMENT_EXT definition for FBO used to be present in the specification (and hence in header files). But, it was later removed. The reason for this can be found in the FBO extension specification (look for Issue 87): (87) What happens if a single image is attached more than once to a framebuffer object? RESOLVED: The value written to the pixel is undefined. There used to be a rule in section 4.4.4.2 that resulted in FRAMEBUFFER_INCOMPLETE_DUPLICATE_ATTACHMENT_EXT if a single image was attached more than once to a framebuffer object. FRAMEBUFFER_INCOMPLETE_DUPLICATE_ATTACHMENT_EXT 0x8CD8 * A single image is not attached more than once to the framebuffer object. { FRAMEBUFFER_INCOMPLETE_DUPLICATE_ATTACHMENT_EXT } This rule was removed in version #117 of the EXT_framebuffer_object specification after discussion at the September 2005 ARB meeting. The rule essentially required an O(n*lg(n)) search. Some implementations would not need to do that search if the completeness rules did not require it. Instead, language was added to section 4.10 which says the values written to the framebuffer are undefined when this rule is violated. To fix this error, remove all usage of GL_FRAMEBUFFER_INCOMPLETE_DUPLICATE_ATTACHMENT_EXT from your code. If this isn't possible in your setup, then add a dummy definition to your glext.h or glew.h file like this: #define GL_FRAMEBUFFER_INCOMPLETE_DUPLICATE_ATTACHMENT_EXT 0x8CD8 ","pontos":4},{"corpo":"You could loop through the zip files, reading individual files using the zipfile module and running your regex on those, eliminating to unzip all the files at once. I'm fairly certain that you can't run a regex over the zipped data, at least not meaningfully. ","pontos":0},{"corpo":"One tip is to load all plugins and such into an own AppDomain, since the code running can be potentially malicious. An own AppDomain can also be used to \"filter\" assemblies and types that you don't want to load. AppDomain domain = AppDomain.CreateDomain(\"tempDomain\"); And to load an assembly into the application domain: AssemblyName assemblyName = AssemblyName.GetAssemblyName(assemblyPath); Assembly assembly = domain.Load(assemblyName); To unload the application domain: AppDomain.Unload(domain); ","pontos":5},{"corpo":"Drop into a cmd instance (or indeed PowerShell itself) and type this: powershell -? You'll see that powershell.exe has a \"-noexit\" parameter which tells it not to exit after executing a \"startup command\". ","pontos":20},{"corpo":"@superjoe30 Yes, absoluteley. Once you start using version control you never go back. I use it for everything, even my \"home\" folder. @Orion Edwards Subversion does not require a server. You can access a local repository directly (via a client, of course), and there is no server process involved. ","pontos":0},{"corpo":"Have you though of implementing the \"Weak Event Pattern\" instead of regular events? Weak Event Pattern in WPF Weak Event Patterns (MSDN) ","pontos":1},{"corpo":"If you are on any fairly recent Cg profile (arbvp1 and later), your Cg shader programs can in fact access the OpenGL state (MVP matrices, material and light settings) directly. This makes writing those programs less painful. Here are some of the state variables which can be accessed: MVP matrices of all types: state.matrix.mvp state.matrix.inverse.mvp state.matrix.modelview state.matrix.inverse.modelview state.matrix.modelview.invtrans state.matrix.projection state.matrix.inverse.projection Light and material properties: state.material.ambient state.material.diffuse state.material.specular state.light[0].ambient For the full list of state variables, refer to the section Accessing OpenGL State, OpenGL ARB Vertex Program Profile (arbvp1) in the Cg Users Manual. Note: All the OpenGL state variables are of uniform type when accessed in Cg. For light variables, the index is mandatory. (Eg: 1 in state.light[1].ambient) Lighting or light(s) need not be enabled to use those corresponding light values inside Cg. But, they need to be set using glLight() functions. ","pontos":3},{"corpo":"Basically, if you're putting your code on someone else's machine, there's no absolute guarantee of security. You can look at all kinds of security tricks, but in the end, the code is on their machine so it's out of your control. How much do you stand to lose if the end user loads an unauthorised plugin? ","pontos":0},{"corpo":" How much do you stand to lose if the end user loads an unauthorised plugin? Admittedly this won't happen often, but when/if it does happen we lose a lot and I although I understand we will produce nothing 100% secure, I want to make it enough of a hindrance to put people off doing it. The annoying thing about going with a simple dynamic loading with full strong name, is that all it takes is a simple string literal change within the loader app to load any other assembly even though the plugins are signed. ","pontos":0},{"corpo":"Note that venerable Nate Robin's GLUT library doesn't support the scrollwheel. But, later implementations of GLUT like FreeGLUT do. Using the scroll wheel in FreeGLUT is dead simple. Here is how: Declare a callback function that shall be called whenever the scroll wheel is scrolled. This is the prototype: void mouseWheel(int, int, int, int); Register the callback with the (Free)GLUT function glutMouseWheelFunc(). glutMouseWheelFunc(mouseWheel); Define the callback function. The second parameter gives the direction of the scroll. Values of +1 is forward, -1 is backward. void mouseWheel(int button, int dir, int x, int y) { if (dir 0) { // Zoom in } else { // Zoom out } return; } That's it! ","pontos":16},{"corpo":"Subversion branches are directories, so you could just move the branches after the import has finished and no history will be lost. ","pontos":1},{"corpo":"\\X seems to be available as a generic word-character in some languages, it allows you to match a single character disregarding of how many bytes it takes up. Might be useful. ","pontos":0},{"corpo":"Short answer: No. Longer answer: No, not at all. There's a reason it hasn't been updated. [EDIT] @ MrBrutal - Sorry - do you mean to generate code or just represent a design? Because I took your question as to generate code for you. ","pontos":5},{"corpo":"This is all described in The Adobe Flex 3 Programming ActionScript 3 PDF on page 550 (Chapter 27: Flash Player Security / Cross-scripting): If two SWF files written with ActionScript 3.0 are served from different domainsfor example, http://siteA.com/swfA.swf and http://siteB.com/swfB.swfthen, by default, Flash Player does not allow swfA.swf to script swfB.swf, nor swfB.swf to script swfA.swf. A SWF file gives permission to SWF files from other domains by calling Security.allowDomain(). By calling Security.allowDomain(\"siteA.com\"), swfB.swf gives SWF files from siteA.com permission to script it. It goes on in some more detail, with diagrams and all. ","pontos":6},{"corpo":"I suppose the only thing that really speaks against them is excessive abstraction. If you will have a good idea what the alias refers to (good naming helps; 'a', 'b', 'c' can be quite problematic especially when you're reading the statement months or years later), I see nothing wrong with aliasing. As others have said, joins require them if you're using the same table (or view) multiple times, but even outside that situation, an alias can serve to clarify a data source's purpose in a particular context. In the alias's name, try to answer why you are accessing particular data, not what the data is. ","pontos":4},{"corpo":"I have tried it out couple of times, mainly for viewing existing classes. If it would show all the relationships, it would be more usefull. Now it only shows inheritation. ","pontos":0},{"corpo":"TestNG's biggest draw cards for me include its support test groups, and more importantly - test group dependencies (marking a test as being dependent of a group causes the tests to simply skip running when the dependent group fails). TestNG's other big draw cards for me include test parameters, data providers, annotation transformers, and more than anything - the vibrant and responsive user community. Whilst on the surface one might not think all of TestNGs features above might not be needed, once you start to understand the flexibility bring to your tests, you'll wonder how you coped with JUnit. (disclaimer - I've not used JUnit 4.x at all, so am unable to really comment on advances or new features there). ","pontos":11},{"corpo":"Depending on the number of emails sent, you cuold use something like Mail::Bulkmail, a perl module, that will send less email be using an envelope (a SMTP feature). Only one email will be sent to each domain. Then the mail server of that domain will take care of the copying and sending the mails to all users. The only problem is that you can't use dynamic emails, like different names in each mail. ","pontos":1},{"corpo":"This answer isn't going to be very helpful but, as a developer I hate doing documentation. This being a opensource project, it's hard to find people to do documentation. ","pontos":3},{"corpo":"Mostly pen and paper, although I occasionally break out Visio and just do some rough diagrams. Would be nice to have a fancy tool I guess, but it would just be another thing to learn. ","pontos":0},{"corpo":"Pen and paper for the first draft. Umlet to digitalize it. It's very minimal but it does what I need ","pontos":1},{"corpo":"When doing an initial design I like a whiteboard and 1 - 3 other developers to bounce ideas off of. That's usually enough to catch any glaring errors/fix any tricky situations that may arise without dropping the s/n ratio by too much. ","pontos":0},{"corpo":"Take a look at common types of computer bugs on Wikipedia. For more specific bugs, most open source projects maintain a public bug tracker. ","pontos":2},{"corpo":"Performance bottlenecks will be the same regardless of whether the architecture is 32- or 64-bit. Performance problems tend to be the result of sub-optimal algorithms the choice between 32- and 64-bit types won't significantly affect performance. Most importantly, don't try to improve the performance of something before you've measured it. In particular you should profile the code to determine where your performance bottlenecks are. ","pontos":0},{"corpo":"Virtually every open source project has a bug tacking system. For example, here's the one for Apache projects: http://issues.apache.org/jira/ However, I think you might be asking about a generic cause/effect bug database. I don't know of anything specifically like that, but you might be interested in the work on Software Patterns and particularly Anti-Patterns. ","pontos":3},{"corpo":"There is BugTraq, however it focuses more on the security implications of the bugs founds. ","pontos":0},{"corpo":"Maybe you might want to see bug.gd. It helps you to search for errors and bugs which other people have searched for. I think it is not very famous nor has many users. ","pontos":0},{"corpo":"I use pen and paper. For all planning purposes, it's the fastest way. I get lost in layout and finetuning when I use a UML package. But that is my burden.. :-) ","pontos":0},{"corpo":"Go for PENCIL and paper, or a whiteboard. Anything permenant-marking like a pen and you'll have a pretty messy design! ","pontos":1},{"corpo":"What @MattMitchell said is probably the reason you're seeing this error. If you want to know why; it is because when you pass null as the controlData parameter when using RenderUserControl(), the framework will try to pass the view data from the current view context onto the user control instead (see UserControlExtensions.DoRendering method in System.Web.Mvc). ","pontos":3},{"corpo":"Tom's and Martin's response are definitely true (in just about any open source project, you'll find that most contributors are particularly interested in, well, developing; not so much in semi-related matters such as documentation), but I don't think your particular question at the end would fit well inside PyObjC documentation. NSThread.detachNewThreadSelector_toTarget_withObject_(\"queryController\", self, None) is part of the Cocoa API, and as such documented over at Apple, including the particular method (I'd link there, but apparently stackoverflow has bugs with parsing it). The CocoaDev wiki also has an article. I don't think it would be a good idea for PyObjC to attempt to document Cocoa, other than a few basic examples of how to use it from within Python. Explaining selectors is also likely outside the scope of PyObjC, as those, too, are a feature of Objective-C, not PyObjC specifically. ","pontos":7},{"corpo":" That service seems a little steep All of these companies will provide a lot of value-added services beside just the sending the email. They're not simply sending emails on your behalf, or leasing you raw computing power. They'll be contributing (or up-selling) on features such as analytics of your email campaign, preventing your email from being marked as spam, helping with the look of your email (providing templates etc), tracking bounces and a lot more. ","pontos":1},{"corpo":"Has anyone tried either patching SSMS not to check the version (perhaps try looking at the binary differences between CTP 6 and RTM?), or patching SS 2005 to pretend to be 2008? Unclean, I know, but I don't see any other way. ","pontos":1},{"corpo":"some day i work in a company that use VSS (and in other companies that use other less unknow SCM) but i prefer use SVN (someday i'll try GIT) for active development, for me and my group. First of all, this situation it's only good idea, if commit to VSS are few over month, because working with other SCM (than VSS) give you more flexiblity, but commint to VSS from SVN is expensive in time. My solution was: VSS -> SVN: I have linux script (or ant script, or XXX script) that copy from currrent update directory work of VSS to current SVN, then refresh SVN client and update/merge/commit to SVN. With this, you are update from changes of the rest of company that use VSS. SVN -> VSS: In this way, you need a checkout of all your modify files to VSS, then you can simply use the reverse script to copy from current update SVN directory (ignore .svn directories) and copy to current update VSS directory, update and commit. But remember, in a few case does worth your time to do this. ","pontos":0},{"corpo":"Early software was often modal, but usability took a turn at some point, away from this style. VI-based editors are total enigmas -- they're the only real surviving members of that order of software. Modes are a no-no in usability and interaction design because we humans are fickle mammals who cannot be trusted to remember what mode the application is in. If you think you are in one \"mode\" when you are actually in another, then all sorts of badness can ensue. What you believe to be a series of harmless keystrokes can (in the wrong mode) cause unlimited catastrophe. This is known as a \"mode error\". To learn more, search for the term \"modeless\" (and \"usability\") As mentioned in the comments below, a Modal interface in the hands of an experienced and non-fickle person can be extremely efficient. ","pontos":35},{"corpo":"Using a loop to iterate over a jQuery of one element is quite inefficient. When selecting an ID, you can just retrieve the first and unique element of the jQuery using get() or the [] notation. var div = $(\"#thediv\")[0]; // certain browsers have a bug such that scrollHeight is too small // when content does not fill the client area of the element var scrollHeight = Math.max(div.scrollHeight, div.clientHeight); div.scrollTop = scrollHeight - div.clientHeight; ","pontos":6},{"corpo":"EditPlus is my editor of choice. All the features you'd need, and no more. ","pontos":6},{"corpo":"Well you could add a: #pragma warning (disable : 4996) before you use fopen, but have you considered using fopen_s as the warning suggests? It returns an error code allowing you to check the result of the function call. The problem with just disabling deprecated function warnings is that Microsoft may remove the function in question in a later version of the CRT, breaking your code (as stated below in the comments, this won't happen in this instance with fopen because it's part of the C C++ ISO standards). ","pontos":14},{"corpo":"When I last looked at Eclipse (some time ago now!) it allowed you to choose any installed font to work in. Not so sure whether it supported the notion of indenting using tab stops. It looked cool, but the code was definitely harder to read... ","pontos":1},{"corpo":"By using an enum you can do this, but will look awkward. [Flags] public enum PESHeaderFlags { IsCopy = 1, // implied that if not present, then it is an original IsCopyrighted = 2, IsDataAligned = 4, Priority = 8, ScramblingControlType1 = 0, ScramblingControlType2 = 16, ScramblingControlType3 = 32, ScramblingControlType4 = 16+32, ScramblingControlFlags = ScramblingControlType1 | ScramblingControlType2 | ... ype4 etc. } ","pontos":15},{"corpo":"Linq to Sql. Sql server will cache the query plans, so there's no performance gain for sprocs. Your linq statements, on the other hand, will be logically part of and tested with your application. Sprocs are always a bit separated and are harder to maintain and test. If I was working on a new application from scratch right now I would just use Linq, no sprocs. ","pontos":61},{"corpo":"A flags enum can work too, I think, if you make it a byte enum: [Flags] enum PesHeaders : byte { /* ... */ } ","pontos":3},{"corpo":"How about tokenize with \"/\" and take the last element from the array ? Example: tokenize(\"XPath is fun\", \"\\s+\") Result: (\"XPath\", \"is\", \"fun\") Was an XSLT fiddler sometime back... lost touch now. But HTH ","pontos":0},{"corpo":"Notepad++ is probably the one I use the most, though I use GVIM whenever I need to do repetitive changes. We got a company license for UltraEdit recently, and it seems to work quite well as well. I've been using that for doing quick edits to java or C++ code when I didn't have the full IDE running and didn't want to wait for it to open up. ","pontos":0},{"corpo":"The Coding Horror article actual got me thinking about this as well. Generally, I large classes I will put a region around the member variables, constants, and properties to reduce the amount of text I have to scroll through and leave everything else outside of a region. On forms I will generally group things into \"member variables, constants, and properties\", form functions, and event handlers. Once again, this is more so I don't have to scroll through a lot of text when I just want to review some event handlers. ","pontos":0},{"corpo":"If I may, I would like to expand on this question: Is there a single source for non-legal breakdowns of the major software licenses? ","pontos":1},{"corpo":"How to get the DATE portion of a DATETIME field in MS SQL Server: One of the quickest and neatest ways to do this is using DATEADD(dd, DATEDIFF( dd, 0, @DAY ), 0) It avoids the CPU busting \"convert the date into a string without the time and then converting it back again\" logic. It also does not expose the internal implementation that the \"time portion is expressed as a fraction\" of the date. Get the date of the first day of the month DATEADD(dd, DATEDIFF( dd, -1, GetDate() - DAY(GetDate()) ), 0) Get the date rfom 1 year ago DATEADD(m,-12,DATEADD(dd, DATEDIFF( dd, -1, GetDate() - DAY(GetDate()) ), 0)) ","pontos":2},{"corpo":"Can you check the permissions for your Network Service account? Specifically make sure they have the \"Act as part of the OS\" permission. If I'm reading the error message correctly, it looks like the NT AUTHORITY\\NETWORK SERVICE account failed to execute as a logged on user. It doesn't look like it ever got to the query, looks like it's failing in the Windows authentication portion, so never gets to the SQL authentication piece. You might also check the Security Event Log in Windows. If it is an authentication problem, there might be additional information logged by the OS. ","pontos":0},{"corpo":" Should I just do it when I'm going to use it? I would recommend that you only retrieve the data when you are going to use it. If you are not going to need it, there is no reason to waste resources by retrieving it in Page_Load. If you are going to need it multiple times throughout the page load, consider saving the query results to a private variable or collection so that the same data can be reused multiple times throughout the page load. Am I opening a new connection when I create a new instance? Asp.net handles connection pooling, and opens and closes connections in an efficient way. You shouldn't have to worry about this. One other thing to consider from a performance perspective is to avoid using Datasets and TableAdapters. In many cases, they add extra overhead into data retrieval that does not exist when using Linq to Sql, Stored Procedures or DataReaders. ","pontos":2},{"corpo":"I edit a lot of documents in LaTeX, so I use SVN to store the tex files and images and so on. Handy for doing Diffs, and hopefully will save me if I have a disaster. ","pontos":3},{"corpo":"This was the solution I came up with http://sourceforge.net/projects/sshtools/ (most error handling omitted for clarity). This is an excerpt from my blog SshClient ssh = new SshClient(); ssh.connect(host, port); //Authenticate PasswordAuthenticationClient passwordAuthenticationClient = new PasswordAuthenticationClient(); passwordAuthenticationClient.setUsername(userName); passwordAuthenticationClient.setPassword(password); int result = ssh.authenticate(passwordAuthenticationClient); if(result != AuthenticationProtocolState.COMPLETE){ throw new SFTPException(\"Login to \" + host + \":\" + port + \" \" + userName + \"/\" + password + \" failed\"); } //Open the SFTP channel SftpClient client = ssh.openSftpClient(); //Send the file client.put(filePath); //disconnect client.quit(); ssh.disconnect(); ","pontos":20},{"corpo":"Unfortunately, Subversion is case-sensitive. This is due to the fact that files from Subversion can be checked out on both case-sensitive file systems (e.g., *nix) and case-insensitive file systems (e.g., Windows, Mac). This script may help you avoid problems when you check in files. If it doesn't solve your problem, my best suggestion is to write a little script to make sure that all extensions are lowercase and run it every time before you check in/check out. It'll be a PITA, but maybe your best bet. ","pontos":17},{"corpo":"hm. I might have some homebrew available for it somewhere I could check, but for now: At our company, we basically gave up on this issue and implemented an (unfortunately win only) ActiveX solution: http://www.chestysoft.com/ximage/default.asp. /mp ","pontos":3},{"corpo":"I personally would perhaps question why each of the types need to have a static method before even thinking further.. Why not create a utlity class with the static methods that they need to share? (e.g. or In my experience with these sort of \"roadblocks\" the problem is not the limitations of the language, but the limitations of my design.. ","pontos":2},{"corpo":"During my final semester in school I took two classes that each had a large, time-consuming project due at the end of the semester. They both also required several long-ish papers throughout the semester. I made heavy use of SVN for both classes to track every change I made to every paper and project. I'm more of a \"write it all at once\" kind of guy when it comes to writing, and tend to lose my train of thought if I try to spread the process over multiple sessions. Being able to diff the latest revisions of my papers made it much easier for me to get back on track. ","pontos":5},{"corpo":"You can use a ComboBox with the DropDownStyle property set to DropDownList and SelectedIndex to 0 (or whatever the default item is). This will force always having an item from the list selected. If you forget to do that, the user could just type something else into the edit box part - which would be bad :) ","pontos":2},{"corpo":"Certainly, but the exact product may be dependent upon the VCS you are using. What you might want to do, is have a a few different branches, and migrate up as you progress. E.g., Development -> Stable-Dev -> Beta -> Production. You can then simply auto-update to the latest version of Stable-Dev and Beta for your testers, and always be able to deploy a new Production version at the drop of a hat. ","pontos":1},{"corpo":"Are you looking for polymorphic behavior? Then you'll want the interface and normal constructor. What is unintuitive about calling a constructor? If you don't need polymorphism (sounds like you don't use it now), then you can stick with your static methods. If these are all wrappers around a vendor component, then maybe you might try to use a factory method to create them like VendorBuilder.GetVendorThing(\"A\") which could return an object of type IVendorWrapper. ","pontos":0},{"corpo":"Anything you can do with cvs can be done with the command line, and I am pretty sure svn is the same. Just work out the functionality you want and stick it in a shell script or a command file. ","pontos":1},{"corpo":"Unless you are willing to duplicate the code in the xref proc, there is no way to avoid using a cursor. ","pontos":1},{"corpo":"You can't overload methods by varying just the return type. You can use different names: static AObject GetAObject(string id); static BObject GetBObject(string id); Or you can create a class with casting operators: class AOrBObject { string id; AOrBObject(string id) {this.id = id;} static public AOrBObject RetrieveByID(string id) { return new AOrBObject(id); } public static AObject explicit operator(AOrBObject ab) { return AObjectQuery(ab.id); } public static BObject explicit operator(AOrBObject ab) { return BObjectQuery(ab.id); } } Then you can call it like so: var a = (AObject) AOrBObject.RetrieveByID(5); var b = (BObject) AOrBObject.RetrieveByID(5); ","pontos":2},{"corpo":"You are not crazy. It is used internally and not even stored in the database. I wondered the same thing when I first started using FogBugz, but found a forum entry to answer my question. As of today, I still don't think they have implemented it. Jump over to FogCreek and submit a request, if you would like to make it editable. \"Description\" missing from Project? How to Edit a Project Description ","pontos":8},{"corpo":"The only two I have experience with are SVN and Mercurial. For Mercurial, you specify which branch you want it to update from (let's say default) and then whenever you merge a branch into default, you can just have the server run: hg update Which updates your repository to the latest version of the branch you set it to. SVN is the same concept, you only check out which branch you want initially svn co http://host/repository/branchname/ then you have your server update that with a cron job, ala svn up In theory though, any VCS that supports branching (all the good ones do : git, mercurial, SVN, etc...), should be able to do something similar to this. ","pontos":1},{"corpo":"@Arcturus: ... clog up your memory and make your application really slow when they are not garbage collected. That's blindingly obvious, and I don't disagree. However: ...you are leaking memory to object that you no longer use... because there is a reference to them. \"memory is allocated to a program, and that program subsequently loses the ability to access it due to program logic flaws\" (Wikipedia, \"Memory leak\") If there is an active reference to an object, which your program can access, then by definition it is not leaking memory. A leak means that the object is no longer accessible (to you or to the OS/Framework), and will not be freed for the lifetime of the operating system's current session. This is not the case here. (Sorry to be a semantic Nazi... maybe I'm a bit old school, but leak has a very specific meaning. People tend to use \"memory leak\" these days to mean anything that consumes 2KB of memory more than they want...) But of course, if you do not release an event handler, the object it's attached to will not be freed until your process' memory is reclaimed by the garbage collector at shutdown. But this behaviour is entirely expected, contrary to what you seem to imply. If you expect an object to be reclaimed, then you need to remove anything that may keep the reference alive, including event handlers. ","pontos":0},{"corpo":"I use revision control for just about all of my documents for any purpose. I'm using Mercurial, so setting up a new repository in a given directory is a matter of a simple \"hg init\", which I found much less of a hassle than setting up a new Subversion repository. I've also found that RCS is great in any situation where you need to sync files - I'm using that now instead of rsync for all of my syncing needs. It's also easier to make backups - cloning a repository to another location/machine/disk means I can just push the changes to that location, which is even easier with a default push repository. If you don't modify in the remote repo, then you don't even need to worry too much about setting that up other than the default. One of the nicest things for me is that I can have syncing, backups or whatever on any system that I have SSH access to. (Well, if they'd install mercurial for me at Uni, then I could!) ","pontos":1},{"corpo":"If I were you I would try to avoid any statics. IMHO I always ended up with some sort of synchronization issues down the road with statics. That being said you are presenting a classic example of generic programming using templates. I will adopt the template based solution of Rob Copper presented in one of the posts above. ","pontos":5},{"corpo":"Yes, I have a doc directory in git. I contains a todo list, a calendar and a few other documents. ","pontos":0},{"corpo":"I found the answer here: http://www.themssforum.com/SVCS/Unable-execute/ Apperently there was something wrong with the login for 'NT AUTHORITY\\NETWORK SERVICE' and it wouldn't run the jobs it owned properly. Anyone understand why this might have happened? ","pontos":1},{"corpo":"if ($entry.EntryType -eq \"Error\") Being Object Oriented, you want to test the property in question with one of the standard comparison operators you can find here. I have a PS script watching logs remotely for me right now - some simple modification should make it work for you. edit: I suppose I should also add that is a cmdlet built for this already if you don't want to unroll the way I did. Check out: man Get-EventLog Get-EventLog -newest 5 -logname System -EntryType Error ","pontos":0},{"corpo":"Yes I know that in the old days Memory Leaks are an entirily different subject. But with managed code, new meaning to the term Memory Leak might be more appropiate... Microsoft even acknowledges it to be a memory leak: Why Implement the WeakEvent Pattern? Listening for events can lead to memory leaks. The typical technique for listening to an event is to use the language-specific syntax that attaches a handler to an event on a source. For instance, in C#, that syntax is: source.SomeEvent += new SomeEventHandler(MyEventHandler). This technique creates a strong reference from the event source to the event listener. Ordinarily, attaching an event handler for a listener causes the listener to have an object lifetime that influenced by the object lifetime for the source (unless the event handler is explicitly removed). But in certain circumstances you might want the object lifetime of the listener to be controlled only by other factors, such as whether it currently belongs to the visual tree of the application, and not by the lifetime of the source. Whenever the source object lifetime extends beyond the object lifetime of the listener, the normal event pattern leads to a memory leak: the listener is kept alive longer than intended. We use WPF for a client app with large ToolWindows that can be dragged dropped, all the nifty stuff, and all compatible with in a XBAP.. But we had the same problem with some ToolWindows that weren't garbadge collected.. This was due to the fact that it was still dependent on event listeners.. Now this might not be a problem when you close your window and shut down your app. But if you are creating very large ToolWindows with a lot of commands, and all these commands gets re-evaluated over and over again, and people must use your application all day long.. I can tell you.. it really clogs up your memory and response time of your app.. Also, I find it much easier to explain to my manager that we have a memory leak, than explaining to him that some objects are not garbadge collected due to some events that needs cleaning ;) ","pontos":2},{"corpo":"Just use TortoiseSVN, and you can live even without knowing actual Subversion commands... But that's bad. Luckily there will always be a great opportunity to learn them by heart  when your priceless repository first gets corrupted. Yes, it happens. ","pontos":0},{"corpo":"Profiler may seem like a \"needle in a haystack\" approach, but it may turn up something useful. Try running it for a couple of minutes while the databases are under typical load, and see if any queries stand out as taking way too much time or hogging resources in some way. While a situation like this could point to some general issue, it could also be related to some specific issue with one or two sites, which mess things up enough in certain circumstances to cause very poor performance across the board. ","pontos":2},{"corpo":"Quick answer: matlab -wait -nosplash -nodesktop -r waitHello In Matlab 7.1 (the version I have) there is an undocumented command line option -wait in matlab.bat. If it doesn't work for your version, you could probably add it in. Here's what I found. The command at the bottom that finally launches matlab is (line 153): start \"MATLAB\" %START_WAIT% \"%MATLAB_BIN_DIR%\\%MATLAB_ARCH%\\matlab\" %MATLAB_ARGS% The relevant syntax of the start command (see \"help start\" in cmd.exe) in this case is: start [\"window title\"] [/wait] myprogram.exe args ... A bit higher, among all of the documented command line options, I found (line 60): ) else if (%opt%) == (-wait) ( set START_WAIT=/wait ) else ( So specifying -wait should do what you want, as long as you're also exiting matlab from your script (otherwise it will wait for you to terminate it interactively). ","pontos":19},{"corpo":"As Yaakov says, run profiler for a few minutes under typical load and save the results to a table which will allow you to run queries against the results making it much easier to spot any resource hogging queries. ","pontos":3},{"corpo":"As I recall, running a website uses the Network User account, which may not have permission to view local printers. There was a page on MSDN that said how you can impersonate another user that might have access to the printers, but I've not been able to find it. Edit: I posted too soon. Here's the page. HTH ","pontos":3},{"corpo":"To answer the original question - there are various ways to do this, but the following would be the simplest. If you already have a handle to the child node that you want to remove, i.e. you have a JavaScript variable that holds a reference to it: myChildNode.parentNode.removeChild(myChildNode); Obviously, if you are not using one of the numerous libraries that already do this, you would want to create a function to abstract this out: function removeElement(node) { node.parentNode.removeChild(node); } EDIT: As has been mentioned by others: if you have any event handlers wired up to the node you are removing, you will want to make sure you disconnect those before the last reference to the node being removed goes out of scope, lest poor implementations of the JavaScript interpreter leak memory. ","pontos":61},{"corpo":"Some differences (that are more substantial than syntactical) that suitably catch me out sometimes: VB.NET does not have anonymous delegates Unsafe code blocks aren't in VB.NET ","pontos":3},{"corpo":"How about this: Spawning the next generation of hackers by Nat Torkington. ","pontos":1},{"corpo":"I love C# to death, but I envy VB.NET's optional parameters. Office automation in C# is so very, very painful. ","pontos":3},{"corpo":"YellowPages.com and Penny Arcade are the biggest that I've heard of off the top of my head. Of course, lots of enterprises are using it for internal apps. As far as scaling goes, liberal caching is the secret no matter what your language/framework. ","pontos":2},{"corpo":"If you talk with almost anyone running a high traffic enterprise site, most of them will tell you the same thing, the language you choose if handled properly will never be your problem it will always come down to IO. If you look at sites like twitter, sure they had issues. But they already admitted it was cause things were not scaled properly. Since they have implemented the changes they did things have been cruising along. The only thing stopping us here where I work is no one knows ruby and doesn't really have much time to learn. ","pontos":3},{"corpo":"I'm still not sold. Twitter has had massive outages (3 days on one episode!). Up to a point it was blamed on the difficulties behind scaling RoR: read here. /mp ","pontos":-7},{"corpo":"I've had to interview people for a few C# positions and this is my general advice for VB.Net developers interviewing for a C# position: Make sure you are clear that you have been working VB.Net. This seems obvious but is something that apparently isn't (in my experience). Try to give a code sample, if possible. I've seen some horrible VB.Net (and C#) written by VB programmers who didn't seem to learn much in the transition to .Net. Be able to write in C# during the interview, if asked. I know there aren't many real differences between the two, but I don't want to pay you to learn the new syntax. For your specific question: I've asked that type of question before and what I wanted to hear about was how the underlying system and framework were the same. If possible, talk about garbage collection, IDisposable, finalizers, the dangers of unsafe code blocks, stack vs heap, etc. All the kind of stuff to show that you really understand the intricacies of the .Net framework. Right or wrong, the heritage of VB brings with it an expectation of a lack of understand of lower level programming and windows in general (which, ironically enough, a c++ developer would have of a c# developer... and so on). Lastly, how you frame your experience can make a world of difference. If you position yourself as a .Net developer, rather than VB.Net or C#, the stupid, pseudo-religious, banter may not enter the conversation. This of course requires that you actually know both VB.Net and C# at the time of the interview, but that's a good policy regardless. The truth of the matter is that if you find that the person interviewing you writes you off simply because you've previously been developing in VB.Net, it's likely not going to be a place you want to work at anyway. ","pontos":9},{"corpo":"When asking for help diagnosing compilation problems, it often helps to post the offending source code :) These errors really mean that the specified name conflicts with another and the compiler cannot resolve this. It does look a little odd tho.. ","pontos":0},{"corpo":" Good suggestion, but unfortunately they just return various shades of grey, when currently I'm running my application with the style CMFCVisualManagerOffice2007::Office2007_LunaBlue CMFCVisualManagerOffice2007::GetTabFrameColors - the clrFace output param is grey? Perhaps they're all masks on top of a single base hue for each theme? Assuming you can determine which color scheme is in effect with CMFCVisualManagerOffice2007::GetStyle(), perhaps you can figure out what that hue is and then do some masking with the GetxxxColor() methods. ","pontos":0},{"corpo":"I upmodded Mark's post about Toad Data Modeler and wanted to point out that they have a beta version that is fully functional and free. The only downsides are the occasional bug and built in expiration (typically around the time a new beta is available), but for this poor bloke it does wonders until I can get my boss to chip in for a license. ","pontos":0},{"corpo":"Take one error (like ArrayList) and replace the type with the full-qualified name (I'm not sure, but I guess here: System.Collection.ArrayList). If the error vanishes, you really have a resolving conflict. If not, it's something else. If all solutions build \"fine\" with these errors, I suggest cleaning your projects. Delete all compiled stuff (dll, pdb, whatsoever), also shadow cached ones. Maybe it compiles because it uses an old version of something. ","pontos":0},{"corpo":"Yes, a previous attachment wasn't unattached properly, or it was attached manually. Go in to Management Studio connect to the database, and disconnect the long database name that looks like a file path. Then try again it should work. ","pontos":0},{"corpo":"Could alter some of the shortest path algorithms, like Dijkstra's, to weight each path by cost but also keep track of time and stop going along a certain path if the time exceeds your threshold. Should find the cheapest that gets you in under your threshold that way ","pontos":7},{"corpo":"I have a set of Powershell scripts that do all of this for me. Script 1: Build - this one is simple, it is mostly handled by a call to msbuild, and also it creates my database scripts. Script 2: Package - This one takes various arguments to package a release for various environments, such as test, and subsets of the production environment, which consists of many machines. Script 3: Deploy - This is run on each individual machine from within the folder created by the Package script (the Deploy script is copied in as a part of packaging) From the deploy script, I do sanity checks on things like the machine name so things don't accidentally get deployed to the wrong place. For web.config files, I use the appSettings file=\"Local.config\" feature to have overrides that are already on the production machines, and they are read-only so they don't accidentally get written over. The Local.config files are not checked in, and I don't have to do any file switching at build time. [Edit] The equivalent of appSettings file= for a config section is configSource=\"Local.config\" ","pontos":9},{"corpo":"If I knew I only had to deal with 5 cities, in a predetermined order, and that there were only 3 routes between adjacent cities, I'd brute force it. No point in being elegant. If, on the other hand, this were a homework assignment and I were supposed to produce an algorithm that could actually scale, I'd probably take a different approach. ","pontos":3},{"corpo":"I see where you're coming from but it's all a bit moot isn't it. You can't send anything but rendered content to the browser, and you have to do it all in one go (AJAX aside). There's no value from what you are suggesting (from what I can see) as even if you build it tree-like, you're still only building a page which is sent wholesale to the client. ","pontos":-1},{"corpo":"Can you write a unit test against your FooRepository class just using it as a POJO. If that works as expected then I'm not familiar with any reason why it would function differently inside a container. I suspect there is something else going on and it will probably be easier to debug if you test it as a POJO. ","pontos":1},{"corpo":"I've not had experience with Telerik but we had a very painful experience with Infragistics and I'd recommend that you exhaust all avenues before using their products, especially in a Web Application. To be specific, here are some issues we had: Client side scripting caused issues since even simple grids are not rendered as html tables but rather javascript arrays of arrays. While they do offer a bloated client scripting library, it was sparsely documented and overkill most of the time. Infragistics releases a new version of its product 3 times a year. In a development cycle that means you have to \"update\" in a pattern that is out of whack with your actual release cycle. In our case we worked on the project for much longer than 4 months. Infragistics client libraries were thrown off by MasterPages. This should be fixed but I'm sure any time there's a new MS technology e.g. UpdatePanels/MVC, you have some additional complexity getting it to work with Infragistics (I assume most 3rd party libraries too) Overkill. 3rd party tools are nice but often they are \"one size fits all\" which means if you've got a simple task (in our case it was a grid that users needed to \"re-order\") and you use one of these libraries, you're getting a rocket launcher where a simple rifle will do. All the unnecessary features just add complexity and pain - especially later on when you start having to do unanticipated things with the project. ","pontos":1},{"corpo":"The MySQL manual page on prepared statements provides lots of information (which should apply to any other RDBMS). Basically, your statement is parsed and processed ahead of time, and the parameters are sent separately instead of being handled along with the SQL code. This eliminates SQL-injection attacks because the SQL is parsed before the parameters are even set. ","pontos":3},{"corpo":"Within the FormClosing event handler could you not interrogate the keyboard buffer (do you even have access to this?) to se if [Alt] + [F4] was pressed, cancel if true, continue if not? ","pontos":0},{"corpo":"Do you need to turn /clr on for the entire project? Could you instead turn it on only for a small select number of files and be very careful how you include managed code? I work with a large C++/MFC application and we have found it very difficult to use managed C++. I love C# and .NET but managed C++ has been nothing but a headache. Most of our problems happened with .NET 1.0/1.1 ... maybe things are better now. ","pontos":2},{"corpo":"Would FormClosing be called even when you're programatically closing the window? If so, you'd probably want to add some code to allow the form to be closed when you're finished with it (instead of always canceling the operation) ","pontos":2},{"corpo":"in layman terms: if a prepared statement is sent then the DB will use a plan if it is available, it doesn't not have to recreate a plan every time this query is sent over but only the values of the params have changed. this is very similar to how procs work, the additional benefit with procs is that you can give permission through procs only and not to the underlying tables at all ","pontos":0},{"corpo":"You can't. Pro*C only knows #if and #include. My best advice would be to preprocess the file as part of your build process to remove stuff Pro*C won't like. Something like grep -v -E '^#(warning|pragma|define)' unchangeable.h unchangeable.pc.h My other advice would be to avoid the abomination which is Pro*C, but I'm guessing you're stuck with it... ","pontos":0},{"corpo":" You are most likely being set up to fail. Welcome to the industry. I disagree - so long as he creates the document, the worst that can happen is that it gets forgotten by everyone. If other people have issues with the content, then you can ask them to update it to show what they'd prefer. That way it's off your plate, and the others have the responsibility to justify their changes. ","pontos":1},{"corpo":"My favourites are: Stack Overflow TWiT Security Now I like listening to John C. Dvorak on TWiT, though I've never tried his other podcasts. He really knows his stuff and is frequently funny, but sometimes he's just an annoying old grump. I used to listen to PaulDotCom Security Weekly, but they talk an awful lot about penetration testing and not so much about other aspects of computer security. ","pontos":1},{"corpo":"No-one did before, so I'll point to the trivial solution: Have you already de-installed the Service Pack and re-installed it again (or the whole framework)? Edit: @Kev: Easy explanation: He said the update works on one machine, but not on the other. I had similar problems in the past and re-installing helped to solve some of them. And it is trivial to do. That's my approach: 1. trivial 2. easy 3. headache You are right, on productive systems you must be careful, but that's his decision. And because it is a virtual server, maybe it is easy for him to copy it and try as a test environment first. ","pontos":-1},{"corpo":"I don't think you really need obfuscation on .Net any more (see another response) I wouldn't consider Vault, SVN is really the market leader at the moment (and free). Git is looking pretty promising but currently is command line only with a steep learning curve. MSBuild beats NAnt for .Net 2 or 3.5 CC.Net is excellent. ","pontos":0},{"corpo":"I don't really understand your question because i really didn't see one. But i'll do my best to infer two: to change your keyboard layout, check this forum post on ubuntu forums and to change the timezone, check this forum post. ","pontos":0},{"corpo":"As it turns out, one of the things that FxCop does is identify unused bits of code, but it sometimes misses stuff. However, your best bet would likely be ReSharper. ","pontos":4},{"corpo":"Why don't you just put the images in an array? ","pontos":3},{"corpo":" Resharper (Agree it sucks you have to pay extra to get this, but well work the money) GhostDoc (Takes away any excuse for not having comments in your code) PowerCommands for VS 2008 (Forgot I even had this installed because it just adds a the little things that should have been there all along) ","pontos":0},{"corpo":"WatiN is excellent. I inherited Mercury Quicktest for functional testing a while back. 30k for the licences and it was truly awful. We never got the same results twice (running on the exact same application). Their support was terrible. It stored tests as collections of encrypted binaries in folders called useful things like Action1 and Action2, so we couldn't source control it properly. No idea whether HP have improved it since they bought out Mercury, but why bother when WatiN is so good? ","pontos":0},{"corpo":"The general rule of thumb is: do not use triggers. As mentioned before, they add overhead and complexity that can easily be avoided by moving logic out of the DB layer. Also, in MS SQL Server, triggers are fired once per sql command, and not per row. For example, the following sql statement will execute the trigger only once. UPDATE tblUsers SET Age = 11 WHERE State = 'NY' Many people, including myself, were under the impression that the triggers are fired on every row, but this isn't the case. If you have a sql statement like the one above that may change data in more than one row, you might want to include a cursor to update all records affected by the trigger. You can see how this can get convoluted very quickly. ","pontos":0},{"corpo":"This is broad problem, so let's start by asking some troubleshooting questions: Based on your description, the ASP.NET runtime is not catching your request and processing the aspx files. You may need to register the asp.net pipeline with IIS again using ASPNET_REGIIS -i. Have you made sure that the app_offline.htm file has been removed from the directory of the application? I have had this happen before after an update. Have you setup fiddler for instance to follow the request to see what is exactly being requested? Make sure ASP.NET is enabled in the IIS Administration Console under \"Web Service Extensions.\" Make sure everything is set to allowed for your different versions of the framework. Well, let's start with those and hopefully we can guide you to the problem. ","pontos":4},{"corpo":"All I've read about Access 2000 -> SQL Server 2005 is that the upsizing wizard isn't supported. If only the inserts and updates aren't functioning, it sounds like a permissions issue. Make sure the sql server login you are using in your connection string has read/write permission on your database. Please avoid using the \"sa\" account for this purpose! ","pontos":0},{"corpo":"I'm not sure about that particular combination being supported, but have you tried setting the compatibilty mode for the database to sql server 2000. Maybe that will resolve your issues. Edit: To do this run the following SQL: EXEC sp_dbcmptlevel Name_of_your_database, 80; More details here: http://blog.sqlauthority.com/2007/05/29/sql-server-2005-change-database-compatible-level-backward-compatibility/ ","pontos":0},{"corpo":"I have not had this exact error with .NET 3.5 SP1, but have seen similar occur in the past. Typically it can be resolved by opening a command prompt, going to the appropriate .NET folder and running ASPNET_REGIIS -i. In the case of .NET 3.5 there wasn't an update to the main bits of the framework, so you'd actually go to the .NET 2.0 folder, which on my machine can be found at: \\Windows\\Microsoft.Net\\framework\\v2.0.50727 Running the ASPNET_REGIIS -i will re-register all the ASP.NET libraries with IIS, and should be the equivalent of a re-install of the framework on a given machine (as far as IIS is concerned) ","pontos":0},{"corpo":" If only the inserts and updates aren't functioning, it sounds like a permissions issue. Make sure the sql server login you are using in your connection string has read/write permission on your database. Please avoid using the \"sa\" account for this purpose! We wanted to use a generic apps account but that login \"could not find\" any of the stored procedures even though they existed and the login has explicit permissions to run them (and was also tested successfully, as that user, in SQL Management Studio). It wasn't until we granted that login \"sa\" privileges that we could actually access the database at all through the application. but have you tried setting the compatibilty mode for the database to sql server 2000. I'm not really sure how this is done. Could you explain? Also of note, if we upgrade the app to Access 2003, everything works fine. Unfortunately, our IT dept does not want to upgrade everyone from Office 2000 to 2003, so this is not an option. Thanks for your help. ","pontos":0},{"corpo":"The Database Publishing Wizard's generated scripts usually need to be tweaked since it sometimes gets the order wrong of table/procedure creation when dealing with constraints. What I do is first backup the database, then run the script, and if I get an error, I move that query to the end of the script. Continue restoring the database and running the script until it works. ","pontos":1},{"corpo":"Ian's answer has a lot of weight. You could buy all those books and read them all and know nothing about web development. What you really need to do is start with something that is not nearly as big as Stack Overflow. Start with your personal site. Read some web dev/css articles on a list apart. Learn about doctypes and why to use them. Add some css and change the colors around. Go over to quirksmode and peruse the site. Add some js. Follow some links on Crockfords site. You will probably stumble across his awesome video lectures, which you should watch. Then after that go back to all the js that you wrote and rewrite it. Then pick a server side language that you want to learn. Python is pretty easy, but it really doesn't matter what you pick. Then come back and integrate all those together in your site. At this point you will at least be getting started with web development and will have worked with several different technologies. EDIT: I forgot to mention. READ BOOKS. Many developers that I have worked with in the past have gotten through their career without really advancing after a certain point. I could be totally wrong, but I attribute it to not reading enough books and relying on using their same bad code over and over. ","pontos":3},{"corpo":"As a junior programmer myself, I thought that Id reveal what it was like when I found myself in a similar situation to your junior developer. When I first came out of uni, I found that it had severly un equipped me to deal with the real world. Yes I knew some JAVA basics and some philosophy (don't ask) but that was about it. When I first got my job it was a little daunting to say the least. Let me tell you I was probably one of the biggest cowboys around, I would hack together a little bug fix / algorithm with no comments / testing / documentation and ship it out the door. I was lucky enough to be under the supervision of a kind and very patient senior programmer. Luckily for me, he decided to sit down with me and spend 1-2 weeks going through my very hacked togethor code. He would explain where I'd gone wrong, the finer points of c and pointers (boy did that confuse me!). We managed to write a pretty decent class/module in about a week. All I can say is that if the senior dev hadn't invested the time to help me along the right path, I probably wouldn't have lasted very long. Happily, 2 years down the line, I would hope that some of my collegues might even consider me an average programmer. Take home points Most Universities are very bad at preparing students for the real world Paired programming really helped me. Thats not to say that it will help everyone but it worked for me. ","pontos":3},{"corpo":"I did some searching, what about tbookdtd? It's downloadable here but it hasn't been active since 2005. It appears to convert the xml to Latex, into PDF. ","pontos":0},{"corpo":"Gears might provide the client-side persistent data storage you need. There isn't a terribly good way of not exposing your source code, though. You could obfuscate it but that only helps somewhat. I've done simple apps like this for stuff like a Sudoku solver. ","pontos":1},{"corpo":" Using those two exception handlers should work. Why \"should?\" The events are not raised using the below: extern \"C\" void wWinMainCRTStartup(); // managed entry point [System::STAThread] int managedEntry( void ) { FinalExceptionHandler^ handler = gcnew FinalExceptionHandler(); Application::ThreadException += gcnew System::Threading::ThreadExceptionEventHandler( handler, FinalExceptionHandler::OnThreadException); AppDomain::CurrentDomain- UnhandledException += gcnew UnhandledExceptionEventHandler( handler, FinalExceptionHandler::OnAppDomainException); wWinMainCRTStartup(); return 0; } // final thread exception handler implementation void FinalExceptionHandler::OnThreadException( Object^ /* sender */, System::Threading::ThreadExceptionEventArgs^ t ) { LogWrapper::log- Error( \"Unhandled managed thread exception.\", t- Exception ); } // final appdomain exception handler implementation void FinalExceptionHandler::OnAppDomainException(System::Object ^, UnhandledExceptionEventArgs ^args) { LogWrapper::log- Error( \"Unhandled managed appdomain exception.\", (Exception^)(args- ExceptionObject) ); } BOOL CMyApp::InitInstance() { throw gcnew Exception(\"test unhandled\"); return TRUE; } ","pontos":0},{"corpo":"Stored procedures. If an error slips or the logic changes a bit, you do not have to recompile the project. Plus, it allows access from different sources, not just the one place you coded the query in your project. I don't think it is harder to maintain stored procedures, you should not code them directly in the database but in separate files first, then you can just run them on whatever DB you need to set-up. ","pontos":13},{"corpo":" Advantages for in Code: Easier to maintain - don't need to run a SQL script to update queries Easier to port to another DB - no procs to port Actually, I think you have that backwards. IMHO, SQL in code is pain to maintain because: you end up repeating yourself in related code blocks SQL isn't supported as a language in many IDE's so you have just a series of un-error checked strings performing tasks for you changes in a data type, table name or constraint are far more prevalent than swapping out an entire databases for a new one your level of difficulty increases as your query grows in complexity and testing an inline query requires building the project Think of Stored Procs as methods you call from the database object - they are much easier to reuse, there is only one place to edit and in the event that you do change DB providers, the changes happen in your Stored Procs and not in your code. That said, the performance gains of stored procs is minimal as Stu said before me and you can't put a break point in a stored procedure (yet). ","pontos":44},{"corpo":"One of the suggestions from a Microsoft TechEd sessions on security which I attended, to make all calls through stored procs and deny access directly to the tables. This approach was billed as providing additional security. I'm not sure if it's worth it just for security, but if you're already using stored procs, it couldn't hurt. ","pontos":4},{"corpo":"This may be a bit heartless, but the way you describe the situation it sounds like you need to fire this guy. Or at least make it clear: refusing to follow house development practices (including writing tests) and checking in buggy code that other people have to clean up will eventually get you fired. ","pontos":0},{"corpo":"Nihilogic (not my site) does a lot of stuff with Javascript. They even have several games that they've made in Javascript. I've also seen a neat roguelike game made in Javascript. Unfortunately, I can't remember what it was called... ","pontos":2},{"corpo":"If you're talking about scripts created by a user that will be run from that users crontab, I typically put those in either a bin or scripts folder in the home directory, or if they're intended to be shared between users, a /usr/local/scripts directory. ","pontos":18},{"corpo":"Just to clarify. The last (4th) point given by Dale was the problem. During the installation of SP1 the Status for ASP.NET and WebDAV became set to Prohibited under Web Service Extensions. Why the installation of SP1 changed this setting on one server and not the other is a mystery that I wouldn't mind (but not expect) an answer to... The second link provided by CodingTheWheel also had the answer so I'm also going to mark this as an answer. ","pontos":0},{"corpo":"I fall on the code side. We build data access layer that's used by all all the apps (both web and client), so it's DRY from that perspective. It simplifies the database deployment because we just have to make sure the table schema's are correct. It simplifies code maintenance because we don't have to look at source code and the database. I don't have much problem with the tight coupling with the data model because I don't see where it's possible to really break that coupling. An application and its data are inherently coupled. ","pontos":16},{"corpo":"The question is who requires you to provide the stats. If it's non-technical people, fake the stats. By \"fake\", I mean \"provide any inevitably meaningless, but real numbers\" of the kind you mentioned. If it's technical people without a CS background, they ought to be told about the halting problem, which is undecidable and is simpler than counting and classifying the remaining bugs. There's a lot of metrics and tools regarding software quality (code coverage, cyclomatic complexity, coding guidelines and tools enforcing them, etc.). In practice, what works is automating as much tests as possible, having human testers do as many tests that weren't automated as possible, and then pray. ","pontos":2},{"corpo":"Most of the agile methodologies address this dilemma pretty clearly. You can't test everything. Neither can you test it infinite number of times before you release. So the procedure is to rely on the risk and likelihood of the bug. Both risk and likelihood are numerical values. The product of both gives you a RPN number. If the number is less than 15 you ship a beta. If you can bring it down to less than 10 you ship the product and push the bug to be fixed in a future releasee. How to calculate risk ? If its a crash then its a 5 If its a crash but you can provide a work around then its a number less than 5. If the bug reduces the functionality then its a 4 How to calculate likelihood ? can you re-produce it every time you run, its a 5. If the work around provided still causes it to crash then less than 5 Well, I am curious to know whether anyone else using this scheme and eager to know their milage on this. ","pontos":1},{"corpo":"Stored Procedures are MORE maintainable because: You don't have to recompile your C# app whenever you want to change some SQL You end up reusing SQL code. Code repetition is the worst thing you can do when you're trying to build a maintainable application! What happens when you find a logic error that needs to be corrected in multiple places? You're more apt to forget to change that last spot where you copy pasted your code. In my opinion, the performance security gains are an added plus. You can still write insecure/inefficient SQL stored procedures. Easier to port to another DB - no procs to port It's not very hard to script out all your stored procedures for creation in another DB. In fact - it's easier than exporting your tables because there are no primary/foreign keys to worry about. ","pontos":2},{"corpo":"@Keith Security? Why would sprocs be more secure? Stored procedures offer inherent protection from SQL Injection attacks. However, you're not completely protected because you can still write stored procedures that are vulnerable to such attacks (i.e. dynamic SQL in a stored proc). ","pontos":1},{"corpo":"I think you might want to look at Bacula (manual), which 'comes in the night and sucks the essence from your computers*'. It's a fairly powerful backup tool which should be able to help you manage a set of complex backup tools. *at least, that's what the user guide says :) ","pontos":20},{"corpo":"I'm currently using Backup2L and Rsync.net - I use it on ten Debian boxes (it's in the repository). It's self managing, so you tell it how many generations you want to keep and it prunes itself as time goes on. Mount the Rsync server via Fuse then use Backup2l to backup to the remote mount. It has pre and post hook scripts, so you can dump databases or whatever to include in the backup Andrew ","pontos":1},{"corpo":"There is an alternative called KDESVN which you might want to try. However, I have never used it, so I cannot vouch for it. ","pontos":1},{"corpo":"@Keith Security? Why would sprocs be more secure? As suggested by Komradekatz, you can disallow access to tables (for the username/password combo that connects to the DB) and allow SP access only. That way if someone gets the username and password to your database they can execute SP's but can't access the tables or any other part of the DB. (Of course executing sprocs may give them all the data they need but that would depend on the sprocs that were available. Giving them access to the tables gives them access to everything.) ","pontos":8},{"corpo":"Note that it is considered bad form for an application to completely prevent itself from closing. You should check the event arguments for the Closing event to determine how and why your application was asked to close. If it is because of a Windows shutdown, you should not prevent the close from happening. ","pontos":12},{"corpo":"C# myList string ().ForEach( delegate(string name) { Console.WriteLine(name); }); Anonymous delegates are not currently implemented in VB.Net, but both C# and VB.Net should be able to do lambdas: C# myList string ().ForEach(name = Console.WriteLine(name)); VB.Net myList(Of String)().ForEach(Function(name) Console.WriteLine(name)) As Grauenwolf pointed out the above VB won't compile since the lambda doesn't return a value. A normal ForEach loop as others have suggested is probably the easiest for now, but as usual it takes a block of code to do what C# can do in one line. Here's a trite example of why this might be useful: this gives you the ability to pass in the loop logic from another scope than where the IEnumerable exists, so you don't even have to expose it if you don't want to. Say you have a list of relative url paths that you want to make absolute: public IEnumerable String Paths(Func String formatter) { List String paths = new List String () { \"/about\", \"/contact\", \"/services\" }; return paths.ForEach(formatter); } So then you could call the function this way: var hostname = \"myhost.com\"; var formatter = f = String.Format(\"http://{0}{1}\", hostname, f); IEnumerable String absolutePaths = Paths(formatter); Giving you etc. Obviously there are better ways to accomplish this in this specfic example, I'm just trying to demonstrate the basic principle. ","pontos":4},{"corpo":" I am using a form as a popup dialog to display a progress bar and I do not want the user to be able to close it. If the user is determined to close your app (and knowledgeable) enough to press alt+f4, they'll most likely also be knowledgeable enough to run task manager and kill your application instead. At least with alt+f4 your app can do a graceful shutdown, rather than just making people kill it. From experience, people killing your app means corrupt config files, broken databases, half-finished tasks that you can't resume, and many other painful things. At least prompt them with 'are you sure' rather than flat out preventing it. ","pontos":11},{"corpo":"I believe the answer to you question is variadic functions. Edit: My answer is so sparse mainly because I am not a C programmer(although I am trying to go through the K R book right now). ","pontos":0},{"corpo":"@Terrapin - sprocs are just as vulnerable to injection attacks. As I said: Always parametrise all queries - never inline something from user input and you'll be fine. That goes for sprocs and dynamic Sql. I'm not sure not recompiling your app is an advantage. I mean, you have run your unit tests against that code (both application and DB) before going live again anyway. @Guy - yes you're right, sprocs do let you control application users so that they can only perform the sproc, not the underlying action. My question would be: if all the access it through your app, using connections and users with limited rights to update/insert etc, does this extra level add security or extra administration? My opinion is very much the latter. If they've compromised your application to the point where they can re-write it they have plenty of other attacks they can use. Sql injections can still be performed against those sprocs if they dynamically inline code, so the golden rule still applies, all user input must always be parametrised. ","pontos":2},{"corpo":"We started using CSLA because we thought it would help with our model layer. Was sort of overkill and mostly all we use now is the SmartDate class, just because we're already linked to the library. We thought the validation interface would really help us enforce business rules but it didn't work well with WCF and serialization (we're still stuck on version 2.0.3.0, so things might have changed). ","pontos":6},{"corpo":"I don't know if this will work for your particular problem, but I have been doing something similar using the shell-command-to-string function: (shell-command-to-string \"bash -c \\\"script-to-exec args\\\"\") So for example, we have existing scripts written in python which will mangle a file, so the above lets me invoke the script via emacs lisp. A quick google search found this page describing a system to write extensions in Python, so it seems feasible to do what you want... you will just have to see if anyone has written a similar framework for OCaml. ","pontos":4},{"corpo":"I am not a fan of stored procedures Stored Procedures are MORE maintainable because: * You don't have to recompile your C# app whenever you want to change some SQL You'll end up recompiling it anyway when datatypes change, or you want to return an extra column, or whatever. The number of times you can 'transparently' change the SQL out from underneath your app is pretty small on the whole You end up reusing SQL code. Programming languages, C# included, have this amazing thing, called a function. It means you can invoke the same block of code from multiple places! Amazing! You can then put the re-usable SQL code inside one of these, or if you want to get really high tech, you can use a library which does it for you. I believe they're called Object Relational Mappers, and are pretty common these days. Code repetition is the worst thing you can do when you're trying to build a maintainable application! Agreed, which is why storedprocs are a bad thing. It's much easier to refactor and decompose (break into smaller parts) code into functions than SQL into... blocks of SQL? You have 4 webservers and a bunch of windows apps which use the same SQL code Now you realized there is a small problem with the SQl code so do you rather...... change the proc in 1 place or push the code to all the webservers, reinstall all the desktop apps(clickonce might help) on all the windows boxes Why are your windows apps connecting directly to a central database? That seems like a HUGE security hole right there, and bottleneck as it rules out server-side caching. Shouldn't they be connecting via a web service or similar to your web servers? So, push 1 new sproc, or 4 new webservers? In this case it is easier to push one new sproc, but in my experience, 95% of 'pushed changes' affect the code and not the database. If you're pushing 20 things to the webservers that month, and 1 to the database, you hardly lose much if you instead push 21 things to the webservers, and zero to the database. More easily code reviewed. Can you explain how? I don't get this. Particularly seeing as the sprocs probably aren't in source control, and therefore can't be accessed via web-based SCM browsers and so on. More cons: Storedprocs live in the database, which appears to the outside world as a black box. Simple things like wanting to put them in source control becomes a nightmare. There's also the issue of sheer effort. It might make sense to break everything down into a million tiers if you're trying to justify to your CEO why it just cost them 7 million dollars to build some forums, but otherwise creating a storedproc for every little thing is just extra donkeywork for no benefit. ","pontos":179},{"corpo":"I tried it with a pojo and it seems to work. I had to modify your code a bit. I think your interfaces were a bit off, but I'm not sure. I assumed \"Foo\" was a concrete type, but if not I can do some more testing for you. I just wrote a main method to test this. I hope this helps! public static void main(String[] args){ FooRepository fooRepository = new FooRepositoryImpl(); fooRepository.delete(new Foo(\"Bar\")); } public class Foo { private String value; public Foo(String inValue){ super(); value = inValue; } public String toString(){ return value; } } public interface Repository E { public void delete(E entity); } public interface FooRepository extends Repository Foo { //other methods } public class AbstractRespository E implements Repository E { public void delete(E entity){ System.out.println(\"Delete-\" + entity.toString()); } } public class FooRepositoryImpl extends AbstractRespository Foo implements FooRepository { @Override public void delete(Foo entity){ //do something before deleting the entity System.out.println(\"something before\"); super.delete(entity); } } ","pontos":2},{"corpo":"Ah, vsprintf() was the thing I was missing. I can use this to pass the variable argument list directly to printf(). void DBG_PrintImpl(char * format, ...) { char buffer[256]; va_list args; va_start (args, format); vsprintf (buffer, format, args); printf(\"%s\", buffer); va_end (args); } Then wrap the whole thing in a macro. ","pontos":1},{"corpo":" you can enter commands into the search box by prefixing them with a > symbol. Wow, I didn't know that. Where do I find the list of possible commands? I never actually use the search box, I've remapped ctrl+F to incremental search, which is usually ctrl+I I find this much cooler than the normal search - give it a go, you might end up not caring about the search box anymore. ","pontos":1},{"corpo":"I had LOTS of issues with developing installers (and software in general) for terminal server. I hate that damn thing. Anyway, VS Setup Projects are just .msi files, and run using the Windows installer framework. This will drop a log file when it errors out, they're called MSIc183.LOG (swap the c183 for some random numbers and letters), and they go in your logged-in-user account's temp directory. The easiest way to find that is to type into the windows explorer address bar - once you're there have a look for these log files, they might give you a clue. Note - Under terminal server, sometimes the logs don't go directly into , but under numbered subdirectories. If you can't find any MSIXYZ.LOG files in there, look for directories called , , and so on, and look in those. If you find a log file, but can't get any clues from it, post it here. I've looked at more than I care to thing about, so I may be able to help ","pontos":2},{"corpo":"If you're trying to use curly brackets inside a String.Format expression... int foo = 3; string bar = \"blind mice\"; String.Format(\"{{I am in brackets!}} {0} {1}\", foo, bar); //Outputs \"{I am in brackets!} 3 blind mice\" ","pontos":111},{"corpo":"Have you got a valid doctype? Otherwise IE7 renders in quirks mode which is basically IE5.5 ","pontos":1},{"corpo":"Our company practised CSLA in some of its projects and some of the legacy projects remain to be CSLA. Other projects moved away from it because CSLA violated a plain and simple OOP rule: Single Responsibility Principle. CSLA objects are self-sustaining, e.g. they retrieve their own data, they manage their own behavior, they save themselves. Unfortunately this meant that your average CSLA object has at least three responsibilities -- representing the domain model, containing business rules, and containing data access definition (not the DAL, or data access implementation, as I previously stated/implied) all at the same time. ","pontos":6},{"corpo":"I have played around a little bit with Spidermonkey. It seems like it would at least be worth a look at in your situation. I have heard good things about Lua as well. The big argument for using a javascript scripting language is that a lot of developers know it already and would probably be more comfortable from the get go, whereas Lua most likely would have a bit of a learning curve. I'm not completely positive but I think that spidermonkey your 4 requirements. ","pontos":1},{"corpo":"Many mailers prefix a mail's subject with \"Re: \" when replying, if that prefix isn't already there. German Outlook instead prefixes with \"AW: \" (for \"AntWort\") if that prefix isn't already there. Unfortunately, these two behaviours clash, resulting in mail subjects like \"Re: AW: Re: AW: Re: AW: Re: AW: Lunch\". So I now have: :0f * ^Subject: (Antwort|AW): |sed -r -e '1,/^$/s/^(Subject: )(((Antwort: )|(Re: )|(AW: ))+)(.*)/\\1Re: \\7\\nX-Orig-Subject: \\2\\7/' Which curtails these (and an \"Antwort: \" prefix that I've evidently also been bothered by at some point) down to a single \"Re: \". ","pontos":5},{"corpo":"I strongly dislike make because of its implicit ruleset and treatment of whitespace. Personally I would use cpp tasks (http://ant-contrib.sourceforge.net/cpptasks/index.html) to do my C compilation. They are not as flexible as make but they are also far less complex and it will mean you don't have to burden your developers with learning make. ","pontos":3},{"corpo":"The comments here suggest that few people find the class designer useful. Amusing to note that Microsoft designed the class designer to be a useful replacement to useless UML (UML diagrams being untrustworthy once they lose synchronisation with source code). The trouble with class diagrams is that they tell us what we already know. ","pontos":0},{"corpo":"As you may know, Oracle now has regular expressions: http://www.oracle.com/technology/oramag/webcolumns/2003/techarticles/rischert_regexp_pt1.html. I have used the new functionality in a few queries, but it hasn't been as useful as in other contexts. The reason, I believe, is that regular expressions are best suited for finding structured data buried within unstructured data. For instance, I might use a regex to find Oracle messages that are stuffed in log file. It isn't possible to know where the messages are--only what they look like. So a regex is the best solution to that problem. When you work with a relational database, the data is usually pre-structured, so a regex doesn't shine in that context. ","pontos":0},{"corpo":"Thanks for the replies. Using placement new for each item in the array was the solution I ended up using when I ran into this (sorry, should have mentioned that in the question). I just felt that there must have been something I was missing about doing it with placement new[]. As it is, it seems like placement new[] is essentially unusable thanks to the standard allowing the compiler to add an additional unspecified overhead to the array. I don't see how you could ever use it safely and portably. I'm not even really clear why it needs the additional data, as you wouldn't call delete[] on the array anyway, so I don't entirely see why it needs to know how many items are in it. ","pontos":1},{"corpo":"I only use the class designer to display my existing classes, but I don't use it the other way, e.g., design your classes there then let it generate the code. ","pontos":0},{"corpo":" A good answer for this question would be a real gold mine for a motivated spammer :) Not really -- as you'll see in that other thread, answers center on showing that you are the authorative sender of the email, and various aspects that are useless to spammers and useful to non-spammers who send a lot of email. ","pontos":2},{"corpo":"I'm a big fan of EditPlus, mainly for its smooth built in ftp open/save functionality. Crimson Editor has this too but that feature seems to be unstable from time to time. ","pontos":1},{"corpo":"You can kind of fake it by changing the font to something like the Lucida Handwriting font, which looks sort of italic or, buy or find a free italic only font. Edit: I've actually gone through the built-in fonts on my VS 2008 on Vista, and chosen Monotype Corsiva, and bumped the size to 12 for my comments setting (getting old - eyes aren't what they used to be) ","pontos":1},{"corpo":"As a visualization tool, it's ok, but generally I find the object browser does fine for most stuff I care about. As a code generation tool, it's a terrible idea. The whole idea that we will design all our code structure first, then fill in the blanks with small bits of implementation is fundamentally broken. The only time you actually know what the code structure should look like, is if you've done the exact same thing before - however then you can just use your previous code, and you don't need to draw up any new code in any kind of designer. If you decide ahead of time to use a particular class structure before you've actually tried to solve the problem, there is a 100% chance that you will pick the wrong design, and shoot yourself in the foot. ","pontos":17},{"corpo":"I'll assume you are talking about Windows, right? I don't believe you can change the icon of a batch file directly. Icons are embedded in .EXE and .DLL files, or pointed to by .LNK files. You could try to change the file association, but that approach may vary based on the version of Windows you are using. This is down with the registry in XP, but I'm not sure about Vista. ","pontos":0},{"corpo":"Textpad replaces notepad for me. I couldn't live without it. Some key features that I use with Textpad are: Find in files (along with open all, replace all, save all, close all). Block Select (along with copy/paste of a column). Clip Library Syntax highlighting Ability to attach externals tools (compilers, etc.) and capture the output to a window. I use Eclipse for Java, Visual Studio for C++, C#, and VB.NET, JellyFish Pro for PowerBasic, I still use Visual Studio 6 for Classic VB, and I use TextPad for perl, python, Powershell, vbscript, SQL, HTML, and batch files. ","pontos":4},{"corpo":"My favorite type of documentations is drawings. Just figures that explains how all the \"stuff\" are connected to each other. In my opinion it is not so important to follow specified standards when you make these drawings, that just complicates things and results in fewer figures being made. And by having a huge standard, you just adds way to much different things you have to understand to understand the drawings. If you can't explain your system just by using boxes and arrows (combined with available developers which can answer questions, of course), your system is to complicated... (this is of course an over-simplification, but in general I think it applies). Some simple drawings will of course not help if the code-base is shitty. The worse your code is, the more documentation you will need. ","pontos":1},{"corpo":"Just change \"Home\" to an empty string. routes.MapRoute( \"Home\", \"\", new { action = Index, controller = Home } ); ","pontos":16},{"corpo":"Maybe try this question at http://www.codeplex.com/n2/Thread/List.aspx They might be able to tell you about performance limitations or bottlenecks. ","pontos":3},{"corpo":"The convention is to avoid labels altogether. There are very, very few valid reasons to use a label for breaking out of a loop. Breaking out is ok, but you can remove the need to break at all by modifying your design a little. In the example you have given, you would extract the 'Lots of code' sections and put them in individual methods with meaningful names. for ( ;/*stuff*/; ) { lotsOfCode(); if ( !isEnough() ) { moreCode(); } } Edit: having seen the actual code in question (over here), I think the use of labels is probably the best way to make the code readable. In most cases using labels is the wrong approach, in this instance, I think it is fine. ","pontos":15},{"corpo":" As others have said, it is possible. However, if both the service and client use an object that has the exact same domain behavior on both sides, you probably didn't need a service in the first place. I have to disagree with this as it's a somewhat narrow comment. Using a webservice that can serialize domain objects to XML means that it makes it easy for clients that work with the same domain objects, but it also means that those clients are restricted to using that particular web service you've exposed and it also works in reverse by allowing other clients to have no knowledge of your domain objects but still interact with your service via XML. ","pontos":0},{"corpo":"My only suggestion is to programmatically remove the dojoType on the server-side or client-side. It is not possible to keep the dojoType and not have it validate. Unless you create your own type that has you logic in it. ","pontos":1},{"corpo":"I usually find architecture to be in some sort of heavy flux at the start of development, so documenting it at the start is not really a good idea (this is the point of contention against Big Upfront Design). Unfortunately that doesn't make the need for documentation go away. :P In .NET (Visual Studio, specifically) these are the things that I found useful in documenting architectures and APIs: Visual Studio Class Designer for diagrams SandCastle + XML Documentation Comments for API Documentation ","pontos":1},{"corpo":"@James I'm not even really clear why it needs the additional data, as you wouldn't call delete[] on the array anyway, so I don't entirely see why it needs to know how many items are in it. After giving this some thought, I agree with you. There is no reason why placement new should need to store the number of elements, because there is no placement delete. Since there's no placement delete, there's no reason for placement new to store the number of elements. I also tested this with gcc on my Mac, using a class with a destructor. On my system, placement new was not changing the pointer. This makes me wonder if this is a VC++ issue, and whether this might violate the standard (the standard doesn't specifically address this, so far as I can find). ","pontos":1},{"corpo":"Ctrl-V escapes the next keystoke. That's how you can get a Ctrl-C out: Ctrl-V Ctrl-C ","pontos":9},{"corpo":"I gave up on proprietary expensive tools (i.e. visio). I just don't see the return on investment (not the cost of the tool, the overhead and time consumed). What fails almost always is that the documentation is obsolete before the first day of coding goes by. My solution: Strong Wiki push. Everyone are responsible and able to update the wiki at any time, images can be made with whatever software they want, as long as at the end there is an image embeded in the wiki page. This works great for me. I document Database this way as well, Store procedures, FAQ, errors, reports.... ","pontos":1},{"corpo":"It may not help if the problem is inside one of your controls - as you expect - but if the page is poorly designed and that's causing render to be slow, YSlow should help clean that up. ","pontos":0},{"corpo":"One useful example is the guys who run DB4O object oriented database. There, WeakReferences are used as a kind of light cache: it will keep your objects in memory only as long as your application does, allowing you to put a real cache on top. Another use would be in the implementation of weak event handlers. Currently, one big source of memory leaks in .NET applications is forgetting to remove event handlers. E.g. public MyForm() { MyApplication.Foo += someHandler; } See the problem? In the above snippet, MyForm will be kept alive in memory forever as long as MyApplication is alive in memory. Create 10 MyForms, close them all, your 10 MyForms will still be in memory, kept alive by the event handler. Enter WeakReference. You can build a weak event handler using WeakReferences so that someHandler is a weak event handler to MyApplication.Foo, thus fixing your memory leaks! This isn't just theory. Dustin Campbell from the DidItWith.NET blog posted an implementation of weak event handlers using System.WeakReference. ","pontos":39},{"corpo":"The convetion/best practise would still be not to use them at all and to refactor the code so that is more readable using extract as method. ","pontos":0},{"corpo":"I vaguely recall having problems with SSRS on one machine when we changed the \"Enable HTTP Keep-Alives\" setting in IIS. Try toggling that checkbox (I don't remember whether it was checked or unchecked when it caused us problems). ","pontos":0},{"corpo":"They are kind of the goto of Java - not sure if C# has them. I have never used them in practice, I can't think of a case where avoiding them wouldn't result in much more readable code. But if you have to- I think all caps is ok. Most people won't use labelled breaks, so when they see the code, the caps will jump out at them and will force them to realise what is going on. ","pontos":0},{"corpo":" I know, I should not use labels. But just assume, I have some code, that could gain a lot in readability from labeled breaks, how do I format them. Mo, your premise is wrong. The question shouldn't be 'how do I format them?' Your question should be 'I have code that has a large amount of logic inside loops - how do I make it more readable?' The answer to that question is to move the code into individual, well named functions. Then you don't need to label the breaks at all. ","pontos":1},{"corpo":"From the demos of the designer I've seen, it's not a flawless tool. It is a version 1.0 product, so it's bound to have some pain points. The change type is one of them it seems. From watching the designer and the code generation, I figured that one would break either at compile time (not likely) or at run-time (when the model is actually executed). ","pontos":1},{"corpo":"I feel your pain. We have an application which is 'cross-platform'. A typical client/server application where the client needs to be able to run on windows and linux. Since our client base mostly uses windows we work using VS2008 (the debugger makes life a lot easier) - however we still need to perform linux builds. The major problem with this was we were checking in code that we didn't know would build under gcc, which would more than likely break the CI stuff we had setup. So we installed MingGW on all our developer's machines which allows us to test that working copy will build under gcc before we commit it back to the repository. ","pontos":3},{"corpo":"This is due to how subversion works. Each revision is really a snapshot of the repository identified by that revision number. If all your projects share a repository then it is unavoidable. Typically, in my experience, however you would setup separate repositories for completely unrelated projects. So short answer is no you are doing nothing wrong it is a common question surrounding subversion but it makes sense when you think about how it stores repository information. ","pontos":4},{"corpo":"The revision number should really only be an identifier for a particular version. Whether it's sequential for a project or not shouldn't matter. That being said, I can understand that it's less than ideal. Most projects I've encountered have been setup in a single repository and the revision ids behave in this way. I don't know any SVN configuration option to change this behavior, and IMHO, maintaining multiple repositories seems like an unnecessary overhead. ","pontos":4},{"corpo":"AngelScript lets you call standard C functions and C++ methods with no need for proxy functions. The application simply registers the functions, objects, and methods that the scripts should be able to work with and nothing more has to be done with your code. The same functions used by the application internally can also be used by the scripting engine, which eliminates the need to duplicate functionality. For the script writer the scripting language follows the widely known syntax of C/C++ (with minor changes), but without the need to worry about pointers and memory leaks. ","pontos":1},{"corpo":"If you right-click on your \"Computer\" (or \"My Computer\") icon and select \"Manage\" from the pop-up menu, that'll take you to the Computer Management console. In there, under System Tools\\Shared Folders, you'll find \"Open Files\". This is probably close to what you want, but if the file is on a network share then you'd need to do the same thing on the server on which the file lives. ","pontos":4},{"corpo":"If you don't want it saved, you do not need to execute the cfg.Save command. The Configuration object will store your changes until it isn't needed anymore. ","pontos":0},{"corpo":" If you can I'd be horrified. Why would you be horrified? Air is a desktop platform, and having access to the OS's APIs (such as registry access) makes plenty of sense. That being said, it isn't supported now (and as Adobe seem to be very Mac-centric, I doubt it will ever be added). I have settled on grabbing the users name from the name of the user directory Using File.userDirectory.name will work in most cases, but it seems like a very fragile implementation, it relies on the OS maintaining the convention of having the username as their directory. I can think of a few possible things that might break it (playing with TweakUI etc). ","pontos":2},{"corpo":"Why not just add a dependency to the \"startup\" project for each of the plugins? This will force the project to be rebuilt if any of the others change, and you won't have to mess with any other pre/post-build events. ","pontos":3},{"corpo":"Well, it appears YAML is gone out the window then. I want something both human writable and readable. Plus, this C# implementation...I have no idea if it's working or not, the documentation consists of a few one line code examples. It barfs on their own YAML files, and is an old student project. The only other C# YAML parser I've found uses the MS-PL which I'm not really comfortable using. I might just end up rolling my own format. Best practices be damned, all I want to do is associate a key with a value. ","pontos":4},{"corpo":"Ultimately, it will not hurt any users if you target the Client Profile. This is because the client profile is a subset of the .net framework v3.5 sp1, and if v3.5 sp1 is already installed you don't need to install anything. The assemblies in the client profile are the same binaries as the full framework, so unless you're loading assemblies dynamically, then you shouldn't need to do any additional testing. My thinking is that unless you must use assemblies which are NOT in the client profile, then you should target it. As for the OS requirements, WPF won't run on pre-XP sp2, so if you need to run on other OSes, then you'll have to use WinForms anyways. EDIT: On IE, yes. It sends the .NET Framework version as part of the UA string, e.g.: Actually so does FF3+3.5sp1: Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.0.1) Gecko/2008070208 Firefox/3.0.1 (.NET CLR 3.5.30729) ","pontos":5},{"corpo":"I often find myself defining some things that are done repetitively in certain functions. That makes the code much shorter and thus allows a better overview. But as always, try to find a good measure to not create a new language out of it. Might be a little hard to read for the occasional maintenance later on. ","pontos":1},{"corpo":" Is #define the only thing that determines if the code is included when compiled? If I have #define DEBUGme as a custom symbol, the only way to exclude it from compile is to remove this #define statement? You can undefine symbols as well #if defined(DEBUG) #undef DEBUG #endif ","pontos":3},{"corpo":"I previously organised my DDL code organised by one file per entity and made a tool that combined this into a single DDL script. My former employer used a scheme where all table DDL was in one file (stored in oracle syntax), indicies in another, constraints in a third and static data in a fourth. A change script was kept in paralell with this (again in Oracle). The conversion to SQL was manual. It was a mess. I actually wrote a handy tool that will convert Oracle DDL to SQL Server (it worked 99.9% of the time). I have recently switched to using Visual Studio Team System for Database professionals. So far it works fine, but there are some glitches if you use CLR functions within the database. ","pontos":0},{"corpo":"CodeRush with Refactor! Pro http://www.devexpress.com/Products/Visual_Studio_Add-in/Coding_Assistance/ ","pontos":1},{"corpo":"Does F# class as a VS addin? :) In all seriousness, ViEmu is the only addin I use. ","pontos":1},{"corpo":"I use: ReSharper VisualSVN TestDriven.net If anyone knows of a good native C++ refactoring tool that doesn't bring the system to a standstill all the time, please post it. Refactor! Pro isn't bad by itself but I can't get it to play nicely with R#. I found Visual Assist too slow even when it's the only plug-in installed. ","pontos":2},{"corpo":"This is the effect of a new feature in Vista called \"Boxing\": Windows has several mechanisms that allow the user/admin to set up applications to automatically run when windows starts. This feature is mostly used for one of these purposes: 1. Programs that are part of the basic work environment of the user, such that the first action the user would usually take when starting the computer is to start them. 2. All sorts of background \"agents\" - skype, messenger, winamp etc. When too many (or too heavy) programs are registered to run on startup the end result is that the user can't actually do anything for the first few seconds/minutes after login, which can be really annoying. In comes Vista's \"Boxing\" feature: Briefly, Vista forces all programs invoked through the Run key to operate at low priority for the first 60 seconds after login. This affects both I/O priority (which is set to Very Low) and CPU priority. Very Low priority I/O requests do not pass through the file cache, but go directly to disk. Thus, they are much slower than regular I/O. The length of the boxing period is set by the registry value: \"HKLM\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Advanced\\DelayedApps\\Delay_Sec\". For a more detailed explanation see here and here ","pontos":6},{"corpo":"You can set the Build Action/Copy to Output Directory property on individual files (select the file and hit F4 to open the properties window) to control what happens to them during build, but not for folders. This could probably be automated with a (pre) build task if you don't want to do it manually. Alternatively, you can exclude these folders from the project (right click and 'exclude from project'); they'll still be there (\"show all files\" in solution explorer), but they won't be included when building the project. ","pontos":2},{"corpo":"I am one of the authors of Drools, I will avoid pimping my wares. But some other options are Jess (not open source) but uses the clips syntax (which we also support a subset of) - which is kinda a lisp dialect. It really depends what you want it for, Haley have strong Natural language tech (and they recently aquired RuleBurst - who has also interesting natural language tech which could deal with word documents with embedded rules - eg legal documentation). RuleBurst was able to target .Net runtimes as well (there is a Drools.net \"port\" available as well - I haven't seen what it has been up to lately, alas, not enough time). Ok I will put my pimp bling away now... sorry about that. ","pontos":6},{"corpo":"What appears to be the matter with the code? OK, the question should be... what should the code do that it doesn't already. When I run the code, I see 2 red 'spikes' am I not ment to? You appear to draw the first spike within the clipped rectangle region verified by adding the the following after the declaration of teh Rectangle : Then you perform a translation, reset the clip so at this point I assume the clientRectangle is being used as the appropriate clip region and then attempt to redarw the translated spike. Where's the bug?!? ","pontos":0},{"corpo":"A lot of people don't know or use the debugger to it's fullest - I.E. just use it to stop code, but right click on the red circle and there are a lot more options such as break on condition, run code on break. Also you can change variable values at runtime using the debugger which is a great feature - saves rerunning code to fix a silly logic error etc. ","pontos":14},{"corpo":" Mo, your premise is wrong. The question shouldn't be 'how do I format them?' Your question should be 'I have code that has a large amount of logic inside loops - how do I make it more readable?' The answer to that question is to move the code into individual, well named functions. Then you don't need to label the breaks at all. Ok, I'll give up on this one. But I will open a new question with a more sepcific code problem and how to refactor it in order to avoid the labels. ","pontos":0},{"corpo":"Forgive me if I am off-base here, but isn't this what the Office PIA's are for? ","pontos":3},{"corpo":"Call me old-skool, but I just like the default. I just can't get into the dark color-schemes. ","pontos":0},{"corpo":"Dark themes as described at length by Scott Hanselman are interesting. ","pontos":18},{"corpo":"i also like the default one.. i tryed the black theme once.. i didn't like it.. ","pontos":0},{"corpo":"I think this is really down to the individual.. There are numerous good posts on the subject (such as Scott Hanselman's). I'm sure Jeff did a post too but Google Reader isn't finding it for me.. :\\ I prefer a dark theme, find it easiter on the eyes... ","pontos":1},{"corpo":"I think that depends on your window manager. I'm a windows user, so this might be a wrong guess, but: Isn't there something called X-Server running on linux machines - at least on ones that might be interesting targets for VNC - that you can connect to with \"X-Clients\"? VNC just takes everything that's on the screen and \"tunnels it through your network\". If I'm not totally wrong then the \"X\" protocol should give you the chance to use your client's desktop resolution. Give X-Server on Wikipedia a try, that might give you a rough overview. ","pontos":-3},{"corpo":"WF is available already in .net 3.0. It is a bit buggy though on the Designer-side in Visual Studio and can get quite messy. I use it on Sharepoint (where WF is pretty much your only option anyway) and overall I am quite satisfied with it, even though the learning curve is rather steep. Foundations of WF is a good book to start with it, as they implement a complete solution from beginning to the end and explain the concepts behind it. ","pontos":0},{"corpo":"Does this work for you? I extracted the inner loop into a method CheckedEntireMatrix (you can name it better than me) - Also my java is a bit rusty.. but I think it gets the message across for( int idx = 0; idx vectorLength; idx++) { if( conditionAtVectorPosition( v, idx ) || !CheckedEntireMatrix(v)) continue; setValueInVector( v, idx ); } private bool CheckedEntireMatrix(Vector v) { for( rowIdx = 0; rowIdx n; rowIdx++ ) { if( anotherConditionAtVector( v, rowIdx ) ) continue; if( conditionAtMatrixRowCol( m, rowIdx, idx ) ) return false; } return true; } ","pontos":0},{"corpo":"Using ints is generally better than using shorts because java uses 32-bit values internally anyway (Even for bytes, unless in an array) so using ints will avoid unnecessary conversion to/from short values in the bytecode. ","pontos":0},{"corpo":"I'm using a customized version of Oren Ellenbogen's dark theme. The main difference is that I've added extra highlighting for types and method signatures so they stand out a bit more for me. ","pontos":2},{"corpo":"I have done some selling and even run some training sessions. I think some people are turned off by the lack of WYSIWYG editing and ability to paste formatted text from Word or Outlook. I know there are some tools to work around these, but they are still barriers. There are some areas where the wiki is being used to log certain areas, but people who update those are not doing anything else with it. I will use the wiki to document my specialised area regardless as it acts as a convenient brain extension. When starting a new development I use it as a notepad for ideas that I can expand on as it progresses. It would help if management would give it some vocal support, even if it is not made mandatory. ","pontos":2},{"corpo":" I like the free silk icons at famfamfam, but they're png's, and when I convert them to ico format, they look pretty crappy. Not sure what I'm doing wrong... Sounds like you're removing the alpha channel. You need to make sure you're loading them as 32-bit ARGB PNGs before converting them to icons. ","pontos":2},{"corpo":"I'm not too sure to understand the first continue. I would copy Gishu and write something like ( sorry if there are some mistakes ) : for( int idx = 0; idx vectorLength; idx++) { if( !conditionAtVectorPosition( v, idx ) CheckedEntireMatrix(v)) setValueInVector( v, idx ); } inline bool CheckedEntireMatrix(Vector v) { for(rowIdx = 0; rowIdx n; rowIdx++) if ( !anotherConditionAtVector(v,rowIdx) conditionAtMatrixRowCol(m,rowIdx,idx) ) return false; return true; } ","pontos":0},{"corpo":"You can't really measure developer performance because as soon as you add metrics, the developers latch onto those metrics and use them to boost measured performance. The most likely people to do this are the ones doing the worst jobs. There's reams of info out in the internet on this subject, but the first step is to ask yourself why you need this information. Is it to give you an idea of project end dates or is it to rate or rank developers. If the latter - Good luck with that - Any metric you create will be too simple too esasily gamed. These metrics will also fail to measure how good a job a developer is doing. That'll foster bad feeling amongst developers and it'll be counterproductive. If you're trying to get an idea of how long a job is going to take... Here's what I do. Split a job into manageable tasks. Each task should take no longer than three hours. Each task should be defined in terms of the number of minutes it could take to complete. If a task takes more than three hours, you need to split it into subtasks. Round all minutes up to the nearest 15 minute increment. Add all the minutes from everyone together. (This step is important) Divide by 60 to give a total number of hours. Double it. I give myself 5 working hours in a day - doesn't sound like a lot, but you'll be amazed at how many interruptions there are in a normal day. For me, this usually works out about right. Once you've got the value above, you can multiply it by a factor calculated from the last three projects to allow for team bias (too optimistic / too pessimistic). On developer performance. I don't really understand why you're concerned about developer performance. There's no need for you to be trying to highlight bad developers using the power of math. If you think someone is swinging the lead, bring it up with your manager and leave it at that. If the management does nothing about it and it's harming your health / job / career, then it's time for you to move on. ","pontos":24},{"corpo":"The bug is that both line segments should be drawn identical but they are not because the spike that is drawn within the clipping region is completely within the clipping region and should not be clipped in any way but it is. This is a very annoying but that results in any software that uses drawlines heavily + clipping to look unprofessional because of gaps that can appear in the polygons. ","pontos":0},{"corpo":"I don't understand where this \"don't use labels\" rule comes from. When doing non-trivial looping logic, the test to break or continue isn't always neatly at the end of the surrounding block. outer_loop: for (...) { // some code for (...) { // some code if (...) continue outer_loop; // more code } // more code } Yes, cases like this do happen all the time. What are people suggesting I use instead? A boolean condition like this? for (...) { // some code boolean continueOuterLoop = false; for (...) { // some code if (...) { continueOuterLoop = true; break; } // more code } if (continueOuterLoop) continue; // more code } Yuck! Refactoring it as a method doesn't alleviate that either: boolean innerLoop (...) { for (...) { // some code if (...) { return true; } // more code } return false; } for (...) { // some code if (innerLoop(...)) continue; // more code } Sure it's a little prettier, but it's still passing around a superfluous boolean. And if the inner loop modified local variables, refactoring it into a method isn't always the correct solution. So why are you all against labels? Give me some solid reasons, and practical alternatives for the above case. ","pontos":32},{"corpo":"Looking at the solutions presented so far: They all look less readable than the original, in that they involve spending more code on the mechanism of the code rather than on the algorithm itself Some of them are broken, or were before they were edited. Most damning is the fact that people are having to think quite hard about how to write the code without labels and not break anything. Some come with a performance penalty of running the same test twice, which may not always be trivial. The alternative to that is storing and passing round booleans, which gets ugly. Refactoring the relevant part of the code into a method is effectively a no-op: it rearranges how the code is laid out in the file, but has no effect on how it's executed. All of which makes me believe that, at least in the case of this question as phrased, the label is the correct solution and doesn't need to be refactored away. Certainly there are cases where labels are used incorrectly and should be refactored away. I just don't think it should be treated as some unbreakable rule. ","pontos":32},{"corpo":"@Derek 5.3.4, section 12 talks about the array allocation overhead and, unless I'm misreading it, it seems to suggest to me that it is valid for the compiler to add it on placement new as well: This overhead may be applied in all array new-expressions, including those referencing the library function operator new[](std::size_t, void*) and other placement allocation functions. The amount of overhead may vary from one invocation of new to another. That said, I think VC was the only compiler that gave me trouble with this, out of it, GCC, Codewarrior and ProDG. I'd have to check again to be sure, though. ","pontos":3},{"corpo":"I've hit the same issue - I was developing a SOAP client, and the dev server has a \"homegrown\" certificate. I wasn't able to solve the issue even using that method, since I wasn't using NSURL, but the (poorly documented and apparently abandoned) WS methods, and decided for the time being to (internally) just use a non-SSL connection. Having said that, however, the question that springs to mind is, if you aren't willing to use a private API in a production app, should you be allowing access to a site with a dodgy certificate? I'll quote Jens Alfke: That's not just a theoretical security problem. Something like 25% of public DNS servers have been compromised, according to recent reports, and can direct users to phishing/malware/ad sites even if they enter the domain name properly. The only thing protecting you from that is SSL certificate checking. ","pontos":1},{"corpo":" The memory windows, very useful if you're doing low level stuff. Control + K , Control + F - Format selection - great for quickly making code neat Regions, some love them, some hate them, most don't even know they exist Changing variables in debug windows during execution Tracepoints Conditional break points Hold down Alt and drag for 'rectangular' selection. Control+B for a breakpoint, to break at function Control+I for incremental search, F3 to iterate ","pontos":4},{"corpo":"Split the big system to smaller pieces. And don't think that it's so complex, because it usually isn't. By thinking too complex it just ruins your thoughts and eventually the design. Some point you just realize that you could do the same thing easier, and then you redesign it. Atleast this has been my major mistake in designing. Keep it simple! ","pontos":0},{"corpo":"@Sadie: They all look less readable than the original, in that they involve spending more code on the mechanism of the code rather than on the algorithm itself Externalizing the second loop outside the algorithm is not necessarily less readable. If the method name is well chosen, it can improve readability. Some of them are broken, or were before they were edited. Most damning is the fact that people are having to think quite hard about how to write the code without labels and not break anything. I have a different point of view: some of them are broken because it is hard to figure out the behavior of the original algorithm. Some come with a performance penalty of running the same test twice, which may not always be trivial. The alternative to that is storing and passing round booleans, which gets ugly. The performance penalty is minor. However I agree that running a test twice is not a nice solution. Refactoring the relevant part of the code into a method is effectively a no-op: it rearranges how the code is laid out in the file, but has no effect on how it's executed. I don't see the point. Yep, it doesn't change the behavior, like... refactoring? Certainly there are cases where labels are used incorrectly and should be refactored away. I just don't think it should be treated as some unbreakable rule. I totally agree. But as you have pointed out, some of us have difficulties while refactoring this example. Even if the initial example is readable, it is hard to maintain. ","pontos":0},{"corpo":"@Nicolas Some of them are broken, or were before they were edited. Most damning is the fact that people are having to think quite hard about how to write the code without labels and not break anything. I have a different point of view: some of them are broken because it is hard to figure out the behavior of the original algorithm. I realise that it's subjective, but I don't have any trouble reading the original algorithm. It's shorter and clearer than the proposed replacements. What all the refactorings in this thread do is emulate the behaviour of a label using other language features - as if you were porting the code to a language that didn't have labels. ","pontos":1},{"corpo":"I don't think the pre-commit hook can actually change the data that is being committed - it can disallow a commit, but I don't think it can do the conversion for you. It sounds like you want the property 'svn:eol-style' set to 'native' - this will automatically convert newlines to whatever is used on your platform (use 'CRLF', 'CR' or 'LF' to get those regardless of what the OS wants). You can use auto-properties so that all future files you create will have this property set (auto props are handled client-side, so you'd have to set this up for each user). ","pontos":30},{"corpo":"If you've got Greasemonkey installed you might want to try the XSS Assistant user script: http://www.whiteacid.org/greasemonkey/#xss_assistant ","pontos":0},{"corpo":"I think this should work. It might be off on the slashes. Not sure if they are needed or not. string url = Request.ApplicationPath + \"/\" + photosLocation + \"/\" + files[0]; ","pontos":-1},{"corpo":"Afaik, there's no method to do what you want directly. I'd store the photosLocation as a path relative to the application; f.ex. \"~/Images/\". This way, you could use MapPath to get the physical location, and ResolveUrl to get the url (with a bit of help from System.IO.Path): string photosLocationPath = HttpContext.Current.Server.MapPath(photosLocation); if (Directory.Exists(photosLocationPath)) { string[] files = Directory.GetFiles(photosLocationPath, \"*.jpg\"); if (files.Length 0) { string filenameRelative = photosLocation + Path.GetFilename(files[0]) return HttpContext.Current.Request.ResolveUrl(filenameRelative); } } ","pontos":9},{"corpo":"Maybe this is not the best way, but it works. // Here is your path String p = photosLocation + \"whatever.jpg\"; // Here is the page address String pa = Page.Request.Url.AbsoluteUri; // Take the page name String pn = Page.Request.Url.LocalPath; // Here is the server address String sa = pa.Replace(pn, \"\"); // Take the physical location of the page String pl = Page.Request.PhysicalPath; // Replace the backslash with slash in your path pl = pl.Replace(\"\\\\\", \"/\"); p = p.Replace(\"\\\\\", \"/\"); // Root path String rp = pl.Replace(pn, \"\"); // Take out same path String final = p.Replace(rp, \"\"); // So your picture's address is String path = sa + final; Edit: Ok, somebody marked as not helpful. Some explanation: take the physical path of the current page, split it into two parts: server and directory (like c:\\inetpub\\whatever.com\\whatever) and page name (like /Whatever.aspx). The image's physical path should contain the server's path, so \"substract\" them, leaving only the image's path relative to the server's (like: \\design\\picture.jpg). Replace the backslashes with slashes and append it to the server's url. ","pontos":3},{"corpo":" but have you tried setting the compatibilty mode for the database to sql server 2000. I just checked the 2005 database, I selected the database, and clicked Properties->Options, and it says the db is already in 2000 compatibility mode. ","pontos":0},{"corpo":"Here it is: Exception message: The member 'MMRI.DAL.ITag.idContent' has no supported translation to SQL. Code: var d = repContent.GetAll().Where(x = x.idContent.Equals(idContent)); foreach (var tagConnect in d) - error line { repContet.DeleteOnSubmit(tagConnect); (it gets all tags from DB, and deletes them) And stack trace: [NotSupportedException: The member 'MMRI.DAL.ITag.idContent' has no supported translation to SQL.] System.Data.Linq.SqlClient.Visitor.VisitMember(SqlMember m) +621763 System.Data.Linq.SqlClient.SqlVisitor.Visit(SqlNode node) +541 System.Data.Linq.SqlClient.SqlVisitor.VisitExpression(SqlExpression exp) +8 System.Data.Linq.SqlClient.SqlVisitor.VisitBinaryOperator(SqlBinary bo) +18 System.Data.Linq.SqlClient.Visitor.VisitBinaryOperator(SqlBinary bo) +18 System.Data.Linq.SqlClient.SqlVisitor.Visit(SqlNode node) +196 System.Data.Linq.SqlClient.SqlVisitor.VisitExpression(SqlExpression exp) +8 System.Data.Linq.SqlClient.SqlVisitor.VisitSelectCore(SqlSelect select) +46 System.Data.Linq.SqlClient.Visitor.VisitSelect(SqlSelect select) +20 System.Data.Linq.SqlClient.SqlVisitor.Visit(SqlNode node) +1024 System.Data.Linq.SqlClient.SqlProvider.BuildQuery( ... When I try do decorate partial class: [Column(Storage = \"_idEvent\", DbType = \"Int NOT NULL\", IsPrimaryKey = true)] public int idContent { get { return this.idEvent; } set { this.idEvent=value; } } it throws error \"Invalid column name 'idContent'.\" ","pontos":1},{"corpo":"Some come with a performance penalty of running the same test twice, which may not always be trivial. The alternative to that is storing and passing round booleans, which gets ugly. The performance penalty is minor. However I agree that running a test twice is not a nice solution. I believe the question was how to remove the labels, not how to optimize the algorithm. It appeared to me that the original poster was unaware of how to use 'continue' and 'break' keywords without labels, but of course, my assumptions may be wrong. When it comes to performance, the post does not give any information about the implementation of the other functions, so for all I know they might as well be downloading the results via FTP as consisting of simple calculations inlined by the compiler. That being said, doing the same test twice is not optimal in theory. EDIT: On a second thought, the example is actually not a horrible use of labels. I agree that \"goto is a no-no\", but not because of code like this. The use of labels here does not actually affect the readability of the code in a significant way. Of course, they are not required and can easily be omitted, but not using them simply because \"using labels is bad\" is not a good argument in this case. After all, removing the labels does not make the code much easier to read, as others have already commented. ","pontos":1},{"corpo":"The Java runtime library supports validation. Last time I checked this was the Apache Xerces parser under the covers. You should probably use a javax.xml.validation.Validator. import javax.xml.XMLConstants; import javax.xml.transform.Source; import javax.xml.transform.stream.StreamSource; import javax.xml.validation.*; ... URL schemaFile = new URL(\"http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd\"); Source xmlFile = new StreamSource(new File(\"web.xml\")); SchemaFactory schemaFactory = SchemaFactory .newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); Schema schema = schemaFactory.newSchema(schemaFile); Validator validator = schema.newValidator(); try { validator.validate(xmlFile); System.out.println(xmlFile.getSystemId() + \" is valid\"); } catch (SAXException e) { System.out.println(xmlFile.getSystemId() + \" is NOT valid\"); System.out.println(\"Reason: \" + e.getLocalizedMessage()); } The schema factory constant is the string which defines XSDs. The above code validates a WAR deployment descriptor against the URL but you could just as easily validate against a local file. You should not use the DOMParser to validate a document (unless your goal is to create a document object model anyway). This will start creating DOM objects as it parses the document - wasteful if you aren't going to use them. ","pontos":178},{"corpo":"Simply delete the .suo file. It contains the list of open files. ","pontos":25},{"corpo":"I've been using Aptana/Eclipse/RadRails, but if I were to do it again, I'd definitely try NetBeans. Aptana has been a major headache. I've never used IronRuby, but that might make you feel more at home. ","pontos":1},{"corpo":"Or you can close all open document from the Window menu before closing VS. ","pontos":0},{"corpo":"To optimize that code the best bet would be to rewrite the strcmp routine since you are only checking for equality and don't need to evaluate the entire word. Other than that you can't do much else. You can't sort as it appears you are looking for text within a larger text. Binary search won't work either since the text is unlikely to be sorted. My 2p (C-psuedocode): wrd_end = wrd_ptr + wrd_len; arr_end = arr_ptr - wrd_len; while (arr_ptr arr_end) { wrd_beg = wrd_ptr; arr_beg = arr_ptr; while (wrd_ptr == arr_ptr) { wrd_ptr++; arr_ptr++; if (wrd_ptr == wrd_en) return wrd_beg; } wrd_ptr++; } ","pontos":0},{"corpo":"object Enum.Parse(System.Type enumType, string value, bool ignoreCase); So if you had an enum named mood it would look like this: enum Mood { Angry, Happy, Sad } // ... Mood m = (Mood) Enum.Parse(typeof(Mood), \"Happy\", true); Console.WriteLine(\"My mood is: {0}\", m.ToString()); ","pontos":4},{"corpo":"OK, are you sure that is wise? I am picturing two scenarios here: There is a default button on the form, which is \"clicked\" when enter is pushed\". There is no default button, and you want the user to have to press enter, regardless. Both of these raise the same questions: Is there any validation that is taking place on the text? Why not create a user control to encapsulate this logic? If you know the enter button is being pushed and consumed fine, how are you having problems with TextBoxName.Text = string.Empty ? Also, as a polite note, can you please try and break up your question a bit? One big block is a bit of a pain to read.. ","pontos":1},{"corpo":"If you do take the rsync/filecopy approach with CVS, it is important to only sync the files at a time when there is not an active commit. Otherwise, the repository's lock file will get copied over and you will be unable to checkout/update on the target side until the next sync. This reason alone may make CVS a bad choice. The migration path from CVS to Subversion is pretty smooth and there are tools to import a full CVS repo, with history, into Subversion. Consider Git or Mercurial if you want to get into true distributed versioning, but it sounds like that would be overkill for your \"read only\" needs. ","pontos":2},{"corpo":" On the other hand, if there's a way to move an existing window from one X-server to another, that might solve the problem. I think you can use xmove to move windows between two separate x-servers. So if it works, this should at least give you a way to do what you want albeit not as easily as changing the resolution. ","pontos":1},{"corpo":"Don't get too caught up on trying to optimize string operations in PHP. Concatenation vs. interpolation is meaningless (in real world performance) if your database queries are poorly written or you aren't using any kind of caching scheme. Write your string operations in such a way that debugging your code later will be easy, the performance differences are negligible. @uberfuzzy Assuming this is just a question about language minutia, I suppose it's fine. I'm just trying to add to the conversation that comparing performance between single-quote, double-quote and heredoc in real world applications in meaningless when compared to the real performance sinks, such as poor database queries. ","pontos":9},{"corpo":"No it is a side effect of Crystal Reports. If you don't need it, remove it from your computer it is nothing but a headache. It is safe to delete the aspnet_client folder. ","pontos":1},{"corpo":"Alienbrain also has Visual Studio integration. Wouldn't really recommend it for code, though (it's more designed for art assets). ","pontos":0},{"corpo":"If having the revision numbers change based on other projects bothers you, then put the projects in separate repositories. That is the only way to make the revision numbers independent. To me, the big reason to use different repositories is to provide separate access control for users and/or using different hook scripts. ","pontos":2},{"corpo":"I have seen RSS used to syndicate gas prices from a service for a specific zip code. ","pontos":0},{"corpo":"In my experience, there are two easy ways to call into C code from Python code. There are other approaches, all of which are more annoying and/or verbose. The first and easiest is to compile a bunch of C code as a separate shared library and then call functions in that library using ctypes. Unfortunately, passing anything other than basic data types is non-trivial. The second easiest way is to write a Python module in C and then call functions in that module. You can pass anything you want to these C functions without having to jump through any hoops. And it's easy to call Python functions or methods from these C functions, as described here: https://docs.python.org/extending/extending.html#calling-python-functions-from-c I don't have enough experience with SWIG to offer intelligent commentary. And while it is possible to do things like pass custom Python objects to C functions through ctypes, or to define new Python classes in C, these things are annoying and verbose and I recommend taking one of the two approaches described above. ","pontos":1},{"corpo":"@Blair Conrad: You could also implement your glob/reduce using sum, like so: files = sum([glob.glob(f) for f in args], []) This is less verbose than either of your two examples, is perfectly Pythonic, and is still only one line of code. So to answer the original question, I personally try to avoid using reduce because it's never really necessary and I find it to be less clear than other approaches. However, some people get used to reduce and come to prefer it to list comprehensions (especially Haskell programmers). But if you're not already thinking about a problem in terms of reduce, you probably don't need to worry about using it. ","pontos":7},{"corpo":"My vote is for Subversion because it does what you need and nothing more. Alternatively if you are a bit more adventurous and require a more complex branching strategy you can check out git. ","pontos":1},{"corpo":"We evaluated GI a few months ago for a project but didn't end up selecting it. The IDE-in-a-browser (which is itself build with GI) actually works surprisingly well, though there are some features you normally expect from an editor that it lacks, most notably (and irritatingly) an Undo command. It's also impossible to do things like subdocument includes (practically a necessity for team development) from the IDE, though you can do them manually in the underlying XML and the IDE will respect them. In the end the main reason we didn't go with it was that it was difficult to make the resulting web application look as good as the designers really wanted. It was relatively easy to build functionality, but the components were very restrictive in look and feel. The way GI renders its own document model to HTML involves a lot of attributes which makes skinning in CSS all but impossible. It seems to prefer making web applications that look like applications, instead of web applications that look like websites. So it would probably be great for building intranet type applications where look and feel isn't a huge issue, but I probably wouldn't use it to make a public facing site. By the way for those that don't know, TIBCO GI is a completely separate product from the rest of TIBCO's SOA business integration stuff - General Interface was a separate company that was acquired by TIBCO a couple of years ago. ","pontos":10},{"corpo":"Hm, where I work we have all our projects in the same repository. I really don't see the benefit of separating them, doesn't that just create a lot of extra work -creating new repositories, granting access to people, etc? I guess separate repositories makes sense if the projects are completely unrelated, and you have, say, external customers that needs to have access to the repo. ","pontos":3},{"corpo":"I never realized how much that annoyed me as well! I haven't been able to find a setting, but in you can bind a shortcut to . was unbound for me so I just used that. I'm interested if there's some hidden setting to automatically do this on solution exit though (or load). ","pontos":5},{"corpo":" Note that a responsible web developer does not use fonts that are only available on Windows (and especially ones that are only available on Vista), nor do they use a technology that isn't supported by at least the majority of browsers. Well You can, as long as you know how it will render on non-Vista/non-Windows OS. Otherwise: yep, @font-face in CSS2 is the best standard alternative, even if it is not widely supported. ","pontos":0},{"corpo":"Doesn't the %c parameter pass in the command issued (including the files being committed)? ","pontos":0},{"corpo":"Dim returnXDoc As New XmlDocument(xDoc.NameTable) returnXDoc = xDoc.Clone() The first line here is redundant - you are creating an instance of an XmlDocument, then reassigning the variable: Dim returnXDoc As XmlDocument = xDoc.Clone() This does the same. Seeing as you appear to be inserting each XmlNode from your node list into a different place in the new XmlDocument then I can't see how you could possibly do this any other way. There may be faster XPath expressions you could write, for example pre-pending an XPath expression with \"//\" is almost always the slowest way to do something, especially if your XML is well structured. You haven't shown your XML so I couldn't really comment on this further however. ","pontos":2},{"corpo":"At my workplace, we have two repositories. One with public read access, and one for everything else. I'd use just one for everything, but we need different access rights for public/private projects. That said, I personally don't see the problem with the revision numbers incrementing on every update. The revision numbers could skip prime and even numbers and still do what its supposed to do. Make it easy to get to a specific revision. ","pontos":3},{"corpo":"You need to be wary of XSS when doing stuff like this: document.getElementById(' %= Label1.ClientID % ').style.display The chances are that no-one will be able to tamper with the ClientID of Label1 in this instance, but just to be on the safe side you might want pass it's value through one of the AntiXss library's methods: document.getElementById(' %= AntiXss.JavaScriptEncode(Label1.ClientID) % ').style.display ","pontos":3},{"corpo":"It sounds like the web server on hosttwo.com doesn't allow undefined domains to be passed through. You also said you wanted to do a redirect, this isn't actually a method for redirecting. If you bought this domain through GoDaddy you may just want to use their redirection service. ","pontos":1},{"corpo":"Try changing it to sudomain -> subdomain.hosttwo.com The cname is an alias for a certain domain, so when you go to the control panel for hostone.com, you shouldn't have to enter the whole name into the cname alias. As far as the error you are getting, can you log onto subdomain.hostwo.com and check the logs? ","pontos":9},{"corpo":"Another interesting find is the presence of assemblies here: C:\\Program Files\\Reference Assemblies\\Microsoft\\Framework\\v3.5 You'd think Microsoft would build a check for \"latest version\" into the framework. ","pontos":1},{"corpo":"Burn it to a DVD and install it from there. Also remove any development software that you don't need from Visual Studio, such as C++, VB.NET, Crystal Reports, etc. ","pontos":1},{"corpo":"Since hard drives are very cheap these days, I would suggest buying a larger hard drive and installing VS on that drive. You should never run your OS hard drive close to max capacity, this can seriously reduce the performance of your system. Also, you may be able to install VS but I'm quite sure it'll use alot of disk space during install (temp files) and while you actually use VS (again temp files). ","pontos":1},{"corpo":"The ones I can think of... Loop invariants are always a good one to watch. Write ESTRICT and ENOTICE compliant code, particularly if you are logging errors. Avoid the @ operator. Absolute paths for requires and includes. Use strpos, str_replace etc. instead of regular expressions whenever possible. Then there's a bunch of other methods that might work, but probably wont give you much benefit. ","pontos":1},{"corpo":"As lomaxx mentioned, it's all about the purpose of the DB model. I find it best to use static classes, as I usually only want one instance of my DAL classes being created. I'd rather use static methods than deal with the overhead of potentially creating multiple instances of my DAL classes where only 1 should exist that can be queried multiple times. ","pontos":0},{"corpo":"Nope, you must save in order for the EntLib (and, I suspect, any other tool) to see the changes. ","pontos":0},{"corpo":"Yes, drag and drop is different in AIR. I HATE that! It takes a lot of playing around to figure out how to get things to work the same as custom dnd that was built in flex. As for the coordinates, maybe play around with localToContent, and localToGlobal methods. They may help in translating the coordinates to something useful. Good luck. I will let you know if I think of anything else. ","pontos":0},{"corpo":"<p>The hash code of an object shouldn't be unique. </p> <p>The checking rule is: </p> <ul> <li>Are the hash codes equal? Then call the full (slow) <code>Equals</code> method.</li> <li>Are the hash codes not equal? Then the two items are definitely not equal.</li> </ul> <p>All you want is a <code>GetHashCode</code> algorithm that splits up your collection into roughly even groups - it shouldn't form the key as the <code>HashTable</code> or <code>Dictionary </code> will need to use the hash to optimise retrieval.</p> <p>How long do you expect the data to be? How random? If lengths vary greatly (say for files) then just return the length. If lengths are likely to be similar look at a subset of the bytes that varies.</p> <p><code>GetHashCode</code> should be a lot quicker than <code>Equals</code>, but doesn't need to be unique.</p> <p>Two identical things <em>must never</em> have different hash codes. Two different objects <em>should not</em> have the same hash code, but some collisions are to be expected (after all, there are more permutations than possible 32 bit integers).</p> ","pontos":44},{"corpo":"I have also been highly annoyed by that behavior. The only solution I have found is to manually change the properties page for each web appllication so it hits a real running instance in IIS. I prefer this anyway, because debugging with the integrated web server can give you a very false impression of how your application will interact with the IIS security model. ","pontos":0},{"corpo":"You could drop off the constructor and just put them in each individual class. Then what you have is each class has its own __construct, which is probably the same depending on if it is a shipper or vendor. If you want to only have those constructs defined once I don't think you want to go down that route. What I think you want to do is make an abstract class that implements vendor, and one that implements shipper. There you could define the constructors differently. abstract class Vendor implements iVendor { public function __construct() { whatever(); } } abstract class Shipper implements iShipper { public function __construct() { something(); } } ","pontos":0},{"corpo":"Are there any standards at all in the way that the addresses are recorded? For example: Are there always commas or new-lines separating street1 from street2 from city from state from zip? Are address types (road, street, boulevard, etc) always spelled out? always abbreviated? Some of each? Define \"error\". My general answer is a series of Regular Expressions, though the complexity of this depends on the answer. And if there is no consistency at all, then you may only be able to achieve partial success with a Regex (ie: filtering out zip code and state) and will have to do the rest by hand (or at least go through the rest very carefully to make sure you spot the errors). ","pontos":5},{"corpo":"Personally, the second one as everything you are using is in the direct order it will be output in. Whereas with the first you have to match up the {0} and {1} with the proper var, which is easy to mess up. At least it's not as bad as the C++ sprintf where if you get the variable type wrong the whole thing will blow up. Also, since the second is all inline and it doesn't have to do any searching and replacing for all the {0} things, the latter should be faster... though I don't know for sure. ","pontos":0},{"corpo":"I've done a lot of work on this kind of parsing. Because there are errors you won't get 100% accuracy, but there are a few things you can do to get most of the way there, and then do a visual BS test. Here's the general way to go about it. It's not code, because it's pretty academic to write it, there's no weirdness, just lots of string handling. (Now that you've posted some sample data, I've made some minor changes) Work backward. Start from the zip code, which will be near the end, and in one of two known formats: XXXXX or XXXXX-XXXX. If this doesn't appear, you can assume you're in the city, state portion, below. The next thing, before the zip, is going to be the state, and it'll be either in a two-letter format, or as words. You know what these will be, too -- there's only 50 of them. Also, you could soundex the words to help compensate for spelling errors. before that is the city, and it's probably on the same line as the state. You could use a zip-code database to check the city and state based on the zip, or at least use it as a BS detector. The street address will generally be one or two lines. The second line will generally be the suite number if there is one, but it could also be a PO box. It's going to be near-impossible to detect a name on the first or second line, though if it's not prefixed with a number (or if it's prefixed with an \"attn:\" or \"attention to:\" it could give you a hint as to whether it's a name or an address line. I hope this helps somewhat. ","pontos":92},{"corpo":"Based on the sample data: I would start at the end of the string. Parse a Zip-code (either format). Read end to first space. If no Zip Code was found Error. Trim the end then for spaces and special chars (commas) Then move on to State, again use the Space as the delimiter. Maybe use a lookup list to validate 2 letter state codes, and full state names. If no valid state found, error. Trim spaces and commas from the end again. City gets tricky, I would actually use a comma here, at the risk of getting too much data in the city. Look for the comma, or beginning of the line. If you still have chars left in the string, shove all of that into an address field. This isn't perfect, but it should be a pretty good starting point. ","pontos":4},{"corpo":"your temp table is out of scope, it is only 'alive' during the first connection and will not be available in the 2nd connection Just move all of it in one block of code and execute it inside one conection ","pontos":4},{"corpo":"With both queries, it looks like you are trying to insert into #temp. #temp is located on one of the databases (for arguments sake, databaseA). So when you try to insert into #temp from databaseB, it reports that it does not exist. Try changing it from Into #temp From to Into databaseA.dbo.#temp From in both statements. Also, make sure that the connection strings have permissions on the other DB, otherwise this will not work. Update: relating to the temp table going out of scope - if you have one connection string that has permissions on both databases, then you could use this for both queries (while keeping the connection alive). While querying the table in the other DB, be sure to use [DBName].[Owner].[TableName] format when referring to the table. ","pontos":3},{"corpo":"Another request for sample data. As has been mentioned I would work backwards from the zip. Once you have a zip I would query a zip database, store the results, and remove them the zip from the string. That will leave you with the address mess. MOST (All?) addresses will start with a number so find the first occurrence of a number in the remaining string and grab everything from it to the (new) end of the string. That will be your address. Anything to the left of that number is likely an addressee. You should now have the City, State, Zip stored in a table and possibly two strings, addressee and address. For the address, check for the existence of \"Suite\" or \"Apt.\" etc. and split that into two values (address lines 1 2). For the addressee I would punt and grab the last word of that string as the last name and put the rest into the first name field. If you don't want to do that, you'll need to check for salutation (Mr., Ms., Dr., etc.) at the start and make some assumptions based on the number of spaces as to how the name is made up. I don't think there's any way you can parse with 100% accuracy. ","pontos":5},{"corpo":"temp is out of scope in q2. All your work can be done in one query: SELECT a.columnA, a.columnB,..., a.columnZ FROM table2 a INNER JOIN (SELECT databaseA..table1.column1 FROM databaseA..table1 WHERE databaseA..table1.xyz = 'A') b ON a.columnB = b.column1 ","pontos":2},{"corpo":"I'd use the String.Format, but I would also have the format string in the resource files so it can be localised for other languages. Using a simple string concat doesn't allow you to do that. Obviously if you wont ever need to localise that string, this isn't a reason to think about. It really depends on what the string is for. If it's going to be showed to the user, I'd use String.Format so I can localize if I need to - and FxCop will spell check it for me, just in case :) If it contains numbers or any other non-string things (e.g. dates), I'd use String.Format because it gives me more control over the formatting. If it's for building a query like SQL, I'd use Linq. If for concatenating strings inside a loop, I'd use StringBuilder to avoid performance problems. If it's for some output the user wont see, and isn't going to effect performance I'd use String.Format because I'm in the habit of using it anyway and I'm just used to it :) ","pontos":3},{"corpo":"Yes in the same way that normal event handlers can cause leaks. Because the lambda is actually changed to: someobject.SomeEvent += () = ...; someobject.SomeEvent += delegate () { ... }; // unhook Action del = () = ...; someobject.SomeEvent += del; someobject.SomeEvent -= del; So basically it is just short hand for what we have been using in 2.0 all these years. ","pontos":1},{"corpo":"You wont just leak memory, you will also get your lambda called multiple times. Each call of 'PotentialMemoryLeaker' will add another copy of the lambda to the event list, and every copy will be called when 'AnEvent' is fired. ","pontos":4},{"corpo":"HTTPS requests are not cached so sending an If-Modified-Since doesn't make any sense. The not caching is a security precaution. ","pontos":2},{"corpo":"Your example just compiles to a compiler-named private inner class (with field firedCount and a compiler-named method). Each call to PotentialMemoryLeaker creates a new instance of the closure class to which where foo keeps a reference by way of a delegate to the single method. If you don't reference the whole object that owns PotentialMemoryLeaker, then that will all be garbage collected. Otherwise, you can either set foo to null or empty foo's event handler list by writing this: foreach (var handler in AnEvent.GetInvocationList()) AnEvent -= handler; Of course, you'd need access to the MyObject class's private members. ","pontos":1},{"corpo":"If you want to specify both a limit for number of items to remove and a condition to select the items to remove, you can use this approach: int limit = 30; // Suppose you want to remove 30 items at most list.RemoveAll(item = ShouldIRemoveThis(item) limit-- 0); ","pontos":8},{"corpo":"Slightly oversimplified: a lambda function is one that can be passed round to other functions and it's logic accessed. In C# lambda syntax is often compiled to simple methods in the same way as anonymous delegates, but it can also be broken down and its logic read. For instance (in C#3): LinqToSqlContext.Where( row = row.FieldName 15 ); LinqToSql can read that function (x > 15) and convert it to the actual SQL to execute using expression trees. The statement above becomes: select ... from [tablename] where [FieldName] 15 --this line was 'read' from the lambda function This is different from normal methods or anonymous delegates (which are just compiler magic really) because they cannot be read. Not all methods in C# that use lambda syntax can be compiled to expression trees (i.e. actual lambda functions). For instance: LinqToSqlContext.Where( row = SomeComplexCheck( row.FieldName ) ); Now the expression tree cannot be read - SomeComplexCheck cannot be broken down. The SQL statement will execute without the where, and every row in the data will be put through . Lambda functions should not be confused with anonymous methods. For instance: LinqToSqlContext.Where( delegate ( DataRow row ) { return row.FieldName 15; } ); This also has an 'inline' function, but this time it's just compiler magic - the C# compiler will split this out to a new instance method with an autogenerated name. Anonymous methods can't be read, and so the logic can't be translated out as it can for lambda functions. ","pontos":9},{"corpo":"Damn if I didn't just find it on MSDN. The answer is: http://msdn.microsoft.com/en-us/library/3kbk77sf(VS.80).aspx \"For best results, you should use a bitmap with dimensions of 500 pixels wide by 70 pixels high.\" ","pontos":43},{"corpo":"This is a timely thread; we switched to Arial because Calibri is WAY small compared to all the other fallback fonts! It pained me greatly to switch to (gag) Arial because it's a crap copy of Helvetica: http://www.ms-studio.com/articles.html The sizing difficulties (too big if you go with a \"c\" font as your standard; too small if you go with something normal) are described in detail here: http://neosmart.net/blog/2006/css-vistas-new-fonts/ I will miss Calibri's beautiful hand-tuned RGB aliasing a lot, but it was just impossible to deliver a good experience for most users without demanding Calibri be installed. It's reasonably common, as it comes with Office 2007 (Win/Mac) and of course Vista.. but it's far from universal, so it's a little irresponsible to rely heavily on it for a global web audience. ","pontos":11},{"corpo":"I'd implement some sort of custom and transmit plain text. As you say, you can rebuild the information doing the reversed process. ","pontos":0},{"corpo":"I use Emacs on Windows. Installing and configuring it to work with rails is a pain though. ","pontos":0},{"corpo":"Is cron sending emails with logs? If not, pipe the output of cron to a log file. Make sure to redirect STDERR to the log. ","pontos":0},{"corpo":"ADD: LIMIT n,1 That will limit the results to one result starting at result n. ","pontos":1},{"corpo":"You should only need to override the method if you want specific behaviour when adding objects to sorted data structures ( etc.) When you do that you should also override . See here for a complete explanation. ","pontos":0},{"corpo":"you'll have to split the file by linebreaks, then loop thru each line and apply the following logic $seat = 0; $name = 1; $chips = 2; foreach( $string in $file ) { if (preg_match(\"Seat ([1-0]): ([A-Za-z_0-9]*) \\(([1-0]*) in chips\\)\", $string, $matches)) { echo \"Seat: \" . $matches[$seat] . \" br \"; echo \"Name: \" . $matches[$name] . \" br \"; echo \"Chips: \" . $matches[$chips] . \" br \"; } } I haven't ran this code, so you may have to fix some errors... ","pontos":-1},{"corpo":"I think that some of the confusion comes from the difference between the concept of a tag and the implementation in SVN. To SVN a tag is a branch which is a copy. Modifying tags is considered wrong and in fact tools like TortoiseSVN will warn you if you attempt to modify anything with ../tags/.. in the path. ","pontos":3},{"corpo":"I'd just like to throw FinalBuilder in to the mix. It's not free, but if you're fed up with editing XML files and want a somewhat nicer (IMO) environment to work in I would give it a go. I've worked with all of them and have always went back to FinalBuilder. ","pontos":14},{"corpo":"Check out preg_match. Probably looking for something like... ?php $str = 'Seat 1: fabulous29 (835 in chips)'; preg_match('/Seat (? seatNo \\d+): (? name \\w+) \\((? chipCnt \\d+) in chips\\)/', $str, $matches); print_r($matches); ? It's been a while since I did php, so this *could be a little or a lot off.* ","pontos":1},{"corpo":"The / syntax in PostgreSQL is: SELECT * FROM mytable ORDER BY somefield LIMIT 1 OFFSET 20; This example selects the 21st row. is telling Postgres to skip the first 20 records. If you don't specify an clause, there's no guarantee which record you will get back, which is rarely useful. Apparently the SQL standard is silent on the limit issue outside of crazy windowing functions, which is why everyone implements it differently. ","pontos":37},{"corpo":"Throwing an ArgumentNullException isn't appropriate unless the argument is actually null. Throw an ArgumentOutOfRangeException instead (preferably with a message informing the user what values of int are actually acceptable). ArgumentOutOfRangeException is thrown when a method is invoked and at least one of the arguments passed to the method is not a null reference (Nothing in Visual Basic) and does not contain a valid value. ","pontos":8},{"corpo":"We've got complex requirements like: Only certain users can create folders in parts of the SVN tree, but everyone can edit files there Certain file extensions cannot contain certain text in the file Certain file extensions can only be stored in a subset of directories As well as several simpler ones like, Must have a commit comment Regression testable by running new hook against all previous SVN commits #5 is huge for us, there's no better way to know you're not gonna break commits moving forward than to be able to push all previous commits through your new hook. Making the hook understand that 1234 was a revision and 1234-1 was a transaction and making the appropriate argument changes when calling svnlook, etc. was the best decision we made during the process. For us the nut got big enough that a fully unit testable, regression testable, C# console exe made the most sense. We have config files that feed the directory restrictions, parse the existing httpd_authz file to get \"privileged\" users, etc. Had we not been running on Windows with a .NET development work force, I would have probably written it all in Python, but since others might need to support it in the future I went .NET over .BAT, .VBS, Powershell silliness. Personally I think Powershell is different enough from .NET to be mostly useless as a \"scripting\" language. It's good if the only cmd line support for a product comes via PS (Exchange, Windows 2k8), etc. but if all you want to do is parse some text or access regular .NET objects PS just adds a crazy syntax and stupid Security Iron Curtain to what could be a quick and easy little .NET app. ","pontos":4},{"corpo":"I was going to say that, I didn't think that Silverlight 2's HttpWebRequest supported streaming, because the request data gets buffered into memory entirely. It had been a while since the last time I looked at it though, therefore I went back to see if Beta 2 supported it. Well turns out it does. I am glad I went back and read before stating that. You can enable it by setting AllowReadStreamBuffering to false. Did you set this property on your HttpWebRequest? That could be causing your block. MSDN Reference File upload component for Silverlight and ASP.NET Edit, found another reference for you. You may want to follow this approach by breaking the file into chunks. This was written last March, therefore I am not sure if it will work in Beta 2 or not. ","pontos":1},{"corpo":"As long as the name of the folder doesn't need to be meaningful, how about using a GUID for them? ","pontos":1},{"corpo":"Well, Amazon EC2 is only as bad as the amount of traffic you get. So the ideal situation is to monetize your site (ads, affiliate programs, etc) so that that more traffic you get, the more you pay Amazon, but the more you make...in theory of course. As for a budget of nothing...there's not really much you can do...hosting typically always costs something, but since you are using the LAMP stack, it's pretty cheap. For example, hosting on GoDaddy.com for 1year can be about $50-60 which is not too bad. I use dreamhost which costs about $80 per year, but I get MUCH more storage and bandwidth. ","pontos":1},{"corpo":"I've had to do this a few times, and there are only two options that I know of. Copy the file locally to the SQL Server, or on the SQL server create a mapped network drive to the share that contains the backup file. ","pontos":0},{"corpo":"You can use (VS.85).aspx\">GetTempFileName to create a temporary file, then delete and re-create this file as a directory instead. Note: link didn't work, copy/paste from: http://msdn.microsoft.com/en-us/library/aa364991(VS.85).aspx ","pontos":1},{"corpo":"How are the Eclipse settings saved? Perhaps you could simply adapt this macro and load the resulting file into Eclipse? ","pontos":1},{"corpo":"The google maps sample is using this code... var bounds = map.getBounds(); var southWest = bounds.getSouthWest(); var northEast = bounds.getNorthEast(); var lngSpan = northEast.lng() - southWest.lng(); var latSpan = northEast.lat() - southWest.lat(); ...which is putting the SouthWest/NorthEast bounds into a variable before attempting to get the individual lng/lat coordinates. Maybe there is something with the \"nested\" evaluations causing problems. Have tried the granular approach to see if you get the data you need? ","pontos":1},{"corpo":" Does anyone know of anyway to reduce/optimize the PDF export phase and or the size of the PDF without lowering the total page count? I have a few ideas and questions: 1. Is this a graphics-heavy report? If not, do you have tables that start out as text but are converted into a graphic by the SSRS PDF renderer (check if you can select the text in the PDF)? 41K per page might be more than it should be, or it might not, depending on how information-dense your report is. But we've had cases where we had minor issues with a report's layout, like having a table bleed into the page's margins, that resulted in the SSRS PDF renderer \"throwing up its hands\" and rendering the table as an image instead of as text. Obviously, the fewer graphics in your report, the smaller your file size will be. 2. Is there a way that you could easily break the report into pieces? E.g., if it's a 10-location report, where Location 1 is followed by Location 2, etc., on your final report, could you run the Location 1 portion independent of the Location 2 portion, etc.? If so, you could join the 10 sub-reports into one final PDF using PDFSharp after you've received them all. This leads to some difficulties with page numbering, but nothing insurmountable. 3. Does anyone else have any other theories as to why this runs on the server but not through the API? My guess would be the sheer size of the report. I don't remember everything about what's an IIS setting and what's SSRS-specific, but there might be some overall IIS settings (maybe in Metabase.xml) that you would have to be updated to even allow that much data to pass through. You could isolate the question of whether the time is the problem by taking one of your working reports and building in a long wait time in your stored procedures with WAITFOR (assuming SQL Server for your DBMS). Not solutions, per se, but ideas. Hope it helps. ","pontos":3},{"corpo":"For completeness sake: even though my company more or less standardizes on Eclipse we use Netbeans (6 and up) with its included, free profiler on a daily basis. It works better than the Eclipse TPTP plugin (last checked 3 months ago) and for us it removes any need for a commercial profiler such as JProfiler, which is excellent, but fast becoming unnecessary. ","pontos":0},{"corpo":"Personally I use PDO, but I think that is mainly a question of preference. PDO has some features that help agains SQL injection (prepared statements), but if you are careful with your SQL you can achieve that with mysqli, too. Moving to another database is not so much a reason to use PDO. As long as you don't use \"special SQL features\", you can switch from one DB to another. However as soon as you use for example \"SELECT ... LIMIT 1\" you can't go to MS-SQL where it is \"SELECT TOP 1 ...\". So this is problematic anyway. ","pontos":5},{"corpo":"Note that Zend Optimizer and MMCache (or similar applications) are totally different things. While Zend Optimizer tries to optimize the program opcode MMCache will cache the scripts in memory and reuse the precompiled code. I did some benchmarks some time ago and you can find the results in my blog (in German though). The basic results: Zend Optimizer alone didn't help at all. Actually my scripts were slower than without optimizer. When it comes to caches: * fastest: eAccelerator * XCache * APC And: You DO want to install a opcode cache! For example: This is the duration it took to call the wordpress homepage 10.000 times. Edit: BTW, eAccelerator contains an optimizer itself. ","pontos":10},{"corpo":"In Sybase SQL Anywhere: SELECT TOP 1 START AT n * from table ORDER BY whatever Don't forget the ORDER BY or it's meaningless. ","pontos":1},{"corpo":"The above method calls for using the SavingChanges event which is called before the changes are persisted. If there is an error during the save, you have already cleared your dirty flag. I would think there would be a SavedChanges event exposed as well. ","pontos":1},{"corpo":"In SQL 2000, the row limit is 8K bytes, which is the same size as a page in memory. [Edit] In 2005, the page size is the same (8K), but the database uses pointers on the row in the page to point to other pages that contain larger fields. This allows 2005 to overcome the 8K row size limitation. ","pontos":9},{"corpo":"This is usually caused by a 'rogue' add-in. Try disabling them all, and then re-enabling them checking for the error - so that you can narrow down the culprit. ","pontos":1},{"corpo":"Are there any add-ons installed? Or is this a \"out of the box\" visual studio install? ","pontos":0},{"corpo":"Can't you edit the Web Deployment project's MSBuild file for it to do what you want? ","pontos":1},{"corpo":"I think you put $_POST['destroy'] Instead of $_GET['destroy'] You need to use a form if you'd like to use a $_POST variable. $_GET variables are stored in the URL. ","pontos":6},{"corpo":"For me, the concept of Haskell's algebraic data types always looked like polymorphism in OO-languages like C#. Look at the example from http://en.wikipedia.org/wiki/Algebraic_data_types: data Tree = Empty | Leaf Int | Node Tree Tree This could be implemented in C# as a TreeNode base class, with a derived Leaf class and a derived TreeNodeWithChildren class, and if you want even a derived EmptyNode class. (OK I know, nobody would ever do that, but at least you could do it.) ","pontos":0},{"corpo":"Yeah, you're going to want to do if( $_GET['destroy'] == 1 ) or if( isset($_GET['destroy']) ) ","pontos":1},{"corpo":"After spending some more time on this I agree with @grapefrukt. Setting wmode to transparent leads to all sorts of strange issues and in my opinion it should be avoided. Instead I've resorted to passing the background color as a parameter. I use the following ActionScript to draw the background. var parameters:Object = LoaderInfo(this.root.loaderInfo).parameters; opaqueBackground = parameters[\"background-color\"]; EDIT: Thanks to @grapefrukt for reminding me of the bgcolor param (which makes the ActionScript above totally unnecessary) ","pontos":0},{"corpo":"SVN with SmartSVN or tortoiseSVN ? not really all that lightweight, but good practice for the big bad world. ","pontos":2},{"corpo":"Example for SVN: trunk/ branch/ tags/ The trunk should be kept at a point where you can always push a release from it. There should be no huge gaping bugs that you know about(of course there will be eventually but that is what you should strive for). Every time you need to make a new feature, do a design change, whatever, branch. Tag that branch at the start. Then when you are finished with the branch tag it at the end. This helps out with merging back into trunk. Every time you need to push a release, tag. This way if something goes horribly wrong you can rollback to the previous release. This setup keeps trunk as clean as possible and allows you to make quick bug fixes and push them out while keeping the majority of your development in branches. Edit: For 3rd party stuff it depends. If I can avoid it I do not have it under source control. I keep it in a directory outside source control and include it from there. For things like jquery, I do leave it under source control. The reason is it simplifies my script for pushing. I can simply have it do an svn export and rsync. ","pontos":7},{"corpo":"Crystal Reports by Business Objects seems to be a popular choice. I never wrote any reports in it myself, but others in my team who did sometimes struggled getting the more complex reports to work. It also might be a bit pricey, depending on your budget. ","pontos":2},{"corpo":"Pick your flavour of distributed version control. I like Mercurial, other folks swear by Git and Bazaar. There's no need to make a fake server to put a directory under version control, which, IMO, makes it very ideal for small projects. I'm not sure if any of these have Visual Studio plugins, though. ","pontos":2},{"corpo":"You can use WebClient in System.Net to download: WebClient Client = new WebClient (); Client.DownloadFile(\"http://data.dot.state.mn.us/dds/det_sample.xml.gz\", \" C:\\mygzipfile.gz\"); then use #ziplib to extract Edit: or GZipStream... forgot about that one ","pontos":7},{"corpo":"Yeah using Microsoft Script Editor is a an option if you have Office XP or Office 2003 installed. In IE uncheck Disable Script debugging (Internet Explorer) and Disable Script debugging (Other). Restart IE. In View menu you will have a new item, \"script debugging\", choose open. You will be given a choice of VS2005 or New instance of Microsoft Script Editor, choose that and give it a go. Edit: try this link for a tutorial ","pontos":0},{"corpo":"break causes the program counter to jump out of the scope of the innermost loop for(i = 0; i 10; i++) { if(i == 2) break; } Works like this for(i = 0; i 10; i++) { if(i == 2) goto BREAK; } BREAK:; continue jumps to the end of the loop. In a for loop, continue jumps to the increment expression. for(i = 0; i 10; i++) { if(i == 2) continue; printf(\"%d\", i); } Works like this for(i = 0; i 10; i++) { if(i == 2) goto CONTINUE; printf(\"%d\", i); CONTINUE:; } ","pontos":58},{"corpo":"I prefer distributed version control for personal projects, because they eliminate the need for a server. Mercurial is the one I try to use most of the time, but I've been hearing good things about git as well. ","pontos":3},{"corpo":"I think the SCM policies and procedures a team adopts are going to be very dependent on the development process they are using. If you've got a team of 50 with several people working on major changes simultaneously and releases only occurring every 6 months, it makes a lot of sense for everyone to have his own branch where he can work in isolation and only merge in changes from other people when he wants them. On the other hand, if you're a team of 5 all sitting in the same room it makes sense to branch much less frequently. Assuming you're working on a small team where communication and collaboration is good and releases are frequent, it makes very little sense to ever branch IMO. On one project we simply rolled the SVN revision number into the product version number for all our releases and we never even tagged. In the rare event that there was a critical bug found in prod we would simply branch straight from the revision that was released. But most of the time we simply fixed the bug in the branch and released from trunk at the end of the week as scheduled. If your releases are frequent enough you'll almost never run into a bug that can't wait until the next official release. I've worked on other projects where we never could have gotten away with that, but due to the lightweight development process and low ceremony we were able to use a lightweight version control policy very effectively. I'll also mention that everything I've written is coming from an enterprise IT context where there's only a single production instance of a given code base. If I was working on a product that was deployed at 100 different customer sites the branching and tagging practices would have to be a little more strenuous in order to manage all of the independent update cycles across all the instances. ","pontos":1},{"corpo":"I can't comment on other source control software but after using VSS 6.0 , StarTeam, Vault and SVN I cannot rate SVN + Tortoise more highly. AnkhSVN is a free plug-in for Visual studio which I personally didn't warm to. Apparently Visual SVN is much better but costs money. ","pontos":3},{"corpo":" Dale Ragan wrote: You can't use the AjaxToolKit controls in ASP.NET MVC How is AJAX handled on Stack Overflow? Does JQuery do it? In his Coding Horror post Secrets of the JavaScript Ninjas Jeff wrote about using JQuery while writing Stack Overflow. Surely they didn't code it by hand. I did that once with all the XMLHttpRequest JavaScript when the term \"AJAX\" was popularized around 2005. It was a nightmare. ","pontos":0},{"corpo":"The so-called xUnit framework is widely used. It was originally developed for Smalltalk as SUnit, evolved into JUnit for Java, and now has many other implementations such as NUnit for .Net. It's almost a de facto standard - if you say you're using unit tests, a majority of other developers will assume you mean xUnit or similar. ","pontos":3},{"corpo":"Ok here's some best practices from some one who doesn't unit test as much as he should...cough. Make sure your tests test one thing and one thing only. Write unit tests as you go. Preferably before you write the code you are testing against. Do not unit test the GUI. Separate your concerns. Minimise the dependencies of your tests. Mock behviour with mocks. ","pontos":19},{"corpo":"Doesn't seem to happen to me. But I wasn't aware of that feature before, and I just tried it today. You might want to try installing Service Pack 1, as I also just installed that today, and the behaviour seems to have been fixed. ","pontos":0},{"corpo":"Maybe they changed it in SP1, but it works that way in mine. Holding down CTRL, tab cycles through the pages. When I let off of CTRL, it selects that page and disappears. I never tried it before SP1, so can't tell you if it's new behavior. ","pontos":0},{"corpo":"I can't replicate this behavior. When I let go of Control, the window switcher disappears. I looked through the settings and didn't find an option for this either. Stuck key maybe? ","pontos":0},{"corpo":"You want to use something that is relatively prime to the size of your set. That way, when you loop around, you won't end up on the same numbers you just tried. ","pontos":3},{"corpo":"It appears that this is a known bug... The following code appears to function as you requested: protected override void OnPaint(PaintEventArgs e) { PointF[] points = new PointF[] { new PointF(73.36f, 196), new PointF(75.44f, 32), new PointF(77.52f, 32), new PointF(79.6f, 196), new PointF(85.84f, 196) }; e.Graphics.SmoothingMode = System.Drawing.Drawing2D.SmoothingMode.AntiAlias; Rectangle b = new Rectangle(70, 32, 20, 165); e.Graphics.SetClip(b); e.Graphics.DrawLines(Pens.Red, points); // clipped incorrectly e.Graphics.TranslateTransform(80, 0); e.Graphics.ResetClip(); e.Graphics.DrawLines(Pens.Red, points); } Note: I have AntiAlias'ed the line and extended your clipping region by 1 it appears that the following work arounds might help (although not tested): The pen is more than one pixel thick The line is perfectly horizontal or vertical The clipping is against the window boundaries rather than a clip rectangle The following is a list of articles that might / or then again might not help: http://www.tech-archive.net/pdf/Archive/Development/microsoft.public.win32.programmer.gdi/2004-08/0350.pdf http://www.tech-archive.net/Archive/Development/microsoft.public.win32.programmer.gdi/2004-08/0368.html OR... the following is also possible: protected override void OnPaint ( PaintEventArgs e ) { PointF[] points = new PointF[] { new PointF(73.36f, 196), new PointF(75.44f, 32), new PointF(77.52f, 32), new PointF(79.6f, 196), new PointF(85.84f, 196) }; Rectangle b = new Rectangle( 70, 32, 20, 164 ); Region reg = new Region( b ); e.Graphics.SetClip( reg, System.Drawing.Drawing2D.CombineMode.Union); e.Graphics.DrawLines( Pens.Red, points ); // clipped incorrectly e.Graphics.TranslateTransform( 80, 0 ); e.Graphics.ResetClip(); e.Graphics.DrawLines( Pens.Red, points ); } This effecivly clips using a region combined/unioned (I think) with the ClientRectangle of the canvas/Control. As the region is difned from the rectangle, the results should be what is expected. This code can be proven to work by adding e.Graphics.FillRectangle( new SolidBrush( Color.Black ), b ); after the setClip() call. This clearly shows the black rectangle only appearing in the clipped region. This could be a valid workaround if Anti-Aliasing the line is not an option. Hope this helps ","pontos":1},{"corpo":"This is where I started. haskell.org ","pontos":1},{"corpo":"Haskell's datatypes are called \"algebraic\" because of their connection to categorical initial algebras. But that way lies madness. @olliej: ADTs are actually \"sum\" types. Tuples are products. ","pontos":8},{"corpo":"@Chuck - No worries. That is what SO is for. You learn something and the person asking the question learns something. ","pontos":0},{"corpo":"By the way you can use $_REQUEST['destroy'] which would work regardless if the data is passed in a POST or a GET request. ","pontos":4},{"corpo":"Some good places to start are: The Gentle Introduction To Haskell Problem Solving in Haskell Other resources: Interesting blog entry on a Study plan for Haskell via the Wayback Machine HaskellWiki Generic Haskell User Guide (PDF) ","pontos":39},{"corpo":"Does this happen when you run the javac command from the command line? You might want to try the fork attribute. ","pontos":1},{"corpo":"I'm pretty much writing my own HTML - I'm using the ListView and Masterpages, but not really using the controls much anymore. My ListView laughs at your silly old repeater, by the way. However, bloatware isn't necessarily a bad thing. If I needed a low volume intranet application built, I'd much rather pay a less experienced developer to drag and drop controls than for an HTML twiddler (like you or me) to craft each tag. There's definitely a place for the quick, simple approach. What's the cost of \"bloatware\" in that scenario, as long as the control based code is written in a maintainable fashion? Often wiring controls together requires less custom code, which means simple maintenance. The one place I have to disagree with you - pretty much regardless of the application - is in crafting your own paging queries. You may like to do that kind of thing, but there's absolutely no business value in it. There are several professional-grade DAL tools which will usually write more maintainable, faster queries than most developers. Even if you lovingly craft the perfect paging query, it won't keep up to date with changes to the schema unless you continue to throw hours after it. I think better use of those hours is to build a lightweight system and put those hours into monitoring and fixing specific bottlenecks, rather than immediately jumping to the \"database assembly language\" layer. ","pontos":17},{"corpo":"That's quite odd, 100 classes really isn't that many. What is the compiler doing when the stack overflows? Is there a useful stack trace generated? What happens if you run directly on the command line instead of thorugh ant? One possible workaround is to simply increase the size of the stack using the argument to the JVM; either to the JVM running or by setting and a on the task. Actually now that I think of it, does the problem go away just putting in the ? ","pontos":0},{"corpo":"Vim is a nice upgrade for Vi, offering decent features and a more usable set of keybindings and default behaviour. However, graphical versions like GVim, KVim and even Cream are extremely lacking in my opinion. I've been using Geany a lot lately, but it also has its shortcomings. I just can't find something in the league of Programmers Notepad, Smultron or TextMate on Linux. A shame, since I want to live in an all open source cyberworld, I'm stuck hopping from one almost-right editor to another. ","pontos":0},{"corpo":"I have a poor man's version of this I have used in the past... this requires jquery and firebug... script type=\"text/javascript\" $(document).ready(function() { $('*[@id]').each(function() { console.log('#' + this.id + ' {}'); }); $('*[@class]').each(function() { $.each($(this).attr('class').split(\" \"), function() { console.log('.' + this + ' {}'); }); }); }); /script it gives you something like this: #spinner {} #log {} #area {} .cards {} .dialog {} .controller {} if you want them in \"natural\" page order instead... script type=\"text/javascript\" $(document).ready(function() { $('*').each(function() { if($(this).is('[@id]')) { console.log('#' + this.id + ' {}'); } if($(this).is('[@class]')) { $.each($(this).attr('class').split(\" \"), function() { console.log('.' + this + ' {}'); }); } }); }); /script I just load the page with that script in there, then cut and paste the results out of firebug... then obviously, remove the script :) you'll need to remove the dups manually or just toss in some simple dup checking logic with a map or array or something.. one for IDs and one for classes. ","pontos":10},{"corpo":"Debug Companion VS plugin seem to be exactly what I was looking for, except that it won't see library project in my solution. Only when I added a console win application to the solution did something appear in that list of projects. The problem with the decompile/compile approach for me was that the code I was debugging wasn't my code. I could have decompiled it anyway but I think there's no way to sign that recompiled assembly so that it gets loaded instead of the original one. With the particular problem I had it turned out that it was enough to just debug it on the assembly language level and get the call stack of the method which was throwing the exception and the parameters with which the method was called. ","pontos":0},{"corpo":"This blog entry references to something similar to what you need here. It contains a link to a Perl script called 'stylizator.pl'. This script parses the html to look for possible CSS elements and outputs them to a file. ","pontos":1},{"corpo":"Just a word of warning with: If you did not truncate the table, and the identity column is the PK, you will get an error when reaching pre-existing identites. For example, you have identities (3,4,5) in the table already. You then reset the identity column to 1. After the identity 2 is inserted, the next insert will try to use the identity 3, which will fail. ","pontos":22},{"corpo":"Sounds to me like your keyboard has a stuck key. Try to find out if Control is sticking by running osk.exe (Windows built-in On-screen keyboard) which will show you what keys are being pushed. ","pontos":0},{"corpo":"It's of course a matter of style, but I agree with Dare: C# 3.0 Implicit Type Declarations: To var or not to var?. I think using var instead of an explicit type makes your code less readable.In the following code: var result = GetUserID(); What is result? An int, a string, a GUID? Yes, it matters, and no, I shouldn't have to dig through the code to know. It's especially annoying in code samples. Jeff wrote a post on this, saying he favors var. But that guy's crazy! I'm seeing a pattern for stackoverflow success: dig up old CodingHorror posts and (Jeopardy style) phrase them in terms of a question. ","pontos":33},{"corpo":"There was a good discussion on this @ Coding Horror Personally I try to keep its use to a minimum, I have found it hurts readability especially when assigning a variable from a method call. ","pontos":2},{"corpo":"@jongalloway - var doesn't necessarily make your code more unreadable. var myvariable = DateTime.Now DateTime myvariable = DateTime.Now; The first is just as readable as the second, and requires less work var myvariable = ResultFromMethod(); here, you have a point, var could make the code less readable. I like var because if i change a decimal to a double, i don't have to go change it in a bunch of places (and don't say refactor, sometimes i forget, just let me var!) EDIT: just read article, i agree. lol. ","pontos":3},{"corpo":"You might want to look at TDD on Three Index Cards and Three Index Cards to Easily Remember the Essence of Test-Driven Development: Card #1. Uncle Bobs Three Laws Write no production code except to pass a failing test. Write only enough of a test to demonstrate a failure. Write only enough production code to pass the test. Card #2: FIRST Principles Fast: Mind-numbingly fast, as in hundreds or thousands per second. Isolated: The test isolates a fault clearly. Repeatable: I can run it repeatedly and it will pass or fail the same way each time. Self-verifying: The Test is unambiguously pass-fail. Timely: Produced in lockstep with tiny code changes. Card #3: Core of TDD Red: test fails Green: test passes Refactor: clean code and tests ","pontos":10},{"corpo":"XMLSpy does that for you, although that's not free... I believe that this does it for you and is free, but I have not personally used it to create create test data. ","pontos":6},{"corpo":"actually I use it in a non traditional way on my site IdeaPipe public override IEnumerator T GetEnumerator() { // goes through the collection and only returns the ones that are visible for the current user // this is done at this level instead of the display level so that ideas do not bleed through // on services foreach (T idea in InternalCollection) if (idea.IsViewingAuthorized) yield return idea; } so basically it checks if viewing the idea is currently authorized and if it is it returns the idea. If it isn't, it is just skipped. This allows me to cache the Ideas but still display the ideas to the users that are authorized. Else I would have to re pull them each time based on permissions, when they are only re-ranked every 1 hour. ","pontos":5},{"corpo":"(2 | 4) is evaluating to 6, but 2 == 6 is false. ","pontos":1},{"corpo":"You probably have the text-to-speech narrator enabled. http://forums.microsoft.com/MSDN/ShowPost.aspx?PostID=2467648 SiteID=1 mode=1 Just uncheck all checkboxes under \"Text-To-Speech\" narrator software. --> To open Narrator using the keyboard, press CTRL+ESC, press R, type narrator, and then press Enter. This one drove me crazy for several months until I found this posting. ","pontos":13},{"corpo":"I don't know which particlar TDD subcommunity you're refering to but the TDD patterns I've come across either use Assert.AreEqual() for positive results or otherwise use an ExpectedException mechanism (e.g., attributes in .NET) to declare the error that should be observed. ","pontos":0},{"corpo":"There is no reason why your test package cannot catch asserts such as the one in doMoreWonderfulThings. This can be done either by having your ASSERT handler support a callback mechanism, or your test asserts contain a try/catch block. ","pontos":1},{"corpo":"I could be wrong but shouldn't you be using a full outer join instead of just a left join? That way you will be getting 'empty' columns from both tables. http://en.wikipedia.org/wiki/Join_(SQL)#Full_outer_join ","pontos":0},{"corpo":"Parity with WPF. Triggers (event triggers and data triggers too), Binding to other elements in xaml, Multi-part value converters, and DynamicResources. Commands... maybe if they got time. ","pontos":3},{"corpo":" Awesome, this seems like the best way to do permissions in a CMS. Yes? No? Maybe, I've never really done it that way. What I have done is used bitwise operators to store a whole bunch of \"yes or no\" settings in a single number in a single column in the database. I guess for permissions, this way would work good if you want to store permissions in the database. If someone wants to post some content, and only wants admins and editors to see it, you just have to store the result of ($editor | $admin) into the database, then to check it, do something like if ($user $database_row['permissions']) { // display content } else { // display permissions error } ","pontos":1},{"corpo":"In my opinion this doesn't scale well. I haven't actually tried using it on a large scale project, but a CMS sounds way to complicated to use this on. ","pontos":0},{"corpo":"I would wager the author is showing they are uncomfortable with certain aspects of qualtiy wrt shell scripting. Who unit tests BASH scripts for example. Also scripts are rather heavily coupled with the underlying operating system, which could be something of a negative thing. ","pontos":0},{"corpo":"Obviously, this is a bit of a straw man for me to knock down. I really am interested in why people believe shell scripts should be avoided in \"mission-critical applications\", but I can't think of a compelling reason. For instance, I've seen (and written) some ksh scripts that interact with an Oracle database using SQL*Plus. Sadly, the system couldn't scale properly because the queries didn't use bind variables. Strike one against shell scripts, right? Wrong. The issue wasn't with the shell scripts but with SQL*Plus. in fact, the performance problem went away when I replaced SQL*Plus with a Perl script that connected to the database and used bind variables. I can easily imagine putting shell scripts in spacecraft flight software would be a bad idea. But Java or C++ may be an equally poor choices. The best choice would be whatever language (assembly?) is usually used for that purpose. The fact is, if you use any flavor of Unix, you are using shell scripts in mission-critical situations assuming you think booting up is mission critical. When a script needs to do something that shell isn't particularly good at, you put that portion into a sub-program. You don't throw out the script wholesale. ","pontos":4},{"corpo":"@Christian -- markdown editor -- UGH; especially when the preview and the final version of your post disagree... @Christian -- full outer join -- the full outer join is overruled by the fact that there are references to SP1 in the WHERE clause, and the WHERE clause is applied after the JOIN. To do a full outer join with filtering on one of the tables, you need to put your WHERE clause into a subquery, so the filtering happens before the join, or try to build all of your WHERE criteria onto the JOIN ON clause, which is insanely ugly. Well, there's actually no pretty way to do this one. @Jonas: Considering this: Also, the report is actually for financial year - so I would love to have empty columns with 0 in both if there was no sales in say month 5 for either 2007 or 2008. and the fact that this job can't be done with a pretty query, I would definitely try to get the results you actually want. No point in having an ugly query and not even getting the exact data you actually want. ;) So, I'd suggest doing this in 5 steps: 1. create a temp table in the format you want your results to match 2. populate it with twelve rows, with 1-12 in the month column 3. update the \"This Year\" column using your SP1 logic 4. update the \"Last Year\" column using your SP2 logic 5. select from the temp table Of course, I guess I'm working from the assumption that you can create a stored procedure to accomplish this. You might technically be able to run this whole batch inline, but that kind of ugliness is very rarely seen. If you can't make an SP, I suggest you fall back on the full outer join via subquery, but it won't get you a row when a month had no sales either year. ","pontos":3},{"corpo":"About the markdown - Yeah that is frustrating. The editor did preview my HTML table, but after posting it was gone - So had to remove all HTML formatting from the post... @kcrumley I think we've reached similar conclusions. This query easily gets real ugly. I actually solved this before reading your answer, using a similar (but yet different approach). I have access to create stored procedures and functions on the reporting database. I created a Table Valued function accepting a product category and a financial year as the parameter. Based on that the function will populate a table containing 12 rows. The rows will be populated with data from the view if any sales available, if not the row will have 0 values. I then join the two tables returned by the functions. Since I know all tables will have twelve roves it's allot easier, and I can join on Product Category and Month: SELECT SP1.Program, SP1.Year, SP1.Month, SP1.TotalRevenue AS ThisYearRevenue, SP2.TotalRevenue AS LastYearRevenue FROM GetFinancialYear(@Category, 'First Look', 2008) AS SP1 RIGHT JOIN GetFinancialYear(@Category, 'First Look', 2007) AS SP2 ON SP1.Program = SP2.Program AND SP1.Month = SP2.Month I think your approach is probably a little cleaner as the GetFinancialYear function is quite messy! But at least it works - which makes me happy for now ;) ","pontos":1},{"corpo":"All of the links on that page are displaced to the right on my copy of IE7 (7.0.6001.18000) even before I enlarge or shrink the fonts. Whereas other pages act normally. (My test page was http://www.frito-lay.com/fl/flstore/cgi-bin/good_questions.htm). It appears to be something specific to the page. ","pontos":0},{"corpo":"I've been reading your posts guys and it made me feel dumb. I mean in every application I made where I work there is at least one datagrid/gridview in it. And I didn't have the feeling I am missing something. Sure I find datagrid/gridview kinda bloated but are they that much disgusting to use? ","pontos":15},{"corpo":"There are two rules I follow: Accept the most basic type that will work Return the richest type your user will need So when writing a function or method that takes a collection, write it not to take a List, but an IList T , an ICollection T , or IEnumerable T . The generic interfaces will still work even for heterogenous lists because System.Object can be a T too. Doing this will save you headache if you decide to use a Stack or some other data structure further down the road. If all you need to do in the function is foreach through it, IEnumerable T is really all you should be asking for. On the other hand, when returning an object out of a function, you want to give the user the richest possible set of operations without them having to cast around. So in that case, if it's a List T internally, return a copy as a List T . ","pontos":90},{"corpo":"I find the main challenge with iFrame headers is resizing. Since the font in your header is of static size, I don't see a problem with using an iFrame. Although I'm not sure if it's really intensive enough to be worth it. ","pontos":0},{"corpo":"Well, the browser appears to cache all seven banner images upon the first load, and runs them out from the cache (for each subsequent page) thereafter. I don't think you have a problem :D Try it out with Firebug's Net monitoring tool in Firefox. ","pontos":0},{"corpo":"I've used this method before. The Length property of StringBuilder is NOT readonly so subtracting it by one means truncate the last character. But you have to make sure your length is not zero to start with (which would happen if your list is empty) because setting the length to less than zero is an error. public string ReturnAsCSV(ContactList contactList) { StringBuilder sb = new StringBuilder(); foreach (Contact c in contactList) { sb.Append(c.Name + \",\"); } if (sb.Length 0) sb.Length -= 1; return sb.ToString(); } ","pontos":0},{"corpo":"@ESV, the closures are the three definitions that are indented (ie. , and ). They are closures because they are functions defined within the scope of the function. ","pontos":0},{"corpo":"This may work without CSS also, but if you use CSS to load the background and your server is configured correctly, the image should already only be downloaded once. Usually the browser will request a resource by asking for it only if it has not been modified since the last time it was downloaded. In this case, the only things sent back and forth are the HTTP headers, no content. If you want to ensure the image is only downloaded once, add an .htacces or an apache2.conf rule to make the image expire a few days into the future so that users will only request it again if their cache is cleared or the content expiration date passes. An .htaccess file is probably too excessive to use in your case, though results may vary. ","pontos":0},{"corpo":"You could have it load the main page once, then asynchronously load the other elements when needed (ajax). If you did that, an iFrame would not be necessary. Here is an example of loading only the new material. ","pontos":0},{"corpo":"In the interest of not reinventing the wheel, why not take a look at ACL/Authentication systems like Zend ACL and Zend Auth? Both can be used independently from the Zend Framework as a whole. Access Control is a tricky situation so it benefits one to at least look at how other systems do it. ","pontos":4},{"corpo":"We migrated from the bad world of VSS with one giant repository (over 4G) before switching to SVN. I really struggled with how to set up the new repository for our company. Our company is very \"old\" school. It's difficult to get change I'm one of the younger developers and I'm 45! I am part of a corporate development team that works on programs for a number of departments in our company. Anyway I set up our directories like this + devroot +--Dept1 +--Dept1Proj1 +--Dept2Proj2 +--Dept2 +--Dept2Proj1 +--Tools +--Purchase3rdPartyTools +--NLog +--CustomBuiltLibrary I wanted to include the ability to branch, but quite honestly that's just too much at this point. Couple things we still struggle with using this scheme. It's hard to fix production problems if you are working on a major product upgrade (ie because we don't do branching) It's hard to manage the concept of promoting from \"Dev\" to \"Prod\". (Don't even ask about promoting to QA) ","pontos":0},{"corpo":"Mailto isn't a bad route to go. But as you mentioned, you'll need to make sure it is encoded correctly. The main problem with using mailto is with breaking lines. Use %0A for carriage returns, %20 for spaces. Also, keep in mind that the mailto is considered the same as a URL of sorts and therefore will have the same limitations for length. See http://support.microsoft.com/kb/208427, note the maximum URL length of 2083 characters. This is confirmed for mailto as well in this article: http://support.microsoft.com/kb/279460/en-us. Also, some mail clients can also have a limit (I believe older versions of Outlook Express had a limit of something much smaller like 483 characters or something. If you expect to have a longer string than that then you'll need to look at alternatives. BTW, you shouldn't have to resort to kicking out a script to do that as long as you can shell out a command from Java (I don't know if you can since I don't do Java). ","pontos":2},{"corpo":"There's a thorough discussion of this that explains all of the fsync related problems that affected pre-3.0 versions of FF. In general, I have not seen the behaviour since then either, and really it shouldn't be a problem at all if your system isn't also doing IO intensive tasks. Firebug/Venkman make for nice debuggers, but they would be painful for figuring out these kinds of problems for someone else's code, IMO. I also wish that there was an easy way to look at CPU utilization in Firefox by tab, though, as I often find myself with FF eating 100% CPU, but no clue which part is causing the problem. ","pontos":1},{"corpo":"OpenGL Extensions are new features added to the OpenGL specification, they are added by the OpenGL standards body and by the various graphics card vendors. These are exposed to the programmer as new function calls or variables. Every new version of the OpenGL specification ships with newer functionality and (typically) includes all the previous functionality and extensions. The real problem with OpenGL extensions exists only on Windows. Microsoft hasn't supported any extensions that have been released after OpenGL v1.1. The graphics card vendors overcome this by shipping their own version of this functionality through header files and libraries. However, using this can be a bit painful as the question you linked to shows. But this problem has mostly gone away with the popularity of GLEW, which takes care of wrapping all this into a easy-to-use package. If you do use a very recent OpenGL extension, be aware that it may not be supported on older graphics hardware. Other than this, there's no other disadvantage to using these extensions. Most of the extensions which become standard are pretty darn useful and there's very little logic to not use them. ","pontos":6},{"corpo":"I listen to and watch: * this week in tech * Cranky Geeks * Security Now * This Week in Media * Tech5 ","pontos":0},{"corpo":"You don't test the converter, you test the final code. If the code doesn't compile, clearly your converter is failing. If the code compiles and your functionality tests fail, then you can tweak the code so that it passes the test. If you are fairly successful you should see that you only need to fix the modules that actually fail. Goodluck! ","pontos":2},{"corpo":"When implementing tree algorithms for class, the framework code the prof gave us had the tree class as a friend of the node class. It doesn't really do any good, other than let you access a member variable without using a setting function. ","pontos":1},{"corpo":"I can't see most developers getting over their distaste for client-side JavaScript programming. I'd rather go to Java for server-side stuff before choosing JavaScript. ","pontos":-1},{"corpo":"I've never even heard of this, but it strikes me as using the wrong tool for the job. Since programming languages are just tools designed to help us solve some problem. Why would you want to process something in Javascript when you can process it in PHP or ASP.NET which are designed specifically for this task? Sure you can pound a nail in with a screw driver, but a hammer works much better because it was actually designed for it... So no, I don't see it taking off. ","pontos":1},{"corpo":"It is possible for other applications to register themselves as a handler for files with a particular extension. Quicktime has (or at least had) a tendency to do this with .png files, so a .png file would display fine inline in an HTML page, but with an URL referring directly to the .png file, IE would immediately delegate all responsibility for handling the file to Quicktime. Might this be what is happening to your .jpg files? Is it only this .jpg file that you're having a problem with? ","pontos":0},{"corpo":"It won't load in IE7 on my Vista x64 box. Also Paint.net won't save the file, saying \"There was an unspecified error while saving the file.\" EDIT: In paint.net I did a Select All, New File, Paste, Save, and now it works fine. I'm guessing that file has some weird corruption. ","pontos":3},{"corpo":"A couple of ideas: Make your function private. Do not make your function virtual. This doesn't actually prevent the function from being shadowed by another definition though. Other than that, I'm not aware of a language feature that will lock away your function in such a way which prevents it from being overloaded and still able to be invoked through a pointer/reference to the child class. Good luck! ","pontos":12},{"corpo":"C++ methods are private and un-overridable by default. You cannot override a private method You cannot override a non- method Are you perhaps referring to overloading? ","pontos":0},{"corpo":" a compile time warning about hiding non-virtual inherited function X. change your compiler settings to make it a error instead of warning. ","pontos":1},{"corpo":"Unless you make the method virtual, the child class cannot override it. If you want to keep child classes from calling it, make it private. So by default C++ does what you want. ","pontos":0},{"corpo":"The file is probably not a fully valid JPG and IE6/7/8 (I tested on IE8 and it wont load). Other browsers are a bit more defensive and can load it, but perhaps IE team choose not to load it as it could be invalid in a way that causes a security hole. As Ryan Fox says, open it in an editor and re-save it ... where did the image come from, if it came from an editor dont use that editor again. Edit: I opened it an Paint Shop Pro and it had an unknown color palette so had to convert it ... perhaps that is the problem. You could report it as a bug to the IE team and see what they say. ","pontos":1},{"corpo":"@roo: Encapsulation is not broken here because the class itself dictates who can access its private members. Encapsulation would only be broken if this could be caused from outside the class, e.g. if your would proclaim I'm a friend of class . replaces use of , not use of ! Actually, the C++ FAQ answers this already. ","pontos":30},{"corpo":"I can't find any documentation that says you shouldn't use those methods directly, but I haven't looked very long. Also you refer to the EditorVisibleAttribute, which doesn't exist. According to Reflector it's the EditorBrowsableAttribute. Reflector disassembly: [EditorBrowsable(EditorBrowsableState.Never)] public bool CheckAccess() { //CODE } ","pontos":0},{"corpo":"Sounds like what you're looking for is the equivalent of the Java language final keyword that prevents a method from being overridden by a subclass. As others here have suggested, you really can't prevent this. Also, it seems that this is a rather frequently asked question. ","pontos":6},{"corpo":"I often use composite controls. Instead of overriding Render or RenderContents, just assign each Control a CssClass and use stylesheets. For multiple Controls.Add, I use an extension method: //Controls.Add(c1, c2, c3) static void Add(this ControlCollection coll, params Control[] controls) { foreach(Control control in controls) coll.Add(control); } For quick and dirty rendering, I use something like this: writer.Render(@\" table tr td {0} /td /tr tr td \", Text); control1.RenderControl(writer); writer.Render(\" /td /tr /table \"); For initializing control properties, I use property initializer syntax: childControl = new Control { ID=\"Foo\" , CssClass=\"class1\" , CausesValidation=true; }; ","pontos":1},{"corpo":"None of the APIs for the more 'Word' like online editors seem to have any 'edit' functionality, just download and upload. This is obviously due to the complexity of the documents being stored. With Google Docs API you can get a document, edit it, and then re-upload it (you may need to delete the previous version as well I think). Zoho seems to provide an 'update' method which combines the two operations. Have you looked at the Google Notebook API instead? This might provide more granular access to the data in the 'note' due to its structured approach to storing the data. ","pontos":2},{"corpo":"I'm familiar with Java rather than C#, but why an earth would you want a private member within an interface? It couldn't have any implementation and would be invisible to implementing classes, so would be useless. Interfaces exist to specify behaviour. If you need default behaviour than use an abstract class. ","pontos":0},{"corpo":"Yep, SandCastle. NDoc was abandoned, unfortunately. ","pontos":5},{"corpo":"The JPG you uploaded is in CMYK, IE and Firefox versions before 3 can't read these. Open it using Photoshop (or anything similar, I'm sure GIMP would work too) and resave it in RGB. edit: Further Googling makes me suspect that CMYK isn't really a part of the jpeg standard, but can be shoehorned in there. That's why some software does not consider the file valid. It does however open just fine in Photoshop CS3, and shows a cmyk colorspace. ","pontos":29},{"corpo":"If an interface is internal, all its members will be internal to the assembly. If an nested interface is protected, only the subclasses of the outer class could access that interface. Internal members for an interface outside of its declaring assembly would be pointless, as would protected members for an interface outside of its declaring outer class. The point of an interface is to describe a contract between a implementing type and users of the interface. Outside callers aren't going to care and shouldn't have to care about implementation, which is what internal and protected members are for. For protected members that are called by a base class, abstract classes are the way to go for specifying a contract between base classes and classes that inherit from them. But in this case, implementation details are usually very relevant, unless it's a degenerate pure abstract class (where all members are abstract) in which case protected members are useless. In that case, go with an interface and save the single base class for implementing types to choose. ","pontos":29},{"corpo":"You can use jpeginfo to find out if a jpeg file is OK or not. $jpeginfo -c blackout_thumb.jpg blackout_thumb.jpg 240 x 240 32bit Exif N 595116 Unsupported color conversion request [ERROR] In your case the file is corrupted which explain why some browsers cannot display it. ","pontos":2},{"corpo":"Regarding your update and speed question, remember to optimise later. First, write your word wrapping algorithm. Run it on a million lines if text. If and only if it is too slow for your requirements, then optimise. ","pontos":8},{"corpo":"Oh dear - after reading one of the other replies I tried reversing the order of the operations - so performing the concatenation first, then the String.Format... Bill Gates Console.WriteLine(p.FirstName + \" \" + p.LastName); took: 8ms - 30488 ticks Bill Gates Console.WriteLine(\"{0} {1}\", p.FirstName, p.LastName); took: 0ms - 182 ticks So the order of the operations makes a HUGE difference, or rather the very first operation is ALWAYS much slower. Here is the results of a run where operations are completed more than once. I have tried changing the orders but things generally follow the same rules, once the first result is ignored: Bill Gates Console.WriteLine(FirstName + \" \" + LastName); took: 5ms - 20335 ticks Bill Gates Console.WriteLine(FirstName + \" \" + LastName); took: 0ms - 156 ticks Bill Gates Console.WriteLine(FirstName + \" \" + LastName); took: 0ms - 122 ticks Bill Gates Console.WriteLine(\"{0} {1}\", FirstName, LastName); took: 0ms - 181 ticks Bill Gates Console.WriteLine(\"{0} {1}\", FirstName, LastName); took: 0ms - 122 ticks Bill Gates String.Concat(FirstName, \" \", LastName); took: 0ms - 142 ticks Bill Gates String.Concat(FirstName, \" \", LastName); took: 0ms - 117 ticks As you can see subsequent runs of the same method (I refactored the code into 3 methods) are incrementally faster. The fastest appears to be the Console.WriteLine(String.Concat(...)) method, followed by normal concatenation, and then the formatted operations. The initial delay in startup is likely the initialisation of Console Stream, as placing a Console.Writeline(\"Start!\") before the first operation brings all times back into line. ","pontos":41},{"corpo":"You need to delve into unmanaged code. Here's a static class that I've been using: public static class Recycle { private const int FO_DELETE = 3; private const int FOF_ALLOWUNDO = 0x40; private const int FOF_NOCONFIRMATION = 0x0010; [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Auto, Pack = 1)] public struct SHFILEOPSTRUCT { public IntPtr hwnd; [MarshalAs(UnmanagedType.U4)] public int wFunc; public string pFrom; public string pTo; public short fFlags; [MarshalAs(UnmanagedType.Bool)] public bool fAnyOperationsAborted; public IntPtr hNameMappings; public string lpszProgressTitle; } [DllImport(\"shell32.dll\", CharSet = CharSet.Auto)] static extern int SHFileOperation(ref SHFILEOPSTRUCT FileOp); public static void DeleteFileOperation(string filePath) { SHFILEOPSTRUCT fileop = new SHFILEOPSTRUCT(); fileop.wFunc = FO_DELETE; fileop.pFrom = filePath + '\\0' + '\\0'; fileop.fFlags = FOF_ALLOWUNDO | FOF_NOCONFIRMATION; SHFileOperation(ref fileop); } } Addendum: Tsk tsk @ Jeff for \"using Microsoft.VisualBasic\" in C# code. Tsk tsk @ MS for putting all the goodies in VisualBasic namespace. ","pontos":13},{"corpo":"I've done this recently, but I can't remember the exact steps. I think I added the external assemblies as dependencies, rather than as actual project assemblies. Let me know if this works. If not I'll do some more digging. ZS ","pontos":1},{"corpo":"The solution is: UPDATE tablename SET [filename] = RTRIM([filename]) + '.jpg' WHERE id 50 RTRIM is required because otherwise the [filename] column in its entirety will be selected for the string concatenation i.e. if it is a varchar(20) column and filename is only 10 letters long then it will still select those 10 letters and then 10 spaces. This will in turn result in an error as you try to fit 20 + 3 characters into a 20 character long field. ","pontos":20},{"corpo":"Here is a word-wrap algorithm I've written in C#. It should be fairly easy to translate into other languages (except perhaps for ). static char[] splitChars = new char[] { ' ', '-', '\\t' }; private static string WordWrap(string str, int width) { string[] words = Explode(str, splitChars); int curLineLength = 0; StringBuilder strBuilder = new StringBuilder(); for(int i = 0; i words.Length; i += 1) { string word = words[i]; // If adding the new word to the current line would be too long, // then put it on a new line (and split it up if it's too long). if (curLineLength + word.Length width) { // Only move down to a new line if we have text on the current line. // Avoids situation where wrapped whitespace causes emptylines in text. if (curLineLength 0) { strBuilder.Append(Environment.NewLine); curLineLength = 0; } // If the current word is too long to fit on a line even on it's own then // split the word up. while (word.Length width) { strBuilder.Append(word.Substring(0, width - 1) + \"-\"); word = word.Substring(width - 1); strBuilder.Append(Environment.NewLine); } // Remove leading whitespace from the word so the new line starts flush to the left. word = word.TrimStart(); } strBuilder.Append(word); curLineLength += word.Length; } return strBuilder.ToString(); } private static string[] Explode(string str, char[] splitChars) { List string parts = new List string (); int startIndex = 0; while (true) { int index = str.IndexOfAny(splitChars, startIndex); if (index == -1) { parts.Add(str.Substring(startIndex)); return parts.ToArray(); } string word = str.Substring(startIndex, index - startIndex); char nextChar = str.Substring(index, 1)[0]; // Dashes and the likes should stick to the word occuring before it. Whitespace doesn't have to. if (char.IsWhiteSpace(nextChar)) { parts.Add(word); parts.Add(nextChar.ToString()); } else { parts.Add(word + nextChar); } startIndex = index + 1; } } It's fairly primitive - it splits on spaces, tabs and dashes. It does make sure that dashes stick to the word before it (so you don't end up with stack\\n-overflow) though it doesn't favour moving small hyphenated words to a newline rather than splitting them. It does split up words if they are too long for a line. It's also fairly culturally specific, as I don't know much about the word-wrapping rules of other cultures. ","pontos":26},{"corpo":"MattMitchell's answer is correct if the column is a CHAR(20), but is not true if it was a VARCHAR(20) and the spaces hadn't been explicitly entered. If you do try it on a CHAR field without the RTRIM function you will get a \"String or binary data would be truncated\" error. ","pontos":5},{"corpo":" To do TDD many times I've used 'friend' keyword in C++.Can a friend know everything about me? No, its only a one way friendship :`( ","pontos":0},{"corpo":"There could also be a difference in character encoding for national characters. There is no \"unix-encoding\" but many linux-variants use UTF-8 as the default encoding. Mac OS (which is also a unix) uses its own encoding (macroman). I am not sure, what windows default encoding is. But this could be another source of trouble (apart from the different linebreaks). What are your problems? The linebreak-related problems can be easily corrected with the programs dos2unix or unix2dos on the unix-machine ","pontos":4},{"corpo":"I would recommend you to stay with Windows XP Pro. I worked for a short while with Windows Vista (not sure of the edition) with Visual Studio 2005 and it took about 2 days to get back to my XP Pro. I could really not put a finger on it but I just didn't like it. Although, I would prefer linux (specifically Ubuntu) over windows any day. ","pontos":-3},{"corpo":"No, that just returns the IP :-( But I just found it: System.Net.Dns.GetHostEntry(Page.Request.UserHostAddress).HostName That only works if there is actually a DNS Server to resolve the name, which is the case for my network. ","pontos":3},{"corpo":"If your secondary drive has it's own file permissions, like say you have an other copy of windows installed on it. It will prompt. It will also prompt if files are in use, which sometimes occurs if you have windows explorer open to the same directory and the file selected with a file previewer displaying the contents... there are some other oddities, but generally you get asked for file permission if the file is in use or it's a sensitive directory. If you do loop the FolderBrowserDialog , make sure to notify the user why, so they dont get mad at your app. Note: it does stink there is no .net way of asking for permission, maybe p/invoke the win32 api...? ","pontos":-1},{"corpo":"I've been using Vista Home Premium as a development machine and I haven't had any problems with it + Visual Studio 2008 Standard Edition, although I haven't had the chance to try using IIS debugging (I just stuck with the ASP.NET debugger). ","pontos":0},{"corpo":"It's probably best not to try to use the Posix subsystem for Windows. It was never really complete and is just a useless marketing tick box. If you're truly interested in programming stuff for Unix, download one of the many Linux distributions (ie. Ubuntu) and VirtualBox. Install and start playing. ","pontos":4},{"corpo":"Using custom composite controls has a point in a situation where you have a large web application and want to reuse large chunks in many places. Then you would only add child controls of the ones you are developing instead of repeating yourself. On a large project I've worked recently what we did is the following: Every composite control has a container. Used as a wrapped for everything inside the control. Every composite control has a template. An ascx file (without the %Control%> directive) which only contains the markup for the template. The container (being a control in itself) is initialized from the template. The container exposes properties for all other controls in the template. You only use this.Controls.Add([the_container]) in your composite control. In fact you need a base class that would take care of initializing a container with the specified template and also throw exceptions when a control is not found in the template. Of course this is likely to be an overkill in a small application. If you don't have reused code and markup and only want to write simple controls, you're better off using User Controls. ","pontos":1},{"corpo":"If you are interested in learning Unix programming, I'd recommend using Linux or FreeBSD. I haven't tried Vista's Unix subsystem, but past experience with Microsoft's Unix-compatibility stuff leads me to expect it will be a little \"weird\", and is therefore likely to confuse you if you are learning. ","pontos":0},{"corpo":"It seems like most of you are put off by this idea because of how unpleasant the various client-side implementations of Javascript have been. I would check out existing solutions before passing judgment, though, because remember that no particular SS/JS solution is tied to the JS implementations currently being used in browsers. Javascript is based on ECMAScript, remember, a spec that is currently in a fairly mature state. I suspect that a SS/JS solution that supports more recent ECMA specs would be no more cumbersome than using other scripting languages for the task. Remember, Ruby wasn't written to be a \"web language\" originally, either. ","pontos":1},{"corpo":"You might like Cygwin for having a Linux environment on your windows machine. Otherwise, definitely go for an isolated environment (virtual machines) like the others have suggested. ","pontos":4},{"corpo":"I'm also thinking of installing Vista (64 version), need to verify the drivers support. Been running Vista Ultimate 32 bits without problems for more than a year in 3 machines. @Vagmi I just don't like tomatoes but I cannot put my finger on it. That said, I don't recommend you to eat bananas. You should be able to pinpoint your problems in a specific question like this. ","pontos":0},{"corpo":"See these two questions on SO for more information: What does branch, tag and trunk really mean? Subversion question ","pontos":5},{"corpo":"I never keep them on in performance critical code. ","pontos":0},{"corpo":"Unless profiling shows that the assertions are causing performance problems, I say they should stay in the production release as well. However, I think this also requires that you handle assertion failures somewhat gracefully. For example, they should result in a general type of dialog with the option of (automatically) reporting the issue to the developers, and not just quit or crash the program. Also, you should be careful not to use assertions for conditions that you actually do allow, but possibly don't like or consider unwanted. Those conditions should be handled by other parts of the code. ","pontos":3},{"corpo":"An assertion is error, pure and simple and therefore should be handled like one. Since an error should be handled in release mode then you don't really need assertions. The main benefit I see for assertions is a conditional break - they are much easier to setup than drilling through VC's windows to setup something that takes 1 line of code. ","pontos":-4},{"corpo":"I do like the Interceptor approach mentioned, and use this on the project I'm currently working on. However, one obvious disadvantage that deserves highlighting is that this approach will only audit data changes made via your application. Any direct data modifications such as ad-hoc SQL scripts that you may need to execute from time to time (it always happens!) won't be audited, unless you remember to perform the audit table insertions at the same time. ","pontos":2},{"corpo":"I rarely use assertions for anything other that compile time type checking. I would use an exception instead of an assertion just because most languages are built to handle them. I offer an example file = create-some-file(); _throwExceptionIf( file.exists() == false, \"FILE DOES NOT EXIST\"); against file = create-some-file(); ASSERT(file.exists()); How would the application handle the assertion? I prefer the old method of dealing with fatal errors. ","pontos":1},{"corpo":"Most of the time, when i use assertion in java (the assert keyword) I automatically add some production codes after. According to the case, it can be a logging message, an exception... or nothing. According to me, all your assertions are critical in dev release, not in production relase. Some of them must be kept, other must be discarded. ","pontos":0},{"corpo":"This is a topic i myself have pondered for a while but I have not really come to a decision, as usual time is the main problem... ;) And since I cant find these links sofar in this post i add them for public interest: Success and Failure story: Lisping at JPL Really impressive success story: Lisp in use at the Orbitz corporation Comparison and analysis of whether to use Lisp instead of Java: Lisp as an Alternative to Java ","pontos":1},{"corpo":"Provided they are handled just as any other error, I don't see a problem with it. Do bear in mind though that failed assertions in C, as with other languages, will just exit the program, and this isn't usually sufficient for production systems. There are some exceptions - PHP, for instance, allows you to create a custom handler for assertion failures so that you can display custom errors, do detailed logging, etc. instead of just exiting. ","pontos":1},{"corpo":"Why not set up a Wiki? If you are on windows, i know that ScrewTurn wiki is pretty simple to deploy on a desktop/laptop. No database to fuss around with. ","pontos":2},{"corpo":"The Maven SourceForge plug-in does not work with Maven 2. Also I believe this plug-in uses FTP which is no longer supported. ","pontos":0},{"corpo":"In Visual Studio you can always disable specific warnings by going to: Project settings -> C/C++ -> Advanced -> Disable Specific warnings: 4341 ","pontos":3},{"corpo":"This is a compiler bug. Here's another post confirming it's a known issue. I've got the same issue in one of my projects and there's no way to prevent it from being triggered unless you have some way of avoiding the use of OdbcParameter. The most conservative way to suppress only the buggy warnings is to use #pragma warning( push ) #pragma warning( disable: 4341 ) // code affected by bug #pragma warning( pop ) ","pontos":4},{"corpo":"Not all IP addresses need to have hostnames. I think that's what is happening in your case. Try it ouy with more well-known IP/hostname pairs eg: Name: google.com Address: 72.14.207.99 Name: google.com Address: 64.233.187.99 Name: google.com Address: 64.233.167.99 ...I might just be wrong ","pontos":0},{"corpo":"Edit of my previous answer. Try (in vb.net): Dim sTmp As String Dim ip As IPHostEntry sTmp = MaskedTextBox1.Text Dim ipAddr As IPAddress = IPAddress.Parse(sTmp) ip = Dns.GetHostEntry(ipAddr) MaskedTextBox2.Text = ip.HostName Dns.resolve appears to be obsolete in later versions of .Net. As stated here before I believe the issue is caused by your IP address not having a fixed name or by it having multiple names. The example above works with Google addresses, but not with an address we use that has a couple of names associated with it. ","pontos":2},{"corpo":"I'm no network expert but I have fiddled with the route command a number of times... route add 0.0.0.0 MASK 0.0.0.0 address of gateway on 10.17.x.x net Will route all default traffic through the 10.17.x.x gateway, if you find that it still routes through the other interface, you should make sure that the new rule has a lower metric than the existing routes. Do this by adding METRIC 1 for example to the end of the line above. You could also adjust the metric in the Advanced TCP/IP Settings window of the 10.17.x.x interface, unticking the Automatic Metric checkbox and setting the value to something low, like 1 or 2. ","pontos":2},{"corpo":"Also remember that reverse lookup won't allways give the same address as the one used in forward DNS lookup. For example for google.com I get ip 64.233.167.99 but reverse dns lookup for that IP returns py-in-f99.google.com ","pontos":0},{"corpo":"A number of people I know swear by Google Notebook ","pontos":2},{"corpo":"If you are using GUIDs you could create a CreateHistory table with columns GUID, CreatedOn, CreatedBy. For populating the table you would still have to create a trigger for every table or handle it in the application logic. ","pontos":0},{"corpo":"This (and lots of problems like it with WebSVN) is why I asked this. ","pontos":1},{"corpo":"Check in the installer if WSE 3.0 is installed and if it isn't alert the person and cancel the install, if it is continue normally. I wouldn't include the DLL in your setup package, because it could get out dated pretty fast, and I don't know if the EULA will allow it. ","pontos":2},{"corpo":"If you want to keep them replace them with error handling. Nothing worse than a program just disappearing. I see nothing wrong with treating certain errors as serious bugs, but they should be directed to a section of your program that is equipped to deal with them by collecting data, logging it, and informing the user that your app has had some unwanted condition and is exiting. ","pontos":3},{"corpo":"Allow me to quote Steve McConnell's Code Complete. The section on Assertions is 8.2. Normally, you don't want users to see assertion messages in production code; assertions are primarily for use during development and maintenance. Assertions are normally compiled into the code at development time and compiled out of the code for production. However, later in the same section, this advice is given: For highly robust code, assert and then handle the error anyway. I think that as long as performance is not an issue, leave the assertion in, but rather than display a message, have it write to a log file. I think that advice is also in Code Complete, but I'm not finding it right now. ","pontos":31},{"corpo":"I also had serious problems testing multi- threaded code. Then I found a really cool solution in \"xUnit Test Patterns\" by Gerard Meszaros. The pattern he describes is called Humble object. Basically it describes how you can extract the logic into a separate, easy-to-test component that is decoupled from its environment. After you tested this logic, you can test the complicated behaviour (multi- threading, asynchronous execution, etc...) ","pontos":15},{"corpo":"Stupid me... The code is posted was 100% valid and working... But 10 lines lower I replaced the this.lblHost.Text with another value, which happened to be the ip address. Sorry. ","pontos":2},{"corpo":"Personally I just rolled my own because it was much simpler to integrate with my error handling system and how I wanted it displayed on the site. 99% of the time you only care about a couple of things, required fields and comparing fields. ","pontos":2},{"corpo":"At my last place of work they wouldn't let me set up a wiki or anything - so I just made various word documents full of tips and instructions and gave that to my successor when I left. Now though I'd use a private wiki, or maybe a blog. ","pontos":0},{"corpo":"Nothing really. ASP.NET 2.0 applications will run just as they have in IIS 6.0. If you want to take advantage of any of the new features then you just need to update your code. But unless you are changing the structure of the header of the response or intercepting requests for other applications you probably will not need to do anything. ","pontos":-3},{"corpo":"OR: SELECT foo FROM bar WHERE baz BETWEEN 1 AND 3 ","pontos":4},{"corpo":"Our database server software contains both production and debug assertions. Debug assertions are just that -- they are removed in production code. Production assertions only happen if (a) some condition exists that should never exist and (b) it is not possible to reliably recover from this condition. A production assertion indicates that a bug in the software has been encountered or some kind of data corruption has occurred. Since this is a database system and we are storing potentially enterprise-critical data, we do whatever we can to avoid corrupted data. If a condition exists that may cause us to store incorrect data, we immediately assert, rollback all transactions, and stop the server. Having said that, we also try to avoid production assertions in performance-critical routines. ","pontos":1},{"corpo":"You might be able to use an anti-CSRF token to achieve what you're after. This article explains it in more detail: Cross-Site Request Forgeries ","pontos":0},{"corpo":"What's the nature of that OnEmailSent event from that third party application? I mean, how do you know the application is triggering such an event? If you are planning on doing interprocess communication, the first question you should ask yourself is: Is it really necessary? Without questioning your motives, if you really need to do interprocess communication, you will need some sort of mechanism. The list is long, very long. From simple WM_DATA messages to custom TCP protocols to very complex Web services requiring additional infrastructures. This brings the question, what is it you are trying to do exactly? What is this third party application you have no control over? Also, the debugger has a very invasive way of debugging processes. Don't expect that to be the standard interprocess mechanism used by all other applications. As a matter of fact, it isn't. ","pontos":0},{"corpo":"Unfortunaly the Magic tool doesn't generates code and also it can't implement a design pattern. I don't have control over the code cause as i stated before it doesn't have code to modify. Te bottom line is that it can speed up productivity in some way but it has the impossibility to user CVS, patterns also and I can't control all the details. I agree with gary when he says \"it seems that the productivity aspect of such CASE tools is heavily dependent on customer requirements and developer skill sets/training/background\" but also I can't agree more with Klelky; Those main disadvantages are: 1. We cannot do automatic merges, making it close to impossible for parallel development on one component. 2.Developers get dependant on the tool and 'forget' how to handcode. Thanks ","pontos":0},{"corpo":"This kind of prolem can occur if you are calling unmanaged code e.g. a dll. It can occur when Marshalling goes horribly wrong. Can you tell us if you are calling unmanaged code? If so are you using default Marshalling or more specific stuff? From the looks of the stack trace are you using unsafe code e.g. Pointers and the like? This could be your problem. ","pontos":1},{"corpo":"Have you tried checking that the bytes loaded are the same as the total bytes? URLLoader.bytesLoaded == URLLoader.bytesTotal That should tell you if the file has finished loading, it wont help with the compleate event firing to early, but it should tell you if its a problem with the xml been read. I am unsure if it will work over domains, as my xml is always on the same site. ","pontos":1},{"corpo":"Craig, without seeing the stream you're reading it's a little hard to debug but MAYBE you could change the setting of the count variable to this: count = resStream.Read(buf, 0, buf.Length-1); It's a bit of a hack, but if the last read is killing you and it's not returning any data then theoretically this will avoid the problem. I still wonder why the stream is doing that. ","pontos":0},{"corpo":"Actually, I ran these tests yesterday, but it was getting late so I didnt put my responses. The bottom line seems that they take both the same time on average. I did the test over 100000 iterations. I'll try with StringBuilder as well, and I'll post the code and results when I get home. ","pontos":0},{"corpo":"List of some possibilities: An object is being used after it has been disposed. This can happen a lot if you are disposing managed object in a finalizer (you should not do that). An unmannaged implementation of one of the object you are using is bugged and it corrupted the process memory heap. Happens a lot with DirectX, GDI and others. Mashaling on managed-unmanaged boundary is flawed. Make sure you pin a managed pointer before you use it on an unmanaged part of code. You are using unsafe block and doing funny stuff with it. In you case it could be a problem with Windows Forms. But the problem is not that it is happening, but rather that it is not being reported correctly; you possibly still have done something wrong. Are you able to determine what control is causing the error using the HWND? Is it always the same? Is this control doing something funny just before the application crashes? Is the unmannaged part of the control a custom window or a standard control? ","pontos":3},{"corpo":"Current version of AnkhSVN does not provide a GUI for proxy settings, but you can hand-edit the servers file (which is a simple .ini) and it should work. Servers file resides in: C:\\Documents and Settings\\YOU\\Application Data\\Subversion (or wherever your APP_DATA is) ","pontos":5},{"corpo":"In short, those values after the % tell how to interpret (or output) all of the variables coming later. In your example, is interpreted as a float (this the 'f'), and the gives information about how many decimal places to use when printing it out. See this link for more details about all of the modifiers you can use with printf. ","pontos":1},{"corpo":"I had plenty of headaches after implementing sIFR on my last website project. Most of the problems were to do with browser inconsistencies like you are describing. Text would appear in odd places, not wrap properly or just not display the way I wanted it to. I found that, as per usual, firefox was displaying nicely while I had to implement several different css hacks in order to get the same code to display properly in IE7 and IE6. I say stick to standard browser fonts if you can, but if the project / client requires you to use it then make sure you test it thoroughly in all browsers and with various flash blockers etc. ","pontos":0},{"corpo":"I tried version 1, and it was unreliable to say the least. I can't say anything about 2.0. If you can afford it, the one I use, VisualSVN, is very good and uses TortoiseSVN for all its gui, except for the specialized things related to its VS integration. ","pontos":5},{"corpo":"XP 64bit wasn't ready for prime time, there were no drivers for it. In Windows Vista 64-bit this isn't the case. So if you are looking to install Windows Vista go 64-bit if you are keeping XP stay at 32-bit. ","pontos":1},{"corpo":"I'm guessing that the settings would have to be in powershell.exe.config in the powershell directory, but that seems to be a bad way of doing things. You can use ConfigurationManager.OpenMappedExeConfiguration to open a configuration file based on the executing DLL name, rather than the application exe, but this would obviously require changes to the DLLs. ","pontos":6},{"corpo":"This way seems to work well: function IsNumeric(input){ var RE = /^-{0,1}\\d*\\.{0,1}\\d+$/; return (RE.test(input)); } And to test it: // alert(TestIsNumeric()); function TestIsNumeric(){ var results = '' results += (IsNumeric('-1')?\"Pass\":\"Fail\") + \": IsNumeric('-1') = true\\n\"; results += (IsNumeric('-1.5')?\"Pass\":\"Fail\") + \": IsNumeric('-1.5') = true\\n\"; results += (IsNumeric('0')?\"Pass\":\"Fail\") + \": IsNumeric('0') = true\\n\"; results += (IsNumeric('0.42')?\"Pass\":\"Fail\") + \": IsNumeric('0.42') = true\\n\"; results += (IsNumeric('.42')?\"Pass\":\"Fail\") + \": IsNumeric('.42') = true\\n\"; results += (!IsNumeric('99,999')?\"Pass\":\"Fail\") + \": IsNumeric('99,999') = false\\n\"; results += (!IsNumeric('0x89f')?\"Pass\":\"Fail\") + \": IsNumeric('0x89f') = false\\n\"; results += (!IsNumeric('#abcdef')?\"Pass\":\"Fail\") + \": IsNumeric('#abcdef') = false\\n\"; results += (!IsNumeric('1.2.3')?\"Pass\":\"Fail\") + \": IsNumeric('1.2.3') = false\\n\"; results += (!IsNumeric('')?\"Pass\":\"Fail\") + \": IsNumeric('') = false\\n\"; results += (!IsNumeric('blah')?\"Pass\":\"Fail\") + \": IsNumeric('blah') = false\\n\"; return results; } I borrowed that regex from http://www.codetoad.com/javascript/isnumeric.asp. Explanation: /^ match beginning of string -{0,1} optional negative sign \\d* optional digits \\.{0,1} optional decimal point \\d+ at least one digit $/ match end of string ","pontos":33},{"corpo":"Another technical benefit, aside from the increased address space, is that 64bit apps always use DEP, so you are forced to fix those bugs and potential security holes. ","pontos":3},{"corpo":" I'm seeing a pattern for stackoverflow success: dig up old CodingHorror posts and (Jeopardy style) phrase them in terms of a question. I plead innocent! But you're right, this seemed to be a relatively popular little question. ","pontos":0},{"corpo":"If you're just searching people's names, it might be in your best interest to not even use the full text index. Full text index makes sense when you have large text fields, but if you're mostly dealing with one word per field, I'm not sure how much extra you would get out of full text indexes. Waiting for the full text index to reindex itself before you can search for new records can be one of the many problems. You could just make a query such as the following. Split your searchstring on spaces, and create a list of the search terms. Select FirstName,MiddleName,LastName From person WHERE Firstname like @searchterm1 + '%' or MiddleName like @searchterm1 + '%' or LastName like @searchterm1 + '%' or Firstname like @searchterm2 + '%' etc.... ","pontos":4},{"corpo":"AFAIK, you only need to call the base constructor if you need to pass down any values to it. ","pontos":0},{"corpo":"It is implied. ","pontos":5},{"corpo":"I started with AnkhSvn and then moved on to VisualSvn. I have my own gripes with VisualSvn but its far less trouble compared to Ankh. I'm yet to try the new version of Ankh which they say is a complete rewrite and had inputs from Microsoft dev team as well. ","pontos":2},{"corpo":"A derived class is built upon the base class. If you think about it, the base object has to be instantiated in memory before the derived class can be appended to it. So the base object will be created on the way to creating the derived object. So no, you do not call the constructor. ","pontos":3},{"corpo":" The stored procedures are stored in independent '.sql' files and not in the code. In order to debug a proc it has to be created in the RDBMS and then executed, how will you debug a proc stored in a file? ","pontos":1},{"corpo":"There's also SQL Prompt from Redgate which has more bells and whistles than you can poke a stick at (MSSQL Only and it's not free) At the other end of the spectrum is the completely barebones Query Express ","pontos":3},{"corpo":"I've been using both the newest version of Ankh SVN and Tortoise on a project at home. I find them to both be very good with a caveat. I've found that both SVN tools have at times failed to keep up with my file/folder renaming and moving resulting in it thinking that a perfectly good file needs to be deleted on the next commit. This is probably down to me misusing SVN in some way but TFS at work does not have this problem. ","pontos":1},{"corpo":"It seems Microsoft Style Cop was causing the issue. It was not registered as an Add-in, but was integrated into VS2005 on some deeper level. ","pontos":0},{"corpo":"First off, I'm a .NET guy, so I am biased. Second, if by Java EE you mean J2EE, and you are planning web based development, then I have some questions. If you are planning on desktop development, ask yourself if the extra 5% market share you get by using Java is worth it. Its definitely a .NET world when developing desktop applications. However, I'm thinking you are looking at this for Web Development. My first question, is what Java application server are you considering? Apache/TomCat is small and free, while on the flipside IBM WebSphere is huge and expensive ($2000 per cpu). Microsoft did a great performance/cost comparison between Windows 2k3/IIS and RedHat/WebSphere here. According to TheServerSide, .NET is both cheaper and faster in this situation. http://www.theserverside.net/tt/articles/showarticle.tss?id=NET2BMNovember Its a good starting point for research. All that said, You will have to look high and low to find a java developer who does not admit that C# is a better language to enjoy writing in. C# has real generics (Java Generics still are boxed/unboxed, its just syntax sugar), LINQ, lambda functions, delegates, and a host of other goodies that the java is missing. ","pontos":10},{"corpo":"I haven't seen the browser eat exceptions, unless you mean script errors. Script errors can be enabled via the property. If you're talking about real exceptions, not just script errors, can you show us some code that reproduces the problem? We've used the browser extensively and haven't seen what you're describing. edit the code sample wasn't there when I asked for a code sample ","pontos":1},{"corpo":"I switched from 32 bit Vista to 64 bit and haven't looked back. I have only had a problem with one device (a multi-track firewire mixing board) - but everything else that has worked for 32-bit works for 64. Throw in the ability to add piles of cheap RAM, and I don't see any reason why anyone would stick with 32 if the processor supports it. If you're really unsure, use Vista's much improved multi-boot functionality and install 32 bit XP and 64 bit Vista on the same machine on different partitions. I did, but to tell you the truth, I haven't gone back into XP for at least 9 months now. ","pontos":2},{"corpo":"A couple of tests to add: IsNumeric('01.05') = false IsNumeric('1.') = false IsNumeric('.') = false I came up with this: function IsNumeric(input) { return /^-?(0|[1-9]\\d*|(?=\\.))(\\.\\d+)?$/.test(input); } The solution covers: An optional negative sign at the beginning A single zero, or one or more digits not starting with 0, or nothing so long as a period follows A period that is followed by 1 or more numbers ","pontos":1},{"corpo":"It is implied, provided it is parameterless. This is because you need to implement constructors that take values, see the code below for an example: public class SuperClassEmptyCtor { public SuperClassEmptyCtor() { // Default Ctor } } public class SubClassA : SuperClassEmptyCtor { // No Ctor's this is fine since we have // a default (empty ctor in the base) } public class SuperClassCtor { public SuperClassCtor(string value) { // Default Ctor } } public class SubClassB : SuperClassCtor { // This fails because we need to satisfy // the ctor for the base class. } public class SubClassC : SuperClassCtor { public SubClassC(string value) : base(value) { // make it easy and pipe the params // straight to the base! } } ","pontos":16},{"corpo":"How about simply sending a hash after or before you send the file, and comparing that with the file you received? That should at least make sure you have a correct file. If you want to go all out you could do the same process, but for small parts of the file. Then when you have all pieces, join them on the receiving end. ","pontos":0},{"corpo":"I frequently take any new interface I'm working on to one of our technical support people. They've heard every complaint about interfaces that you could ever imagine, so if anyone is going to think up potential problems, they will. Also, and I'm not kidding about this, I often take the least computer literate person I know (you're mother is often a good choice...but they have to have used a computer before, otherwise it's going to by pointless) and let them loose on the interface with no instruction. If they can't figure out where things are intuitively, then your GUI likely needs work. Remember, Don't make them think! (yes, I know this is for web design, but it applies) ","pontos":1},{"corpo":"What I like to do is give someone an install package, ask them to perform a number of tasks related to how the application works, and watch. Hardest part is to keep your mouth shut. ","pontos":6},{"corpo":"If you're planning on coding against a sql database using .NET, skip ADO and go directly to Linq. You will NOT miss anything. Oh, also, Joe Celko. If you see his name on an article or a book about SQL, read it. ","pontos":3},{"corpo":"Not an answer, but I find the whole fopen/fread/fclose thing very dull to peruse when looking at code. You can replace: $file = 'test.xml'; $fileHandle = fopen($file, 'r'); $request = fread($fileHandle, filesize($file)); fclose($fileHandle); $request = trim($request); With: $request = trim(file_get_contents('test.xml')); But anyway - to your question; if those are the headers that are being sent, then it shouldn't be a problem with the remote server. Try changing the contents of your xml file and using var_dump() to check the exact output (including the string length, so you can look for missing things) Hope that helps ","pontos":2},{"corpo":"I disagree with Jon. While this solution can be used poorly in the way he describes, it does not necessarily mean it will. Any wise developer or designer is going to take the script generated css classes and pull only what is really needed into the css file. The solution still solves the OP's question. ","pontos":1},{"corpo":"Your trigger is only using the first row from 'Inserted'. This is a common misunderstanding when dealing with SQL triggers for the first time. The trigger fires per update not per row. For example if you do the following:- update products set title = 'geoff de geoff' this would update all the products, but a trigger on the product table would only fire once. The Inserted 'table' you get in trigger would contain all the rows. You must either loop through Inserted with a cursor, or better join Inserted to the table you are updating. ","pontos":3},{"corpo":"The trigger only fires once for each INSERT statment executed - not once for each record inserted. In your trigger you can access the 'virtual' table called inserted for details of the records inserted. ie: SELECT COUNT(*) FROM inserted Will return the number of inserted records. ","pontos":1},{"corpo":"What I always do is let MS SQL Management Studio create the script to rebuild database und empty tables. Then I use another script to generate a ms-dos batch file to export/import the data via \"bcp\". See sql below. /* this is used to export */ use databaseXXX select ('bcp databaseXXX..' + name + ' OUT ' + name + ' /eErrors.txt /b100 /n /Usa /Ppwd /Sserver') as bcp from sysobjects where type = 'U' order by [name] /* this is used to import */ use databaseXXX select ('bcp databaseXXX..' + name + ' IN ' + name + ' /E /eErrors.txt /b100 /n /Usa /Ppwd /Sserver') as bcp from sysobjects where type = 'U' order by [name] Works for me everytime and is quick. If you save the table generation script in a file you can put this also into a batch file via sqlcmd command. ","pontos":1},{"corpo":"You could always write a small client/server app that encrypts at the source, pushes the files, and then decrypts at the destination. That's a little bit of work, but probably a trivial amount. And it's scriptable as long as your automation tool supports executing something in the file system (which I think all do). The only downside is that you may not be able to get meaningful error messages on failure in your integration environment without a bit more work on your part (though depending on your setup, this could be as simple as sending error messages to stdout). ","pontos":0},{"corpo":"Please lookup multi row consideration for triggers What is with the cursor inside a trigger? Learn how to program set based, cursors are Evil in T-SQL and should only be used to defragment/update stats/other maintanance a bunch of tables ","pontos":2},{"corpo":"Don't collapse by concatenation for storage of related records in your database. Its not exactly best practices. What you're describing is a pivot table. Pivot tables are hard. I'd suggest avoiding them if at all possible. Why not just read in your related rows and process them in memory? It doesn't sound like you're going to spend too many milliseconds doing this... ","pontos":0},{"corpo":"Make a copy of your live site directory, use rsync to update that copy with your latest version, then rename the live and updated directories so that the updated version is now live. In bash: #!/bin/bash set -e cp -R /var/livesite /var/newversion rsync user@devserver:/var/readytogolive /var/newversion mv /var/livesite /var/oldlivesite mv /var/newversion /var/livesite Viola! Edit: @Ted Percival - That's a good idea. I didn't even know about \"set -e\". Updated script. Edit: updated again at Ted's suggestion (although I think it would still work if somehow the cp command failed, and if cp fails you probably have more serious problems.) ","pontos":1},{"corpo":"I did a 'wc -m test.xml' and came back with 743 characters in the XML file and the var_dump on $request comes back with 742 characters so something is getting stripped with trim() (I assume). I did a: print \"=====\" . $request . \"=====\"; and the start and end of the XML butts right up agains the ===== with no white space. ","pontos":0},{"corpo":"I'd like to add the following: 1. IsNumeric('0x89f') => true 2. IsNumeric('075') => true Positive hex numbers start with 0x and negative hex numbers start with -0x. Positive oct numbers start with 0 and negative oct numbers start with -0. This one takes most of what has already been mentioned into consideration, but includes hex and octal numbers, negative scientific, Infinity and has removed decimal scientific (4e3.2 is not valid). function IsNumeric(input){ var RE = /^-?(0|INF|(0[1-7][0-7]*)|(0x[0-9a-fA-F]+)|((0|[1-9][0-9]*|(?=[\\.,]))([\\.,][0-9]+)?([eE]-?\\d+)?))$/; return (RE.test(input)); } ","pontos":3},{"corpo":" Note that a responsible web developer does not use fonts that are only available on Windows (and especially ones that are only available on Vista), nor do they use a technology that isn't supported by at least the majority of browsers. I think this is rather missing the point. It wouldn't matter if you did; everyone would get something sensible that they could read easily, and the ones who need to can change the font to whatever they want anyway because it's just text and all major browsers let you customise the font you see regardless of the preferences of the site designer. There is nothing broken about suggesting fonts in your CSS that some users don't have; they just see something different from you. Different is not broken. They won't even wonder why you're using default fonts because they won't know that other people see anything different. This is the whole point of font sets: Verdana, Arial, Helvetica, sans-serif It's good practice precisely because it acknowledges that people will see different things. This is good practice too: Gill Sans, Verdana, Arial, Helvetica, sans-serif So most people don't have Gill  who cares? They get a perfectly good site regardless. And this would be fine too, but a bit weird and lazy: Gill Sans Irresponsible web design is doing things like setting text as images without using alt text, not using interesting fonts in font sets. ","pontos":1},{"corpo":"I'm probably going a million miles in the wrong direct (but i'm only young :P ). but couldn't you add the graphic to a panel and then a mouselistener to the graphic object so that when the user on the graphic your action is preformed. ","pontos":5},{"corpo":"Related but values are values are kept in separate columns and you have know your \"special types\" a head of time: http://stackoverflow.com/questions/17194/sql-query-to-compare-product-sales-by-month#17290 Otherwise I would do this with cursor in a stored procedure or preform the transformation in the business or presentation layer. Stab at sql if you know all cases: Select ID,NAME ,Synchro+DARK+Effect -- add a some substring logic to trim any trailing /'s from (select ID ,NAME --may need to replace max() with min(). ,MAX(CASE SPECIALTYPE WHEN \"Synchro\" THEN SPECIALTYPE +\"/\" ELSE \"\" END) Synchro ,MAX(CASE SPECIALTYPE WHEN \"DARK\" THEN SPECIALTYPE +\"/\" ELSE \"\" END) DARK ,MAX(CASE SPECIALTYPE WHEN \"Effect\" THEN SPECIALTYPE ELSE \"\" END) Effect from table group by ID ,NAME) sub1 ","pontos":1},{"corpo":"@Neall, I'd add a on the second line, because you don't want the live site being replaced if the fails for any reason. causes the script to exit if any of its commands fail. Edit: The should be the first thing in the script, right after . ","pontos":1},{"corpo":"If you do have a budget take a look at the following OpenEdge. I know that they did excatly what you want for us. A linux based PDF generation system. I'd ask what they can do for you. Val Cassidy is the persons name. BTW: I'm not getting anything for this and I don't even work for bespoke company anymore nor for OpenEdge ... ","pontos":0},{"corpo":"I agree with Jon, but I don't see a problem* with doing what the OP wants. Using the script provided, you'd know all of your classes and ids. While working on your CSS, you should be deciding if you need to use each of them. At the end, or at the point that you feel like you have a good handle on what you're doing, run it through an optimizer / compressor so it removes unused ids and classes. *Operating assumption: You either didn't write the original HTML or you wrote it and later decided that \"gosh CSS would be really nice here now, I wish I would have started with it.\" :-) ","pontos":2},{"corpo":"It turns out it's an encoding issue. The app apparently needs the XML in www-form-urlencoded instead of form-data so I had to change: # This sets the encoding to multipart/form-data curl_setopt($curlHandle, CURLOPT_POSTFIELDS, array('XML'= $request)); to # This sets it to application/x-www-form-urlencoded curl_setopt($curlHandle, CURLOPT_POSTFIELDS, 'XML=' . urlencode($request)); ","pontos":2},{"corpo":"You can run OpenSSH on Cygwin, and even install it as a Windows service. I once used it this way to easily add backups of a Unix system - it would rsync a bunch of files onto the Windows server, and the Windows server had full tape backups. ","pontos":1},{"corpo":"This can be broad but here are some responsibilities that could get thrown at you in a brain dump format. on the DBA end Backups Indexes Triggers Security per table database creating users ect. ODBC in your windows control panel know you normal forms the diff between a data warehouse (for reporting) and a Transactional database for most everything else (esp reporting in most environments) On the Programing end Reporting (Run for the hills) Stored procedures Star and snowflake schema's ADO, ODBC CRUD apps (Create Read Update Delete) ","pontos":3},{"corpo":"MySQL is more likely to have database corruption issues, and it doesn't fix them automatically when they happen. I've worked with MSSQL since version 6.5 and don't remember a database corruption issue taking the database offline. The few times I've worked with MySQL in a production environment, a database corruption issue took the entire database offline until we ran the magic \"please fix my corrupted index\" thing from the commandline. MSSQL's transaction and journaling system, in my experience, handles just about anything - including a power cycle or hardware failure - without database corruption, and if something gets messed up it fixes it automatically. This has been my experience, and I'd be happy to hear that this has been fixed or we were doing something wrong. http://dev.mysql.com/doc/refman/6.0/en/corrupted-myisam-tables.html http://www.google.com/search?q=site%3Abugs.mysql.com+index+corruption ","pontos":9},{"corpo":"Try this code. It's a slightly modified version of your code. 1. I removed Console.WriteLine as it's probably few orders of magnitude slower than what I'm trying to measure. 2. I'm staring the Stopwatch before the loop and stopping it right after, this way I'm not losing precision if the function takes for example 26.4 ticks to execute. 3. The way you divided result by number of iterations was wrong. See what hapens if you have 1000 milliseconds and 100 milliseconds. In both situations you will get 0 ms after dividing it by 1000000. Stopwatch s = new Stopwatch(); var p = new { FirstName = \"Bill\", LastName = \"Gates\" }; int n = 1000000; long fElapsedMilliseconds = 0, fElapsedTicks = 0, cElapsedMilliseconds = 0, cElapsedTicks = 0; string result; s.Start(); for (var i = 0; i n; i++) result = (p.FirstName + \" \" + p.LastName); s.Stop(); cElapsedMilliseconds = s.ElapsedMilliseconds; cElapsedTicks = s.ElapsedTicks; s.Reset(); s.Start(); for (var i = 0; i n; i++) result = string.Format(\"{0} {1}\", p.FirstName, p.LastName); s.Stop(); fElapsedMilliseconds = s.ElapsedMilliseconds; fElapsedTicks = s.ElapsedTicks; s.Reset(); Console.Clear(); Console.WriteLine(n.ToString()+\" x result = string.Format(\\\"{0} {1}\\\", p.FirstName, p.LastName); took: \" + (fElapsedMilliseconds) + \"ms - \" + (fElapsedTicks) + \" ticks\"); Console.WriteLine(n.ToString() + \" x result = (p.FirstName + \\\" \\\" + p.LastName); took: \" + (cElapsedMilliseconds) + \"ms - \" + (cElapsedTicks) + \" ticks\"); Thread.Sleep(4000); Those are my results: 1000000 x result = string.Format(\"{0} {1}\", p.FirstName, p.LastName); took: 618ms - 2213706 ticks 1000000 x result = (p.FirstName + \" \" + p.LastName); took: 166ms - 595610 ticks ","pontos":52},{"corpo":"@Mat I suppose saying don't do this because it's not safe and will probably break more often than just initializing this stuff in main() isn't going to be that popular. [And yes, I know that suggesting that means you shouldn't attempt to do interesting stuff in constructors of global objects. That's the point.] MSN He's not trying to do anything interesting in a global object constructor. He's trying to avoid doing anything interesting, by delaying initialization until later (lazy construction). Initializing a variable to 0 and initializing a mutex with a static initializer do not count as interesting, because they are both things that the compiler can do. ","pontos":-1},{"corpo":"I've found SvcTraceViewer.exe to be the most valuable tool when it comes to diagnosing WCF errors. ","pontos":9},{"corpo":"The concerning thing to me is that it might be firing Event.COMPLETE before it's finished loading, and that makes me wonder whether or not the load is timing out. How often does the problem happen? Can you have success one moment, then failure the very next with the same feed? For testing purposes, try tracing the and the at the top of your handler method. If they don't match, you know that the event is firing prematurely. If this is the case, you can listen for the URLLoader's progress event. Check the against the in your handler and only parse the XML once the loading is truly complete. Granted, this is very likely akin to what the URLLoader is doing before it fires , but if that's broken, you can try rolling your own. Please let us know what you find out. And if you could, please paste in some source code. We might be able to spot something of note. ","pontos":1},{"corpo":"@Paul, that code looks like it should work. Have you tried putting some tracing in that method to make sure isn't somehow hosing the path? ","pontos":0},{"corpo":"Also, make sure your C# class doesn't have this attribute: [ClassInterface(ClassInterfaceType.AutoDual)] -- Seems to cause errors in C++ with _TypePtr ","pontos":0},{"corpo":"In PHP, I do it this way: ?php function timesince($original) { // array of time period chunks $chunks = array( array(60 * 60 * 24 * 365 , 'year'), array(60 * 60 * 24 * 30 , 'month'), array(60 * 60 * 24 * 7, 'week'), array(60 * 60 * 24 , 'day'), array(60 * 60 , 'hour'), array(60 , 'minute'), ); $today = time(); /* Current unix time */ $since = $today - $original; if($since 604800) { $print = date(\"M jS\", $original); if($since 31536000) { $print .= \", \" . date(\"Y\", $original); } return $print; } // $j saves performing the count function each time around the loop for ($i = 0, $j = count($chunks); $i $j; $i++) { $seconds = $chunks[$i][0]; $name = $chunks[$i][1]; // finding the biggest chunk (if the chunk fits, break) if (($count = floor($since / $seconds)) != 0) { break; } } $print = ($count == 1) ? '1 '.$name : \"$count {$name}s\"; return $print . \" ago\"; } ? ","pontos":11},{"corpo":"I do have a type/format for my properties table, that way I know how to cast/evaluate when I'm dealing with an integer value. I wasn't sure if it was pertinent to this issue or not. ","pontos":0},{"corpo":"What I did at the end was attach gdb to the process before it crashed, and then when it got the segfault I executed the command. That forced generation of a core dump. ","pontos":16},{"corpo":"One of the biggest parts of a project manager's job is communicating between the stake holders (e.g., upper management) and the project resources (the programmers, etc.). The risk you run into by using two more more very different Big-M Methodologies is you will have to \"retrain\" management. They will have different expectations of what you will be delivering to them as interim reports, etc. Especially where one is used almost everywhere else in the organisation. You may very well start looking sloppy to them. AGILE and SCRUM don't necessarily reduce the planning and analysis that has to go into an IT project, it distributes it throughout the project, and make the programmers feel like they aren't having to do all this yucky planning before they actually build something. ","pontos":2},{"corpo":" Perhaps I'm being naive, but would forcing the communication to be via https be acceptable? I develop web services that run on 2.0 and have had success with just getting IIS to enforce https on the virtual directory. That would be the simplest way to go probably, but unfortunately I don't have control over the IIS configuration, and can't guarantee that it can run https. In that case, perhaps the best bet is to either case-by-case encrypt portions of the SOAP messages (after all, you may not need the entire message to be encrypted - just certain sensitive fields?), or you could opt to use an HttpModule to intercept all the messages and operate on the contents. In either case you're probably going to have to provide custom proxies. ","pontos":1},{"corpo":"I've been using SSRS for a while now... and coworkers who look over my shoulder say it looks to be MUCH easier to do the SSRS thing than the Crystal. I've never used Crystal, so I can't tell you which is better, but I get the distinct impression that MS tried to rush SSRS out the door. Largest weaknesses: Sharing Datasets. I work in a DoD environment. 90% of my reports use a Service parameter. I get sick of typing the same query over and over again. Skinning. If you do the report wizard you can skin your report, but not if you do it manually? huh? I can \"skin\"things by selecting all the affectedfields and then setting back colors,fore colors, etc. But nowhere (atleast no where I can find) can youskin something with 1 click. No custom skinning. Report wizard/ manual, there's no where I can find to implement a custom skin. Would be nice to just set up something (like CSS for HTML) and then just link to it. Tools should help you by reducing your effort rather than add to said effort. Matrixes need better documentation. I can do VERY simple things, but once I try to get into fun/difficult things, books/the internet seem to let me down. Tables don't have this issue. Strengths: Very simple for an old SQL developer to get good reports that at least look better than the drek that dumping a restlt set to Excel provides. Custom sorting (use on most reports) Handles SP and Straight SQL. Love that I'm not locked into 1 path or the other (I've used both depending on circumstances). Price... once you've paid for Visual Studio/SQL Server... it's a freebie. My 2 cents, hope this helps you. ","pontos":7},{"corpo":"There is also the DirectCast method which you should use only if you are sure what the type of the object is. It is faster, but doesn't do any proper checks. I use DirectCast when I'm extracting values from a loosely typed DataTable when I know the type for each column. ","pontos":1},{"corpo":"If you need speed, I'm pretty sure a direct cast is the fastest way. That being said, I normally use .Parse or .TryParse because is seems to make things easier to read, and behave in a more predictable manner. Convert actually calls Parse under the hood, I believe. So there is little difference there, and its really just seems to be a matter of personal taste. ","pontos":1},{"corpo":"Attempting to mimic a file system using SQL is generally a bad plan. You ultimately write less code with equal or better results if you stick with the file system for external storage. ","pontos":0},{"corpo":"The issue you are having is a symptom of not keeping the data atomic. In this case it looks purely unintentional (Legacy) but here is a link about it. To design yourself out of this create a range_lookup table: Create table rangeLookup( rangeID int -- or rangeCD or not at all ,rangeLabel varchar(50) ,LowValue int--real or whatever ,HighValue int ) To hack yourself out here some pseudo steps this will be a deeply nested mess. normalize your input by replacing all your crazy charecters. replace(replace(rangeLabel,\"%\",\"\"),\" \",\"\") --This will entail many nested replace statments. Add a CASE and CHARINDEX to look for a space if there is none you have your number else use your substring to take everything before the first \" \". -- theses steps are wrapped around the previous step. ","pontos":0},{"corpo":"In many cases, you can take existing code and just run it on Mono, particularly if you're porting an ASP.NET application. In some cases, you may require whole new sections of code to make it work. If you use System.Windows.Forms, for example, the application won't work unmodified. Likewise if you use any Windows-specific code (registry access code, for example). But I think the worst offender is UI code. That's particularly bad on Macintosh systems. ","pontos":4},{"corpo":"It really depends on the namespaces and classes that you are using from the .NET framework. I had interest in converting one of my windows services to run on my email server, which is Suse, but we ran into several hard roadblocks with APIs that had not been completely implemented. There is a chart somewhere on the Mono website that lists all of the classes and their level of completion. If your application is covered, then go for it. Like any other application, do prototyping and testing before you make a full commitment, of course. Another problem we ran into is licensed software: if you are referencing someone else's DLL, you can't code your way around incompatibilities that are buried in that assembly. ","pontos":1},{"corpo":"I am not clear if you need to share dataset sicne you have some SQL results that you need to use twice, and don't want to re-compute the same data twice, or you want to do something regarding parameters... so with this \"I didn't really understand the questions\" preface... you cannot share dataset. Meaning, you can't lets say have a dataset returning table A, and in dataset 2 ty to join with A. If this is really what you want to do, you could use temporary tables to store A and then in dataset 2 use the temporary table. There are best practices around that, but since I am not sure this is what you need, I won't spend time talking about that right now. ","pontos":1},{"corpo":"I've found what was wrong. The column must allow updates. uwgMyGrid.Columns.FromKey(\"colTest\").AllowUpdate = AllowUpdate.Yes; ","pontos":1},{"corpo":"It's possible. But it's extremely sketchy. Your application may also break with the next version of Windows, since it's undocumented. What you need to do is find the window handle of the taskbar, then find the window handle of the child window representing the button, then send it a WM_MOUSEDOWN (I think) message. Here's a bit on finding the window handle of the taskbar: http://www.codeproject.com/ FWIW, the restrictions on BringWindowToTop/SetForeground are there because it's irritating when a window steals focus. That may not matter if you're working on a corporate environment. Just keep it in mind. :) ","pontos":2},{"corpo":"I'm a big fan of TryParse, since it saves you a lot of headache of error catching when there's a chance the value you're going to parse is not of the appropriate type. My order is usually: Parse (if I can be sure the value will be the right type, and I do try to ensure this) TryParse (if I can't be sure, which happens whenever user input is involved, or input from a system you cannot control) Convert (which I think I have not used since I started using Parse and TryParse, but I could be wrong) ","pontos":3},{"corpo":"As far as I know, iterate and instantiate is the only way to do this. Something like (for others potential help, since I'm sure you know how to do this): List Integer oldList = ... /* Specify the size of the list up front to prevent resizing. */ List String newList = new ArrayList String (oldList.size()) for (Integer myInt : oldList) { newList.add(String.valueOf(myInt)); } ","pontos":45},{"corpo":"Since .NET 3.5 came out, I've exclusively used LINQ. It's really that good; I don't see any reason to use any of those old crutches any more. As great as LINQ is, though, I think any ORM system would allow you to do away with that dreck. ","pontos":17},{"corpo":"The only reason we store images in our tables is because each table (or set of tables per range of work) is temporary and dropped at the end of the workflow. If there was any sort of long term storage we'd definitely opt for storing file paths. It should also be noted that we work with a client/server application internally so there's no web interface to worry about. ","pontos":1},{"corpo":"I think using Object.toString() for any purpose other than debugging is probably a really bad idea, even though in this case the two are functionally equivalent (assuming the list has no nulls). Developers are free to change the behavior of any toString() method without any warning, including the toString() methods of any classes in the standard library. Don't even worry about the performance problems caused by the boxing/unboxing process. If performance is critical, just use an array. If it's really critical, don't use Java. Trying to outsmart the JVM will only lead to heartache. ","pontos":2},{"corpo":"I was fed up with DataSets in .Net 1.1, at least they optimised it so that it doesn't slow as exponentially for large sets any more. It was always a rather bloated model - I haven't seen many apps that use most of its features. SqlDataReader was good, but I used to wrap it in an where the T was some typed representation of my data row. Linq is a far better replacement in my opinion. ","pontos":3},{"corpo":"A more complete discussion of the pitfalls of using a regex to find matching tags can be found at: http://faq.perl.org/perlfaq4.html#How_do_I_find_matchi. In particular, be aware that nesting tags really need a full-fledged parser in order to be interpreted correctly. Note that case sensitivity will need to be turned off in order to answer the question as stated. In perl, that's the i modifier: $ echo \"Data Data Data [Start] Data i want [End] Data\" \\ | perl -ne '/\\[start\\](.*?)\\[end\\]/i; print \"$1\\n\"' Data i want The other trick is to use the *? quantifier which turns off the greediness of the captured match. For instance, if you have a non-matching [end] tag: Data Data [Start] Data i want [End] Data [end] you probably don't want to capture: Data i want [End] Data ","pontos":3},{"corpo":"I layer out the application and at least unit test from the presenter/controller (whichever is your preference, mvc/mvp) to the data layer. That way I have good test coverage over most of the code that is written. I have looked at FitNesse, Watin and Selenium as options to automate the UI testing but I haven't got around to using these on any projects yet, so we stick with human testing. FitNesse was the one I was leaning toward but I couldn't introduce this as well as introducing TDD (does that make me bad? I hope not!). ","pontos":4},{"corpo":"I save all my dates as a bigint due to having had issues with the dateTime type before. I save the result of the time() PHP function into it, now they count as being in the same timezone :) ","pontos":0},{"corpo":"We've been using it for a project here at work that needed to run on Linux but reuse some .NET libraries that we built in Managed C++. I've been very surprised at how well it has worked out. Our main executable is being written in C# and we can just reference our Managed C++ binaries with no issue. The only difference in the C# code between Windows and Linux is RS232 serial port code. The only big issue I can think of happened about a month ago. The Linux build had a memory leak that wasn't seen on the Windows build. After doing some manual debugging (the basic profilers for Mono on Linux didn't help much), we were able to narrow the issue down to a specific chunk of code. We ended up patching a workaround, but I still need to find some time to go back and figure out what the root cause of the leak was. ","pontos":4},{"corpo":"I just build my business objects from scratch, and almost never use the DataTable and especially not the DataSet anymore, except to initially populate the business objects. The advantages to building your own are testability, type safety and intellisense, extensibility (try adding to a DataSet) and readability (unless you enjoy reading things like Convert.ToDecimal(dt.Rows[i][\"blah\"].ToString())). If I were smarter I'd also use an ORM and 3rd party DI framework, but just haven't yet felt the need for those. I'm doing lots of smaller size projects or additions to larger projects. ","pontos":0},{"corpo":"From the official Stackoverflow FAQ: What kind of questions should I not ask here? Tabs versus Spaces. Emacs versus Vi. C++ versus Java. This is not yet another place for programmers to argue about The One True Way. Why do we have to talk about this? ","pontos":-5},{"corpo":"I agree totally with Slavo but I also think that there are no silly questions. Hopefully this site doesn't become a flamewar site. ","pontos":-2},{"corpo":"One reason - separating your domain model from your database model. What I do is use Test Driven Development so I write my UI and Model layers first and the Data layer is mocked, so the UI and model is build around domain specific objects, then later I map these objects to what ever technology I'm using the the Data Layer. Its a bad idea to let the database structure determine the design of your application. Where possible write the app first and let that influence the structure of your database, not the other way around. ","pontos":25},{"corpo":"FileMon is a free stand alone tool that can detect all kinds of file access. You can filter out any unwanted. It does not show you the data that has actually changed though. ","pontos":1},{"corpo":"One of the reason I imagine size binding is not allowed is because the screen may change between sessions. Loading the size back when the resolution has reduced could result in the title bar being beyond the limits of the screen. You also need to be wary of multiple monitor setups, where monitors may no longer be available when you app next runs. ","pontos":1},{"corpo":"Not exactly a language but I find Regex very unfriendly to read. ","pontos":14},{"corpo":"Here is the php code for the same: function time_since($since) { $chunks = array( array(60 * 60 * 24 * 365 , 'year'), array(60 * 60 * 24 * 30 , 'month'), array(60 * 60 * 24 * 7, 'week'), array(60 * 60 * 24 , 'day'), array(60 * 60 , 'hour'), array(60 , 'minute'), array(1 , 'second') ); for ($i = 0, $j = count($chunks); $i $j; $i++) { $seconds = $chunks[$i][0]; $name = $chunks[$i][1]; if (($count = floor($since / $seconds)) != 0) { break; } } $print = ($count == 1) ? '1 '.$name : \"$count {$name}s\"; return $print; } The function takes the number of seconds as input and outputs text such as: 10 seconds 1 minute etc ","pontos":53},{"corpo":"Perl is incomprehensible to me because it's a language I haven't learned, like Thai, Greek, or Klingon. Looks like cartoon characters swearing. :) ","pontos":0},{"corpo":"I second LISP. Had a class in college that used Scheme which is a LISP Dialect. The Polish (prefix) notation and seemingly infinite parenthesis make it a drastic departure from the C and Java I'm used to. ","pontos":1},{"corpo":"Foreign keys can also help the programmer write less code using things like ON DELETE CASCADE. This means that if you have one table containing users and another containing orders or something, then deleting the user could automatically delete all orders that point to that user. ","pontos":47},{"corpo":"I can't imagine designing a database without foreign keys. Without them, eventually you are bound to make a mistake and corrupt the integrity of your data. They are not required, strictly speaking, but the benefits are huge. I'm fairly certain that FogBugz does not have foreign key constraints in the database. I would be interested to hear how the Fog Creek Software team structures their code to guarantee than they will never introduce an inconsistency. ","pontos":31},{"corpo":"Without a foreign key how do you tell that two records in different tables are related? I think what you are referring to is referential integrity, where the child record is not allowed to be created without an existing parent record etc. These are often known as foreign key constraints - but are not to be confused with the existence of foreign keys in the first place. ","pontos":6},{"corpo":"You can't avoid the \"boxing overhead\"; Java's faux generic containers can only store Objects, so your ints must be boxed into Integers. In principle it could avoid the downcast from Object to Integer (since it's pointless, because Object is good enough for both String.valueOf and Object.toString) but I don't know if the compiler is smart enough to do that. The conversion from String to Object should be more or less a no-op, so I would be disinclined to worry about that one. ","pontos":1},{"corpo":"There is a separate terminal service connection available called the 'console' connection. You can connect to this space using mstsc /console /v:servername. Use mstsc /? for full command line options. This allows you to connect, open up the terminal services manager and boot the bad sessions. ","pontos":3},{"corpo":"Assuming non-malicious code, I can read C, Pascal, VB, Java, C#, python, C++, SML, Haskell without colour coding. I can't do the same for lisp or scheme; those ones need assistance from the editor. So they \"win\", as far as I'm concerned. ","pontos":5},{"corpo":"The classes generated by Visual Studio for webservices are just proxies with little state so creating them is pretty cheap. I wouldn't worry about memory consumption for them. If what you are looking for is a way to call the webmethod in one line you can simply do this: new mywebservice().call() Cheers ","pontos":1},{"corpo":"Check out the section \"How to steal focus on 2K/XP\" at http://www.codeproject.com/KB/dialog/dlgboxtricks.aspx, as this is exactly what you need. I wouldn't go the taskbar route as the taskbar could be hidden or simply not there. ","pontos":4},{"corpo":" Suppose a programmer is actually doing this in the right manner already Making such a supposition seems to me to be an extremely bad idea; in general software is phenomenally buggy. And that's the point, really. Developers can't get things right, so ensuring the database can't be filled with bad data is a Good Thing. Although in an ideal world, natural joins would use relationships (i.e. FK constraints) rather than matching column names. This would make FKs even more useful. ","pontos":8},{"corpo":"Personally, I am in favor of foreign keys because it formalizes the relationship between the tables. I realize that your question presupposes that the programmer is not introducing data that would violate referential integrity, but I have seen way too many instances where data referential integrity is violated, despite best intentions! Pre-foreign key constraints (aka declarative referential integrity or DRI) lots of time was spent implementing these relationships using triggers. The fact that we can formalize the relationship by a declarative constraint is very powerful. @John - Other databases may automatically create indexes for foreign keys, but SQL Server does not. In SQL Server, foreign key relationships are only constraints. You must defined your index on foreign keys separately (which can be of benefit.) Edit: I'd like to add that, IMO, the use of foreign keys in support of ON DELETE or ON UPDATE CASCADE is not necessarily a good thing. In practice, I have found that cascade on delete should be carefully considered based on the relationship of the data -- e.g. do you have a natural parent-child where this may be OK or is the related table a set of lookup values. Using cascaded updates implies you are allowing the primary key of one table to be modified. In that case, I have a general philosophical disagreement in that the primary key of a table should not change. Keys should be inherently constant. ","pontos":10},{"corpo":"This is C and it prints the words of 'first day of Christmas' (try it if you don't believe me). Any questions? main(t,_,a ) char * a; { return! 0 t? t 3? main(-79,-13,a+ main(-87,1-_, main(-86, 0, a+1 ) +a)): 1, t _? main( t+1, _, a ) :3, main ( -94, -27+t, a ) t == 2 ?_ 13 ? main ( 2, _+1, \"%s %d %d\\n\" ) :9:16: t 0? t -72? main( _, t, \"@n'+,#'/*{}w+/w#cdnr/+,{}r/*de}+,/*{*+,/w{%+,/w#q#n+,/#{l,+,/n{n+,/+#n+,/#;#q#n+,/+k#;*+,/'r :'d*'3,}{w+K w'K:'+}e#';dq#'l q#'+d'K#!/+k#;q#'r}eKK#}w'r}eKK{nl]'/#;#q#n'){)#}w'){){nl]'/+#n';d}rw' i;# ){nl]!/n{n#'; r{#w'r nc{nl]'/#{l,+'K {rw' iK{;[{nl]'/w#q#n'wk nw' iwk{KK{nl]!/w{%'l##w#' i; :{nl]'/*{q#'ld;r'}{nlwb!/*de}'c ;;{nl'-{}rw]'/+,}##'*}#nc,',#nw]'/+kd'+e}+;#'rdq#w! nr'/ ') }+}{rl#'{n' ')# }'+}##(!!/\") : t -50? _==*a ? putchar(31[a]): main(-65,_,a+1) : main((*a == '/') + t, _, a + 1 ) : 0 t? main ( 2, 2 , \"%s\") :*a=='/'|| main(0, main(-61,*a, \"!ek;dc i@bK'(q)-[w]*%n+r3#l,{}:\\nuwloca-O;m .vpbks,fxntdCeghiry\") ,a+1);} ","pontos":5},{"corpo":"Unit testing will be achievable if you separate your layers appropriately. As Rob Cooper implied, don't put any logic in your WebForm other than logic to manage your presentation. All other stuff logic and persistence layers should be kept in separate classes and then you can test those individually. To test the GUI some people like selenium. Others complain that is a pain to set up. ","pontos":17},{"corpo":"Simple answer is going to be no. Sorry, you are going to have to re-declare. I have, in the past however, written scripts to import my C++ enums to a C# format in a enums.cs file and run it as part of the build, that way everything syncs. ","pontos":1},{"corpo":"I use this in a .bat file: @echo off for %i in (*.txt) python markdown.py \"%i\" ","pontos":0},{"corpo":"I found your question really interesting. Usually I need entities objects to encapsulate the business logic of an application. It would be really complicated and inadequate to push this logic into the data layer. What would you do to avoid these entities objects? What solution do you have in mind? ","pontos":4},{"corpo":"Have you tried connecting when logged on as domain/server-local Administrator? ","pontos":0},{"corpo":"A table scan has to examine every single row of the table. The clustered index scan only needs to scan the index. It doesn't scan every record in the table. That's the point, really, of indices. ","pontos":1},{"corpo":"@Dan, sorry, that's not the kind of thing I'm looking for. I know the theory. Your statement \"is a very bad idea\" is not backed up by a real example. We are trying to develop software in less time, with less people, with less mistakes, and we want the ability to easily make changes. Your multi-layer model, in my experience, is a negative in all of the above categories. Especially with regards to making the data model the last thing you do. The physical data model must be an important consideration from day 1. ","pontos":7},{"corpo":"Look at the where clause - verify use of indexes / verify nothing silly is being done where SomeComplicatedFunctionOf(table.Column) = @param --silly ","pontos":2},{"corpo":"@jdecuyper, one maxim I repeat to myself often is \"if your business logic is not in your database, it is only a recommendation\". I think Paul Nielson said that in one of his books. Application layers and UI come and go, but data usually lives for a very long time. How do I avoid entity objects? Stored procedures mostly. I also freely admit that business logic tends to reach through all layers in an application whether you intend it to or not. A certain amount of coupling is inherent and unavoidable. ","pontos":2},{"corpo":"Generic work-flow and DFDs can be very useful for complex processes. All other diagramming (ESPECIALLY UML) has, in my experience, without exception been a painful waste of time and effort. ","pontos":16},{"corpo":"I think it comes down to how complicated the \"logic\" of the application is, and where you have implemented it. If all your logic is in stored procedures, and all your application does is call those procedures and display the results, then developing entity objects is indeed a waste of time. But for an application where the objects have rich interactions with one another, and the database is just a persistence mechanism, there can be value to having those objects. So, I'd say there is no one-size-fits-all answer. Developers do need to be aware that, sometimes, trying to be too OO can cause more problems than it solves. ","pontos":58},{"corpo":"They are not strictly necessary, in the way that seatbelts are not strictly necessary. But they can really save you from doing something stupid that messes up your database. It's so much nicer to debug a FK constraint error than have to reconstruct a delete that broke your application. ","pontos":3},{"corpo":" Prefix all tables with dbo. to prevent recompilations. View query plans and hunt for table/index scans. In 2005, scour the management views for missing indexes. ","pontos":0},{"corpo":"Of course after I create this question I immediately find the answer after a few more searches on Google http://forums.asp.net/t/1197059.aspx Apparently this happens because of the wrapper class. Even so, it seems like any property passed should get added to the ViewData collection by default. I really need to stop answering my own questions :( ","pontos":2},{"corpo":"Theory says that highly cohesive, loosely coupled implementations are the way forward. So I suppose you are questioning that approach, namely separating concerns. Should my aspx.cs file be interacting with the database, calling a sproc, and understanding IDataReader? In a team environment, especially where you have less technical people dealing with the aspx portion of the application, I don't need these people being able to \"touch\" this stuff. Separating my domain from my database protects me from structural changes in the database, surely a good thing? Sure database efficacy is absolutely important, so let someone who is most excellent at that stuff deal with that stuff, in one place, with as little impact on the rest of the system as possible. Unless I am misunderstanding your approach, one structural change in the database could have a large impact area with the surface of your application. I see that this separation of concerns enables me and my team to minimise this. Also any new member of the team should understand this approach better. Also, your approach seems to advocate the business logic of your application to reside in your database? This feels wrong to me, SQL is really good at querying data, and not, imho, expressing business logic. Interesting thought though, although it feels one step away from SQL in the aspx, which from my bad old unstructured asp days, fills me with dread. ","pontos":26},{"corpo":"Try quoting the wildcard: $ find /usr -name \\*.sh or: $ find /usr -name '*.sh' If you happen to have a file that matches *.sh in the current working directory, the wildcard will be expanded before find sees it. If you happen to have a file named tkConfig.sh in your working directory, the find command would expand to: $ find /usr -name tkConfig.sh which would only find files named tkConfig.sh. If you had more than one file that matches *.sh, you'd get a syntax error from find: $ cd /usr/local/lib $ find /usr -name *.sh find: bad option tkConfig.sh find: path-list predicate-list Again, the reason is that the wildcard expands to both files: $ find /usr -name tclConfig.sh tkConfig.sh Quoting the wildcard prevents it from being prematurely expanded. Another possibility is that /usr or one of its subdirectories is a symlink. find doesn't normally follow links, so you might need the -follow option: $ find /usr -follow -name '*.sh' ","pontos":45},{"corpo":"Don't prefix Stored Procedure names with \"sp_\" because system procedures all start with \"sp_\", and SQL Server will have to search harder to find your procedure when it gets called. ","pontos":0},{"corpo":"For me it boils down to I don't want my application to be concerned with how the data is stored. I'll probably get slapped for saying this...but your application is not your data, data is an artifact of the application. I want my application to be thinking in terms of Customers, Orders and Items, not a technology like DataSets, DataTables and DataRows...cuz who knows how long those will be around. I agree that there is always a certain amount of coupling, but I prefer that coupling to reach upwards rather than downwards. I can tweak the limbs and leaves of a tree easier than I can alter it's trunk. I tend to reserve sprocs for reporting as the queries do tend to get a little nastier than the applications general data access. I also tend to think with proper unit testing early on that scenario's like that one column not being persisted is likely not to be a problem. ","pontos":22},{"corpo":"Slightly off topic but if you have control over these issues... High level and High Impact. For high IO environments make sure your disks are for either RAID 10 or RAID 0+1 or some nested implementation of raid 1 and raid 0. Don't use drives less than 1500K. Make sure your disks are only used for your Database. IE no logging no OS. Turn off auto grow or similar feature. Let the database use all storage that is anticipated. Not necessarily what is currently being used. design your schema and indexes for the type queries. if it's a log type table (insert only) and must be in the DB don't index it. if your doing allot of reporting (complex selects with many joins) then you should look at creating a data warehouse with a star or snowflake schema. Don't be afraid of replicating data in exchange for performance! ","pontos":18},{"corpo":"In C/C++ you can #include a .cs file which contains the enumeration definition. Careful use of preprocessor directives takes care of the syntax differences between C# and C. Example: #if CSharp namespace MyNamespace.SharedEnumerations { public #endif enum MyFirstEnumeration { Autodetect = -1, Windows2000, WindowsXP, WindowsVista, OSX, Linux, // Count must be last entry - is used to determine number of items in the enum Count }; #if CSharp public #endif enum MessageLevel { None, // Message is ignored InfoMessage, // Message is written to info port. InfoWarning, // Message is written to info port and warning is issued Popup // User is alerted to the message }; #if CSharp public delegate void MessageEventHandler(MessageLevel level, string message); } #endif In your C# project, set a conditional compilation symbol \"CSharp\", make sure no such preprocessor definition exists in the C/C++ build environment. Note that this will only ensure both parts are syncronised at build time. If you mix-and-match binaries from different builds, the guarantee fails. ","pontos":6},{"corpo":"My regexp would go along the lines of: edit: I think it's the lack of a line end ($) that makes it fail. ","pontos":4},{"corpo":"I don't like the Views to become too complex, and so far I have tended to have separate views for Edit and Add. I use a user control to store the common elements to avoid repetition. Both of the views will be centered around the same ViewData, and I have a marker on my data to say whether the object is new or an existing object. This isn't any more elegant than what you have stipulated, so I wonder if any of the Django or Rails guys can provide any input. I love asp.net mvc but it is still maturing, and still needs more sugar adding to take away some of the friction of creating websites. ","pontos":4},{"corpo":"My read of the question was that the server is set up to use SQL authentication only, and perhaps you don't know the sa password or any other SQL login credentials? If so, you might be able to change the authentication mode. For SQL Server 2005 default instances, it's stored in the registry at: HKEYLOCALMACHINE\\SOFTWARE\\Microsoft\\Microsoft SQL Server\\MSSQL.1\\MSSQLServer in a DWORD called LoginMode. A value of 2 indicates Mixed Mode (both Windows and SQL authentication are supported); I think 0 is Windows only and 1 is SQL only. You can try changing it to 2, restart the MSSQL service, then try to get into the SQL management studio after logging into the machine as an administrator. If that fails, you can create another instance by re-running the setup program. ","pontos":2},{"corpo":"By 'not working' I take it you mean it is letting invalid entries through (rather than not letting valid entries through). As Annan has said, this would probably be due to the lack of the '$' symbol at the end of the expression, as currently it only requires a single valid character at the start of the value, and the rest can be anything. ","pontos":0},{"corpo":"Your regex /^([a-zA-Z0-9_])+/ Looks for Start of string(check), followed by 1 or more letters, numbers, or underscore (check) And then whatever comes after it doesn't matter. This regex will match anything at all so long as it begins with a letter, number, or underscore If you put a at the end, then it will work - matches 'end of string', so the only way it can match is if there are only numbers, letters, and underscores between the start and end of the string. /^([a-zA-Z0-9_])+$/ Secondly, I'd suggest using instead of as it won't break if you rearrange the HTML, and is more 'the commonly accepted standard of what to do' ","pontos":12},{"corpo":"What does \"doesn't work\" mean? Does it reject valid display names? Does it accept invalid display names? Which ones? Per @Annan, leaving off the would make the regexp accept invalid display names like . If the code is rejecting valid display names, it may be because the parentheses are being matched literally instead of denoting a group (I'm not sure of the quoting convention in JS). ","pontos":0},{"corpo":"One intuition is that if you have a very large number of entities, tuple stores can save yourself the trouble of having your indexes routinely knocked out of memory as you switch between tables, and instead always have the first couple levels of the tuple index in RAM. ","pontos":1},{"corpo":"That's the issue I have too. My problem is that WebSVN is so amazingly slow. It takes about 20 mins to open a head revision (sample repository: few thousand files, 2500 odd revisions). Everything else seems to require MySql and so on. ","pontos":2},{"corpo":"No, you can't. It's set up so it only works on localhost, and I couldn't find any workarounds to make it work. But, here's what I've been doing - I created the website on a specific port in IIS and opened that port up so it's visible on the network. I pointed that IIS website to my website's root folder (the one with web.config in it). Then I continued to use the ASP.NET Development server on that local machine while developing - both IIS and the ASP.NET Development Server can access the files at the same time (unless you're doing something wacky). Let me know if there's a challenge with running IIS on your machine and I'll update my answer. ","pontos":20},{"corpo":" Have a pretty good idea of the optimal path of running the query in your head. Check the query plan - always. Turn on STATS, so that you can examine both IO and CPU performance. Focus on driving those numbers down, not necessarily the query time (as that can be influenced by other activity, cache, etc.). Look for large numbers of rows coming into an operator, but small numbers coming out. Usually, an index would help by limiting the number of rows coming in (which saves disk reads). Focus on the largest cost subtree first. Changing that subtree can often change the entire query plan. Common problems I've seen are: If there's a lot of joins, sometimes Sql Server will choose to expand the joins, and then apply WHERE clauses. You can usually fix this by moving the WHERE conditions into the JOIN clause, or a derived table with the conditions inlined. Views can cause the same problems. Suboptimal joins (LOOP vs HASH vs MERGE). My rule of thumb is to use a LOOP join when the top row has very few rows compared to the bottom, a MERGE when the sets are roughly equal and ordered, and a HASH for everything else. Adding a join hint will let you test your theory. Parameter sniffing. If you ran the stored proc with unrealistic values at first (say, for testing), then the cached query plan may be suboptimal for your production values. Running again WITH RECOMPILE should verify this. For some stored procs, especially those that deal with varying sized ranges (say, all dates between today and yesterday - which would entail an INDEX SEEK - or, all dates between last year and this year - which would be better off with an INDEX SCAN) you may have to run it WITH RECOMPILE every time. Bad indentation...Okay, so Sql Server doesn't have an issue with this - but I sure find it impossible to understand a query until I've fixed up the formatting. ","pontos":19},{"corpo":"Logging in over RDP shouldn't affect whether the console locks. If you don't log out of RDP (just closing the client keeps your session pending), then your session will be locked. You can solve that with idle timeouts in Terminal Services Manager. If your console is locking, that's a seperate policy in Local Computer Settings or some such. If you have a domain, set it with a GPO. If you need the exact name of the policy, let me know and I'll dig it up for you. ","pontos":1},{"corpo":"I look out for: Unroll any CURSOR loops and convert into set based UPDATE / INSERT statements. Look out for any application code that: Calls an SP that returns a large set of records, Then in the application, goes through each record and calls an SP with parameters to update records. Convert this into a SP that does all the work in one transaction. Any SP that does lots of string manipulation. It's evidence that the data is not structured correctly / normalised. Any SP's that re-invent the wheel. Any SP's that I can't understand what it's trying to do within a minute! ","pontos":1},{"corpo":"If you have all the money in the world, go with Cognos. They provide a data cube that essentially makes the reporting \"developer free\" and the end user can create reports, dashboards, anything they like. For the \"common man\", I've grown quite fond of the ComponentOne reports for .NET library/tools. It has a similar feel to Crystal Reports, but has a very friendly XML format that you and edit under the hood and none of the headaches with versioning, keys, and other items that I've had to deal with when making simple updates to either the report or the underlying version. ","pontos":2},{"corpo":"Partitions have UUIDs associated with them. I don't know how to find these in Windows but in linux you can find the UUID for each partition with: sudo vol_id -u device (e.g. /dev/sda1) If there is an equivilent function in Windows you could simply store the UUIDs for whatever partition they pick then iterate through all known partitions in linux and match the UUIDs. Edit: This may be a linux-only thing, and it may speficially be the volid util that generates these from something (instead of reading off meta-data for the drive). Having said that, there is nothing stopping you getting the source for volid and checking out what it does. ","pontos":1},{"corpo":"Vista's failure to gain mass acceptance is largely responsible for the reason we still have to support IE6. Most of the people still using IE6 are the ones who never upgrade their browser or update their OS. If most of them just moved to Vista, IE7 would automatically replace IE6 ","pontos":0},{"corpo":"I can't find anything built in... but using the ExpandoMetaClass I can do this: ArrayList.metaClass.collectMap = {Closure callback- def map = [:] delegate.each { def r = callback.call(it) map[r[0]] = r[1] } return map } this adds the collectMap method to all ArrayLists... I'm not sure why adding it to List or Collection didn't work.. I guess that's for another question... but now I can do this... assert [\"foo\":\"oof\", \"42\":\"24\", \"bar\":\"rab\"] == [\"foo\", \"42\", \"bar\"].collectMap { return [it, it.reverse()] } from List to calculated Map with one closure... exactly what I was looking for. Edit: the reason I couldn't add the method to the interfaces List and Collection was because I did not do this: List.metaClass.enableGlobally() after that method call, you can add methods to interfaces.. which in this case means my collectMap method will work on ranges like this: (0..2).collectMap{[it, it*2]} which yields the map: [0:0, 1:2, 2:4] ","pontos":1},{"corpo":"A database schema without FK constraints is like driving without a seat belt. One day, you'll regret it. Not spending that little extra time on the design fundamentals and data integrity is a sure fire way of assuring headaches later. Would you accept code in your application that was that sloppy? That directly accessed the member objects and modified the data structures directly. Why do you think this has been made hard and even unacceptable within modern languages? ","pontos":29},{"corpo":"Put the shared functionality in a library, then write a command-line and a GUI front-end for it. That way your layer transition isn't tied to the command-line. (Also, this way adds another security concern: shouldn't the GUI first have to make sure it's the RIGHT todo.exe that is being called?) ","pontos":7},{"corpo":"Are you sure the issue is with the parameters and not maybe the variable in SPD? Certainly nothing looks wrong with your XML. I always hated the way SPD and workflows make you create a variable within the workflow and another within the page to assign to the same value as the workflow variable. ","pontos":0},{"corpo":"Kinda depends on your goal for the program, but yeah i do this from time to time - it's quicker to code, easier to debug, and easier to write quick and dirty test cases for. And so long as i structure my code properly, i can go back and tack on a GUI later without too much work. To those suggesting that this technique will result in horrible, unusable UIs: You're right. Writing a command-line utility is a terrible way to design a GUI. Take note, everyone out there thinking of writing a UI that isn't a CLUI - don't prototype it as a CLUI. But, if you're writing new code that does not itself depend on a UI, then go for it. ","pontos":1},{"corpo":"Sorry guys I should have been more specific. Whenever I added spaces the values were still being accepted. The dollar sign ($) did the trick! ","pontos":0},{"corpo":"Benefits to your company are few. All of the reasons others have given assume a degree of popularity that is... unlikely. Most business folks are going to realize that without needing to think very hard about it so they aren't going to find advertising or leverage or public scrutiny or tool improvement enough of a reason to take the \"risk\" of releasing it as open source. That said, here's the best counter to the \"risk\" argument for a company to release an internal tool as Open Source: if it isn't part of your core competency and care is taken so that it doesn't suck company resources (or expose company secrets/infrastructure), there really is no risk. The company loses nothing and gains a potential for gain even if that potential is small. ","pontos":5},{"corpo":"Support IE6 by not blocking it and letting it fend for itself for the most part. Only work around IE6 bugs that break major functionality. As for JS bugs and horrible DOM support, you still have that in IE7 and IE8. In that case, you might as well use a JS toolkit and get IE6 support for almost free. Bugs are bugs and they should be fixed (in any browser) instead of being worked around. But, you gotta do what you gotta do to please visitors. One day, working around IE6 bugs will be asking too much. ","pontos":0},{"corpo":"I've made it a habit to always use bind variables. It's possible bind variables won't help if the RDBMS doesn't cache SQL statements. But if you don't use bind variables the RDBMS doesn't have a chance to reuse query execution plans and parsed SQL statements. The savings can be enormous: http://www.akadia.com/services/ora_bind_variables.html. I work mostly with Oracle, but Microsoft SQL Server works pretty much the same way. In my experience, if you don't know whether or not you are using bind variables, you probably aren't. If your application language doesn't support them, find one that does. Sometimes you can fix query A by using bind variables for query B. After that, I talk to our DBA to find out what's causing the RDBMS the most pain. Note that you shouldn't ask \"Why is this query slow?\" That's like asking your doctor to take out you appendix. Sure your query might be the problem, but it's just as likely that something else is going wrong. As developers, we we tend to think in terms of lines of code. If a line is slow, fix that line. But a RDBMS is a really complicated system and your slow query might be the symptom of a much larger problem. Way too many SQL tuning tips are cargo cult idols. Most of the time the problem is unrelated or minimally related to the syntax you use, so it's normally best to use the cleanest syntax you can. Then you can start looking at ways to tune the database (not the query). Only tweak the syntax when that fails. Like any performance tuning, always collect meaningful statistics. Don't use wallclock time unless it's the user experience you are tuning. Instead look at things like CPU time, rows fetched and blocks read off of disk. Too often people optimize for the wrong thing. ","pontos":2},{"corpo":"There may be a problem if you are running these tasks as Administrator and others are logging in via Remote Desktop as Administrator. The task should be run from its own account. ","pontos":0},{"corpo":" From the application level (unfortunately). I agree that the proper way to prevent duplication is at the database level through the use of a unique index, but in SQL Server 2005, an index is allowed to be only 900 bytes, and my varchar(2048) field blows that away. I dunno how well it would perform, but I think you could write a trigger to enforce this, even if you couldn't do it directly with an index. Something like: -- given a table stories(story_id int not null primary key, story varchar(max) not null) CREATE TRIGGER prevent_plagiarism ON stories after INSERT, UPDATE AS DECLARE @cnt AS INT SELECT @cnt = Count(*) FROM stories INNER JOIN inserted ON ( stories.story = inserted.story AND stories.story_id != inserted.story_id ) IF @cnt 0 BEGIN RAISERROR('plagiarism detected',16,1) ROLLBACK TRANSACTION END Also, varchar(2048) sounds fishy to me (some things in life are 2048 bytes, but it's pretty uncommon); should it really not be varchar(max)? ","pontos":4},{"corpo":"I am certainly opposed to excluding browsers from a public facing site. There is nothing more irritating than going to a website and discovering they ONLY support IE because some dev somewhere couldn't make things \"work\". As many of the other authors above have noted there is a considerable number of users out there who use a company imposed desktop build or install of IE6. Your best bet is always to identify and communicate with your users, not impose your draconian concepts upon them. Ryan Farley had an entry about this recently which describes what I think is the best first step to transitioning over users to a different browser. It encourages people to upgrade and explains why things may not render correctly in one graphic. Many years ago, BinaryBonsai.com was the first blog I encountered which had a badge appear suggesting FireFox and I totally downloaded it just not to be bothered with an additional graphic. There really is nothing like nerd peer-pressure. ","pontos":0},{"corpo":"Unfortunately that is not officially supported. See the following MSDN article. If a Web site is precompiled for deployment, content provided by a VirtualPathProvider instance is not compiled, and no VirtualPathProvider instances are used by the precompiled site. The site you referred to is an unofficial workaround. I don't think it's been fixed in .NET 3.5 SP1 ","pontos":2},{"corpo":"I usually start with a class library and a separate, really crappy and basic GUI. As the Command Line involves parsing the Command Line, I feel like i'm adding a lot of unneccessary overhead. As a Bonus, this gives an MVC-like approach, as all the \"real\" code is in a Class Library. Of course, at a later stage, Refactoring the library together with a real GUI into one EXE is also an option. ","pontos":1},{"corpo":"http://oracle.ittoolbox.com/groups/technical-functional/oracle-dev-l/difference-between-yyyy-and-rrrr-format-519525 YY allows you to retrieve just two digits of a year, for example, the 99 in 1999. The other digits (19) are automatically assigned to the current century. RR converts two-digit years into four-digit years by rounding. 50-99 are stored as 1950-1999, and dates ending in 00-49 are stored as 2000-2049. RRRR accepts a four-digit input (although not required), and converts two-digit dates as RR does. YYYY accepts 4-digit inputs butdoesn't do any date converting Essentially, your first example will assume that 81 is 2081 whereas the RR one assumes 1981. So the first example should not return any rows as you most likely did not hire any guys after May 1 2081 yet :-) ","pontos":20},{"corpo":"The way I did it before (and the last time I worked in Access was around '97 so my memory is not so hot) was raising a key-up event and executing a VBA function. It's a similar method to what you do with an AJAX suggest text box in a modern webform application, but as I recall it could get tripped up if your Access form has other events which tend to occur frequently such a onMouseMove over the entire form object. ","pontos":3},{"corpo":"in jquery you can use: $(document).ready(function(){/*do stuff here*/}); which makes sure the javascript is loaded and the dom is ready before doing your stuff. in prototype it looks like this might work document.observe(\"dom:loaded\", function() {/*do stuff here*/}); If I understand your problem correctly.. I think that may help.. If you don't want to rely on a lib to do this... I think this might work: script function doIt() {/*do stuff here*/} /script body onLoad=\"doIt();\" /body ","pontos":8},{"corpo":"Developing against Project Server 2003 isn't the friendliest experience around, but I have worked a little bit with the PDS (Project Data Services) which is SOAP based http://msdn.microsoft.com/en-us/library/aa204408(office.11).aspx It contains .NET samples there ","pontos":1},{"corpo":"ok... I've played with this a little more and I think this is a pretty cool method... def collectMap = {Closure callback- def map = [:] delegate.each { def r = callback.call(it) map[r[0]] = r[1] } return map } ExpandoMetaClass.enableGlobally() Collection.metaClass.collectMap = collectMap Map.metaClass.collectMap = collectMap now any subclass of Map or Collection have this method... here I use it to reverse the key/value in a Map [1:2, 3:4].collectMap{[it.value, it.key]} == [2:1, 4:3] and here I use it to create a map from a list [1,2].collectMap{[it,it]} == [1:1, 2:2] now I just pop this into a class that gets called as my app is starting and this method is available throughout my code. EDIT: to add the method to all arrays... Object[].metaClass.collectMap = collectMap ","pontos":5},{"corpo":"Why not use -moz-border-radius and -webkit-border-radius in the stylesheet? It's valid CSS and throwing an otherwise unused attribute would hurt less than having javascript do the legwork of figuring out if it should apply it or not. Then, in the javascript you'd just check if the browser is I.E. (or Opera?) - if it is, it'll ignore the proprietary tags, and your javascript could do it's thing. Maybe I'm missing something here... ","pontos":4},{"corpo":" Is it time to do away with IE6 programming? Yes. ","pontos":1},{"corpo":"I don't really have much SSAS work to do but I've been quite taken with this: Cube Browser for ASP.net It offers many of the capabilities of an excel pivot table in a web app, (thought I'm not enough of an expert on Excel to really know the whole of the pivot table's capabilities - it at least looks comparable to visual studio's cube browser). Unfortunately the demos don't seem to be online anymore :( ","pontos":2},{"corpo":"To get a real \"upsert\" type of query you need to use an if exists... type of thing, and this unfortunately means using a cursor. However, you could run two queries, one to do your updates where there is an existing row, then afterwards insert the new one. I'd think this set-based approach would be preferable unless you're dealing exclusively with small numbers of rows. ","pontos":1},{"corpo":"Actually, I think you're making it much harder than it is. Won't this code work for what you're trying to do? SELECT StaffName, SUM(InStage1) AS 'JobsAtStage1', SUM(InStage2) AS 'JobsAtStage2' FROM ViewJob GROUP BY StaffName ","pontos":3},{"corpo":"What do you need to remove? It keeps on adding that folder back to the project that I'm working on... ","pontos":0},{"corpo":"One thing I've seen a printer manufacturer do with their printer properties dialog is to have a little help baloon icon beside disabled items that display a tooltip when hovered over. Another thing you can do with disabled items is to add in parenthesis why it's disabled or what the user would have to do to enable it. E.g., \"Save (already saved)\" or \"Copy (select something to copy)\". I don't like keeping it enabled because then it will instill hesitation in users to select any menu item in fear that they'll just get an error message making them feel stupid for not realizing that they couldn't possibly perform that operation at the time. Menu items that spring dialogs have elipsis (...) after them to let users know it's not just click and carry on. Required form fields have an asterisk or bold label to spare the user from being scolded with a validation error message. ","pontos":4},{"corpo":"You have to consider the alternatives. Hide the menu item. This is bad. Now you have menu items disappearing and reappearing all the time? Disable the menu item. Now the user can find what they're looking for, it just isn't obvious how to enable it. This is better, but still leaves the user slightly puzzled. Keep the menu item enabled, but make it display a dialog that explains what needs to be done when the program is in a state where the menu item can't be properly used. I agree with Joel on this one, #3 seems like the best choice. ","pontos":2},{"corpo":"cat will just print the data to standard out, which happens to be redirected to the standard in of tail. This can be seen in the man page of bash. In other words, there is no pausing going on, tail is just reading from standard in and cat is just writing to standard out. ","pontos":0},{"corpo":"@Bill the Lizard: I'd combine #2 and #3 - disable the item, but have a tooltip that indicates why it is disabled. ","pontos":0},{"corpo":"What you are after would be a data generator. There is one available here which i had bookmarked but i haven't got around to trying it yet. ","pontos":17},{"corpo":"@pauldoo It is actually possible to get rid of the if statement and the addition if you do it like this. byte[] foobar = ..; int value = (foobar[10] 0xff); This way Java doesn't interpret the byte as a negative number and flip the sign bit on the integer also. ","pontos":71},{"corpo":"Managed code Check position of the mouse every second. If there are new messages for user, hold on to them until you detect any move with the mouse. Unmanaged code See Detecting Idle Time with Mouse and Keyboard Hooks ","pontos":1},{"corpo":"I managed to get it working with a variation of BCS's answer. It wouldn't let me use a table variable though, so I had to make a temp table. CREATE TABLE #ResultTable ( StaffName nvarchar(100), Stage1Count int, Stage2Count int ) INSERT INTO #ResultTable (StaffName) SELECT StaffName FROM ViewJob GROUP BY StaffName UPDATE #ResultTable SET Stage1Count= ( SELECT COUNT(*) FROM ViewJob V WHERE InStage1 = 1 AND V.StaffName = @ResultTable.StaffName COLLATE Latin1_General_CI_AS GROUP BY V.StaffName), Stage2Count= ( SELECT COUNT(*) FROM ViewJob V WHERE InStage2 = 1 AND V.StaffName = @ResultTable.StaffName COLLATE Latin1_General_CI_AS GROUP BY V.StaffName) SELECT StaffName, Stage1Count, Stage2Count FROM #ResultTable DROP TABLE #ResultTable ","pontos":0},{"corpo":"At a previous employer we reviewed Accurev and Plastic SCM. At the end of the day, I was not impressed with Accurev's interface, or the so-called \"streams\". We went with Plastic, and nobody complained. @Jonathan The streams are interesting,but I don't see how any version control can magically avoid collisions when two people touch the same code in the same file. Accurev's model was intriguing, but at the end of the day, nice clean branching and merging with a drop dead easy interface made Plastic the choice for us. Plastic's timeline view (I forget the actual name), showing the branch/merge/check-in history made it very simple to review the history of the project from a bird's eye view. ","pontos":5},{"corpo":"I would say the biggest limitation might be the extra overhead for have the browser render a script tag to call the server. Plus is JSONP really considered AJAX since it doesn't actually use the XMLHttpRequest object? ","pontos":2},{"corpo":"Definitely IoC practices and contract-based programming in general would be at the top of my list. From a matter of experience, though, I would caution against abstracting too much away from the problem simply for the sake of abstraction. E.g. abstracting because you can and not because anyone will ever be able to make use of that abstraction. I've seen that kind of architecture gone bad and simply add too high a degree of complexity to a system making maintenance of the system worse. Some sort of feedback loop around your development process -- be it unit tests, continuous integration and/or \"scrum\" meetings. I realize that doesn't really fall into the scope of agile \"architectures\", but if you don't have and agile process, no degree of \"agile-oriented\" architecture will matter. ","pontos":2},{"corpo":"There is probably some errors in your eventlog under the Application and System categories. Try to find the origin of these errors or post them here we'll see what we can do :) Edit : @Daniel Silveira A memory leak is probable. What COM+ object do you use? I had some issues with Excel with an application I support. ","pontos":1},{"corpo":"You have a memory leak :) This blog entry is my bible for IIS troubleshooting: http://blogs.msdn.com/david.wang/archive/2005/12/31/HOWTO_Basics_of_IIS6_Troubleshooting.aspx If you can't audit your code and find where the reference leaks are, an alternative is to recycle the application by restarting IIS every 24 hours or so. You can just setup a commandline script as a server job to do this. ","pontos":2},{"corpo":" That does not work, it still allows all users, (Authenticated or not) to access. I would think you could even omit the allow tag, as it's redundant. Just: deny users=\"?\"/ ","pontos":0},{"corpo":"This is something that I'm constantly unsatisfied with - our solution to this problem that is. For several years we maintained a separate change script for each release. This script would contain the deltas from the last production release. With each release of the application, the version number would increment, giving something like the following: dbChanges_1.sql dbChanges_2.sql ... dbChanges_n.sql This worked well enough until we started maintaining two lines of development: Trunk/Mainline for new development, and a maintenance branch for bug fixes, short term enhancements, etc. Inevitably, the need arose to make changes to the schema in the branch. At this point, we already had dbChanges_n+1.sql in the Trunk, so we ended up going with a scheme like the following: dbChanges_n.1.sql dbChanges_n.2.sql ... dbChanges_n.3.sql Again, this worked well enough, until we one day we looked up and saw 42 delta scripts in the mainline and 10 in the branch. ARGH! These days we simply maintain one delta script and let SVN version it - i.e. we overwrite the script with each release. And we shy away from making schema changes in branches. So, I'm not satisfied with this either. I really like the concept of migrations from Rails. I've become quite fascinated with LiquiBase. It supports the concept of incremental database refactorings. It's worth a look and I'll be looking at it in detail soon. Anybody have experience with it? I'd be very curious to hear about your results. ","pontos":2},{"corpo":"If you remove the float from the element below the table, does the margin appear? ","pontos":1},{"corpo":" AMQ depends on prototype which the error console in FireFox says object is not defined. Do you mean that AMQ depends on the Prototype library? I can't see an import for that library in the code you've provided. ","pontos":2},{"corpo":"I use Grokster or Bearshare ","pontos":0},{"corpo":"No. Instead you could use a in browser modal popup. ","pontos":2},{"corpo":"FormsAuthentication encrypts the tokens that it gives to the user, and by default it encrypts keys different for each application. To get Forms Auth to work across applications, there are a couple of things you need to do: Firstly, set the Forms Auth \"name\" the same on all Applications. This is done with: authentication mode=\"Forms\" forms name=\"{name}\" path=\"/\" ... /authentication Set the \"name\" to be the same in both applications web.configs. Secondly, you need to tell both applications to use the same key when encrypting. This is a bit confusing. When I was setting this up, all I had to do was add the following to both web.configs: machineKey validationKey=\"AutoGenerate\" decryptionKey=\"AutoGenerate\" validation=\"SHA1\" / According to the docs, thats the default value, but it didnt work for me unless I specified it. ","pontos":2},{"corpo":"I think about it in terms of cost/benefit... In MySQL, adding a constraint is a single additional line of DDL. It's just a handful of key words and a couple of seconds of thought. That's the only \"cost\" in my opinion... Tools love foreign keys. Foreign keys prevent bad data (that is, orphaned rows) that may not affect business logic or functionality and therefor go unnoticed, and build up. It also prevents developers who are unfamiliar with the schema from implementing entire chunks of work without realizing they're missing a relationship. Perhaps everything is great within the scope of your current application, but if you missed something and someday something unexpected is added (think fancy reporting), you might be in a spot where you have to manually clean up bad data that's been accumulating since the inception of the schema without a database enforced check. The little time it takes to codify what's already in your head when you're putting things together could save you or someone else a bunch of grief months or years down the road. The question: Are there any other uses for foreign keys? Am I missing something here? It is a bit loaded. Insert comments, indentation or variable naming in place of \"foreign keys\"... If you already understand the thing in question perfectly, it's \"no use\" to you. ","pontos":2},{"corpo":"Where does that code sit Jonathan? In my experience I have a login control and in the OnAuthenticate event I would set Authenticated to false... If CustomAuthenticate(Login1.UserName, Login1.Password) Then FormsAuthentication.RedirectFromLoginPage(Login1.UserName, False) Else e.Authenticated = False End If But that's using the Microsoft Way ","pontos":0},{"corpo":"In this case, if you don't call the base OnInit, then the Init even will not fire. In general, it is best practice to ALWAYS call the base method, unless you specifically know that you do not want the base behaviour to occur. Whether its called at the start or the end depends on how you want things to work. In a case like this, where you are using an override instead of hooking up an event handler, calling it at the start of the method makes more sense. That way, your code will run after any handlers, which makes it more emulate a \"normal\" event handler. ","pontos":0},{"corpo":"You might also need to put path=\"/\" in the forms tag(s) I think. Sorry, its been a while since i've done this ","pontos":1},{"corpo":"UML is useful, yes indeed! The main uses I've made of it were: Brainstorming about the ways a piece of software should work. It makes easy to communicate what you are thinking. Documenting the architecture of a system, it's patterns and the main relationships of its classes. It helps when someone enters your team, when you're leaving and want to make sure your successor will understand it, and when you eventually forget what the hell that little class was meant for. Documenting any architectural pattern you use on all your systems, for the same reasons of the dot above I only disagree with Michael when he says that using UML for a single developer and/or a simple software project seems overkill to him. I've used it on my small personal projects, and having them documented using UML saved me a lot of time when I came back to them seven months later and had completely forgotten how I had built and put together all those classes. ","pontos":1},{"corpo":"Yeah, the built-in will be much faster than any regex parsing, because it's built-in and compiled, instead of interpreted on the fly. Although the results are somewhat different to what you're looking for (try it): // IS NUMERIC document.write(!isNaN('-1') + \" br / \"); // true document.write(!isNaN('-1.5') + \" br / \"); // true document.write(!isNaN('0') + \" br / \"); // true document.write(!isNaN('0.42') + \" br / \"); // true document.write(!isNaN('.42') + \" br / \"); // true document.write(!isNaN('99,999') + \" br / \"); // false document.write(!isNaN('0x89f') + \" br / \"); // true document.write(!isNaN('#abcdef') + \" br / \"); // false document.write(!isNaN('1.2.3') + \" br / \"); // false document.write(!isNaN('') + \" br / \"); // true document.write(!isNaN('blah') + \" br / \"); // false ","pontos":24},{"corpo":"@Ch00k and @Scott I dunno - I like the OnEventName pattern myself. And yeah, I'm one of the people who are guilty of firing the event from that method. I think overriding the On* method and calling the base one is the way to go. Handling your own events seems wrong somehow. ","pontos":0},{"corpo":"I find it easier to read languages which use brackets for breaking up blocks of code. For example C/C++, C#, D, and Perl. The language which is in common use today, that I really find difficult to understand, is shell scripting. Plus the keyword you use to end a construct isn't always the mirror of the beginning keyword. I don't think anyone would use it if it wasn't already so widely used. READABLE: Perl if( $anything == 1 ){ # some code }elsif( $anything == 2 ){ # some code }else{ # some more code } UNREADABLE: Shell if [ $a == z* ] # File globbing and word splitting take place. then if [[ $a == z* ]] # True if $a starts with an \"z\" (regex pattern matching). then echo do-something # But only if both conditions are valid. fi fi I don't know about you, but I keep wanting to end the if block like this: if [ $Jack $Beanstalk ] then echo plant beanstalk fee fi fo fum Further Those people who automatically say Perl is a terrible language, generally assume that it is unreadable because they take one look at the Regex sub-language, and assume there is no possible way to rewrite it in a cleaner way. Which is completely wrong. The first thing you must learn is of the /x modifier, which allows whitespace embedded in the Regex to be used to separate out different parts of the Regex. So we can turn this: /^([+-]?)(\\d+\\.\\d+|\\d+\\.|\\.\\d+|\\d+)([eE][+-]?\\d+)?$/; into this: / ^ ([+-]?) # first, match an optional sign ( # then match integers or f.p. mantissas: \\d+\\.\\d+ # mantissa of the form a.b |\\d+\\. # mantissa of the form a. |\\.\\d+ # mantissa of the form .b |\\d+ # integer of the form a ) ([eE][+-]?\\d+)? # finally, optionally match an exponent $ /x; Which I might add (as far as I know) is not available in any other general purpose Regular Expression librarys, accessible within other languages. So in other words if you are using another language you are stuck with the first form, or you have to write significantly more code to achieve the same ends, which will be error prone. See here for more information. Actually Perl can be very powerful, imagine running arbitrary code, from within a Regex. Don't worry you're not allowed to use interpolation with this feature, by default. Also this feature, last I heard is experimental, although I would bet it will stay in the language in some form or another. I know for a fact, it is a feature of Perl 6. $x =~ /(?{print \"Hi Mom!\";})/; # matches, # prints 'Hi Mom!' Yet another useful feature: Named back-references ( copied directly from perldoc perlretut ) Perl 5.10 also introduced named capture buffers and named backreferences. To attach a name to a capturing group, you write either or . The backreference may then be written as . It is permissible to attach the same name to more than one group, but then only the leftmost one of the eponymous set can be referenced. Outside of the pattern a named capture buffer is accessible through the hash. Assuming that we have to match calendar dates which may be given in one of the three formats , or y, we can write three suitable patterns where we use , and respectively as the names of the buffers capturing the pertaining components of a date. The matching operation combines the three patterns as alternatives: $fmt1 = '(? year \\d\\d\\d\\d)-(? mon \\d\\d)-(? day \\d\\d)'; $fmt2 = '(? mon \\d\\d)/(? day \\d\\d)/(? year \\d\\d\\d\\d)'; $fmt3 = '(? day \\d\\d)\\.(? mon \\d\\d)\\.(? year \\d\\d\\d\\d)'; for my $d qw( 2006-10-21 15.01.2007 10/31/2005 ){ if ( $d =~ m{$fmt1|$fmt2|$fmt3} ){ print \"day=$+{day} month=$+{mon} year=$+{year}\\n\"; } } prints: day=21 month=10 year=2006 day=15 month=01 year=2007 day=31 month=10 year=2005 If any of the alternatives matches, the hash is bound to contain the three key-value pairs. Perl 6 If we take the number matching Regex from above and convert it to a Perl 6 Grammar, it becomes even easier to read. Perl 6 grammar Date { rule year{ \\d{4} } rule day{ \\d{1,2} } rule month{ \\d{1,2} } rule ymd{ year - month - day } rule mdy{ month / day / year } rule dmy{ day . month . year } rule match{ (ymd) | (mdy) | (dmy) } } Note: I probably have some mistakes in this last bit of code, due to the Perl 6 design changing, and because I also haven't written a lot of Perl 6 code yet. It is also a bit of a contrived example You would also need to change the for loop also. for [qw( 2006-10-21 15.01.2007 10/31/2005 )] - $d { if ( $d =~ Date.match ){ print \"day=$ day month=$ mon year=$ year \\n\"; } } prints: day=21 month=10 year=2006 day=15 month=01 year=2007 day=31 month=10 year=2005 ","pontos":74},{"corpo":"You could try Simple State Machine. You would have to implement access control and background timers yourself, but that shouldn't be a big deal. SSM was also built out of frustration with WF. There are some other state machine implementations on Codeplex as well. If one of them doesn't fit he bill out of the box, they are open source and should get you close enough. I wholeheartedly agree with you about state machines in WF - they aren't testable, are too complicated, the threading model is peculiar and hard to follow, and I'm not sure a visual designer could have been more poorly conceived for designing state machines graphically. I think this may be because the state machine concept feels tacked onto the WF runtime, which was designed for sequential state machines, something WF does a much better job with, in my opinion. The problem is that state machines are really not the same animal as a sequential work flow, and should have been given a first class implementation of their own, because the warping of WF to make it seem to support them turned out to be more or less unsupportable, if not actually unusable. ","pontos":13},{"corpo":" Is there a way to make sure both scripts load before I use them in my application.js? JavaScript files should load sequentially and block so unless the scripts you are depending on are doing something unusual all you should need to do is load application.js after the other files. Non-blocking JavaScript Downloads has some information about how scripts load (and discusses some techniques to subvert the blocking). ","pontos":25},{"corpo":"I use quite archaic design that just works. /Test_app.config /Prod_app.config /app.config Then in my nant script, I have a task that copies, the current build environment plus _ app.config and copy it to app.config. Its nasty, but you can't get in between providers and ConfigurationManager to spoof it, by saying providers look at \"dev\" or \"prod\" connection string and just have 3 named connection strings. nant task: target name=\"copyconfigs\" depends=\"clean\" foreach item=\"File\" property=\"filename\" unless=\"${string::get-length(ConfigPrefix) == 0}\" in items include name=\"**/${ConfigPrefix}App.config\" / include name=\"**/${ConfigPrefix}connectionstrings.config\" / include name=\"**/${ConfigPrefix}web.config\" / /items /in do copy overwrite=\"true\" file=\"${filename}\" tofile=\"${string::replace(filename, ConfigPrefix,'')}\" / /do /foreach /target ","pontos":0},{"corpo":"The only way to know for sure would be to dig through the Cassini source and see if there are any areas where it generates code on the heap and then executes it without clearing the NX flag. However, instead of doing that, why not use IIS? EDIT: The danger of disabling DEP is that you open up security holes. DEP works by not allowing arbitrary generated code on the heap to be executed. This helps prevent malware programs from inserting code into the data segments of legit programs. ","pontos":3},{"corpo":"You are on vista, iis got better (7), cassini stayed crappy. So just start this app on iis with a host header and a hosts file entry. ","pontos":2},{"corpo":"It looks like it cannot be done without some kind of tool. It's not really to do with windows, but with the ttf format. The style properties are built into the font file, and I don't think it's possible to tell windows to ignore them (if that's what you were asking for). As for modifying the font, it looks like it's either FontForge or a hex-editor. I am looking into this one, and if/when I figure it out, I'll post instructions. So far I've only managed to create a horribly broken version of Consolas :P ","pontos":1},{"corpo":" Can the \"file\" method suggested by @Jonathon be somehow used with the connectionStrings section? No, but there is nothing stopping you from storing the ConnectionString as an AppSettings key. ","pontos":0},{"corpo":"There are a couple of libraries out there which can help you. Unfortunately I haven't tried them myself, because I've never run into such a situation. Retroweaver Retrotransaltor backport-jsr166 ","pontos":4},{"corpo":"Sounds like dodgy COM objects causing the problem .. do you load them into the \"Application\", if you do then are they threadsafe; or are they used and discarded on each request? Yes, recycling every few hours would help 'hide' the problem, but they ought to be debugged and fixed properly ... have you tried divide/conquer to discover which COM object is the problem ... I can imagine this is tricky on a production environment so you need to set up some heavy automated tests to reproduce the problem locally then you can do something about it. ","pontos":2},{"corpo":"They are not adding a real GOTO, but extending the BREAK keyword to use static labels. Basically, it will be enhancing the ability to break out of switch nested if statements. Here's the concept example I found: ?php for ($i = 0; $i 9; $i++) { if (true) { break blah; } echo \"not shown\"; blah: echo \"iteration $i\\n\"; } ? Of course, once the GOTO \"rumor\" was out, there was nothing to stop some evil guys to propagate an additional COMEFROM joke. Be on your toes. See also: http://www.php.net/~derick/meeting-notes.html#adding-goto ","pontos":8},{"corpo":"@steveth45 My rule of thumb is that if you have nested code more than 3 levels deep, you are doing something wrong. Then you don't have to worry about using multiple break statements or goto :D ","pontos":0},{"corpo":" SELECT * FROM table ORDER BY RAND() LIMIT 1 ","pontos":1},{"corpo":"Solutions like Jeremies: SELECT * FROM table ORDER BY RAND() LIMIT 1 work, but they need a sequential scan of all the table (because the random value associated with each row needs to be calculated - so that the smallest one can be determined), which can be quite slow for even medium sized tables. My recommendation would be to use some kind of indexed numeric column (many tables have these as their primary keys), and then write something like: SELECT * FROM table WHERE num_value = RAND() * ( SELECT MAX (num_value ) FROM table ) ORDER BY num_value LIMIT 1 This works in logarithmic time, regardless of the table size, if is indexed. One caveat: this assumes that is equally distributed in the range . If your dataset strongly deviates from this assumption, you will get skewed results (some rows will appear more often than others). ","pontos":146},{"corpo":"You can grant certain programs exclusion from DEP if you need. As Jonathan mentions this does open up any vulnerabilities that application may have. ","pontos":1},{"corpo":"I think I know the Java language very well. I work with it every day. I have 2 Sun certifications - one is directly related to language syntax, the other is about threads issues and how the heap is managed. And I always have the Java 1.6 javadoc page open. Sadly, Java is the only language I know well, follow far behind by PL/SQL. ","pontos":-1},{"corpo":"You can access all of the keys: gridView.DataKeys[rowNum][dataKeyName] where rowNum is e.RowIndex from the gridView_RowDeleting event handler, and dataKeyName is the key you want to get: asp:GridView ID=\"gridView\" runat=\"server\" DataKeyNames=\"userid, id1, id2, id3\" OnRowDeleting=\"gridView_RowDeleting\" protected void gridView_RowDeleting(object sender, GridViewDeleteEventArgs e) { gridView.DataKeys[e.RowIndex][\"userid\"]... gridView.DataKeys[e.RowIndex][\"id1\"]... gridView.DataKeys[e.RowIndex][\"id2\"]... gridView.DataKeys[e.RowIndex][\"id3\"]... } ","pontos":1},{"corpo":"You can't trust what any called procedure does to any of the registers. Either push the registers onto the stack and pop them back off after calling printf or have the increment and end point values held in memory and read/written into registers as you need them. I hope the following works. I'm assuming that pushl has an equivalant popl and you can push an extra couple of numbers onto the stack. # count.s: print the numbers from 0 to 100. .text string: .asciz \"%d\\n\" .globl _main _main: movl $0, %eax # The starting point/current value. movl $100, %ebx # The ending point. _loop: # Remember your registers. pushl %eax pushl %ebx # Display the current value. pushl %eax pushl $string call _printf addl $8, %esp # reinstate registers. popl %ebx popl %eax # Check against the ending value. cmpl %eax, %ebx je _end # Increment the current value. incl %eax jmp _loop _end: ","pontos":11},{"corpo":"You can have deterministic object destruction in c++ You never want to call GC.Collect, it messes with the self tuning of the garbage collector to detect memory pressure and in some cases do nothing other than increase the current generation of every object on the heap. For those posting IDisposable answers. Calling a Dispose method doesn't destroy an object as the asker describes. ","pontos":0},{"corpo":"Just about every language has bindings to C, so you'll probably want to get the applicable C libraries for encoding/decoding mp3's and FLAC files. This list might include libFLAC http://flac.sourceforge.net/api/index.html FLAC encoding/decoding LAME http://lame.sourceforge.net/index.php MP3 encoding MAD http://www.underbit.com/products/mad/ MP3 decoding The rest of your signal processing needs could be gathered around a single popular API such as LADSPA http://www.ladspa.org/. Here's a stretching / pitch shifting library: http://www.breakfastquay.com/rubberband/ Most audio processing programs have a certain internal format they use. That keeps things simple. Everything coming in gets converted to the same format. Once you've standardized the internal format, cutting and splicing audio data is about as difficult as cutting and splicing strings. You don't really need a library for that. ","pontos":5},{"corpo":"As far as I know, there's no way to tell from the header. There's a DDPF_ALPHAPIXELS flag, but I don't think that will get set based on what's in the pixel data. You'd need to parse the DXT1 blocks, and look for colours that have 0 alpha in them (making sure to check that the colour is actually used in the block, too, I suppose). ","pontos":1},{"corpo":"Foreign keys had never been explicit (FOREIGN KEY REFERENCES table(column)) declared in projects (business applications and social networking websites) which I worked on. But there always was a kind of convention of naming columns which were foreign keys. It's like with database normalization -- you have to know what are you doing and what are consequence of that (mainly performance). I am aware of advantages of foreign keys (data integrity, index for foreign key column, tools aware of database schema), but also I am afraid of using foreign keys as general rule. Also various database engines could serve foreign keys in a different way, which could lead to subtle bugs during migration. Removing all orders and invoices of deleted client with ON DELETE CASCADE is the perfect example of nice looking, but wrong designed, database schema. ","pontos":0},{"corpo":"Oh, sorry, I missed it. AFAIK there is no such a possibility by default. Maybe you can create a composite key from your primary keys, like Key1UnderscoreKey2UnderscoreKey3 and split it in the event handler. So this is a DIY multi-key handler for DataList :-) Edit: The underscore got lost during format, it replaces with italic text. So instead of \"underscore\" word use real underscores ","pontos":0},{"corpo":"This page shows how to do it a little more automated. ","pontos":0},{"corpo":"If you want to use the merge-tracking of Subversion 1.5 over more than one project at the same time you should use a single tree without externals. A tracked merge is (just like a commit) always over a directory and its children. The same rule applies on atomic commits. (Works only stable within a single workingcopy. It might work in some specific other cases but that behavior is not guaranteed) ","pontos":0},{"corpo":"That would sure be nice to have the compiler check that rather than through an expression. :/ Don't see any way to do that though... ","pontos":0},{"corpo":"I'd suggest that modifying the underlying XML file is \"considered harmful\". Especially if you haven't checked to see if the document is open! I've had a quick look at the Scripting Dictionary for Pages, and it seems pretty comprehensive; here is part of one entry: documentn [inh. document > item; see also Standard Suite] : A Pages document. elements contains captured pages, character styles, charts, graphics, images, lines, list styles, pages, paragraph styles, sections, shapes, tables, text boxes. properties body text (text) : The main text flow of the document. bottom margin (real) : The bottom margin of the publication. facing pages (boolean) : Whether or not the view is set to facing pages. footer margin (real) : The footer margin of the publication. header margin (real) : The header margin of the publication. id (integer, r/o) : The unique identifier of the document. ... So, I guess I'd want to know what it is that you want to do that you can't do with AppleScript? ","pontos":1},{"corpo":"Using Status as a return value remembers me of the \"old days\" of C programming, when you returned an integer below 0 if something didn't work. Wouldn't it be better if you throw an exception when (as you put it) something went wrong? If some \"lazy code\" doesn't catch your exception, you'll know for sure. ","pontos":1},{"corpo":"Unless I'm missing something, what's wrong with using reCAPTCHA as all the work is done externally. Just a thought. ","pontos":57},{"corpo":"Even System.Net.WebRequest throws an exception when the returned HTTP status code is an error code. The typical way to handle it is to wrap a try/catch around it. You can still ignore the status code in the catch block. You could, however, have a parameter of Action Status> so that the caller is forced to pass a callback function that accepts a status and then checking to see if they called it. void MyFunction(Action Status callback) { bool errorHappened = false; if (somethingBadHappend) errorHappened = true; Status status = (errorHappend) ? new Status(false, \"Something went wrong\") : new Status(true, \"OK\"); callback(status) if (!status.isOkWasCalled) throw new Exception(\"Please call IsOK() on Status\"). } MyFunction(status = if (!status.IsOK()) onerror()); If you're worried about them calling IsOK() without doing anything, use Expression Func Status,bool>> instead and then you can analyse the lambda to see what they do with the status: void MyFunction(Expression Func Status,bool callback) { if (!visitCallbackExpressionTreeAndCheckForIsOKHandlingPattern(callback)) throw new Exception (\"Please handle any error statuses in your callback\"); bool errorHappened = false; if (somethingBadHappend) errorHappened = true; Status status = (errorHappend) ? new Status(false, \"Something went wrong\") : new Status(true, \"OK\"); callback.Compile()(status); } MyFunction(status = status.IsOK() ? true : onerror()); Or forego the status class altogether and make them pass in one delegate for success and another one for an error: void MyFunction(Action success, Action error) { if (somethingBadHappened) error(); else success(); } MyFunction(()= ;,()= handleError()); ","pontos":3},{"corpo":"If you really want to require the user to retrieve the result of MyFunction, you might want to void it instead and use an out or ref variable, e.g., void MyFunction(out Status status) { } It might look ugly but at least it ensures that a variable is passed into the function that will pick up the result you need it to pick up. @Ian, The problem with exceptions is that if it's something that happens a little too often, you might be spending too much system resources for the exception. An exception really should be used for exceptional errors, not totally expected messages. ","pontos":7},{"corpo":"The HTTP_HOST only contains the host name, not the path of the URL requested. RewriteCond %{REQUEST_URI} !^/audio Should be all you need. Further, you can get debug info from the rewrite engine with the following, which is really useful to see how your conditions and rules are being matched: RewriteLog /path/to/log/file RewriteLogLevel 3 ","pontos":30},{"corpo":"I'm unclear as to what your actual problem is, so I'll throw out a few thoughts. Do you want restartable copies (with such small file sizes, that doesn't seem like it'd be that big of a deal)? If so, look at CopyFileEx with COPYFILERESTARTABLE Do you want verifiable copies? Sounds like you already have that by verifying hashes. Do you want better performance? It's going to be tough, as it sounds like you can't run anything on the server. Otherwise, TransmitFile may help. Do you just want a fire and forget operation? I suppose shelling out to robocopy, or TeraCopy or something would work - but it seems a bit hacky to me. Do you want to know when the network comes back? IsNetworkAlive has your answer. Based on what I know so far, I think the following pseudo-code would be my approach: sourceFile = Compress(\"*.*\"); destFile = \"X:\\files.zip\"; int copyFlags = COPYFILEFAILIFEXISTS | COPYFILERESTARTABLE; while (CopyFileEx(sourceFile, destFile, null, null, false, copyFlags) == 0) { do { // optionally, increment a failed counter to break out at some point Sleep(1000); while (!IsNetworkAlive(NETWORKALIVELAN)); } Compressing the files first saves you the tracking of which files you've successfully copied, and which you need to restart. It should also make the copy go faster (smaller total file size, and larger single file size), at the expense of some CPU power on both sides. A simple batch file can decompress it on the server side. ","pontos":5},{"corpo":"Your question is very confusing... If you want to find types that implement IStep, then do this: foreach (Type t in Assembly.GetCallingAssembly().GetTypes()) { if (!typeof(IStep).IsAssignableFrom(t)) continue; Console.WriteLine(t.FullName + \" implements \" + typeof(IStep).FullName); } If you know already the name of the required type, just do this IStep step = (IStep)Activator.CreateInstance(Type.GetType(\"MyNamespace.MyType\")); ","pontos":8},{"corpo":"If the mandate of the new lead is to put the house in order, the current situation should likely be simplified as much as possible prior. If I had to bring things to order, I wouldn't want to have to manage an ongoing language conversion project on top of everything else, or at least I'd like some choice when initiating the project. When making your recommendation, did you think about the additional managerial complexity that coming into the middle of a conversion would entail? ","pontos":4},{"corpo":"I'm not entirely sure what you're asking, but i'll give it a shot. Visual C++ is a pure C/C++ compiler so has none of .NET's memory management, nor any of its runtime -- You have to manually call new and delete. .NET also provides C++/CLI, which is a slightly modified version of C++ that targets the .NET runtime, and is GC aware -- eg. its memory is managed by the .NET runtime. Without more details about your bug I can't really make any suggestions, beyond suggesting that you make sure you use the appropriate GC guards, and the provide finalizers in any place they are needed. ","pontos":0},{"corpo":"We use virtualisation for testing out applications on Vista. Or rather customers do the testing and we use virtualisation to reproduce the bugs they complain about. I guess the thing that would stop me from using lots of virtual instances of my favourite proprietary OS would be licencing. I presume Microsoft would want me to have a licence for every installation, virtual or otherwise? ","pontos":0},{"corpo":"You could use but you should run benchmarks if you think it is slow. ","pontos":1},{"corpo":"As long as all three of these things are true, you're out of luck: Server needs web access Users need absolute control over server (root) You don't want users to have server's web access If you can't remove #2 or #3, your only choice is to remove #1. Set up an internal server that hosts all the software updates. Keep that one locked down from your other users and don't allow other servers to have web access. Anything else you try to do is just fooling yourself. ","pontos":0},{"corpo":"I've got myself into a horrible mess with COM before. I had to pick my way though the registry deleting each reference, unfortunately. ","pontos":0},{"corpo":"Your object's GUID's should not be changing. In other words, once you register the COM object, re-registering shouldn't be adding anything additional to the registry. Unless you added additional COM interfaces or objects to the project. In any case, if this is a one time deal (and it sounds like it is), open regedit and delete the unneeded keys manually. ","pontos":9},{"corpo":"I know it's not helpful, so I'll probably get downvoted for this, but really, the solution is to fix the firewall problem. I think if you use remote (not linked) servers (which are not the preferred option these days) then you can use SET REMOTEPROCTRANSACTIONS OFF to prevent the use of DTC for remote transactions, which might do the right thing here. But that probably doesn't help you with a linked server anyway. ","pontos":2},{"corpo":"Use a profiler. Yes they cost money, and using them can occasionally be a bit awkward, but they do provide you with a great deal more real evidence rather than guesswork. Human beings are universally bad at guessing where performance bottlenecks are. It just seems to be something our brains aren't build to do very well. It may seem obvious, you may have great ideas about what the problem is, but the real world often turns out to be doing something different. And optimising the wrong part of code means, at best, lots of work for minimal benefit. More often it makes things slower, and sometimes it breaks things entirely. So before you make any changes for the sake of optimisation, you should always have real evidence from a profiler or other accurate tool. As mentioned, both JProfiler and YourKit are both fairly good and not prohibitively expensive. Last time I looked, they both had free demos too. ","pontos":1},{"corpo":"We use both methods at my work, but slightly different, we keep all sales data in the primary table for 30 days, then at night (part of the nightly jobs) the days sales are rolled up into summaries (n qty of x product sold today ect) in a separate table for reporting reasons, and sales over 30 days are archived into a different database, then once a year (we go on tax years) a new archive database is started. not exactly perfect but.. this way we get the summaries data fast, keep all current sales data at hand and have an unlimited space for the detailed archive data. we did try keeping it all in one database (in different tables) but the file size of the database (interbase) would grow so large that it would drag the system down. the only real problem we have is accessing detailed data that spans several database, as connecting and disconnecting is slow, and analysis has to be done in code rather than sql ","pontos":3},{"corpo":"Check out Drip. That usually takes the guesswork out of IE memory leaks. If for some reason Drip doesn't find it, take a close look at any JavaScript code that works with events. That is almost always the source of any significant memory leak in a browser. Destroying a DOM element with handlers attached to it, without removing those handlers first, will prevent the memory associated with those handlers from being recovered. ","pontos":7},{"corpo":"Can you give some more details about this \"huge web app\"? Are you using AJAX? Any javascript frameworks? Maybe the site is live and you can give us an URL? Do you have the same issues with users running IE7? Here are some general links talking about varius memory leak problems in IE6: - Link 1 (ie6memoryleak_fix) - Link 2 (is-finally-the-answer-to-all-ie6-memory-leak-issues) - Link 3 (javascript-memory-leak-detector) ","pontos":0},{"corpo":"Does the application use a lot of JavaScript? If it does, then one thing I've found that helps for avoiding memory leaks is to make sure you're using a JavaScript framework such as Prototype or jQuery because they have tried and tested event-handling code that doesn't leak memory. IE6 can also leak memory if you have circular references to DOM objects Also try this JavaScript Memory Leak Detector and see if you can diagnose where the problem is ","pontos":1},{"corpo":"I'd probably be looking to use a JTable rather than a JList and since the default rendering of a checkbox is rather ugly, I'd probably be looking to drop in a custom TableModel, CellRenderer and CellEditor to represent a boolean value. Of course, I would imagine this has been done a bajillion times already. Sun has good examples. ","pontos":10},{"corpo":"You're leaking memory from Java functions? Here's a solution: Take your homebrew java and chuck it. Use one of the standard javascript frameworks, such as jQuery. If you're doing complex javascript and aren't a java guru, don't do it yourself. Edit: What, is that bad advice? Javascript isn't just a simple scripting language; its a complex and surprisingly powerful programming language that is closely linked to the HTML DOM, which is implemented differently in different browsers. If you do it wrong, you will not only leak memory but also throw errors everywhere and generally make the browsing experience awful. Do you want to drive away the people coming to your website? No? Then use a javascript framework and get rid of all your hacky cross-browser bullshittery. ","pontos":-2},{"corpo":"TortoiseSVN can search the logs very easily, and on my system I can enter \".plg\" in the search box and find all adds, modifies, and deletes for those files. Without Tortoise, the only way I can think of doing that would be to grep the full logs or parse the logs and do your own searching for 'A' and 'D' indicators on the file you are looking for (use to get file paths). svn log --verbose | grep .bat ","pontos":21},{"corpo":"I am fairly certain you can't get the effect you want as a return value from a method. C# just can't do some of the things C++ can. However, a somewhat ugly way to get a similar effect is the following: using System; public class Example { public class Toy { private bool inCupboard = false; public void Play() { Console.WriteLine(\"Playing.\"); } public void PutAway() { inCupboard = true; } public bool IsInCupboard { get { return inCupboard; } } } public delegate void ToyUseCallback(Toy toy); public class Parent { public static void RequestToy(ToyUseCallback callback) { Toy toy = new Toy(); callback(toy); if (!toy.IsInCupboard) { throw new Exception(\"You didn't put your toy in the cupboard!\"); } } } public class Child { public static void Play() { Parent.RequestToy(delegate(Toy toy) { toy.Play(); // Oops! Forgot to put the toy away! }); } } public static void Main() { Child.Play(); Console.ReadLine(); } } In the very simple example, you get an instance of Toy by calling Parent.RequestToy, and passing it a delegate. Instead of returning the toy, the method immediately calls the delegate with the toy, which must call PutAway before it returns, or the RequestToy method will throw an exception. I make no claims as to the wisdom of using this technique -- indeed in all \"something went wrong\" examples an exception is almost certainly a better bet -- but I think it comes about as close as you can get to your original request. ","pontos":2},{"corpo":"I would not do this for a couple of reasons. Design: A GUI and a CLI are two different interfaces used to access an underlying implementation. They are generally used for different purposes (GUI is for a live user, CLI is usually accessed by scripting) and can often have different requirements. Coupling the two together is not a wise choice and is bound to cause you trouble down the road. Performance: The way you've described things, you need to spawn an executable every time the GUI needs to d o something. This is just plain ugly. The right way to do this is to put the implementation in a library that's called by both the CLI and the GUI. ","pontos":1},{"corpo":"Just use the mssql_connect() function like this: $conn = mssql_connect('localhost', 'sa' , '123456') or die('Can\\'t connect.'); mssql_select_db('database', $conn) or die('Can\\'t select the database'); Functions relating to SQL Server are defined in the PHP manual for the MSSQL driver. One question though, \"all the query work is done on the client side\" WTF? :D ","pontos":2},{"corpo":"The problem is that TryParse isn't defined on an interface or base class anywhere, so you can't make an assumption that the type passed into your class will have that function. Unless you can contrain T in some way, you'll run into this a lot. Constraints on Type Parameters ","pontos":5},{"corpo":"You probably cant do it. First of all if it should be possible you would need a tighter bound on T so the typechecker could be sure that all possible substitutions for T actually had a static method called TryParse. ","pontos":0},{"corpo":"That is not how statics work. You have to think of statics as sort of in a Global class even if they are are spread across a whole bunch of types. My recommendation is to make it a property inside the T instance that can access the necessary static method. Also T is an actual instance of something, and just like any other instance you are not able to access the statics for that type, through the instantiated value. Here is an example of what to do: class a { static StaticMethod1 () virtual Method1 () } class b : a { override Method1 () return StaticMethod1() } class c : a { override Method1 () return \"XYZ\" } class generic T where T : a { void DoSomething () T.Method1() } ","pontos":-1},{"corpo":"You may want to read my previous post on limiting generic types to primitives. This may give you some pointers in limiting the type that can be passed to the generic (since TypeParse is obviously only available to a set number of primitives ( string.TryParse obviously being the exception, which doesn't make sense). Once you have more of a handle on the type, you can then work on trying to parse it. You may need a bit of an ugly switch in there (to call the correct TryParse ) but I think you can achieve the desired functionality. If you need me to explain any of the above further, then please ask :) ","pontos":0},{"corpo":"Do you mean to do something like this: Class test T { T method1(object Parameter1){ if( Parameter1 is T ) { T value = (T) Parameter1; //do something with value return value; } else { //Parameter1 is not a T return default(T); //or throw exception } } } Unfortunately you can't check for the TryParse pattern as it is static - which unfortunately means that it isn't particularly well suited to generics. ","pontos":1},{"corpo":"Without any error handling code: File.Copy(path, path2); ","pontos":10},{"corpo":"Just use a route: // We couldn't find a route to handle the request. Show the 404 page. routes.MapRoute(\"Error\", \"{*url}\", new { controller = \"Error\", action = \"404\" } ); Since this will be a global handler, put it all the way at the bottom under the Default route. ","pontos":12},{"corpo":"where T : IConvertible I think... ","pontos":0},{"corpo":"You should find your answer in the Java language specification. You have forgot static method call, method call inside parameters... ","pontos":0},{"corpo":"This is common behaviour for a lot of component hosted in an executable binary. The host application will startup and then do the job. I don't know if there is a surefire way to prevent that since you have no control over the component nor over the process until the application is started and is responding. A hack I tried in the past (for something totally unrelated) was starting a process and constantly detecting if its main windows was created. As soon as it was created, I was hiding it. You could do this with the main module of the faulty application and hope it will be fast enough to hide the window before the user notices. Then you instanciate your component; the component will usually recycle an existing process, hopefuly the one with the hidden main window. I can't garentee you this will work in your situation, but it's worth a try it the issue is that important, or if you don't find a better way of course. ","pontos":1},{"corpo":"I don't really know javascript, but couldn't you create a stack of windows? ","pontos":1},{"corpo":"Does M include calls to its own methods? Or calls to inner classes? For instance: class J { a() { } b() { this.a(); } c() { jj.aa(); } d() { i.k(); } e() { this.f().a(); } f() { return this; } g() { i.m().n(); } class JJ { aa() { a(); } } } What would the M value of this be? There's only three function calls to a method not defined in this class (the calls in the d() and g() functions). Do you want to include calls to inner classes, or calls to the main class made in the inner class? Do you want to include calls to other methods on the same class? If you're looking at any method calls, regardless of the source, then a regex could probably work, but would be tricky to get right (does your regex properly ignore strings that contain method-call like contents? Does it handle constructor calls properly?). If you care about the source of the method call then regexes probably won't get you what you want. You'd need to use reflection (though unfortunately I don't know enough about reflection to be helpful there). ","pontos":0},{"corpo":"Short answer, you can't. Long answer, you can cheat: public class Example { internal static class Support { private delegate bool GenericParser T (string s, out T o); private static Dictionary Type, object parsers = MakeStandardParsers(); private static Dictionary Type, object MakeStandardParsers() { Dictionary Type, object d = new Dictionary Type, object (); // You need to add an entry for every type you want to cope with. d[typeof(int)] = new GenericParser int (int.TryParse); d[typeof(long)] = new GenericParser long (long.TryParse); d[typeof(float)] = new GenericParser float (float.TryParse); return d; } public static bool TryParse T (string s, out T result) { return ((GenericParser T )parsers[typeof(T)])(s, out result); } } public class Test T { public static T method1(string s) { T value; bool success = Support.TryParse(s, out value); return value; } } public static void Main() { Console.WriteLine(Test int .method1(\"23\")); Console.WriteLine(Test float .method1(\"23.4\")); Console.WriteLine(Test long .method1(\"99999999999999\")); Console.ReadLine(); } } I made a static dictionary holding a delegate for the TryParse method of every type I might want to use. I then wrote a generic method to look up the dictionary and pass on the call to the appropriate delegate. Since every delegate has a different type, I just store them as object references and cast them back to the appropriate generic type when I retrieve them. Note that for the sake of a simple example I have omitted error checking, such as to check whether we have an entry in the dictionary for the given type. ","pontos":3},{"corpo":"I am not sure there is. To make it conceptually simpler for the application I guess you could implement a transport layer on top of the polling requests, and thus removing the polling responsibility from your application logic. Maybe someone even already implemented this? Edit: Apparently it's called reverse Ajax and Comet, but so far it looks like you have to implement it yourself. A JavaScript library for this, anyone? ","pontos":0},{"corpo":"Once a connection is opened to the server it can be kept open and the server can Push content a long while ago I did with using but this didn't work in IE. I think you can do clever stuff with polling that makes it work more like push by not sending content unchanged headers but leaving the connection open but I've never done this. ","pontos":0},{"corpo":"There are other methods. Not sure if they are \"better\" in your situation. You could have a Java applet that connects to the server on page load and waits for stuff to be sent by the server. It would be a quite a bit slower on start-up, but would allow the browser to receive data from the server on an infrequent basis, without polling. ","pontos":1},{"corpo":"It's a long shot but there's an ODBC adapter for ActiveRecord that might work. ","pontos":3},{"corpo":"How old? Lots of us stared with BASIC at some point, but before then, I learned the concepts of stringing commands together, variables, and looping with LOGO. Figuring out how to draw a circle with a triangle that can only go in a straight line and turn was my very first programming accomplishment. Edit: This question its answers make me feel old. ","pontos":3},{"corpo":"I don't know if a database is necessarily what you want. That may be overkill for storing stats for a simple game like that. Databases are good; but you should not automatically use one in every situation (I'm assuming that this is a client application, not an online game). Personally, for a game that exists only on the user's computer, I would just store the stats in a file (XML or binary - choice depends on whether you want it to be human-readable or not). ","pontos":3},{"corpo":"I would have to agree with Greg so long as setting the isolation level to read uncommitted doesn't have any ill effects on other queries. I'd be interested to know, Jeff, how setting it at the database level would affect a query such as the following: Begin Tran Insert into Table (Columns) Values (Values) Select Max(ID) From Table Commit Tran ","pontos":0},{"corpo":"Are you instantiating a new LINQ to SQL DataContext object for every operation or are you perhaps sharing the same static context for all your calls? I originally tried the latter approach, and from what I remember, it caused unwanted locking in the DB. I now create a new context for every atomic operation. ","pontos":14},{"corpo":"Go to Tools > Options > Advanced \"Tab\"(?) > Encryption Tab Click the \"Validation\" button, and uncheck the checkbox for checking validity Be advised though that this is pretty unsecure as it leaves you wide open to accept any invalid certificate. I'd only do this if using the browser on an Intranet where the validity of the cert isn't a concern to you, or you aren't concerned in general. ","pontos":14},{"corpo":"The number one rule is do NOT just ask for status updates. It is Especially annoying when phrases like \"where are we on this?\" are used. If you aren't directly involved in the details then just make sure you have established communication times or plans so that you know whats going on rather than asking for updates. ","pontos":3},{"corpo":"As long as your styles are loaded after the reset ones they should work. What browser is this? because I work in a similar way myself and I've not hit this problem I wonder if it's something in my testing at fault. ","pontos":2},{"corpo":"Optimising bytecode is probably an oxymoron in most cases. Unless you control the VM, you have no idea what it does to speed up code execution, if anything. The compiler would need to know the details of the VM in order to generate optimised code. ","pontos":0},{"corpo":"A better workaround (depending on the size of the datasource) is to declare two objects (new as of 2.00) bind the collection to those and then bind those to the comboboxes. I enclose a complete example. using System; using System.Collections.Generic; using System.ComponentModel; using System.Data; using System.Drawing; using System.Text; using System.Windows.Forms; namespace WindowsFormsApplication2 { public partial class Form1 : Form { private BindingSource source1 = new BindingSource(); private BindingSource source2 = new BindingSource(); public Form1() { InitializeComponent(); Load += new EventHandler(Form1Load); } void Form1Load(object sender, EventArgs e) { List string myitems = new List string { \"Item 1\", \"Item 2\", \"Item 3\" }; ComboBox box = new ComboBox(); box.Bounds = new Rectangle(10, 10, 100, 50); source1.DataSource = myitems; box.DataSource = source1; ComboBox box2 = new ComboBox(); box2.Bounds = new Rectangle(10, 80, 100, 50); source2.DataSource = myitems; box2.DataSource = source2; Controls.Add(box); Controls.Add(box2); } } } If you want to confuse yourself even more then try always declaring bindings in the constructor. That can result in some really curious bugs, hence I always bind in the Load event. ","pontos":13},{"corpo":"It's fine with me if my profile is even several minutes out of date. Are you re-trying the read after it fails? It's certainly possible when firing a ton of random reads that a few will hit when they can't read. Most of the applications that I work with are very few writes compared to the number of reads and I'm sure the reads are no where near the number you are getting. If implementing \"READ UNCOMMITTED\" doesn't solve your problem, then it's tough to help without knowing a lot more about the processing. There may be some other tuning option that would help this behavior. Unless some MSSQL guru comes to the rescue, I recommend submitting the problem to the vendor. ","pontos":0},{"corpo":" Optimising bytecode is probably an oxymoron in most cases I don't think that's true. Optimizations like hoisting loop invariants and propagating constants can never hurt, even if the JVM is smart enough to do them on its own, by simple virtue of making the code do less work. ","pontos":3},{"corpo":"Path.GetTempFileName and Path.GetTempPath. Then you can use this link to read/write encrypted data to the file. Note, .NET isn't the best platform for critical security apps. You have to be well versed in how the CLR works in order to avoid some of the pitfalls that might expose your critical data to hackers. Edit: About the race condition... You could use GetTempPath, then create a temporary filename by using Path.Combine(Path.GetTempPath(), Path.ChangeExtension(Guid.NewGuid().ToString(), \".TMP\")) ","pontos":6},{"corpo":"I had a similar problem when I added the YUI Reset to the top of my stock CSS file. I found that the best thing for me was to simply remove all of the font-weight: normal; declarations from the YUI Reset. I haven't noticed that this has affected anything \"cross-browser.\" All my declarations were after the YUI Reset so I'm not sure why they weren't taking affect. ","pontos":3},{"corpo":"I would go with what I wish I had known first: a simple MS-DOS box and the integrated assembler (debug). It is great to really learn and understand the basics of talking to a computer. If that does not scare away a child, then I would go the \"next level up\" and introduce C. This shouldn't be hard given that the basic concept of pointers, registers and instructions in general are well-understood by then. However, I am not entirely sure, where to go next. Take the big jump to Lisp, Haskell or similarly abstracted languages or should there be some simple object oriented languages (maybe even C++) be thrown in or would that more hurt than help? ","pontos":1},{"corpo":"There are some wierd things in Access that might cause issues and I don't know if ODBC takes care of it. If it does @John Topley is right, ODBC would be your only cance. True in access = -1 not 1 Access treats dates differently than regular TSQL. You might run into trouble creating relations. If you go with access, will probably learn more about debuging AcriveRecord then you ever cared to ( which might not be a bad thing) ","pontos":1},{"corpo":"Reset stylesheets are best used as a base. If you don't want to reset em or strong, remove them from the stylesheet. ","pontos":2},{"corpo":"Unless the specific tools you are using allow an obfuscated format, or you can create some sort of workflow to go from obfuscated to plain on demand, you are probably out of luck. One thing I've seen in cases like this is creating per-server, per-user, or per-server/per-user dedicated credentials that only have access to the proxy from a specific IP. It doesn't solve your core obfuscation problem but it mitigates the effects of someone seeing the password because it's worth so little. Regarding the latter option, we came up with a \"reverse crypt\" password encoding at work that we use for stuff like this. It's only obfuscation because all the data needed to decode the pw is stored in the encoded string, but it prevents people from accidentally seeing passwords in plain text. So you might, for instance, store one of the above passwords in this format, and then write a wrapper for apt that builds apt.conf dynamically, calls the real apt, and at exit deletes apt.conf. You still end up with the pw in plaintext for a little while, but it minimizes the window. ","pontos":1},{"corpo":"No, I don't think we can do that. ","pontos":1},{"corpo":"I think this is down to the debug information that can be included with the compiled assemblies..(although I could definately be wrong) ","pontos":0},{"corpo":"As Chris said, you don't have to use the exact CSS they provide religiously. I would just save a copy to your server, and edit to your needs. ","pontos":2},{"corpo":"I believe the information that maps the source to the MSIL is stored in the PDB file. If this is not present then that mapping won't happen. It is this lookup that makes an exception such a expensive operation (\"exceptions are for exceptional situations\"). ","pontos":0},{"corpo":"What happens if you paste the broken image URL directly into the browser address bar? ","pontos":1},{"corpo":"Let me start off saying that I don't recommend doing this in a service on a server, but I'll do my best to answer the questions. Running as a service makes it difficult to clean up. For example with what you have running as a service survive killing a hung word or excel. You may be in a position to have to kill the service. Will your service stop if word or excel is in this state. One problem with trying to test if it is hung, is that your test could cause a new instance of word to startup and work, while the one that the service is running would still be hung. The best way to determine if it's hung is to ask it to do what it is supposed to be doing and check for the results. I would need to know more about what it is actually doing. Here are some commands to use in a batch file for cleaning up (both should be in the path): sc stop servicename - stops service named servicename sc start servicename - starts service named servicename sc query servicename - Queries the status of servicename taskkill /F /IM excel.exe - terminates all instances of excel.exe ","pontos":2},{"corpo":"Keep in mind that MSFT might be requiring the 3.5 Framework so they can write against it in future updates/releases, which might place your app in an unsupported (by MSFT) state. ","pontos":1},{"corpo":"I would do what jsight suggested and make sure that your machine did not have a virus. I would also submit the .msi file to Avast's online scanner and see what they identified as being in your package. If that reports your file as containing a trojan, contact Avast and ask them to verify that your .msi package does contain a trojan. If it doesn't contain a trojan, find out from Avast what triggered their scanner. There may be something in your code that matches a pattern that Avast looks for, They may be able to adjust their pattern to ignore your file or you could tweak your code so that it doesn't trigger their scanner. ","pontos":1},{"corpo":"I'd say: give the kid a real C64, because that's how I got started. But, today... I'd say Ruby, but Ruby is a bit too chaotic. BASIC would be better in the long run. Processing is easy to learn, and it's basically Java. The reason I recommend a C64 is because it's BASIC, but you still have to learn certain computer-related things, like the memory model, pixels, characters, character maps, newlines, etc. etc, if you want to do more advanced stuff. Also, if your kid finds it boring, you know his heart really isn't into coding. ","pontos":6},{"corpo":"I dont know Avast, but in Kaspersky if the configuration is set to high almost every installer fires an alarm (iTunes, Windows Update, everything) especially if the installer modify some registry key or open a port. If avast checks for behavior and your program open a port probably thats be the cause. ","pontos":0},{"corpo":" Daniel Auger: As others have said, it is possible. However, if both the service and client use an object that has the exact same domain behavior on both sides, you probably didn't need a service in the first place. lomax: I have to disagree with this as it's a somewhat narrow comment. Using a webservice that can serialize domain objects to XML means that it makes it easy for clients that work with the same domain objects, but it also means that those clients are restricted to using that particular web service you've exposed and it also works in reverse by allowing other clients to have no knowledge of your domain objects but still interact with your service via XML. @ Lomax: You've described two scenarios. Scenario 1: The client is rehydrating the xml message back into the exact same domain object. I consider this to be \"returning an object\". In my experience this is a bad choice and I'll explain this below. Scenario 2: The client rehydrates the xml message into something other than the exact same domain object: I am 100% behind this, however I don't consider this to be returning a domain object. It's really sending a message or DTO. Now let me explain why true/pure/not DTO object serialization across a web service is usually a bad idea. An assertion: in order to do this in the first place, you either have to be the owner of both the client and the service, or provide the client with a library to use so that they can rehydrate the object back into it's true type. The problem: This domain object as a type now exists in and belongs to two semi-related domains. Over time, behaviors may need to be added in one domain that make no sense in the other domain and this leads to pollution and potentially painful problems. I usually default to scenario 2. I only use scenario 1 when there is an overwhelming reason to do so. I apologize for being so terse with my initial reply. I hope this clears things up to a degree as far as what my opinion is. Lomax, it would seem we half agree ;). ","pontos":1},{"corpo":"Dirty reads - set transaction isolation level read uncommitted Prevents dead locks where transactional integrity isn't absolutely necessary (which is usually true) ","pontos":0},{"corpo":"Do you actually need to do this? If you're using some kind of pseudo factory pattern without a true design need for it, you're only going to make your code harder to understand, maintain and extend. If you don't need to do this, just implement a true factory pattern. Or, more ALTy, use a DI/IoC framework. ","pontos":0},{"corpo":"I thought I had an ideal solution: strong, b { font-weight: bold; font-style: inherit; } em, i { font-style: italic; font-weight: inherit; } Unfortunately, Internet Explorer doesn't support \"inherit.\" :-( ","pontos":0},{"corpo":"Can you re-factor in parallel? What I mean is re-write the pieces you want to refactor using TDD, but leave the existing code base in place. Then phase out the existing code when your new tests meet the needs for your PM? ","pontos":2},{"corpo":"What you need to do is this to prevent the default constructor to be create. The internal can be change to public if the classes are not in the same assembly. public abstract class AbstractClass{ public static AbstractClass MakeAbstractClass(string args) { if (args == \"a\") return ConcreteClassA().GetConcreteClassA(); if (args == \"b\") return ConcreteClassB().GetConcreteClassB(); } } public class ConcreteClassA : AbstractClass { private ConcreteClassA(){} internal static ConcreteClassA GetConcreteClassA(){ return ConcreteClassA(); } } public class ConcreteClassB : AbstractClass { private ConcreteClassB(){} internal static ConcreteClassB Get ConcreteClassB(){ return ConcreteClassB(); } } ","pontos":-2},{"corpo":"VBScript isn't Visual Basic. ","pontos":1},{"corpo":"Can't you use the keyword for splitting the code for a class into many files? ","pontos":0},{"corpo":"I don't know that there is a solution to your problem. To me, it sounds like your situation falls into the agile-run-amok camp. It sounds like your productivity is already crippled if you can't even check in (for example) a null check to fix a crash without someone looking at it for you. ","pontos":1},{"corpo":"The only situation in which I've had to do this is sending a templated e-mail. In .NET this is provided out of the box by the MailDefinition class. So this is how you create a templated message: MailDefinition md = new MailDefinition(); md.BodyFileName = pathToTemplate; md.From = \"test@somedomain.com\"; ListDictionary replacements = new ListDictionary(); replacements.Add(\" %To% \", someValue); // continue adding replacements MailMessage msg = md.CreateMailMessage(\"test@someotherdomain.com\", replacements, this); After this, msg.Body would be created by substituting the values in the template. I guess you can take a look at MailDefinition.CreateMailMessage() with Reflector :). Sorry for being a little off-topic, but if this is your scenario I think it's the easiest way. ","pontos":7},{"corpo":"Is it no code at all, or no code in the trunk without review? I think using branching (hopefully you are not using VSS!) would possibly work: i.e. only trunk changes need peer review. ","pontos":3},{"corpo":"That is silly. Even if you require code review does not mean it can't be checked in. That's what source code control is for! Especially if review is bottlenecked, batching it is the only way to go. ","pontos":1},{"corpo":"An attribute is a class that contains some bit of functionality that you can apply to objects in your code. To create one, create a class that inherits from System.Attribute. As for what they're good for... there are almost limitless uses for them. http://www.codeproject.com/KB/cs/dotnetattributes.aspx ","pontos":3},{"corpo":"You could use set_error_handler to set a custom exception to log your errors. I'd personally consider storing them in the database as the default Exception handler's backtrace can provide information on what caused it - this of course won't be possible if the database handler triggered the exception however. You could also use error_log to log your errors. It has a choice of message destinations including: Quoted from error_log PHP's system logger, using the Operating System's system logging mechanism or a file, depending on what the error_log configuration directive is set to. This is the default option. Sent by email to the address in the destination parameter. This is the only message type where the fourth parameter, extra_headers is used. Appended to the file destination . A newline is not automatically added to the end of the message string. Edit: Does markdown have a noparse tag for underscores? ","pontos":10},{"corpo":"Depends which branching strategy you use. If your repo is working on release branching, the trunk is meant to be unstable, but maybe your policy stems from some really bad experience in the past. If you are doing feature branching, then you can have a rule that says no merge back to trunk without peer review. Doing diffs at that point should be quite efficient to review with a colleague and should remove the bottleneck. But changing your branching strategy is no small thing. Good question... ","pontos":24},{"corpo":"In most cases what is in source control isn't what is going to be imminently released to the customer. Therefore I would perform the reviewS after the full feature has been checked in, allowing you to edit and/or rollback as necessary later on. ","pontos":2},{"corpo":"I really like log4php for logging, even though it's not yet out of the incubator. I use log4net in just about everything, and have found the style quite natural for me. With regard to system crashes, you can log the error to multiple destinations (e.g., have appenders whose threshold is CRITICAL or ERROR that only come into play when things go wrong). I'm not sure how fail-safe the existing appenders are--if the database is down, how does that appender fail?--but you could quite easily write your own appender that will fail gracefully if it's unable to log. ","pontos":4},{"corpo":"I think it depends a lot of where your error occured. If the DB is down logging it to the DB is no good idea ;) I use the syslog() function for logging the error, but I have no problems writing it to a file when I'm on a system which has no syslog-support. You can easily set up your system to send you an email or a jabber message using for example logwatch or the standard syslogd. ","pontos":0},{"corpo":"I don't think debugbar has a profiler.. but it does have a debugger and a console... so you can fake it... ","pontos":0},{"corpo":"Safest bet is to assume undefined. ","pontos":1},{"corpo":"Why are you dropping objects? Seems to me the sequence should be a lot simpler, and less destructive: assign all of these objects a default value, then make the change to not nullable. ","pontos":0},{"corpo":"Based purely upon experience and when I get my best revelations/eureka moments: Take a shower Lie in bed, trying to fall asleep ","pontos":3},{"corpo":"svnadmin dump C:\\SVNRepositorio\\Repositorio > \\\\Backups\\BkTmpSubversion\\subversiontemp.dump Try this. ","pontos":3},{"corpo":"Statistics are too data-specific to be tooled. It would be potentially very inefficient to blindly re-create them on a data set. ","pontos":0},{"corpo":"A lot of the things that can cause memory leaks in unmanaged languages can still cause memory leaks in managed languages. For example, bad caching policies can result in memory leaks. But as Greg and Danny have said, there is no comprehensive list. Anything that can result in holding memory after its useful lifetime can cause a leak. ","pontos":0},{"corpo":"That doesn't really cause leaks, it just makes more work for the GC: // slows GC Label label = new Label(); this.Controls.Add(label); this.Controls.Remove(label); // better Label label = new Label(); this.Controls.Add(label); this.Controls.Remove(label); label.Dispose(); // best using( Label label = new Label() ) { this.Controls.Add(label); this.Controls.Remove(label); } Leaving disposable components lying around like this is never much of a problem in a managed environment like .Net - that's a big part of what managed means. You'll slow you app down, certainly. But you won't leave a mess for anything else. ","pontos":21},{"corpo":"Do you have any code you could share? Double post backs plagued me so much in classic ASP back in the day that it was what finally prompted me to switch to .NET once and for all. Whenever I have problems like these for .NET, I go to every CONTROL and every PAGE element like load, init, prerender, click, SelectedIndexChanged, and the like and put a breakpoint. Even if I don't have code there, I'll insert something like: Dim i As Integer i = 0 I am usually able to pinpoint some action that I wasn't expecting and fix as needed. I would suggest you do that here. Good luck. ","pontos":0},{"corpo":"Can you create a self signed certificate and add your custom certificate authority to the trusted CAs? I'm not quite sure how this would work on the iPhone, but I'd assume on Mac OS X you would add these to the Keychain. You may also be interested in this post Re: How to handle bad certificate error in NSURLDownload ","pontos":1},{"corpo":"Some revision control systems make this easy (those with a decentralized strategy). I've experimented with using several as local middle-layers to a company subversion server. I've used svk to maintain a local subversion repository I can commit to often, then push changes (individually or as a single combined commit) to the parent repository. svk mirror svk pull svk push This works pretty well, but development on svk seems to be sporadic. I've started to try the same thing using git. I've made a local clone ok, but have yet to be brave enough to attempt to push local commits back up. I'm sure it's possible though. git svn clone git svn fetch git svn dcommit With this private, local repository, you can commit all you like, then bundle or cherry-pick changes to push to the master repository. (Or create a patch that can be peer reviewed.) Best of both worlds perhaps? These alternative revision control tools aren't likely to gain traction at work, but they're really useful for local commits or to be able to commit when the work repository is inaccessible (I'm offline, travelling, etc.) And they still sync with the parent repository. ","pontos":3},{"corpo":"You can strip out the tags with regular expressions. Just make sure that your expressions will not filter tags that were actually text. If the text had \"\\b\" in the body of text, it would appear as \\b in the RTF stream. In other words, you would match on \"\\b\" but not \"\\b\". You could probably take a short cut and filter out the header RTF tags. Look for the first occurrence of \"\\viewkind4\" in the input. Then read ahead to the first space character. You would remove all of the characters from the start of the text up to and including that space character. That would strip out the RTF header information (fonts, colors, etc). ","pontos":2},{"corpo":" I can't remember if PHP is different in this respect, but in Java, you can implement multiple Interfaces, but you can't inherit multiple abstract classes. I'd assume PHP works the same way. In PHP you can apply multiple interfaces by seperating them with a comma (I think, I don't find that a clean soloution). As for multiple abstract classes you could have multiple abstracts extending each other (again, I'm not totally sure about that but I think I've seen that somewhere before). The only thing you can't extend is a final class. ","pontos":4},{"corpo":" Do you mean that AMQ depends on the Prototype library? I can't see an import for that library in the code you've provided. Yes for ActiveMQ's javascript (amq.js) does depend on Prototype. In the amq.js it loads 3 scripts, _amq.js, behaviour.js and prototype.js. Thanks you for your help on the JavaScript load order wrumsby. This tells me that my bug is in another castle :( I guess I have a different problem. I also checked the js files from ActiveMQ 5.0 to 5.1 and noticed they were the same as well. Something has changed in 5.0 to 5.1 that requires a refresh for the topics to subscribe. I'll keep looking, but thanks for eliminating this possible cause. ","pontos":2},{"corpo":"In the project I'm currently working on, there is a set of UI objects of various flavours and an editor to assembly these objects to create pages for use in the main application, a bit like the form designer in DevStudio. These objects exist in their own assembly and each object is a class derived from and has a custom attribute. This attribute is defined like this: [AttributeUsage (AttributeTargets::Class)] public ref class ControlDescriptionAttribute : Attribute { public: ControlDescriptionAttribute (String ^name, String ^description) : _name (name), _description (description) { } property String ^Name { String ^get () { return _name; } } property String ^Description { String ^get () { return _description; } } private: String ^ _name, ^ _description; }; and I apply it to a class like this: [ControlDescription (\"Pie Chart\", \"Displays a pie chart\")] public ref class PieControl sealed : UserControl { // stuff }; which is what the previous posters have said. To use the attribute, the editor has a containing the control types. There is a list box which the user can drag from and drop onto the page to create an instance of the control. To populate the list box, I get the for the control and fill out an entry in the list: // done for each control type array Object ^ // get all the custom attributes ^attributes = controltype- GetCustomAttributes (true); Type // this is the one we're interested in ^attributetype = ECMMainPageDisplay::ControlDescriptionAttribute::typeid; // iterate over the custom attributes for each (Object ^attribute in attributes) { if (attributetype- IsInstanceOfType (attribute)) { ECMMainPageDisplay::ControlDescriptionAttribute ^description = safe_cast ECMMainPageDisplay::ControlDescriptionAttribute ^ (attribute); // get the name and description and create an entry in the list ListViewItem ^item = gcnew ListViewItem (description- Name); item- Tag = controltype- Name; item- SubItems- Add (description- Description); mcontrols- Items- Add (item); break; } } Note: the above is C++/CLI but it's not difficult to convert to C# (yeah, I know, C++/CLI is an abomination but it's what I have to work with :-( ) You can put attributes on most things and there are whole range of predefined attributes. The editor mentioned above also looks for custom attributes on properties that describe the property and how to edit it. Once you get the whole idea, you'll wonder how you ever lived without them. ","pontos":4},{"corpo":"The first thing I would check is if this project does the same thing on other machines. If not, it could be your box is heading south. If not it's the VC6 project itself. Typically I get goofiness with the debugger when my program is doing something with the hardware, especially the video. I would recommend turning off parts of your program until you figure out what part is causing this. If your program is small and not doing much it might be that the project is corrupted and needs to get rebuilt. Make a new project from scratch and put your files and settings back in by hand. ","pontos":1},{"corpo":"As far as I know, and I'm definately not a hacker, you are completely fine. Really, if someone wanted to, they could exploit your code anyway clientside, but i don't see how they could exploit your server side code using javascript (unless you use server side javascript) ","pontos":0},{"corpo":"For clarification: what sort of access do you have to your web server? FTP or WebDAV only? From your question, I'm guessing ssh access isn't available - you're dropping files in a directory to deploy. Is that correct? If so, the answer for unit testing is likely 'do it before you deploy'. You can set up functional testing driven by an automated tool like Selenium to test your app remotely via the web interface, but that's not really unit testing the sense that you're restricted to testing the system as a whole. Have you considered setting up a staging server, perhaps as a VMWare instance, that mirrors or at least mimics your deployment environment? ","pontos":1},{"corpo":"Interfaces will not give your code any performance boosts or anything like that, but they can go a long way toward making it maintainable. It is true that an abstract class (or even a non-abstract class) can be used to establish an interface to your code, but proper interfaces (the ones you define with the keyword and that only contain method signatures) are just plain easier to sort through and read. That being said, I tend to use discretion when deciding whether or not to use an interface over a class. Sometimes I want default method implementations, or variables that will be common to all subclasses. Of course, the point about multiple-interface implementation is a sound one, too. If you have a class that implements multiple interfaces, you can use an object of that class as different types in the same application. The fact that your question is about PHP, though, makes things a bit more interesting. Typing to interfaces is still not incredibly necessary in PHP, where you can pretty much feed anything to any method, regardless of its type. You can statically type method parameters, but some of that is broken (String, I believe, causes some hiccups). Couple this with the fact that you can't type most other references, and there isn't much value in trying to force static typing in PHP (at this point). And because of that, the value of interfaces in PHP, at this point is far less than it is in more strongly-typed languages. They have the benefit of readability, but little else. Multiple-implementation isn't even beneficial, because you still have to declare the methods and give them bodies within the implementor. ","pontos":3},{"corpo":"What's preventing you from running unit tests on the server? If you can upload your production code and let it run there, why can't you upload this other code and run it as well? ","pontos":1},{"corpo":"Best open source one is Smultron in my opinion, but it doesn't a torch to TextMate. ","pontos":4},{"corpo":"Ctrl-Alt (up/down) Copy selected line(s) above or below current line. Alt (up/down) Move current (or multiple selected) lines up or down Ctrl-Shift-R Bring up the resource window, start typing to find class/resource Ctrl-O Bring up all methods and fields for the current class. Hitting it again will bring up all methods and fields for current class and super classes. Ctrl-/ or Ctrl-Alt-C Comment single or multiple lines with // Ctrl-Shift-/ Comment selected lines with /* */ Ctrl-. Take you to the next error or warning line ","pontos":14},{"corpo":"Is the device running out of memory and therefore gives up the ghost when it requires the additional memory to stop at the breakpoint? ","pontos":0},{"corpo":"The least amount of code possible to fulfill a requirement. ","pontos":1},{"corpo":"I find the project-specific settings useful in Eclipse 3.3. For example, if you have several developers working on a project who have different code styles for curly braces, line spacing, number of imports etc. then you can specify the style settings for the project. Then you can configure the save actions so that the code is automatically formatted when a file is saved. The result is everyone's code is formatted the same before it's checked in. ","pontos":0},{"corpo":"I don't see where this lets them do anything that they couldn't do already by calling eval. If there's a security hole being introduced here, I don't see it. ","pontos":0},{"corpo":"This is a difficult question to answer, because there are many qualtiy attibutes of code that could make it \"beautiful\". To make it more difficult, some of the quality attributes conflict. For example, if I need to make a piece of code execute an algorithm that uses as little memory as possible because I am running on an embedded device that has very little, then that code might not be as resusable, or readable, or maintainable as the same algorithm that doesn't have this requirement. With this in mind, my definition of beautiful code is any code that does the job inteneded, and fulfills all the quality attributes it is required to fulfill. ","pontos":2},{"corpo":"I was able to combine my two repositories in this way: Use to clone one of the repositories. Use to pull the code in from the other repository. The (force) flag on the pull is the key -- it says to ignore the fact that the two repositories are not from the same source. Here are the docs for this feature: http://mercurial.selenic.com/wiki/MergingUnrelatedRepositories ","pontos":66},{"corpo":"Try using a CLR stored procedure. You might be able to come up with something, but without first creating a temporary file, it might still be difficult. Could you set up a share on another machine and write to that, and then ftp from there? ","pontos":0},{"corpo":"This isn't inherently dangerous, but the moment you pass any user-provided data into the function, it's ripe for a code injection exploit. That's worrisome, and something I'd avoid. I think a better approach would be to only expose the functionality you need, and nothing more. ","pontos":1},{"corpo":"Is there a server anywhere that you can use where you can create a temporary file? If so, make a web service that returns an array containing the contents of the file. Call the web service from the computer where you can create a temporary file, use the contents of the array to build the temp file and ftp it over. If there is no where at all where you can create a temporary file, I don't see how you will be able to send anything by FTP. ","pontos":1},{"corpo":"A simple regex to detect all CRUD sql statements used with functions (assuming $script contains the whole php script) preg_match_all('/\\(\\s*?\"(?:SELECT|INSERT|UPDATE|DELETE) .*?\"\\s*?\\)\\s*?;/is', $script, $matches); It should match all possible SELECT, INSERT, UPDATE, DELETE statements, if they're placed within parentheses and double quotes. It's case insensetive and should match statements that span across multiple lines too. edit #1: Regex for matching CRUD statement like string assignments; preg_match_all('/\\$\\w+\\s*?=\\s*?\"(?:SELECT|INSERT|UPDATE|DELETE) .*?\"\\s*?;/is', $script, $matches); edit #2: // $variable detecting version of #1 regex preg_match_all('/\\(\\s*?\"(?:SELECT|INSERT|UPDATE|DELETE) .*?(?:\\$\\w+){1}.*?\"\\s*?\\)\\s*?;/is', $script, $matches); ","pontos":0},{"corpo":"I'd agree with the previous two answers that in this instance it may be better from a usability perspective to split the two functions into separate screens. You really want your users to be focussed on entering complete and accurate credit card information, and having a map on the same screen may be distracting. For the record though, Virtual Earth certainly does fully support SSL. To enable it you simple need to change the script reference from http:// to https:// and append s=1 to the URL, e.g. script src=\"http://dev.virtualearth.net/mapcontrol/mapcontrol.ashx?v=6.1\" type=\"text/javascript\" /script becomes script src=\"https://dev.virtualearth.net/mapcontrol/mapcontrol.ashx?v=6.1 s=1\" type=\"text/javascript\" /script ","pontos":13},{"corpo":"Is it possible that the project nodes aren't child nodes, but grandchildren or lower? GetElementsByTagName will give you elements from anywhere in the child element tree, IIRC. ","pontos":1},{"corpo":"It would be handy to see a sample of the XML file you're processing but my guess would be that you have something like this Root Blah project ... /project /Blah /Root The error message seems to be because you're trying to remove from the grandparent rather than the direct parent of the project node ","pontos":0},{"corpo":"My most commonly used features are ctrl+1 quick-fix / spell-checker opening files ctrl+shift+t load class file by classname ctrl+shift+r load any file by filename matches are made on the start of the class/filename. start your search pattern with a * to search anywhere within the filename/classname. Formatting ctrl+shift+f Format source file (set up your formatting style in Window | preferences | java | code style | formatter) ctrl+shift+o Organise imports Generated code alt+s,r to generate getters and setters alt+s,v to insert method signatures for overidden methods from superclass or interface Refactorings alt+shift+l Extract text-selection as local variable (really handy in that it determines and inserts the type for you. alt+shift+m Extract text-selection as a method alt+shift+i inline selected method Running and debugging. alt+shift+x is a really handy prefix to run stuff in your current file. alt+shift+x, t run unit tests in current file alt+shift+x, j run main in current file alt+shift+x, r run on server There are more. The options are shown to you in the lower-right popup after hitting alt+shift+x. alt+shift+x can be switched for alt+shift+d in all the above examples to run in the debugger. Validation As of the recent Ganymede release, you can now switch of validation in specified files and folders. I've been waiting for this feature for ages. Go to Project | Properties | Validation click on the ... button in the settings column of the validator you want to shut up Add a rule to the exclude group code navigation hold down ctrl to make all variables, methods and classnames hyperlinks to their definitions. alt+left to navigate back to where you clicked ctrl alt+right to go \"forwards\" again ","pontos":67},{"corpo":"Always assume undefined, otherwise you'll hit bad problems if you ever try to port architectures. There is nothing quite like the pain of porting code that assumes everything uninitialized will be set to zero. ","pontos":1},{"corpo":"@Brian Warshaw: This issue happens only about 10-20% of the time. Sometimes it hiccups and simply reloading the app will work fine, other times I will spend half an hour reloading the app over and over again to no avail. This is the original code (when I asked the question): public class BlogReader extends MovieClip { public static const DOWNLOAD_ERROR:String = \"Download_Error\"; public static const FEED_PARSED:String = \"Feed_Parsed\"; private var mainXMLLoader:URLLoader = new URLLoader(); public var data:XML; private var _totalEntries:Number = 0; public function BlogReader(url:String){ mainXMLLoader.addEventListener(Event.COMPLETE, LoadList); mainXMLLoader.addEventListener(IOErrorEvent.IO_ERROR, errorCatch); mainXMLLoader.load(new URLRequest(url)); XML.ignoreWhitespace; } private function errorCatch(e:IOErrorEvent){ trace(\"Oh noes! Yous gots no internets!\"); dispatchEvent(new Event(DOWNLOAD_ERROR)); } private function LoadList(e:Event):void { data = new XML(e.target.data); // calculate the total number of entries. for each (var i in data.channel.item){ _totalEntries++; } dispatchEvent(new Event(FEED_PARSED)); } } And this is the code that I wrote based on Re0sless' original reply (similar to some suggestions mentioned): public class BlogReader extends MovieClip { public static const DOWNLOAD_ERROR:String = \"Download_Error\"; public static const FEED_PARSED:String = \"Feed_Parsed\"; private var mainXMLLoader:URLLoader = new URLLoader(); public var data:XML; protected var _totalEntries:Number = 0; public function BlogReader(url:String){ mainXMLLoader.addEventListener(Event.COMPLETE, LoadList); mainXMLLoader.addEventListener(IOErrorEvent.IO_ERROR, errorCatch); mainXMLLoader.load(new URLRequest(url)); XML.ignoreWhitespace; } private function errorCatch(e:IOErrorEvent){ trace(\"Oh noes! Yous gots no internets!\"); dispatchEvent(e); } private function LoadList(e:Event):void { isDownloadComplete(); } private function isDownloadComplete() { trace (mainXMLLoader.bytesLoaded + \"/\" + mainXMLLoader.bytesLoaded); if (mainXMLLoader.bytesLoaded == mainXMLLoader.bytesLoaded){ trace (\"xml fully loaded\"); data = new XML(mainXMLLoader.data); // calculate the total number of entries. for each (var i in data.channel.item){ _totalEntries++; } dispatchEvent(new Event(FEED_PARSED)); } else { trace (\"xml not fully loaded, starting timer\"); var t:Timer = new Timer(300, 1); t.addEventListener(TimerEvent.TIMER_COMPLETE, loaded); t.start(); } } private function loaded(e:TimerEvent){ trace (\"timer finished, trying again\"); e.target.removeEventListener(TimerEvent.TIMER_COMPLETE, loaded); e.target.stop(); isDownloadComplete(); } } I'll point out that since adding the code determining if I have not had an issue - that said, this bug is hard to reproduce so for all I know I haven't fixed anything, and instead just added useless code. ","pontos":0},{"corpo":"There's no need for the JavaScript function, the first argument to can be any JavaScript code, it doesn't have to be a function name (the documentation says so, but it is wrong). Try this: ExternalInterface.call(\"alert('hello')\"); ","pontos":7},{"corpo":"The Editor stands open and empty, a vast field of white marred only by the thin blinking cursor. It is beautiful. The Programmer sits quietly, motionless save for the finger of one hand tapping the desk. In his mind, ideas whirl and twist, designs grow from them, composed as if of their own will, and are as quickly rent asunder. Something begins to take shape behind the half-closed eyes. It is beautiful. A keypress. And another. Like the ringing of a hammer on the nails of a coffin. The wondrous visage is carved into code, clumsy symbols replacing concepts, crude scrawls on the cave walls. Beauty is absent. A Reader gazes, tombstone glyphs spark imagination, a window opens onto the mind of the Programmer. And the code is beautiful. ","pontos":24},{"corpo":"With a has (MD5, SHA-1) one input matches only with one output, and then if you down load the file and calculate the hash again should obtain the same output. If the output is different the file is corrupt. If (hash(file) == Hash in page) validFile = true; else validFile = false; ","pontos":0},{"corpo":"Try just turning the option on in VirtualPC. If it doesn't do anything (or the option isn't available), then your PC doesn't. ","pontos":0},{"corpo":"Maybe a permissions issue on the Crystal libraries?? I've run into that before with Crystal, not specfically the ImageHandler though. ","pontos":1},{"corpo":"Running Debian, I had the same issue. What I did is run xev and see what keycode those keys return. Microsoft likes to break standards a little, so some of the multimedia keys just won't work. But the ones that do will return a keycode. Then write a script with xmodmap to map those keys properly. The Gentoo Wiki has excellent documentation on how to do these things. I put my xmodmap script in ~/.kde/Autostart/ because I use kde, but you could just as easily put it in your home folder and have your .bashrc or .profile source it. Once you've mapped the keycodes, you can assign those keys to specific actions in your desktop environment. ","pontos":1},{"corpo":"Unless I'm misunderstanding, don't you just need something like this: class Foo private def Foo.bar # Complex logic goes here puts \"hi\" end public def bar Foo.bar end end Of course you could change the second definition to use your self.class.send approach if you wanted to avoid hardcoding the class name... ","pontos":-1},{"corpo":"Yes. Orthogonal concerns, like security, are best done with AOP-style interception. Whether that is done automatically (through something like a dependency injection container) or manually is unimportant to the end goal. One example: the \"before/after\" attributes in xUnit.net (an open source project I run) are a form of AOP-style method interception. You decorate your test methods with these attributes, and just before and after that test method runs, your code is called. It can be used for things like setting up a database and rolling back the results, changing the security context in which the test runs, etc. Another example: the filter attributes in ASP.NET MVC also act like specialized AOP-style method interceptors. One, for instance, allows you to say how unhandled errors should be treated, if they happen in your action method. Many dependency injection containers, including Castle Windsor and Unity, support this behavior either \"in the box\" or through the use of extensions. ","pontos":12},{"corpo":"Try cpu-z or SecurAble on windows or on linux, and look for the flags: vmx (Intel) or svm (AMD) All of those will tell you if the hardware supports it, but as others said it must be enabled in the BIOS. (But checking first will avoid an unnecessary reboot...) ","pontos":1},{"corpo":"Use the Microsoft Application Verifier. AppVerifier helps to determine: When the application is using APIs correctly: (Unsafe TerminateThread APIs., Correct use of Thread Local Storage (TLS) APIs., o Correct use of virtual space manipulations (for example, VirtualAlloc, MapViewOfFile). Whether the application is hiding access violations using structured exception handling. Whether the application is attempting to use invalid handles. Whether there are memory corruptions or issues in the heap. Whether the application runs out of memory under low resources. Whether the correct usage of critical sections is occurring. Whether an application running in an administrative environment will run well in an environment with less privilege. Whether there are potential problems when the application is running as a limited user. Whether there are uninitialized variables in future function calls in a thread's context. ","pontos":1},{"corpo":"You should implement dirty reads. SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED If you don't absolutely require perfect transactional integrity with your queries, you should be using dirty reads when accessing tables with high concurrency. I assume your Posts table would be one of those. This may give you so called \"phantom reads\", which is when your query acts upon data from a transaction that hasn't been committed. We're not running a banking site here, we don't need perfect accuracy every time Use dirty reads. You're right in that they won't give you perfect accuracy, but they should clear up your dead locking issues. Without that, we'd have to wrap every LINQ call we make (well, the simple reading ones, which is the vast majority of them) in a 3-4 line transaction code block, which is ugly If you implement dirty reads on \"the base database context\", you can always wrap your individual calls using a higher isolation level if you need the transactional integrity. ","pontos":0},{"corpo":"m.str(\"\"); seems to work. ","pontos":22},{"corpo":"So the OpenID protocol doesn't actually offer a solution for this situation? I would have to rely on individual sites to offer some sort of migration function? That's quite unfortunate. The whole design of OpenID seems focused on a \"all your eggs in one basket\" approach, i.e. you should try to use your OpenID everywhere you can. This would be fine if all providers are identical, but they are not. Imagine the worse case, where you pick a provider that ends up closing down. Wouldn't you potentially lose your accounts on many sites? ","pontos":3},{"corpo":"Here is a code snippet to go along with the question. Using \"private\" in a class definition does not apply to class methods. You need to use \"private_class_method\" as in the following example. class Foo def self.private_bar # Complex logic goes here puts \"hi\" end private_class_method :private_bar class self private def another_private_bar puts \"bar\" end end public def instance_bar self.class.private_bar end def instance_bar2 self.class.another_private_bar end end f=Foo.new f=instance_bar # NoMethodError: private method `private_bar' called for Foo:Class f=instance_bar2 # NoMethodError: private method `another_private_bar' called for Foo:Class I don't see a way to get around this. The documentation says that you cannot specify the receive of a private method. Also you can only access a private method from the same instance. The class Foo is a different object than a given instance of Foo. Don't take my answer as final. I'm certainly not an expert, but I wanted to provide a code snippet so that others who attempt to answer will have properly private class methods. ","pontos":9},{"corpo":"No, you cannot reposition the view report button in the ReportViewer control. However, you could create your own custom report viewing control. The control would be comprised of fields for report parameters and a button to generate the report. When a user clicks the button you could generate the report in the background. You could display the report as a PDF, HTML, etc. ","pontos":3},{"corpo":"I have searched previously for this, with no luck. There does not seem to be any tools available for this conversion, the manual method thereby becomes the only method. And yes, there are consulting firms who will do the manual work for you, but they still do it manually. Crystal Reports and Reporting Services have different architectural styles, making it a difficult task for a conversion tool, so I view it as unlikely that someone will build one anytime soon. ","pontos":12},{"corpo":"The only time I've ever used one of those tools is Split (C programming language). I thought it was helpful, but I was by no means a power user and I think I barely scratched the surface of what it could do. ","pontos":0},{"corpo":"Creating a many-to-many releationship via simple DBML manipulation is not supported currently. You can extend the partial class to manually create properties, if you really want that sort of functionality \"built in\". ","pontos":1},{"corpo":"If you ever plan on making a serious effort at learning Emacs, immediately forget about Aquamacs. It tries to twist and bend Emacs into something it's not (a super-native OS X app). That might sound well and all, but once you realize that it completely breaks nearly every standard keybinding and behavior of Emacs, you begin to wonder why you aren't just using TextEdit or TextMate. Carbon Emacs is a good Emacs application for OS X. It is as close as you'll get to GNU Emacs without compiling for yourself. It fits in well enough with the operating system, but at the same time, is the wonderful Emacs we all know and love. Currently it requires Leopard with the latest release, but most people have upgraded by now anyway. You can fetch it here. Alternatively, if you want to use Vim on OS X, I've heard good things about MacVim. Beyond those, there are the obvious TextEdit, TextMate, etc line of editors. They work for some people, but most \"advanced\" users I know (myself included) hate touching them with anything shorter than a 15ft pole. ","pontos":5},{"corpo":"Lint is the only one I have used at a previous position. It wasn't bad, most of the things it suggested were good catches, some didn't make much sense. As long you don't have a process in place to ensure that there are no lint errors or warnings, then it is useful to perhaps catch some otherwise hidden bugs ","pontos":1},{"corpo":"This a really hard problem for automated tools. You might want to look into model checking your code. Don't expect magical results: model checkers are very limited in the amount of code and the number of threads they can effectively check. A tool that might work for you is CHESS (although it is unfortunately Windows-only). BLAST is another fairly powerful tool, but is very difficult to use and may not handle C++. Wikipedia also lists StEAM, which I haven't heard of before, but sounds like it might work for you: StEAM is a model checker for C++. It detects deadlocks, segmentation faults, out of range variables and non-terminating loops. Alternatively, it would probably help a lot to try to converge the code towards a small number of well-defined (and, preferably, high-level) synchronization schemes. Mixing locks, semaphores, and monitors in the same code base is asking for trouble. ","pontos":2},{"corpo":"See this question, http://stackoverflow.com/questions/19893 Instead of converting the byte[] into String then pushing into XML somewhere, convert the byte[] to a String via BASE64 encoding (some XML libraries have a type to do this for you). The BASE64 decode once you get the String back from XML. Use http://commons.apache.org/codec/ You data may be getting messed up due to all sorts of weird character set restrictions and the presence of non-priting characters. Stick w/ BASE64. ","pontos":2},{"corpo":"I'm not a python guy but it looks like os.readlink()? The logic I would use in perl is to use readlink() to find the target and the use stat() to test to see if the target exists. Edit: I banged out some perl that demos readlink. I believe perl's stat and readlink and python's os.stat() and os.readlink()are both wrappers for the system calls, so this should translate reasonable well as proof of concept code: wembley 0 /home/jj33/swap cat p my $f = shift; while (my $l = readlink($f)) { print \"$f - $l\\n\"; $f = $l; } if (!-e $f) { print \"$f doesn't exist\\n\"; } wembley 0 /home/jj33/swap ls -l | grep ^l lrwxrwxrwx 1 jj33 users 17 Aug 21 14:30 link - non-existant-file lrwxrwxrwx 1 root users 31 Oct 10 2007 mm - ../systems/mm/20071009-rewrite// lrwxrwxrwx 1 jj33 users 2 Aug 21 14:34 mmm - mm/ wembley 0 /home/jj33/swap perl p mm mm - ../systems/mm/20071009-rewrite/ wembley 0 /home/jj33/swap perl p mmm mmm - mm mm - ../systems/mm/20071009-rewrite/ wembley 0 /home/jj33/swap perl p link link - non-existant-file non-existant-file doesn't exist wembley 0 /home/jj33/swap ","pontos":1},{"corpo":"os.lstat() may be helpful. If lstat() succeeds and stat() fails, then it's probably a broken link. ","pontos":10},{"corpo":"Generally when you need to do a sizeable (or frequent) queries to busy tables, where read committed would possibly be blocked by locks from uncommited transactions, but ONLY when you can live with inaccurate data. As an example, on a gaming web site I worked on recently there was a summary display of some stats about recent games, this was all based on dirty reads, it was more important for us to include then exclude the transactional data not yet committed (we knew anyway that few, if any, transactions would be backed out), we felt that on average the data would be more accurate that way. ","pontos":5},{"corpo":"From MSDN: When this option is set, it is possible to read uncommitted or dirty data; values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. Simply put, when you are using this isolation level, and you are performing multiple queries on an active table as part of one transaction, there is no guarantee that the information returned to you within different parts of the transaction will remain the same. You could query the same data twice within one transaction and get different results (this might happen in the case where a different user was updating the same data in the midst of your transaction). This can obviously have severe ramifications for parts of your application that rely on data integrity. ","pontos":10},{"corpo":"Not sure what you're asking. If you're looking to do this without some sort of webserver in between your test and the service, you're going to be disappointed. If that's not what you're asking... maybe some clarification? ","pontos":0},{"corpo":"Simplest method is this: select *, (select count(*) from tbl2 t2 where t2.tbl1ID = t1.tbl1ID) as cnt from tbl1 t1 here is a workable version (using table variables): declare @tbl1 table ( tbl1ID int, prop1 varchar(1), prop2 varchar(2) ) declare @tbl2 table ( tbl2ID int, tbl1ID int ) select *, (select count(*) from @tbl2 t2 where t2.tbl1ID = t1.tbl1ID) as cnt from @tbl1 t1 Obviously this is just a raw example - standard rules apply like don't select *, etc ... UPDATE from Aug 21 '08 at 21:27: @AlexCuse - Yes, totally agree on the performance. I started to write it with the outer join, but then saw in his sample output the count and thought that was what he wanted, and the count would not return correctly if the tables are outer joined. Not to mention that joins can cause your records to be multiplied (1 entry from tbl1 that matches 2 entries in tbl2 = 2 returns) which can be unintended. So I guess it really boils down to the specifics on what your query needs to return. UPDATE from Aug 21 '08 at 22:07: To answer the other parts of your question - is a VB function the way to go? No. Absolutely not. Not for something this simple. Functions are very bad on performance, each row in the return set executes the function. If you want to \"compartmentalize\" the different parts of the query you have to approach it more like a stored procedure. Build a temp table, do part of the query and insert the results into the table, then do any further queries you need and update the original temp table (or insert into more temp tables). ","pontos":0},{"corpo":"I try to remove move the comments to separate functions when it seems the function is getting big. To look big sooner I use a big font size like 14 or 15. ","pontos":1},{"corpo":"I comment as a service to others, and only when the code is \"done\". When working on my own projects I rarely bother since I'd rather be adding features and fixing bugs than writing something I'll probably never read. Interestingly, when reading other people's code, I very often delete or ignore the comments and look directly at the code. I find that is many cases it can be clearer to read than the corresponding comments. ","pontos":1},{"corpo":"Why not just have both QuoteId and JobId fields in the message table? Or does a message have to be regarding either a quote or a job and not both? ","pontos":0},{"corpo":"I don't comment the obvious stuff (i.e. \"Set i to 2\" or \"check if a is greater than 5\"), but sometimes just a little information about what the code is used for, i.e. \"build the outer table\" or some oddities like \"MyClass.Count is actually Count-1\". And of course, Workaround for bugs, i.e. \"Workaround for KB123456 - url to some site that explains the bug....\" So basically: I almost never comment the \"What\" but sometimes the \"Why\". ","pontos":3},{"corpo":"There seems to be something of an Access connection adapter here: http://svn.behindlogic.com/public/rails/activerecord/lib/active_record/connection_adapters/msaccess_adapter.rb The database.yml file would look like this: development: adapter: msaccess database: C:\\path\\to\\access_file.mdb I'll post more after I've tried it out with Rails 2.1 ","pontos":2},{"corpo":"They are probably using a div with onclick event handler rather than an anchor. But chances are that it's not really nested any way. ","pontos":0},{"corpo":"The problem with comments interspersed with code is that when the code changes (the code will change) the comments very often do not, or at least not consistently. This leads to even more confusing, unmaintainable code, because after several changes the comments and code don't say nearly the same thing. Instead, I prefer to have comments for each module (class, function, whatever). This comment section should explain in plain English what function the module is intended for. If I think a section of code is tricky enough to warrant a comment, then I refactor it out into its own function so the function name and related comments can explain what it is supposed to do. ","pontos":3},{"corpo":"They must be doing some really crazy stuff with JavaScript to get it to work (notice how neither the parent nor the nested anchor tags have a name or href attribute - all functionality is done through the class name and JS). Here is what the html looks like: a class=\"page_tab page_tab\" div class=\"page_title\" title=\"Click to rename this page.\" Click Type Page Name /div a class=\"delete_page\" title=\"Click to delete this page\" style=\"display: block;\" X /a /a ","pontos":9},{"corpo":"I try to comment only on things that are necessary. Like what is the purpose of this class, what does this method do (if not obvious), which values can the parameters be etc. I try to avoid comments that describe what the code does. Instead, I try to make the code self-descriptive. Extract smaller methods from big chunks of code etc. Of course, this is not always possible and may sometimes even make it worse. You have to find the balance where your combination of code and comments is the most readable. The worst thing you can do is add comments to obvious methods like getters and setters when they don't do more than what they should - get or set the named field. One thing that is really dangerous about comments is that they may get outdated when the implementation changes and the comments are forgotten. So you should try to focus on the interesting stuff, because that's what users of your code or yourself will see and have to trust, if they don't have the source code ;) ","pontos":1},{"corpo":" I usually comment \"ifs\" and write in \"human language\" what it means, like \"checks if it's A or B\". If you find yourself doing this, it may be better to refactor so that the complex boolean logic is extracted to another method, or at least introduce a variable with a name that makes it clear what the logic means. The problem with comments is that they (sometimes) violate the DRY (Don't Repeat Yourself) guideline. When you duplicate the logic by adding it to documentation, even comments right next to the code, you run the risk of having things fall out of date. Soon the comments may become incomplete or inaccurate. That said, I don't mind looking at comments, even if they are a little out of date. I have run into code that looks like: // collect data Data data = collectData(); // analyze data Report report = analyze(data); // print report report.print(); Those types of comments are absolutely worthless to everybody and I will usually delete them on sight. ","pontos":21},{"corpo":"I realize it's kind of cliche, but the code should document itself. I tend to err on the side of declaring more variables for the sake of clarity (on the assumption that the compiler can/will optimize the unnecessary ones away). Keep the functions short and variables and functions well named. I try to do that and then only comment the tricky stuff. Be aware, though, that shorter functions make it harder to see how the code, as a whole, works together. Keep this in mind when documenting functions (as opposed to individual lines of code). At the function or even unit level, you should be documenting how the functions interact with each other. ","pontos":2},{"corpo":" Ctrl-shift-T, but only type the initial characters (and even a few more) of the class you're looking for. For example, you can type \"NetLi\" to find NetworkListener In the Search window, Ctrl-. takes you to the first leaf of a tree branch Alt-/ is Word Completion. Slightly different from Ctrl-space ","pontos":4},{"corpo":"Actually, the code I had pasted previously was the generated DOM, after all JS manipulation. If you don't have the Firebug extension for Firefox, you should get it now. Edit: Deleted the old post, it was no longer useful. Firebug is, so this one is staying :) ","pontos":0},{"corpo":"Throw away only in my opinion. UML is a great tool for communicating ideas, the only issue is when you store and maintain it because you are essentially creating two copies of the same information and this is where it usually blows. After the initial round of implementation most of the UML should be generated from the source code else it will go out of date very quickly or require a lot of time (with manual errors) to keep up to date. ","pontos":11},{"corpo":"Either that, or System.Reflection.Assembly.GetLoadedModules(). Note that AppDomain.GetAssemblies will only iterate assemblies in the current AppDomain. It's possible for an application to have more than one AppDomain, so that may or may not do what you want. ","pontos":2},{"corpo":"You would also need to then save the message. Then it that should work. ","pontos":4},{"corpo":"it is varchar right? So it then doesn't matter if you use 50 or 25, better be safe and use 50, that said I believe the longest I have seen is about 19 or so. Last names are longer ","pontos":0},{"corpo":"I just queried my database with millions of customers in the USA. The maximum first name length was 46. I go with 50. (Of course, only 500 of those were over 25, and they were all cases where data imports resulted in extra junk winding up in that field.) Last name was similar to first name. Email addresses maxed out at 62 characters. Most of the longer ones were actually lists of email addresses separated by semicolons. Street address maxes out at 95 characters. The long ones were all valid. Max city length was 35. This should be a decent statistical spread for people in the US. If you have localization to consider, the numbers could vary significantly. ","pontos":152},{"corpo":"No, it's not unreasonable of you. I'm the same way. Unfortunately, there are people with a fetish for omnibus classes that do everything except wash your dishes, and are thousands of lines long (usually management types). Don't know that there's much you can do about it. In my experience, most programmers willing to create monstrosities like that are usually the type who don't even know what \"refactor\" means. ","pontos":7},{"corpo":"Looking at the members of the class, I'd say the answer is probably no*. I'm not sure why you'd want to do this anyway, rather than create your own XML configuration file. *That's no, excluding messy reflection hacks ","pontos":0},{"corpo":"Just make sure you allow non-alpha characters in the names! points at hyphen in his last name ","pontos":12},{"corpo":"Ditto what Cheekysoft said - basically, a method/functions needs to have good cohesion. If it is doing just one thing, it will be short by nature. Refactoring a long method into a bunch of short ones is only part of the idea - the short ones should do more than just divide the work, they should do what they do well and only do that one thing. ","pontos":2},{"corpo":"I guess depending on what you're trying to do should most dictate how long something is going to be. It sounds like this person is unnecessarily making things longer. For starters, showing them HOW to refactor their code would be the best start. \"Here, you took 100 lines to do this, but doing it this way, it can be done in 20\" or \"Using this built in function, you can eliminate the need to do this\" or whatever. Code reviews can also be helpful and then you put your work up for constructive criticism, too, so it's not one-sided. On the other hand, as Joel mentioned in one of the StackOverflow podcasts, sometimes you have to ask yourself from a business standpoint if it's really worth optimizing or not. We'll often write bad or long code and plan to make it better, but decide against because \"it's working\" and there's other work to be done that's not working. Can you justify spending the time to make something better? For this case, if he's constantly writing too much code, maybe the answer is 'yes'. ","pontos":1},{"corpo":"I recommend storing the id rather than the object. The downside is that you have to hit the database every time you want to get that user's information. However, unless every millisecond counts in your page, the performance shouldn't be an issue. Here are two advantages: If the user's information changes somehow, then you won't be storing out-of-date information in your session. For example, if a user is granted extra privileges by an admin, then those will be immediately available without the user needing to log out and then log back in. If your session information is stored on the hard drive, then you can only store serializable data. So if your User object ever contains anything like a database connection, open socket, file descriptor, etc then this will not be stored properly and may not be cleaned up properly either. In most cases these concerns won't be an issue and either approach would be fine. ","pontos":11},{"corpo":"It should be refactored if... It does more than one thing. It does that one thing more than once, outside of a loop. If you forget the first line, by the time you read the last line. ","pontos":16},{"corpo":"@ John Sibly You can get away with not calling EndInvoke when dealing with WinForms without any negative consequences. The only documented exception to the rule that I'm aware of is in Windows Forms, where you are officially allowed to call Control.BeginInvoke without bothering to call Control.EndInvoke. However in all other cases when dealing with the Begin/End Async pattern you should assume it will leak, as you stated. ","pontos":1},{"corpo":"Like @Brad-Wilson said Why not How. But I do also use TODO's in my code as well, but for production I try to limit those. ","pontos":1},{"corpo":"If a section of code needs comments. It probably needs refactoring. e.g. void MyMethod() { //set the UI myTextbox.text = \"Foo\"; myOthertextbox.text = \"Bar\"; foreach (n in thing) //something other stuff } should probably be refactored to extact the UI stuff. void MyMethod() { SetUI(); foreach (n in thing) //something other stuff } void SetUI() { myTextbox.text = \"Foo\"; myOthertextbox.text = \"Bar\"; } ","pontos":6},{"corpo":"I used to write quite a lot of comments, and whenever I saw code without comments it just looked strange (I think I was used to seeing lots of green bits). Even when I stopped trusting comments and always skipped reading them, code would look strange without blocks of green text mixed in with the code. These days, I almost never write any comments (the same goes for everyone on my team). The last few times I have wrote comments have all been warnings for the next person to see that code. E.g. \"OPTIMIZED: Don't refactor this without running a profiler\" or \"WORKAROUND: Because of a bug in XYZ library we need to do ABC here\" If I come across comments that explain 'how' something works, I usually refactor the code so the comment becomes redundant then delete the comment. ","pontos":0},{"corpo":"We are still struggling to understand the HOW of this issue, but it seems that [ourdomain\\SQLAccessGroup] was aliased by a consultant to a different user name (this is part of an MS CRM installation). We finally were able to use some logic and some good old SID comparisons to determine who was playing the imposter game. Our hint came when I tried to add the login as a user to the database (since it supposedly already existed) and got this error: The login already has an account under a different user name. So, I started to examine each DB user and was able to figure out the culprit. I eventually tracked it down and was able to rename the user and login so that the CRM install would work. I wonder if I can bill them $165.00 an hour for my time... :-) ","pontos":4},{"corpo":"Not that I know of. This has been a plague of Windows versions for quite some time. ","pontos":0},{"corpo":"I've been obfuscating code in the same application since .Net 1, and it's been a major headache from a maintenance perspective. As you've mentioned, the serialization problem can be avoided, but it's really easy to make a mistake and obfuscate something you didn't want obfuscated. It's easy to break the build, or to change the obfuscation pattern and not be able to open old files. Plus it can be difficult to find out what went wrong and where. Our choice was Xenocode, and were I to make the choice again today I would prefer to not obfuscate the code, or use Dotfuscator. ","pontos":2},{"corpo":"For just two strings, you definitely do not want to use StringBuilder. There is some threshold above which the StringBuilder overhead is less than the overhead of allocating multiple strings. So, for more that 2-3 strings, use DannySmurf's code. Otherwise, just use the + operator. ","pontos":0},{"corpo":"This is not directly an answer, but The thing is that to remove the disk you have to eject the volume and in this case do it for both volumes I have a similar situation. OSX remembers where you put your icons on the desktop - I've moved the icons for both of my removable drives to just above where the trash can lives. Eject procedure becomes Hit top-left of screen with mouse to show desktop Drag small box around both removable drives Drag 2cm onto trash so they both get ejected Remove firewire cable ","pontos":1},{"corpo":"Rico Mariani, the .NET Performance guru, had an article on this very subject. It's not as simple as one might suspect. The basic advice is this: If your pattern looks like: that's one concat and it's zippy, StringBuilder probably won't help. If your pattern looks like: then you probably want StringBuilder. ","pontos":153},{"corpo":"You could rewrite it so that you use registers that aren't suppose to change, for example . Just make sure you push them onto the stack at the beginning, and pop them off at the end of your routine. # count.s: print the numbers from 0 to 100. .text string: .asciz \"%d\\n\" .globl _main _main: push %ecx push %ebp movl $0, %ecx # The starting point/current value. movl $100, %ebp # The ending point. _loop: # Display the current value. pushl %ecx pushl $string call _printf addl $8, %esp # Check against the ending value. cmpl %ecx, %ebp je _end # Increment the current value. incl %ecx jmp _loop _end: pop %ebp pop %ecx ","pontos":-1},{"corpo":"At best the whole function should fit into screen (not so hard nowadays :) ). Also it should do one thing and doesn't duplicate any code. However, there are exception -- function which try to solve all the problems with i.e. many optional parameters is bad. ","pontos":0},{"corpo":"Actually Windows XP tries to avoid that. Of course some programs found a way to circumvented that. Microsoft Powertoy TweakUI has a way to turn the option on again in case it was turned off. You could also edit the registry yourself using the following information. ","pontos":0},{"corpo":"According to MSDN: http://msdn.microsoft.com/en-us/library/ms191242.aspx When either the READ COMMITTED SNAPSHOT or ALLOW SNAPSHOT ISOLATION database options are ON, logical copies (versions) are maintained for all data modifications performed in the database. Every time a row is modified by a specific transaction, the instance of the Database Engine stores a version of the previously committed image of the row in tempdb. Each version is marked with the transaction sequence number of the transaction that made the change. The versions of modified rows are chained using a link list. The newest row value is always stored in the current database and chained to the versioned rows stored in tempdb. For short-running transactions, a version of a modified row may get cached in the buffer pool without getting written into the disk files of the tempdb database. If the need for the versioned row is short-lived, it will simply get dropped from the buffer pool and may not necessarily incur I/O overhead. There appears to be a slight performance penalty for the extra overhead, but it may be negligible. We should test to make sure. Try setting this option and REMOVE all NOLOCKs from code queries unless its really necessary. NOLOCKs or using global methods in the database context handler to combat database transaction isolation levels are Band-Aids to the problem. NOLOCKS will mask fundamental issues with our data layer and possibly lead to selecting unreliable data, where automatic select / update row versioning appears to be the solution. ALTER Database [StackOverflow.Beta] SET READ_COMMITTED_SNAPSHOT ON ","pontos":44},{"corpo":"The PECL APD extension is used as follows: ?php apd_set_pprof_trace(); //rest of the script ? After, parse the generated file using . Example output: Trace for /home/dan/testapd.php Total Elapsed Time = 0.00 Total System Time = 0.00 Total User Time = 0.00 Real User System secs/ cumm %Time (excl/cumm) (excl/cumm) (excl/cumm) Calls call s/call Memory Usage Name -------------------------------------------------------------------------------------- 100.0 0.00 0.00 0.00 0.00 0.00 0.00 1 0.0000 0.0009 0 main 56.9 0.00 0.00 0.00 0.00 0.00 0.00 1 0.0005 0.0005 0 apd_set_pprof_trace 28.0 0.00 0.00 0.00 0.00 0.00 0.00 10 0.0000 0.0000 0 preg_replace 14.3 0.00 0.00 0.00 0.00 0.00 0.00 10 0.0000 0.0000 0 str_replace ","pontos":78},{"corpo":"There's a tragic flaw with the \"self-documenting code\" theory. Yes, reading the code will tell you exactly what it's doing. However, the code is incapable of telling you what it's supposed to be doing. I think it's safe to say that all bugs are caused when code is not doing what it's supposed to be doing :). So if we add some key comments to provide maintainers with enough information to know what a piece of code is supposed to be doing, then we have given them the ability to fix a whole lot of bugs. That leaves us with the question of how many comments to put in. If you put in too many comments, things become tedious to maintain and the comments will inevitably be out of date with the code. If you put in too few, then they're not particularly useful. I've found regular comments to be most useful in the following places: 1) A brief description at the top of a .h or .cpp file for a class explaining the purpose of the class 2) A comment block before the implementation of a non-trivial function explaining the purpose of it and detailing its expected inputs, potential outputs, and any oddities to expect when calling the function. Other than that, I tend to comment anything that might appear confusing or odd to someone. For example: \"This array is 1 based instead of 0 based because of blah blah\". ","pontos":31},{"corpo":"I have found that I also need to set to 7 in Firefox's . ","pontos":1},{"corpo":"That depends on the clipboard format. If it is plain-text, then no. Unless you want to install global hooks on the clipboard. Which you cannot do from Java. ","pontos":1},{"corpo":"After grepping my code, it seems the only thing I've used reduce for is calculating the factorial: reduce(operator.mul, xrange(1, x+1) or (1,)) ","pontos":3},{"corpo":"LINQ is not about SQL. LINQ is about being apply functional programming paradigmns on objects. LINQ to SQL is an ORM built ontop of the LINQ foundation, but LINQ is much more. I don't use LINQ to SQL, yet I use LINQ all the time. Take the task of finding the intersection of two lists: Before LINQ, this tasks requires writing a nested foreach that iterates the small list once for every item in the big list O(N*M), and takes about 10 lines of code. foreach (int number in list1) { foreach (int number2 in list2) { if (number2 == number) { returnList.add(number2); } } } Using LINQ, it does the same thing in one line of code: var results = list1.Intersect(list2); You'll notice that doesn't look like LINQ, yet it is. You don't need to use the expression syntax if you don't want to. ","pontos":37},{"corpo":"I've used bqbackup.com for 1-2 years no problem. You can do a sync using rsync nightly. Wanted to add that their prices are dirt cheap, and I now have close to 1TB with them. ","pontos":0},{"corpo":"The current version I am using is this bool is_equals(float A, float B, float maxRelativeError, float maxAbsoluteError) { if (fabs(A - B) maxAbsoluteError) return true; float relativeError; if (fabs(B) fabs(A)) relativeError = fabs((A - B) / B); else relativeError = fabs((A - B) / A); if (relativeError = maxRelativeError) return true; return false; } This seems to take care of most problems by combining relative and absolute error tolerance. Is the ULP approach better? If so, why? ","pontos":3},{"corpo":" I want to add a rule that checks for the presence of a folder.jpg file in each directory, but to add this would make the code substantially more messy in it's current state.. This doesn't look bad. In fact your current code does it very nicely, and Sven mentioned a good way to do it as well: Get a list of all the files Check for \"required\" files You would just have have add to your dictionary a list of required files: checker = { ... 'required': ['file', 'list', 'for_required'] } As far as there being a better/extensible way to do this? I am not exactly sure. I could only really think of a way to possibly drop the \"multiple\" regular expressions and build off of Sven's idea for using a delimiter. So my strategy would be defining a dictionary as follows (and I'm sorry I don't know Python syntax and I'm a tad to lazy to look it up but it should make sense. The /regex/ is shorthand for a regex): check_dict = { 'delim' : /\\-/, 'parts' : [ 'Show Name', 'Episode Name', 'Episode Number' ], 'patterns' : [/valid name/, /valid episode name/, /valid number/ ], 'required' : ['list', 'of', 'files'], 'ignored' : ['.*', 'hidden.txt'], 'start_dir': '/path/to/dir/to/test/' } Split the filename based on the delimiter. Check each of the parts. Because its an ordered list you can determine what parts are missing and if a section doesn't match any pattern it is malformed. Here the and have a 1 to 1 ratio. Two arrays instead of a dictionary enforces the order. Ignored and required files can be listed. The and files should probably be ignored automatically. The user should be allowed to input \"globs\" which can be shell expanded. I'm thinking here of properties, but globbing is natural for listing files. Here would be default to the current directory but if you wanted a single file to run automated testing of a bunch of directories this would be useful. The real loose end here is the path template and along the same lines what path is required for \"valid files\". I really couldn't come up with a solid idea without writing one large regular expression and taking groups from it... to build a template. It felt a lot like writing a TextMate language grammar. But that starts to stray on the ease of use. The real problem was that the path template was not composed of , which makes sense but adds complexity. Is this strategy in tune with what you were thinking of? ","pontos":2},{"corpo":"I've used Spring.NET in the past and had great success with it. I never noticed any substantial overhead with it, though the project we used it on was fairly heavy on its own. It only took a little time reading through the documentation to get it set up. ","pontos":3},{"corpo":"I did basically the same thing that you did Adam, but with a slide modification to make sure I was appending to the head tag to get the job done. I simply created an include function (code below) to handle both script and css files. This function also checks to make sure that the script or CSS file hasn't already been loaded dynamically. It does not check for hand coded values and there may have been a better way to do that, but it served the purpose. function include( url, type ){ // First make sure it hasn't been loaded by something else. if( Array.contains( includedFile, url ) ) return; // Determine the MIME-type var jsExpr = new RegExp( \"js$\", \"i\" ); var cssExpr = new RegExp( \"css$\", \"i\" ); if( type == null ) if( jsExpr.test( url ) ) type = 'text/javascript'; else if( cssExpr.test( url ) ) type = 'text/css'; // Create the appropriate element. var tag = null; switch( type ){ case 'text/javascript' : tag = document.createElement( 'script' ); tag.type = type; tag.src = url; break; case 'text/css' : tag = document.createElement( 'link' ); tag.rel = 'stylesheet'; tag.type = type; tag.href = url; break; } // Insert it to the head and the array to ensure it is not // loaded again. document.getElementsByTagName(\"head\")[0].appendChild( tag ); Array.add( includedFile, url ); } ","pontos":15},{"corpo":" This seems to take care of most problems by combining relative and absolute error tolerance. Is the ULP approach better? If so, why? ULPs are a direct measure of the \"distance\" between two floating point numbers. This means that they don't require you to conjure up the relative and absolute error values, nor do you have to make sure to get those values \"about right\". With ULPs, you can express directly how close you want the numbers to be, and the same threshold works just as well for small values as for large ones. ","pontos":0},{"corpo":" If you have floating point errors you have even more problems than this. Although I guess that is up to personal perspective. Even if we do the numeric analysis to minimize accumulation of error, we can't eliminate it and we can be left with results that ought to be identical (if we were calculating with reals) but differ (because we cannot calculate with reals). ","pontos":0},{"corpo":" If you are looking for two floats to be equal, then they should be identically equal in my opinion. If you are facing a floating point rounding problem, perhaps a fixed point representation would suit your problem better. Perhaps we cannot afford the loss of range or performance that such an approach would inflict. ","pontos":0},{"corpo":"The short answer is yes. Any function can be declared inline, and putting the function body in the class definition is one way of doing that. You could also have done: class Foo { int* p; public: Foo(); ~Foo(); }; inline Foo::Foo() { p = new char[0x00100000]; } inline Foo::~Foo() { delete [] p; } However, it's up to the compiler if it actually does inline the function. VC++ pretty much ignores your requests for inlining. It will only inline a function if it thinks it's a good idea. Recent versions of the compiler will also inline things that are in seperate .obj files and not declared inline (e.g. from code in different .cpp files) if you use link time code generation. You could use the __forceinline keyword to tell the compiler that you really really mean it when you say \"inline this function\", but it's usally not worth it. In many cases, the compiler really does know best. ","pontos":14},{"corpo":" If you are looking for two floats to be equal, then they should be identically equal in my opinion. If you are facing a floating point rounding problem, perhaps a fixed point representation would suit your problem better. Perhaps I should explain the problem better. In C++, the following code: #include iostream using namespace std; int main() { float a = 1.0; float b = 0.0; for(int i=0;i 10;++i) { b+=0.1; } if(a != b) { cout \"Something is wrong\" endl; } return 1; } prints the phrase \"Something is wrong\". Are you saying that it should? ","pontos":0},{"corpo":"For security's sake, I would generate (either a GUID or cryptographically safe RNG) a session ID and have a table that just maps session IDs to user IDs. Then, you just store the session ID in their cookies, and have it act as a proxy for the user id. With this, no one can impersonate another user by guessing their ID. It also lets you limit users' sessions so they have to log in every so often (two weeks is the usual). And if you want to store other data about their session, you can just add it to this table. ","pontos":6},{"corpo":"I think perhaps there isn't a definitive answer - hence the lack of \"interest\" in this question. But I have personally had mixed experience with MDA. The only time it was good experience was with great tools - I used to use TogetherSoft (I believe they somehow ended up at borland) - they were one of the first to introduce editing which was not \"code generation\" but actually editing the code/model directly (so you could edit code, or the model, it was all the one thing). They also had refactoring (which was the first time I remember it post smalltalk environments). Since that time I haven't seen MDA grow any more in popularity, at least in the mainstream, so in terms of popularity it doesn't appear to be the future (so that kind of answers it). Of course popularity isn't everything, and things to have a tendency to come back, but for the time being I think MDA+tools is viewed by many as \"wizard based code generation\" tools (regardless of what it really is) so I think it will be some time or perhaps never that it really takes off. ","pontos":3},{"corpo":"Setting your default to read uncommitted is not a good idea. Your will undoubtedly introduce inconsistencies and end up with a problem that is worse than what you have now. Snapshot isolation might work well, but it is a drastic change to the way Sql Server works and puts a huge load on tempdb. Here is what you should do: use try-catch (in T-SQL) to detect the deadlock condition. When it happens, just re-run the query. This is standard database programming practice. There are good examples of this technique in Paul Nielson's Sql Server 2005 Bible. Here is a quick template that I use: -- Deadlock retry template declare @lastError int; declare @numErrors int; set @numErrors = 0; LockTimeoutRetry: begin try; -- The query goes here return; -- this is the normal end of the procedure end try begin catch set @lastError=@@error if @lastError = 1222 or @lastError = 1205 -- Lock timeout or deadlock begin; if @numErrors = 3 -- We hit the retry limit begin; raiserror('Could not get a lock after 3 attempts', 16, 1); return -100; end; -- Wait and then try the transaction again waitfor delay '00:00:00.25'; set @numErrors = @numErrors + 1; goto LockTimeoutRetry; end; -- Some other error occurred declare @errorMessage nvarchar(4000), @errorSeverity int select @errorMessage = error_message(), @errorSeverity = error_severity() raiserror(@errorMessage, @errorSeverity, 1) return -100 end catch; ","pontos":3},{"corpo":"It's not possible to make it \"impossible\" to download. When a user visits your site you're sending them the pictures. The user will have a copy of that image in the browsers cache and he'd be able to access it even after he leaves the site ( depending on the browser, of course ). Your only real option is to watermark them :O ","pontos":30},{"corpo":"using JavaScript to override the click event is the most common I have seen... see: http://pubs.logicalexpressions.com/pub0009/LPMArticle.asp?ID=41 ","pontos":4},{"corpo":"You could embed each image inside of a flash application, then the browser wouldn't know how to 'save' the image and wouldn't store the raw jpg in the cache folder either. They could still just press the print screen key to get a copy of the image, but it would probably be enough to stop most visitors. ","pontos":13},{"corpo":"Anything you send to the client is, like, on the client. Not much you can do about it besides making somewhere between \"sorta hard\" and \"quite hard\" to save the image. ","pontos":0},{"corpo":"Sorry. That's impossible. All you can do is make it inconvenient a la flickr. ","pontos":1},{"corpo":"It suppose to be a registry change that helps with this type of situations (mentioned in this Coding Horror post about the subject of \"focus stealing\"). I try it, it doesn't work with all popups but helps with some of them, causing the offending application to flash in the taskbar instead of gain focus. ","pontos":0},{"corpo":"Short answer: you can't. Whatever you display to a user is going to be available to them. You can watermark it, blur it, or offer a low-res version of it, but the bottom line is that whatever images are displayed in the user's browser are going to be available to them in some way. ","pontos":3},{"corpo":"Response.WriteBinary(), embedded flash, JavaScript hacks, hidden divs. Over the years I have seen and tried every possible way to secure an image and I have come to one conclusion: If it can be seen online; it can be taken, my friend. So, what you really should consider what the final goal of this action would really be. Prevent piracy? If a gross and oversized watermark is not your style, you can always embed hidden data (Apress had an article that looked promising on digital steganography) in images to identify them as your own later. You might only offer reduced or lower quality images. Flickr takes the approach of placing a transparent gif layer on top of the image so if you are not logged in and right click you get their ever awesome spaceball.gif. But nothing can prevent a screenshot other than, well, just not offering the picture. If the music industry could get you to listen to all of your music without copying or owning files they would. If television could broadcast and be certain nobody could store a copy of the cast, they probably would as well. It's the unfortunate part of sharing media with the public. The really good question here is how you can protect your material WITHOUT getting in the way of respectable users from consuming your images. Put on too much protection and nobody will go to your site/use your software (Personally if you try to disable my mouse I'll go from good user to bad nearly instantly). ","pontos":13},{"corpo":"To add to what Nick said, the MSDN documentation does not list any pre-defined names. It would seem that all need to come from and . #if on MSDN ","pontos":4},{"corpo":"It's just not possible. There is always the PrintScreen button. Whatever is displayed, can be captured. ","pontos":3},{"corpo":"This site covers some of the basics with little regard for the NDA. Start at the bottom and work up. ","pontos":2},{"corpo":"Tags are basically our admission that search algorithms aren't up to snuff. If we can get a computer to be smart enough to identify that things tagged \"Subversion\" have similar content to things tagged \"svn\", presumably we can parse the contents, so why not skip tags altogether, and match a search term directly to the content (i.e., autotagging, which is basically mapping keywords to results)?! ","pontos":0},{"corpo":"unfortunately you can always screen grab the browser and crop the image out, not perfect but it circumvents almost every solution posted here :( ","pontos":2},{"corpo":"You should be able to do this with System.DirectoryServices.DirectoryEntry. If you are having trouble running it remotely, maybe you could install something on the remote machines to give you your data via some sort of RPC, like remoting or a web service. But I think what you're trying should be possible remotely without getting too fancy. ","pontos":0},{"corpo":"We had this same issue with a production system late last year (sept 2007) and the official word from our Microsoft contact was that they had a 64 bit oledb driver to connect to ASI/DB2 but it was in BETA at the time. Not sure when it will be out of beta but that was the news as of last year. We decided to move the production server onto a 32 bit machine since we were not comfortable using beta drivers on production systems. I know this doesn't answer your question but it hopefully gives you some insight ","pontos":1},{"corpo":"Here's the script that I came up with. It handles Identity columns, default values, and primary keys. It does not handle foreign keys, indexes, triggers, or any other clever stuff. It works on SQLServer 2000, 2005 and 2008. declare @table varchar(100) set @table = 'MyTable' -- set table name here declare @sql table(s varchar(1000), id int identity) -- create statement insert into @sql(s) values ('create table [' + @table + '] (') -- column list insert into @sql(s) select ' ['+column_name+'] ' + data_type + coalesce('('+cast(character_maximum_length as varchar)+')','') + ' ' + case when exists ( select id from syscolumns where object_name(id)=@table and name=column_name and columnproperty(id,name,'IsIdentity') = 1 ) then 'IDENTITY(' + cast(ident_seed(@table) as varchar) + ',' + cast(ident_incr(@table) as varchar) + ')' else '' end + ' ' + ( case when IS_NULLABLE = 'No' then 'NOT ' else '' end ) + 'NULL ' + coalesce('DEFAULT '+COLUMN_DEFAULT,'') + ',' from information_schema.columns where table_name = @table order by ordinal_position -- primary key declare @pkname varchar(100) select @pkname = constraint_name from information_schema.table_constraints where table_name = @table and constraint_type='PRIMARY KEY' if ( @pkname is not null ) begin insert into @sql(s) values(' PRIMARY KEY (') insert into @sql(s) select ' ['+COLUMN_NAME+'],' from information_schema.key_column_usage where constraint_name = @pkname order by ordinal_position -- remove trailing comma update @sql set s=left(s,len(s)-1) where id=@@identity insert into @sql(s) values (' )') end else begin -- remove trailing comma update @sql set s=left(s,len(s)-1) where id=@@identity end -- closing bracket insert into @sql(s) values( ')' ) -- result! select s from @sql order by id ","pontos":26},{"corpo":" It's just not possible. There is always the PrintScreen button. I remember testing ImageFreeze years ago. It used a Java applet to fetch and display images. The image data and connection was encrypted and the unencrypted image wasn't stored in a temp folder or even in Java's cache. Also, the applet constantly cleared the windows clipbrd so Print Screen didn't work. It worked pretty good, but it had some faults. Besides requiring Java, the JS that embedded the applet (and maybe the applet itself) was setup to not load properly in any browser that didn't give access to the windows clipbrd. This meant that it only worked in IE and only on windows. Also, the interval the applet used to clear the clipbrd could be beaten with a really fast Print Screen and ctrl+v into Gimp. Printing the screen in other ways would work too. Finally, Jad could decompile the applet and all/most of its files. So, if you really wanted the pics, you could poke around in the source to figure out how they did it. In short, you can go out of your way to stop a lot of people, but usability goes down the drain and there will always be a way to get the image if the visitor can see it. ","pontos":1},{"corpo":"I hate cursors with a passion... but here's a dodgy cursor version... Declare @NewName Varchar(50) Declare @OldName Varchar(50) Declare @CountNum int Set @CountNum = 0 DECLARE nameCursor CURSOR FOR SELECT Name FROM NameTest OPEN nameCursor FETCH NEXT FROM nameCursor INTO @NewName WHILE @@FETCH_STATUS = 0 BEGIN if @OldName @NewName BEGIN Print @OldName + ' (' + Cast(@CountNum as Varchar(50)) + ')' Set @CountNum = 0 END SELECT @OldName = @NewName FETCH NEXT FROM nameCursor INTO @NewName Set @CountNum = @CountNum + 1 END Print @OldName + ' (' + Cast(@CountNum as Varchar(50)) + ')' CLOSE nameCursor DEALLOCATE nameCursor ","pontos":2},{"corpo":"There's no real way to unit test a database other than asserting that the tables exist, contain the expected columns, and have the appropriate constraints. But that's usually not really worth doing. You don't typically unit test the database. You usually involve the database in integration tests. You typically use your favourite automated unit testing framework to perform integration tests, which is why some people get confused, but they don't follow the same rules. You are allowed to involve the concrete implementation of many of your classes (because they've been unit tested). You are testing how your concrete classes interact with each other and with the database. ","pontos":24},{"corpo":"DBunit You can use this tool to export the state of a database at a given time, and then when you're unit testing, it can be rolled back to its previous state automatically at the beginning of the tests. We use it quite often where I work. ","pontos":11},{"corpo":"The usual solution to external dependencies in unit tests is to use mock objects - which is to say, libraries that mimic the behavior of the real ones against which you are testing. This is not always straightforward, and sometimes requires some ingenuity, but there are several good (freeware) mock libraries out there for .Net if you don't want to \"roll your own\". Two come to mind immediately: Rhino Mocks is one that has a pretty good reputation. NMock is another. There are plenty of commercial mock libraries available, too. Part of writing good unit tests is actually desinging your code for them - for example, by using interfaces where it makes sense, so that you can \"mock\" a dependent object by implmenting a \"fake\" version of its interface that nonetheless behaves in a predictable way, for testing purposes. In database mocks, this means \"mocking\" your own DB access layer with objects that return made up table, row, or dataset objects for your unit tests to deal with. Where I work, we typically make our own mock libs from scratch, but that doesn't mean you have to. ","pontos":5},{"corpo":"What you should do is run your tests from a blank copy of the database that you generate from a script. You can run your tests and then analyze the data to make sure it has exactly what it should after your tests run. Then you just delete the database, since it's a throwaway. This can all be automated, and can be considered an atomic action. ","pontos":1},{"corpo":" A virtual base class is a class that cannot be instantiated : you cannot create direct object out of it. I think you are confusing two very different things. Virtual inheritance is not the same thing as an abstract class. Virtual inheritance modifies the behaviour of function calls; sometimes it resolves function calls that otherwise would be ambiguous, sometimes it defers function call handling to a class other than that one would expect in a non-virtual inheritance. ","pontos":7},{"corpo":"You're being a little confusing. I dont' know if you're mixing up some concepts. You don't have a virtual base class in your OP. You just have a base class. You did virtual inheritance. This is usually used in multiple inheritance so that multiple derived classes use the members of the base class without reproducing them. A base class with a pure virtual function is not be instantiated. this requires the syntax that Paul gets at. It is typically used so that derived classes must define those functions. I don't want to explain any more about this because I don't totally get what you're asking. ","pontos":1},{"corpo":"I'd like to add to OJ's kind clarifications. Virtual inheritance doesn't come without a price. Like with all things virtual, you get a performance hit. There is a way around this performance hit, that is questionably less elegant. Instead of breaking the diamond by deriving virtually, you can add another layer to the diamond, to get something like this: B / \\ D11 D12 | | D21 D22 \\ / DD Non of the class inherit virtuall, all inherit publicaly. Classes D21 and D22 will then hide virtual function f() which is ambiguous for DD, perhaps by declaring the function private. They'd each define a wrapper function, f1() and f2() respectively, each calling class-local (private) f(), thus resolving conflicts. Class DD calls f1() if it wants D11::f() and f2() if it wants D12::f(). If you define the wrappers inline you'll probably get about zero overhead. Of course, if you can change D11 and D12 then you can do the same trick inside these classes, but often that is not the case. ","pontos":5},{"corpo":"The problem you are having is clear, recursion in SQL. You need to get the parent of the parent... of the leaf and updates it's total (either subtracting the old and adding the new, or recomputing). You need some form of identifier to see the structure of the tree, and grab all of a nodes children and a list of the parents/path to a leaf to update. This method adds constant space (2 columns to your table --but you only need one table, else you can do a join later). I played around with a structure awhile ago that used a hierarchical format using 'left' and 'right' columns (obviously not those names), calculated by a pre-order traversal and a post-order traversal, respectively --don't worry these don't need to be recalculated every time. I'll let you take a look at a page using this method in mysql instead of continuing this discussion in case you don't like this method as an answer. But if you like it, post/edit and I'll take some time and clarify. ","pontos":1},{"corpo":"I think you should benchmark and take a look at what you are doing to determine if stat() is the slowest part of your code. Stating 1 file on each request on a server that gets about 100 hits/day is not a problem. Stating every file could be a problem when you have to eek out a few more requests a second. You can avoid stating the same file repeatedly by caching the results via memcached, apc or some other in-memory caching system. Premature optimization is the root of all evil. - Donald Knuth ","pontos":0},{"corpo":"Just follow closely the chain of events. Grab 10 Grab 20 Grab 30 Grab EOF Look at the second-to-last iteration. You grabbed 30, then carried on to check for EOF. You haven't reached EOF because the EOF mark hasn't been read yet (\"binarically\" speaking, its conceptual location is just after the 30 line). Therefore you carry on to the next iteration. x is still 30 from previous iteration. Now you read from the stream and you get EOF. x remains 30 and the ios::eofbit is raised. You output to stderr x (which is 30, just like in the previous iteration). Next you check for EOF in the loop condition, and this time you're out of the loop. Try this: while (true) { int x; iFile x; if( iFile.eof() ) break; cerr x endl; } By the way, there is another bug in your code. Did you ever try to run it on an empty file? The behaviour you get is for the exact same reason. ","pontos":69},{"corpo":"@MrBrutal I love Notepad2 as well. The only problem is it's lame with large files. :( ","pontos":1},{"corpo":"In my code, I find that MOST exceptions percolate up to a UI layer where they are caught by my exception handlers which simply display a message to the user (and write to the log). It's an unexpected exception, after all. Sometimes, I do want to catch a specific exception (as you seem to want to do). You'll probably find, however, that this is somewhat rare and that it is indicative of using exceptions to control logic -- which is inefficient (slow) and often frowned upon. So using your example, if you want to run some special logic when the email server is not configured, you may want to add a method to the emailUtil object like: public bool isEmailConfigured() ... call that first, instead of looking for a specific exception. When an exception does happen, it really means that the situation was completely unexpected and the code can't handle it -- so the best you can do is report it to the user (or write it to a log or restart ) As for having an exception hierarchy vs exceptions-with-error-codes-in-them, I typically do the latter. It's easier to add new exceptions, if you just need to define a new error constant instead of a whole new class. But, it doesn't matter much as long as you try to be consistent throughout your project. ","pontos":10},{"corpo":"From a purely theoretical stance: The implementation I am familiar with would be to build a Deterministic Finite Automaton to recognize the regex. This is done in O(2^m), m being the size of the regex, using a standard algorithm. Once this is built, running a string through it is linear in the length of the string - O(n), n being string length. A replacement on a match found in the string should be constant time. So overall, I suppose O(2^m + n). ","pontos":11},{"corpo":"Have you looked at as3corelib? It appears to provide an AS3 parser for JSON data, and my hope would be that it doesn't rely upon eval (eval tends to be bad for security as you noted). There are similar libs for Javascript as well, and they tend to be the preferred way to parse json due to the security implications of calling eval on (potentially) evil data. ","pontos":2},{"corpo":"I generally only derive my own collection classes if I need to \"add value\". Like, if the collection itself needed to have some \"metadata\" properties tagging along with it. ","pontos":2},{"corpo":"I've been going back and forth on 2 options: public class BusinessObjectCollection : List BusinessObject {} or methods that just do the following: public IEnumerable BusinessObject GetBusinessObjects(); The benefits of the first approach is that you can change the underlying data store without having to mess with method signatures. Unfortunately if you inherit from a collection type that removes a method from the previous implementation, then you'll have to deal with those situations throughout your code. ","pontos":4},{"corpo":"6 of 1, half dozen of another Either way its the same thing. I only do it when I have reason to add custom code into the BusinessObjectCollection. With out it having load methods return a list allows me to write more code in a common generic class and have it just work. Such as a Load method. ","pontos":0},{"corpo":"You should probably avoid creating your own collection for that purpose. It's pretty common to want to change the type of data structure a few times during refactorings or when adding new features. With your approach, you would wind up with a separate class for BusinessObjectList, BusinessObjectDictionary, BusinessObjectTree, etc. I don't really see any value in creating this class just because the classname is more readable. Yeah, the angle bracket syntax is kind of ugly, but it's standard in C++, C# and Java, so even if you don't write code that uses it you're going to run into it all the time. ","pontos":3},{"corpo":"Instead of using exceptions, I tend to return a list of status objects from methods that may have problems executing. The status objects contain a severity enum (information, warning, error, ...) a status object name like \"Email Address\" and a user readable message like \"Badly formatted Email Address\" The calling code would then decide which to filter up to the UI and which to handle itself. Personally, I think exceptions are strictly for when you can't implement a normal code solution. The performance hit and handling restrictions are just a bit too much for me. Another reason for using a list of status objects is that identifying multiple errors (such as during validation) is MUCH easier. After all, you can only throw one exception which must be handled before moving on. Imagine a user submitting an email that had a malformed destination address and contained language that you are blocking. Do you throw the malformed email exception, then, after they fix that and resubmit, throw a bad language exception? From a user experience perspective dealing with all of them at once is a better way to go. UPDATE: combining answers @Jonathan: My point was that I can evaluate the action, in this case sending an email, and send back multiple failure reasons. For example, \"bad email address\", \"blank message title\", etc.. With an exception, you're limited to just percolating the one problem then asking the user to resubmit at which point they find out about a second problem. This is really bad UI design. Reinventing the wheel.. possibly. However, most applications should analyze the whole transaction in order to give the best possible information to the user. Imagine if your compiler stopped dead at the first error. You then fix the error and hit compile again only to have it stop again for a different error. What a pain in the butt. To me, that's exactly the problem with throwing exceptions and hence the reason I said to use a different mechanism. ","pontos":1},{"corpo":"Pat Notz is correct. You can get the commit back so long as it's been within a few days. git only garbage collects after about a month or so unless you explicitly tell it to remove newer blobs. $ git init Initialized empty Git repository in .git/ $ echo \"testing reset\" file1 $ git add file1 $ git commit -m 'added file1' Created initial commit 1a75c1d: added file1 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 file1 $ echo \"added new file\" file2 $ git add file2 $ git commit -m 'added file2' Created commit f6e5064: added file2 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 file2 $ git reset --hard HEAD^ HEAD is now at 1a75c1d... added file1 $ cat file2 cat: file2: No such file or directory $ git reflog 1a75c1d... HEAD@{0}: reset --hard HEAD^: updating HEAD f6e5064... HEAD@{1}: commit: added file2 $ git reset --hard f6e5064 HEAD is now at f6e5064... added file2 $ cat file2 added new file You can see in the example that the file2 was removed as a result of the hard reset, but was put back in place when I reset via the reflog. ","pontos":789},{"corpo":"Eric, You are dead on. For any really scalable / easily maintained / robust application the only real answer is to dispense with all the garbage and stick to the basics. I've followed a similiar trajectory with my career and have come to the same conclusions. Of course, we're considered heretics and looked at funny. But my stuff works and works well. Every line of code should be looked at with suspicion. ","pontos":16},{"corpo":"I use generic lists for almost all scenarios. The only time that I would consider using a derived collection anymore is if I add collection specific members. However, the advent of LINQ has lessened the need for even that. ","pontos":1},{"corpo":"Static methods are not instance methods. There's no instance context, therefore to implement it from the interface makes little sense. ","pontos":6},{"corpo":"I'll answer your question with an example. Suppose we had a Math class with a static method add. You would call this method like so: Math.add(2, 3); If Math were an interface instead of a class, it could not have any defined functions. As such, saying something like Math.add(2, 3) makes no sense. ","pontos":14},{"corpo":"The reason why you can't have a static method in an interface lies in the way Java resolves static references. Java will not bother looking for an instance of a class when attempting to execute a static method. This is because static methods are not instance dependent and hence can be executed straight from the class file. Given that all methods in an interface are abstract, the VM would have to look for a particular implementation of the interface in order to find the code behind the static method so that it could be executed. This then contradicts how static method resolution works and would introduce an inconsistency into the language. ","pontos":31},{"corpo":" Updating all rows of the customer table because you forgot to add the where clause. That was exactly i did :| . I had updated the password column for all users to a sample string i had typed onto the console. The worst part of it was i was accessing the production server and i was checking out some queries when i did this. My seniors then had to revert an old backup and had to field some calls from some really disgruntled customers. Ofcourse there is another time when i did use the delete statement, which i don't even want to talk about ;-) ","pontos":0},{"corpo":"I tend to have less Exception types, although it's not really the OO way to do it. Instead I put an enum to my custom Exceptions, which classifies the Exception. Most of the time I have a custom base Exception, which holds on to a couple of members, which can be overridden or customized in derived Exception types. A couple of months ago I blogged about the idea of how to internationalize Exceptions. It includes some of the ideas mentioned above. ","pontos":0},{"corpo":"It is possible to recover it if Git hasn't garbage collected yet. Get an overview of dangling commits with : $ git fsck --lost-found dangling commit b72e67a9bb3f1fc1b64528bcce031af4f0d6fcbf Recover the dangling commit with rebase: $ git rebase b72e67a9bb3f1fc1b64528bcce031af4f0d6fcbf ","pontos":48},{"corpo":"Add a 'Generic Handler' to your web project, name it something like Image.ashx. Implement it like this: public class ImageHandler : IHttpHandler { public void ProcessRequest(HttpContext context) { using(Image image = GetImage(context.Request.QueryString[\"ID\"])) { context.Response.ContentType = \"image/jpeg\"; image.Save(context.Response.OutputStream, ImageFormat.Jpeg); } } public bool IsReusable { get { return true; } } } Now just implement the GetImage method to load the image with the given ID, and you can use asp:Image runat=\"server\" ImageUrl=\"~/Image.ashx?ID=myImageId\" / to display it. You might want to think about implementing some form of caching in the handler too. And remember if you want to change the image format to PNG, you need to use an intermediate MemoryStream (because PNGs require a seekable stream to be saved). ","pontos":18},{"corpo":"This is relatively easy: git checkout -b fake_master master # fake_master now points to the same commit as master git branch -D master # get rid of incorrect master git checkout -b master real_master # master now points to your actual master git checkout master # optional -- switch on to your master branch ","pontos":6},{"corpo":"Start on , create a branch called , then reset to an earlier commit. $ git branch in-progress $ git reset --hard HEAD^ ","pontos":12},{"corpo":"annotate, available via that link or as in the Debian package. $ echo -e \"a\\nb\\nc\" lines $ annotate-output cat lines 17:00:47 I: Started cat lines 17:00:47 O: a 17:00:47 O: b 17:00:47 O: c 17:00:47 I: Finished with exitcode 0 ","pontos":40},{"corpo":"This post claims to have a link to a video that shows how to use VB9's XML Literals in C#. However, it only really discusses them and from what I can gather, you cannot use them in C#. http://blogs.msdn.com/bethmassi/archive/2008/07/03/teched-panel-vb-xml-literals-for-c-developers.aspx ","pontos":4},{"corpo":"Before burning the house down to catch a fly with NOLOCK all over, you may want to take a look at that deadlock graph you should've captured with Profiler. Remember that a deadlock requires (at least) 2 locks. Connection 1 has Lock A, wants Lock B - and vice-versa for Connection 2. This is an unsolvable situation, and someone has to give. What you've shown so far is solved by simple locking, which Sql Server is happy to do all day long. I suspect you (or LINQ) are starting a transaction with that UPDATE statement in it, and SELECTing some other piece of info before hand. But, you really need to backtrack through the deadlock graph to find the locks held by each thread, and then backtrack through Profiler to find the statements that caused those locks to be granted. I expect that there's at least 4 statements to complete this puzzle (or a statement that takes multiple locks - perhaps there's a trigger on the Posts table?). ","pontos":9},{"corpo":"The handler really shouldn't be called unless the loader was fully loaded, it makes no sense. Have you confirmed that it is in fact not fully loaded (by looking at the vs. values that you trace)? If the event is dispatched before that is a bug. Good that you've got it working with the timer, but it is very odd that you need it. ","pontos":0},{"corpo":"I think the article \"Java theory and practice: A brief history of garbage collection\" from IBM should help explain some of the questions you have. ","pontos":7},{"corpo":"Well, I don't seen any difference between catching a general exception or a specific one, except that when having multiple catch blocks, you can react differently depending on what the exception is. You will catch both IOException and NullPointerException with a generic Exception, but the way you program should react is probably different. ","pontos":1},{"corpo":"I think a good guideline is to catch only specific exceptions from within a framework (so that the host application can deal with edge cases like the disk filling up etc), but I don't see why we shouldn't be able to catch all exceptions from our application code. Quite simply there are times where you don't want the app to crash, no matter what might go wrong. ","pontos":0},{"corpo":"Most of the time catching a general exception is not needed. Of course there are situations where you don't have a choice, but in this case I think it's better to check why you need to catch it. Maybe there's something wrong in your design. ","pontos":0},{"corpo":"Unless you are doing some logging and clean up code in the front end of your application, then I think it is bad to catch all exceptions. My basic rule of thumb is to catch all the exceptions you expect and anything else is a bug. If you catch everything and continue on, it's a bit like putting a sticking plaster over the warning light on your car dashboard. You can't see it anymore, but it doesn't mean everything is ok. ","pontos":12},{"corpo":"Yes! (except at the \"top\" of your application) By catching an exception and allowing the code execution to continue, you are stating that you know how do deal with and circumvent, or fix a particular problem. You are stating that this is a recoverable situation. Catching Exception or SystemException means that you will catch problems like IO errors, network errors, out-of-memory errors, missing-code errors, null-pointer-dereferencing and the likes. It is a lie to say that you can deal with these. In a well organised application, these unrecoverable problems should be handled high up the stack. In addition, as code evolves, you don't want your function to catch a new exception that is added in the future to a called method. ","pontos":8},{"corpo":"In my opinion you should catch all exceptions you expect, but this rule applies to anything but your interface logic. All the way down the call stack you should probably create a way to catch all exceptions, do some logging/give user feedback and, if needed and possible, shut down gracefully. Nothing is worse than an application crashing with some user unfriendly stacktrace dumped to the screen. Not only does it give (perhaps unwanted) insight into your code, but it also confuses your end-user, and sometimes even scares them away to a competing application. ","pontos":5},{"corpo":"There are drawbacks of using reference counting. One of the most mentioned is circular references: Suppose A references B, B references C and C references B. If A were to drop its reference to B, both B and C will still have a reference count of 1 and won't be deleted with traditional reference counting. CPython (reference counting is not part of python itself, but part of the C implementation thereof) catches circular references with a separate garbage collection routine that it runs periodically... Another drawback: Reference counting can make execution slower. Each time an object is referenced and dereferenced, the interpreter/VM must check to see if the count has gone down to 0 (and then deallocate if it did). Garbage Collection does not need to do this. Also, Garbage Collection can be done in a separate thread (though it can be a bit tricky). On machines with lots of RAM and for processes that use memory only slowly, you might not want to be doing GC at all! Reference counting would be a bit of a drawback there in terms of performance... ","pontos":33},{"corpo":"Interesting. I don't know, but I did try this: now = time.mktime((2008, 8, 22, 11 ,17, -1, -1, -1, -1)) tomorrow = time.mktime((2008, 8, 23, 11 ,17, -1, -1, -1, -1)) tomorrow - now 86400.0 which is what you expected. My guess? Maybe some time correction was done since the epoch. This could be only a few seconds, something like a leap year. I think I heard something like this before, but can't remember exactly how and when it is done... ","pontos":0},{"corpo":"Short answer: Because of timezones. The Epoch is in UTC. For example, I'm on IST (Irish Stsandard Time) or GMT+1. time.mktime() is relative to my timezone, so on my system this refers to time.mktime((2009, 1, 31, 0, 0, 0, 5, 31, -1)) 1233360000.0 Because you got the result 1233378000, that would suggest that you're 5 hours behind me (1233378000 - 1233360000) / (60*60) 5 Have a look at the time.gmtime() function which works off UTC. ","pontos":7},{"corpo":"If it is just an internal application, then you can avoid printing from the browser, and send a printout directly from the server to the nearest printer to the user. ","pontos":0},{"corpo":"Using fck for some tine now, after \"free text box\", or something like that. Had problems only once, when I put fck inside asp.net ajax updatepanel, but found fix on forums. Problem was solved in next release. I would like to see some nice photo browser in it, because fck comes only with simple browser that displays filename, no thumbs. The other one, that has thumbs costs bunch of money. Didn't try it with asp.net mvc, don't know how will uploading work. It uses one ascx for wrapping js functionality. ","pontos":1},{"corpo":"The problem with catching all exceptions is that you may be catching ones that you don't expect, or indeed ones that you should not be catching. The fact is that an exception of any kind indicates that something has gone wrong, and you have to sort it out before continuing otherwise you may end up with data integrity problems and other bugs that are not so easy to track down. To give one example, in one project I implemented an exception type called CriticalException. This indicates an error condition that requires intervention by the developers and/or administrative staff otherwise customers get incorrectly billed, or other data integrity problems might result. It can also be used in other similar cases when merely logging the exception is not sufficient, and an e-mail alert needs to be sent out. Another developer who didn't properly understand the concept of exceptions then wrapped some code that could potentially throw this exception in a generic try...catch block which discarded all exceptions. Fortunately, I spotted it, but it could have resulted in serious problems, especially since the \"very uncommon\" corner case that it was supposed to catch turned out to be a lot more common than I anticipated. So in general, catching generic exceptions is bad unless you are 100% sure that you know exactly which kinds of exceptions will be thrown and under which circumstances. If in doubt, let them bubble up to the top level exception handler instead. A similar rule here is never throw exceptions of type System.Exception. You (or another developer) may want to catch your specific exception higher up the call stack while letting others go through. (There is one point to note, however. In .NET 2.0, if a thread encounters any uncaught exceptions it unloads your whole app domain. So you should wrap the main body of a thread in a generic try...catch block and pass any exceptions caught there to your global exception handling code.) ","pontos":2},{"corpo":"I haven't looked up the whole thing, but the problem lies somewhere in the style sheets. If you copy out only the table part of it, it is displaying the map correctly. If you remove the final tag from this part, it is also working (however the page gets mixed): div class=\"inner\" span class=\"corners-top\" span /span /span div class=\"content\" style=\"font-size: 1.1em;\" !-- Stackoverflow findy thingy -- table border=\"0\" cellspacing=\"0\" cellpadding=\"0\" So either try from the beginning with the css or try to remove one-by-one them, to see, which is causing the problem. ","pontos":1},{"corpo":"I heard that TypeMock is often being used to refactor legacy code. ","pontos":0},{"corpo":"Phil's answer really solved it, but I'll elaborate a little more. Since the epoch is in UTC, if I want to compare other times to the epoch, I need to interpret them as UTC as well. calendar.timegm((2009, 1, 31, 0, 0, 0, 5, 31, -1)) 1233360000 1233360000 / (60*60*24) 14275 By converting the time tuple to a timestamp treating is as UTC time, I get a number which is evenly divisible by the number of seconds in a day. I can use this to convert a date to a days-from-the-epoch representation which is what I'm ultimately after. ","pontos":1},{"corpo":"I think you need to use on your images. When images are there's a little extra space for the line spacing. ","pontos":10},{"corpo":"One nice approach I've used lately is to add an event handler for the AppDomain's AssemblyResolve event. AppDomain currentDomain = AppDomain.CurrentDomain; currentDomain.AssemblyResolve += new ResolveEventHandler(MyResolveEventHandler); Then in the event handler method you can load the assembly that was attempted to be resolved using one of the Assembly.Load, Assembly.LoadFrom overrides and return it from the method. EDIT: Based on your additional information I think using the technique above, specifically resolving the references to an assembly yourself is the only real approach that is going to work without restructuring your app. What it gives you is that the location of each and every assembly that the CLR fails to resolve can be determined and loaded by your code at runtime... I've used this in similar situations for both pluggable architectures and for an assembly reference integrity scanning tool. ","pontos":12},{"corpo":"I think OpenID is far too confusing and clunky to force on any user, and I'm not even convinced it's solving an authentic problem. Having to register on each site I use has never struck me as a major issue. Particularly as it doesn't especially solve that problem; when I linked my OpenID to StackOverflow I had to fill out extra details anyway. It might as well have had a regular registration process for all the difference it makes. ","pontos":1},{"corpo":"Well.. I'd have liked a simple login-pwd combo (that I'd breeze thru with Passwordmaker.org). However being a developer, I can understand that they didnt want to reinvent the login wheel again... OpenID: I enter my blog url => Google sign in => I'm in. It's an extra level.. but it's OK. ","pontos":1},{"corpo":"That sounds just right to me. Exceptions are preferable as they can be thrown up to the top of the service layer from anywhere inside the service layer, no matter how deeply nested inside the service method implementation it is. This keeps the service code clean as you know the calling presenter will always get notification of the problem. Don't catch Exception However, don't catch Exception in the presenter, I know its tempting because it keeps the code shorter, but you need to catch specific exceptions to avoid catching the system-level exceptions. Plan a Simple Exception Hierarchy If you are going to use exceptions in this way, you should design an exception hierarchy for your own exception classes. At a minumum create a ServiceLayerException class and throw one of these in your service methods when a problem occurs. Then if you need to throw an exception that should/could be handled differently by the presenter, you can throw a specific subclass of ServiceLayerException: say, AccountAlreadyExistsException. Your presenter then has the option of doing try { // call service etc. // handle success to view } catch (AccountAlreadyExistsException) { // set the message and some other unique data in the view } catch (ServiceLayerException) { // set the message in the view } // system exceptions, and unrecoverable exceptions are allowed to bubble // up the call stack so a general error can be shown to the user, rather // than showing the form again. Using inheritance in your own exception classes means you are not required to catch multipile exceptions in your presenter -- you can if there's a need to -- and you don't end up accidentally catching exceptions you can't handle. If your presenter is already at the top of the call stack, add a catch( Exception ) block to handle the system errors with a different view. I always try and think of my service layer as a seperate distributable library, and throw as specific an exception as makes sense. It is then up to the presenter/controller/remote-service implementation to decide if it needs to worry about the specific details or just to treat problems as a generic error. ","pontos":11},{"corpo":"The key thing is that the person in question needs to have some problem that they want solving. If you don't have a program that you want to write (and something sensible and well-defined, not \"I want to write the next Quake!\") then you can't learn to program, because you have nothing to motivate you. I mean, you could read a book and have a rough understanding of a language's syntax and semantics, but until you have a program that you want written you'll never grasp the nettle. If that impetus exists then everything else is just minor details. ","pontos":11},{"corpo":"Actually, in the case of StackOverflow, a separate account would have saved me a lot of trouble. I decided to use my WordPress.com OpenID, since that's where I'm hosting my blog, but it turned out that WordPress.com have serious problems with their OpenID service, and most of the time I am not able to log on to StackOverflow at all. Of course, I can use a different OpenID provider to log on with, but then I will have a different identity on the site. I guess you could say WordPress.com is to blame for this, but the problem reimains the same. By using OpenID you are depending on another site's service to function. Any problems on the third party's site will in effect also disable your site. As an alternative solution i tried signing in with my Yahoo OpenID, but then I got some random string as the user name, and as DrPizza already pointed out, I would have to edit my personal details anyway. OpenID is a nice idea, but it's still not something I would rely on with the current state of things. ","pontos":0},{"corpo":"Also, SSO (as you mentioned) usually implies that I only have to login once (presumably to my workstation) and then from there on, I don't need to sign-in anywhere. OpenID of course doesn't solve that problem. For example, if I use OpenID to sign in to StackOverflow, it doesn't mean I don't need to sign in to another website again using the same openID. ","pontos":6},{"corpo":"Unless your code is already architectured to allow for \"hot swapping\" of your model layer backend, changing it in any way will always be extremely risky. Trying to build a safety net of unit tests on poorly architected code isn't going to guarantee success, only make you feel safer about changing it. So, unless you have a strong business case for taking on the risks involved it's probably best to leave well enough alone. ","pontos":0},{"corpo":"Couldn't agree more with what's being said. Fail early, fail fast. Pretty good Exception mantra. The question about which Exception to throw is mostly a matter of personal taste. In my mind IllegalArgumentException seems more specific than using a NPE since it's telling me that the problem was with an argument I passed to the method and not with a value that may have been generated while performing the method. My 2 Cents ","pontos":6},{"corpo":" Is the device running out of memory and therefore gives up the ghost when it requires the additional memory to stop at the breakpoint? No, there's over a gig of RAM to go, and even more of virtual memory. ","pontos":0},{"corpo":"I'm not sure I quite understand what you are getting at, but here's a few things I can suggest you can try... This behaviour changes between different versions of Delphi. I'd suggest that this is due to the hoops they jumped through to support Windows Vista in Delphi 2007. If you are using Delphi 2007, try removing the line from the project source file that sets the Application.MainFormOnTaskBar boolean variable. With this removed, you should be able to use the various Form's BringToFront / SendToBack methods to achieve the Z-ordering that you are after. I suspect that what you've discovered has been discussed on this link Of course, I may have just missed your point entirely, so apologies in advance! ","pontos":0},{"corpo":"If the ID's prefix added by ASP.NET is an issue for you to access them later using JS or something... you have the .ClientID property server side. If the overhead added by ASP.NET you should consider ASP.NET MVC (still preview) where you have full control over the emitted html. I'm moving to MVC because I don't like all that stuffs added too.... ","pontos":0},{"corpo":"Credit due to @Blorgbeard for sharing his script. I'll certainly bookmark it in case I need it. Yes, you can \"right click\" on the table and script the script, but: The a script will contain loads of cruft (interested in the extended properties anyone?) If you have 200+ tables in your schema, it's going to take you half a day to script the lot by hand. With this script converted into a stored procedure, and combined with a wrapper script you would have a nice automated way to dump your table design into source control etc. The rest of your DB code (SP's, FK indexes, Triggers etc) would be under source control anyway ;) ","pontos":3},{"corpo":"Visual Studio Team System does include something like this http://msdn.microsoft.com/en-us/library/aa833197(VS.80).aspx Not much help for Java though, so sorry. ","pontos":4},{"corpo":"There's a good set of slides on Ruby Blocks as part of the \"Rails with Passion\" course: Ruby_Blocks.pdf This covers representing a block, how they get passed arguments and executed, and even further into things like Proc objects. It's very clearly explained. It might then be of interest to look at how the JRuby guys handled these in their parsing to Java. Take a look at the source at codehaus. ","pontos":2},{"corpo":"That's an interesting problem because I suppose it depends on the quantity of each length you're producing. If they are all the same quantity and you can get Each different length onto one 5m extrusion then you have the optimum soloution. However if they don't all fit onto one extrusion then you have a greater problem. To keep the same amount of cuts for each length you need to calculate how many lengths (not necessarily in order) can fit on one extrusion and then go in an order through each extrusion. ","pontos":1},{"corpo":"This is a classic, difficult problem to solve efficiently. The algorithm you describe sounds like a Greedy Algorithm. Take a look at this Wikipedia article for more information: The Cutting Stock Problem ","pontos":7},{"corpo":"Basically a user control is a piece of server logic and UI. An HTTP Handler is only a piece of logic that is executed when a resource on your server is requested. For example you may decide to handle requests for images sent to your server through your own handler and serve images from a database instead of the file system. However, in this case there's no interface that the user sees and when he visits a URL on your server he would get the response you constructed in your own handler. Handlers are usually done for specific extensions and HTTP request types (POST, GET). Here's some more info on MSDN: http://msdn.microsoft.com/en-us/library/ms227675(VS.80).aspx ","pontos":1},{"corpo":"In my scenario, I am not using the built-in \"save\" button. I have a data connection that I use to \"post\" the data to another list. Yes, that's what I mean by site-specific. I don't think you can use localhost 'cos then when a user saves the form, it'll try to post to the user's computer (i.e. localhost). I have tried to use relative paths but that doesn't seem to work. ","pontos":0},{"corpo":"Have you tried putting in the standard library directories? It should be picked up by the linker if it's in one of those directories. For example: /lib/ /usr/lib/ /usr/share/lib/ /usr/local/lib/ ","pontos":0},{"corpo":"The \"Robert C Martin\" book, which was actually written by Michael Feathers (\"Uncle Bob\" is, it seems, a brand name these days!) is a must. It's near-impossible - not to mention insanely time-consuming - to put unit tests into an application not developed with them. The code just won't be amenable. But that's not a problem. Refactoring is about changing design without changing function (I hope I haven't corrupted the meaning too badly there) so you can work in a much broader fashion. Start out with big chunks. Set up a repeatable execution, and capture what happens as the expected result for subsequent executions. Now you have your app, or part of it at least, under test. Not a very good or comprehensive test, sure, but it's a start and things can only get better from there. Now you can start to refactor. You want to start extracting your data access code so that it can be replaced with ORM functionality without disturbing too much. Test often: with legacy apps you'll be surprised what breaks; cohesion and coupling are seldom what they might be. I'd also consider looking at Martin Fowler's Refactoring, which is, obviously enough, the definitive work on the process. ","pontos":2},{"corpo":"I have been doing that with a nokia phone, connected to a linux machine. I have a cron job and a script that would check a database table for new messages and use gnokii to send messages. It works great if the number of sms you are goig to send isn't to big. ","pontos":1},{"corpo":"Darren Thomas gives a good answer. However, one big difference between the Java and Python approaches is that with reference counting in the common case (no circular references) objects are cleaned up immediately rather than at some indeterminate later date. For example, I can write sloppy, non-portable code in CPython such as def parse_some_attrs(fname): return open(fname).read().split(\"~~~\")[2:4] and the file descriptor for that file I opened will be cleaned up immediately because as soon as the reference to the open file goes away, the file is garbage collected and the file descriptor is freed. Of course, if I run Jython or IronPython or possibly PyPy, then the garbage collector won't necessarily run until much later; possibly I'll run out of file descriptors first and my program will crash. So you SHOULD be writing code that looks like def parse_some_attrs(fname): with open(fname) as f: return f.read().split(\"~~~\")[2:4] but sometimes people like to rely on reference counting to always free up their resources because it can sometimes make your code a little shorter. I'd say that the best garbage collector is the one with the best performance, which currently seems to be the Java-style generational garbage collectors that can run in a separate thread and has all these crazy optimizations, etc. The differences to how you write your code should be negligible and ideally non-existent. ","pontos":11},{"corpo":"Would something like Web Access Framework: C++ Objects for Internet Programming be what you are looking for? ","pontos":0},{"corpo":"There's been a lot of philosophical discussions (more like arguments) about this issue. Personally, I believe the worst thing you can do is swallow exceptions. The next worst is allowing an exception to bubble up to the surface where the user gets a nasty screen full of technical mumbo-jumbo. ","pontos":4},{"corpo":"I'm pretty sure VC++ just inserts a return 0 if you don't include one in main functions. The same thing can happen with functions too, but in those cases at least you'll get a warning. ","pontos":2},{"corpo":"I wrote a script to do this a little while back. The script (Compare-QueryResults.ps1) is available here and you will also need my Run-SQLQuery script (available here) or you can replace that with a script or function of your own. Basically, what the script does is take the results of each of your queries and break the datarows apart so that each field is its own object. It then uses Compare-Object to check for any differences between the data in those rows. It returns a comparison object that shows you all the differences between the data returned. The results are an object, so you can save them to a variable and use Sort-Object or the Format-* cmdlets with them. Good luck. If you have any problems with the scripts, let me know, I'd be happy to walk you through them. I've been using them for application testing, seeing what rows are being modified by different actions in a program. ","pontos":3},{"corpo":"As for speeding up the IIS reset, Andrew Connell has some tips here as well http://www.andrewconnell.com/blog/archive/2006/08/21/3882.aspx This brought my IIS reset time from 10+ seconds down to less than 2 seconds. ","pontos":1},{"corpo":"Here are a few links that might be helpful as an overview. From my own experience, when I first started using MVC based web-frameworks the biggest issue I had was with the Models. Prying SQL out of my fingers and making me use Objects just felt strange. Once I started thinking of my data as Objects instead of SELECT statements it started getting easier. MVC In laymen's terms MVC: The Most Vexing Conundrum How to use Model-View-Controller ","pontos":0},{"corpo":"Next to the GOF Command Pattern you might also want to have a look at the Transaction Script pattern from P of EAA. You should probably create a Composite Command (or Transaction Script) that executes in sequence. ","pontos":1},{"corpo":"I have dealt with something similar, and the hardest part is figuring out exactly what you needed to \"fake\" to get authorized. In my case it was authorizing into some Lotus Notes webservice, but the details are unimportant, the method is the same. Essentially, we need to record a regular user session. I would recommend Fiddler http://www.fiddler2.com but if you're on linux or something, then you'll need to use wireshark to figure some of the things out. Not sure if there is a firefox plugin that could be used. Anyway, start up IE, then start up Fiddler. Complete the login process. Stop what you're doing. Switch to the fiddler pane, and examine the recorded sessions in detail. It should give you exactly what you need to fake using WebRequests. ","pontos":2},{"corpo":"When working with XML, always use the XML API that works with your programming environment. Don't try to roll your own XML document building and escaping code. As Longhorn213 mentioned, in .Net all the appropriate stuff is in the System.XML namespace. Trying to to write your own code for writing XML documents will just result in many bugs and troubles down the line. ","pontos":1},{"corpo":"ActiveRecord seems to be the state of the art at the moment. I can't recommend any good PHP frameworks for that though. I tried Propel which, while nice, is not easy to set up (especially on a host that you can't install anything on). Ultimately, I rolled my own ORM/ActiveRecord framework, which is not too much work and very instructive. I'm sure other people can recommend good PHP frameworks. ","pontos":3},{"corpo":"I don't entirely understand your question. Are you saying that files you check out on one machine seems to be unaccessible on another of your machines? I'd say that would be entirely by design, as now you have a file that has local modifications done on one machine, which may or may not be available on your other machines. When you say checked out by somebody else, what does that mean exactly? How are you verifying this, what are you looking at? Or do you mean something else? In that case, please elaborate. ","pontos":0},{"corpo":"I encountered a similar scenario a while back. A toolkit I was using did not behave well in a 64-bit environment and I wasn't able to find a way to dynamically force the assemblies to bind as 32 bit. It is possible to force your assemblies to work in 32 bit mode, but this requires patching the CLR header, (there is a tool that does that in the Framework) and if your assemblies are strongly-named, this does not work out. I'm afraid you'll need to build and publish two sets of binaries for 32 and 64 bit platforms. ","pontos":1},{"corpo":"I'm going to assume you mean \"workspace\", not \"workstation\", as your question doesn't quite make sense to me otherwise. In Visual Studio, go to the Source Control Explorer (View->Other Windows->Source Control Explorer). At the top of the source control explorer window you should have a toolbar with a few buttons. Somewhere on that toolbar (for me it's at the right) there should be a Workspace dropdown. Just select the workspace you want to use from that dropdown. ","pontos":19},{"corpo":"I guess the answer really is to not use WebSVN. ","pontos":0},{"corpo":"When it's for something that \"matters\", I plop down the $50 and have the folks at PickyDomains.com help out. That also results in a name that's available as a .com. For guidelines, here's an extract from my own guide on naming open source projects: If the name you're thinking of is directly pulled from a scifi or fantasy source, don't bother. These sources are WAY overrepresented as naming sources in software. Not only are your chances of coming up with something original pretty small, most of the names of characters and places in scifi are trademarked and you run the risk of being sued. If the name you're thinking of comes straight from Greek, Roman or Norse mythology, try again. We've got more than enough mail related software called variations of \"Mercury\". Run your proposed name through Google. The fewer results you get the better. If you get down to no results, you're there. Don't try to get a unique name by just slightly misspelling something. Calling your new Windows filesystem program Phat32 is just going to end up with users getting frustrated looking at the results of \"fat32\" in a search engine. If your name couldn't be said on TV in the 50s or 60s, you're probably on the wrong track. This is particularly true if you would like anyone to use your product in a work environment. No one is going to recommend a product to their co-workers if they can get sued for sexual harassment just for uttering its name. If your product name can't be pronounced at all, you'll get no word of mouth benefit at all. Similarly, if no one knows how to pronounce it, they will not be very likely to try to say it out loud to ask questions about it, etc. How do YOU say MySQL? PostgreSQL? GNU? Almost all spoken languages on Earth are based on consonant/vowel syllables of some sort. Alternating between consonants and vowels is a pretty good way to ensure that someone can pronounce it. The shorter the better. See if the .com domain is available. If it's not, it's a pretty good indicator that someone has already thought of it and is using it or closer to using it than you are. Do this even if you don't intend to use the domain. Don't build inherent limitations on your product into the name. Calling your product LinProduct or WinProduct precludes you from ever releasing any sort of cross-platform edition. Don't use your own name for open source products. If the project lives on beyond your involvement, the project will either have to be renamed or your name may be used in ways you didn't intend. ","pontos":23},{"corpo":"A couple of observations: Don't create simple delegates explicitly in code like that unless you're pre-2.0 so you could use: BeginInvoke(new EventHandler CoolObjectEventArgs (mCoolObject_CoolEvent), sender, args); Also you don't need to create and populate the object array because the args parameter is a \"params\" type so you can just pass in the list. I would probably favor over as the latter will result in the code being called asynchronously which may or may not be what you're after but would make handling subsequent exceptions difficult to propagate without a call to . What would happen is that your app will end up getting a instead. ","pontos":17},{"corpo":"You can use fseek() to clear the eof condition on the stream. Essentially, read to the end of the file, sleep for a while, fseek() (without changing your position) to clear eof, the read to end of file again. wash, rinse, repeat. man fseek(3) for details. Here's what it looks like in perl. perl's seek() is essentially a wrapper for fseek(3), so the logic is the same: wembley 0 /home/jj33/swap # cat p my $f = shift; open(I, \" $f\") || die \"Couldn't open $f: $!\\n\"; while (1) { seek(I, 0, 1); while (defined(my $l = I )) { print \"Got: $l\"; } print \"Hit EOF, sleeping\\n\"; sleep(10); } wembley 0 /home/jj33/swap # cat tfile This is some text in a file wembley 0 /home/jj33/swap # perl p tfile Got: This is Got: some Got: text Got: in Got: a file Hit EOF, sleeping Then, in another session: wembley 0 /home/jj33/swap echo \"another line of text\" tfile And back to the original program output: Hit EOF, sleeping Got: another line of text Hit EOF, sleeping ","pontos":4},{"corpo":"Just as an update in case anyone else has this problem, I installed the .Net 3.5 SP1 update separately. Now I'm down to \"only\" 5045MB required. ","pontos":0},{"corpo":"I was able to do this about a year ago, but I no longer remember all of the details. Basically, you can use IntPtr.Size to determine which DLL to load, then perform the actual LoadLibrary through p/Invoke. At that point, you've got the module in memory and you ought to be able to just p/Invoke functions from inside of it -- the same module name shouldn't get reloaded again. I think, though, that in my application I actually had the C++ DLL register itself as a COM server and then accessed its functionality through a generated .NET wrapper -- so I don't know if I ever tested p/Invoking directly. ","pontos":3},{"corpo":"You can try to develop some sort of a generic component that accepts a SynchronizationContext as input and uses it to invoke the events. ","pontos":0},{"corpo":"The architecture you are talking about could become very cumbersome in the long run, and if you need to change the questions it means more changes to the UDF you are using. I would think you could probably do your analysis in code without necessarily de-normalizing your database. De-normalization could also lend to inflexibility, or at least added expense to update, down the road. ","pontos":0},{"corpo":"What this probably means is that your Apache is only using 1 child process. Therefore: The 1 child process is handling a request (in this case sleeping but it could be doing real work, Apache can't tell the difference), so when a new request comes it, it will have to wait until the first process is done. The solution would be to increase the number of child processes Apache is allowed to spawn (MaxClients directive if you're using the prefork MPM), simply remove the sleep() from the PHP script. Without exactly knowing what's going on in your script it's hard to say, but you can probably get rid of the sleep(). ","pontos":4},{"corpo":"No way, you definitely want to keep it normalized. It's not even that hard of a query. Basically, you want to left join the students correct answers with the total answers for that question, and do a count. This will give you the percent correct. Do that for each student, and put the minimum percent correct in a where clause. ","pontos":0},{"corpo":"I think you should just shake this feeling of \"odd\". There's nothing odd about it. ","pontos":1},{"corpo":"Have you tried using Valgrind? That is usually the fastest and easiest way to debug these sorts of errors. If you are reading or writing outside the bounds of allocated memory, it will flag it for you. ","pontos":0},{"corpo":"Seems like dealing with licensing issues would be nightmarish for the host. ","pontos":0},{"corpo":" can return if no memory is available. You're not checking for that. ","pontos":21},{"corpo":"I run XCode on a 17\" iMac (2 yrs old) with 2GB of RAM and haven't had any trouble. ","pontos":3},{"corpo":"Well, is a greedy selector. You make it non-greedy by using When using the latter construct, the regex engine will, at every step it matches text into the attempt to match whatever make come after the . This means that if for instance nothing comes after the , then it matches nothing. Here's what I used. contains your original string. This code is .NET specific, but most flavours of regex will have something similar. ","pontos":1},{"corpo":"There's a couple of things. You're using which is inherently unsafe; unless you're 100% positive that you're not going to exceed the size of the buffer, you should almost always prefer . The same applies to ; prefer the safer alternative . Obviously this may not fix anything, but it goes a long way in helping spot what might otherwise be very annoying to spot bugs. ","pontos":4},{"corpo":" malloc can return NULL if no memory is available. You're not checking for that. Right you are... I didn't think about that as I was monitoring the memory and it there was enough free. Is there any way for there to be available memory on the system but for malloc to fail? Yes, if memory is fragmented. Also, when you say \"monitoring memory,\" there may be something on the system which occasionally consumes a lot of memory and then releases it before you notice. If your call to occurs then, there won't be any memory available. -- Joel Either way...I will add that check :) ","pontos":3},{"corpo":" You're using sprintf which is inherently unsafe; unless you're 100% positive that you're not going to exceed the size of the buffer, you should almost always prefer snprintf. The same applies to strcat; prefer the safer alternative strncat. Yeah..... I mostly do .NET lately and old habits die hard. I likely pulled that code out of something else that was written before my time... But I'll try not to use those in the future ;) ","pontos":0},{"corpo":"You know it might not even be your code... Are there any other programs running that could have a memory leak? ","pontos":0},{"corpo":"I don't know if there is a way to optimize UpdatePanels, but my company has found its performance to be pretty poor. jQuery is much much faster at doing pretty much anything. There can be a lot of lag between the time when an UpdatePanel triggers an update and when the UpdatePanel actually updates the page. The only reason we use UpdatePanels is because of the ease of development. Almost nothing needs to be done to make them work. ","pontos":6},{"corpo":"There are some minor differences, but I think later editions of K R are for ANSI C, so there's no real difference anymore. \"C Classic\" for lack of a better terms had a slightly different way of defining functions, i.e. int f( p, q, r ) int p, float q, double r; { // Code goes here } I believe the other difference was function prototypes. Prototypes didn't have to - in fact they couldn't - take a list of arguments or types. In ANSI C they do. ","pontos":6},{"corpo":"We use something similar to bcwoord to keep our database schemata synchronized across 5 different installations (production, staging and a few development installations), and backed up in version control, and it works pretty well. I'll elaborate a bit: To synchronize the database structure, we have a single script, update.php, and a number of files numbered 1.sql, 2.sql, 3.sql, etc. The script uses one extra table to store the current version number of the database. The N.sql files are crafted by hand, to go from version (N-1) to version N of the database. They can be used to add tables, add columns, migrate data from an old to a new column format then drop the column, insert \"master\" data rows such as user types, etc. Basically, it can do anything, and with proper data migration scripts you'll never lose data. The update script works like this: Connect to the database. Make a backup of the current database (because stuff will go wrong) [mysqldump]. Create bookkeeping table (called _meta) if it doesn't exist. Read current VERSION from _meta table. Assume 0 if not found. For all .sql files numbered higher than VERSION, execute them in order If one of the files produced an error: roll back to the backup Otherwise, update the version in the bookkeeping table to the highest .sql file executed. Everything goes into source control, and every installation has a script to update to the latest version with a single script execution (calling update.php with the proper database password etc.). We SVN update staging and production environments via a script that automatically calls the database update script, so a code update comes with the necessary database updates. We can also use the same script to recreate the entire database from scratch; we just drop and recreate the database, then run the script which will completely repopulate the database. We can also use the script to populate an empty database for automated testing. It took only a few hours to set up this system, it's conceptually simple and everyone gets the version numbering scheme, and it has been invaluable in having the ability to move forward and evolving the database design, without having to communicate or manually execute the modifications on all databases. Beware when pasting queries from phpMyAdmin though! Those generated queries usually include the database name, which you definitely don't want since it will break your scripts! Something like CREATE TABLE .(...) will fail if the database on the system is not called mydb. We created a pre-comment SVN hook that will disallow .sql files containing the string, which is a sure sign that someone copy/pasted from phpMyAdmin without proper checking. ","pontos":35},{"corpo":"There may be some confusion here about what \"K R C\" is. The term refers to the language as documented in the first edition of \"The C Programming Language.\" Roughly speaking: the input language of the Bell Labs C compiler circa 1978. Kernighan and Ritchie were involved in the ANSI standardization process. The \"ANSI C\" dialect superceded \"K R C\" and subsequent editions of \"The C Programming Language\" adopt the ANSI conventions. \"K R C\" is a \"dead language,\" except to the extent that some compilers still accept legacy code. ","pontos":19},{"corpo":"I think trying to use XmlHttpRequest will be a huge headache, unless its the type of headache you don't mind - to do it properly you're almost reinventing the wheel. Then again, people like to reinvent wheels in their spare time, just to say, \"Hey, I did it\". Not me... I would get a framework like prototype or Extjs, that has alot of data loading functions built in for XML and JSON, plus you'll get more predictable results, as the frameworks have event handlers to make sure your XmlHttpRequest succeeded or failed. Plus you get support for all the various browsers. ","pontos":0},{"corpo":"If you will be deploying on IIS 6 or IIS 7, just use the built-in IIS compression. We're using it on production sites for compressing HTML, CSS, and JavaScript with no errors. It also caches the compressed version on the server, so the compression hit is only taken once. ","pontos":0},{"corpo":"OK, here's a solution: preg_match( '/(?x)^J[0-9]{7}:\\s+ (.*?) #Extract the Transaction Start Date msg \\s+J[0-9]{7}:\\s+Project\\sname:\\s+ (.*?) #Extract the Project Name \\s+J[0-9]{7}:\\s+Job\\sname:\\s+ (.*?) #Extract the Job Name \\s+J[0-9]{7}:\\s+/' , $this- getResultVar('FullMessage'), $atmp); The key is (?x) at the beginning which makes whitespace insignificant and allows comments. It's also important that there's no whitespace between the starting and ending quotes and the start end of the regex. My first attempt like this gave errors: preg_match(' /(?x)^J[0-9]{7}:\\s+ (.*?) #Extract the Transaction Start Date msg \\s+J[0-9]{7}:\\s+Project\\sname:\\s+ (.*?) #Extract the Project Name \\s+J[0-9]{7}:\\s+Job\\sname:\\s+ (.*?) #Extract the Job Name \\s+J[0-9]{7}:\\s+/ ', $this- getResultVar('FullMessage'), $atmp); What Konrad said also works and feels a little easier than sticking (?x) at the beginning. ","pontos":1},{"corpo":"Is it only CSS files that get corrupted? Do JS files (or any other static text files) come through ok? Also can you duplicate the behavior if you browse directly to the CSS file? I've only enabled compression on Windows 2003 server's IIS using this approach: IIS  Web Sites  Properties  Service tab, check both boxes IIS  Web Service Extensions  Right click, Add New Name Http Compression Required Files %systemroot%\\system32\\inetsrv\\gzip.dll IIS  Right click top node, Internet Information Services, check Enable Direct Metabase Edit Backup and Edit Find Add , , and any other static file extensions to Add and any other executable extensions to Save Restart IIS (run ) If you have a Windows 2003/2008 server to play with you could try that approach. ","pontos":5},{"corpo":"As Cheekysoft suggests, I would tend to move all major exceptions into an ExceptionHandler and let those exceptions bubble up. The ExceptionHandler would render the appropriate view for the type of exception. Any validation exceptions however should be handled in the view but typically this logic is common to many parts of your application. So I like to have a helper like this public static class Try { public static List string This( Action action ) { var errors = new List string (); try { action(); } catch ( SpecificException e ) { errors.Add( \"Something went 'orribly wrong\" ); } catch ( ... ) // ... return errors; } } Then when calling your service just do the following var errors = Try.This( () = { // call your service here tasks.CreateMember( ... ); } ); Then in errors is empty, you're good to go. You can take this further and extend it with custome exception handlers which handle uncommon exceptions. ","pontos":3},{"corpo":"Yes, you can add the Pattern Modifier. This modifier turns on additional functionality of PCRE that is incompatible with Perl. Any backslash in a pattern that is followed by a letter that has no special meaning causes an error, thus reserving these combinations for future expansion. By default, as in Perl, a backslash followed by a letter with no special meaning is treated as a literal. There are at present no other features controlled by this modifier. For your example try this: preg_match('/ ^J[0-9]{7}:\\s+ (.*?) #Extract the Transaction Start Date msg \\s+J[0-9]{7}:\\s+Project\\sname:\\s+ (.*?) #Extract the Project Name \\s+J[0-9]{7}:\\s+Job\\sname:\\s+ (.*?) #Extract the Job Name \\s+J[0-9]{7}:\\s+ /x', $this- getResultVar('FullMessage'), $atmp); ","pontos":2},{"corpo":"I run XCode on a current-gen Macbook with only ONE GB of RAM and it runs fine, so long as I limit the amount of total applications running. ","pontos":6},{"corpo":"While the question touches on a couple of very debatable issues (OOP, User authentication) I'll skip by those and second Konrad's comment about __autoload. Anyone who knows C/C++ knows how much of a pain including files can be. With autoload, a PHP5 addition, if you choose to use OOP (which I do almost exclusively) you only need use some standard file naming convention and (I would recommend) restricting a single class per file and PHP will do the rest for you. Cleans up the code and you no longer have to worry about remembering to remove includes that are no longer necessary (one of the many problems with includes). ","pontos":4},{"corpo":"How will the user upload the photos? If you are writing an ASP page to accept the uploaded files then only the user that IIS runs as will need write permission to the folder, since IIS will be doing the file I/O. Your ASP page should check the file size and have some form of authentication to prevent hackers from filling your hard drive. If you are setting up an FTP server or some other file transfer method, then the answer will be specific to the method you choose. ","pontos":1},{"corpo":"Legally, you need to buy a Mac. It is \"possible\" to run (at least Tiger) in VMWare -- the experience is not optimal, but you can do it. It's also possible to run OS X on PC hardware; however, it's an exercise in illegal software and hacks. ","pontos":2},{"corpo":"Don't move to UpdatePanels. After coming from jQuery, the drop in performance would be untenable. Especially on a page as complex as yours sounds. If you have 2,000 lines of JavaScript code, the solution is to refactor that code. If you put 2,000 lines of C# code in one file, it would be difficult to maintain too. That would be difficult to manage effectively with any language or tool. If you're using 3.5 SP1, you can use the ScriptManager's new script combining to separate your JavaScript into multiple files with no penalty. That way, you can logically partition your code just as you would with server side code. ","pontos":37},{"corpo":"While you can differenciate the code execution looking the exception don't matter if it's done by the \"catch exceptionType hierarchy mode\" or by \"if(...) else...exception code mode\" but if you are developing software wich is going to be used by other people, like a library i think it's usefull create your own exception types to notice the other people that your sofware can throw other exceptions than the normal ones, and they better catch and resolve them. When i use a library and their methods simply launch an 'Exception' i allways wonder: What can cause this exception?, how must my program react?, if there is a javadoc maybe the cause will be explained, but mustly of times there is not a javadoc or the exception is not explained. Too much overhead witch can be avoided with a WellChossenExceptionTypeName ","pontos":0},{"corpo":"You pretty much have to keep the left side of your where clause clean. So, normally, you'd do something like: WHERE MyDateTime = @activityDateMidnight AND MyDateTime (@activityDateMidnight + 1) (Some folks prefer DATEADD(d, 1, @activityDateMidnight) instead - but it's the same thing). The TimeZone table complicates matter a bit though. It's a little unclear from your snippet, but it looks like t.TheDateInTable is in GMT with a Time Zone identifier, and that you're then adding the offset to compare against @activityDateMidnight - which is in local time. I'm not sure what ds.LocalTimeZone is, though. If that's the case, then you need to get @activityDateMidnight into GMT instead. ","pontos":8},{"corpo":"I can't see how licensing would be any different than for a co-lo provider. ","pontos":0},{"corpo":"The rule of thumb is to avoid Catching and Throwing the basic object. This forces you to be a little smarter about exceptions; in other words you should have an explicit catch for a so that your handling code doesn't do something wrong with a . In the real world though, catching and logging the base exception is also a good practice, but don't forget to walk the whole thing to get any it might have. ","pontos":12},{"corpo":"Easy Git has a nice page comparing actual usage of Git and SVN which will give you an idea of what things Git can do (or do more easily) compared to SVN. (Technically, this is based on Easy Git, which is a lightweight wrapper on top of Git.) ","pontos":6},{"corpo":"It is legal to run Mac OS X Server in a virtual machine on Apple hardware. All other forms of Mac OS X virtualization are currently forbidden. ","pontos":11},{"corpo":"I usually use and I can't think of the last time I used or read a use of . Don't forget about , depending on what you're doing in the loop! map { print \"$_ = $hash{$_}\\n\" } keys %hash; ","pontos":1},{"corpo":"You may also use: try { // Dangerous code } finally { // clean up, or do nothing } And any exceptions thrown will bubble up to the next level that handles them. ","pontos":1},{"corpo":"For the really gritty problems that would be too time consuming to use print_r/echo to figure out I use my IDE's (PhpEd) debugging feature. Unlike other IDEs I've used, PhpEd requires pretty much no setup. the only reason I don't use it for any problems I encounter is that it's painfully slow. I'm not sure that slowness is specific to PhpEd or any php debugger. PhpEd is not free but I believe it uses one of the open-source debuggers (like XDebug previously mentioned) anyway. The benefit with PhpEd, again, is that it requires no setup which I have found really pretty tedious in the past. ","pontos":5},{"corpo":"Please don't put your self in that world of pain. Instead use UFRAME which is a lot faster and is implemented in jQuery. Now, to manage those 2000 lines of Javascript code I recommend splitting the code in different files and set up your build process to join them using JSMin or Yahoo Compressor into chunks. ","pontos":10},{"corpo":"I couldn't agree with you more, HollyStyles. I also used to be a TSQL guy, and find some of Oracle's idiosyncrasies more than a little perplexing. Unfortunately, temp tables aren't as convenient in Oracle, and in this case, other existing SQL logic is expecting to directly query a table, so I give it this view instead. There's really no application logic that exists outside of the database in this system. Oracle developers do seem to use cursors much more eagerly than I would have thought. Given the bondage discipline nature of PL/SQL, that's all the more surprising. ","pontos":0},{"corpo":"In Python 2, use urllib2 which comes with the standard library. import urllib2 response = urllib2.urlopen('http://www.example.com/') html = response.read() This is the most basic way to use the library, minus any error handling. You can also do more complex stuff such as changing headers. The documentation can be found here. ","pontos":201},{"corpo":"Do not ever assume your user has access to certain key areas of the disc (i.e. program files, windows directory etc). Instead the default user account will only be able to write to a small section of their application data. Also, they won't be able to write to global areas of the registry - only the current user section. You can of course elevate their privileges, but that in itself is a task. Generally programming for Vista is the same as XP, it's just the new account restrictions you have to be wary of. Have a look at this page with regards to making your application \"UAC aware\" http://www.codeproject.com/KB/vista-security/MakingAppsUACAware.aspx ","pontos":5},{"corpo":"Is there a benefit to not having foreign keys? Unless you are using a crappy database, FKs aren't that hard to set up. So why would you have a policy of avoiding them? It's one thing to have a naming convention that says a column references another, it's another to know the database is actually verifying that relationship for you. ","pontos":5},{"corpo":"For myself, I have started insisting that every bug I find and fix be expressed as a test: \"Hmmm, that's not right...\" Find possible problem Write a test, show that the code fails Fix the problem Show that the new code passes Loop if the original problem persists I try to do this even while banging stuff out, and I get done in about the same time, only with a partial test suite already in place. (I don't live in a commercial programming environment, and am often the only coder working a particular project.) ","pontos":19},{"corpo":"Are you sure this is a problem with plink? It sounds to me like you have CVS/Root files lying around that still point to the old cvs ip address. In general, CVS doesn't make changing repositories into a fun process. Since you are using Windows, if you install WinCVS with macros support (Python module loaded) it has a macro that can be used to mass change CVS roots. Otherwise, its up to you to script the process. FWIW, I've used plink quite a bit and never had a similar problem. ","pontos":7},{"corpo":" Yes. Unless there's a feature we really need in a beta version. There's no point using a beta version in dev if you aren't certain you'll use it in production. That just seems like a wasted exercise I'll use the patch. Why write code for something you've paid for? ","pontos":0},{"corpo":"If you don't want an event interfering, you can set up the Validation Rule property for the textbox to be NOT LIKE \"*\"+Chr(10)+\"*\" OR \"*\"+Chr(13)+\"*\" You will probably also want to set the Validation Text to explain specifically why Access is throwing up an error box. ","pontos":0},{"corpo":"I've used beta libraries in commercial projects before but mostly during development and when the vendor is likely to release a final version before I finish the product. For example, I developed a small desktop application using Visual Studio 2005 Beta 2 because I knew that the RTM version would be available before the final release of my app. Also I used a beta version of FirebirdSQL ADO.NET Driver during development of another project. For bugs I try to post complete bug reports whenever there's a way to reproduce it but most of the time you have to find a workaround to release the application ASAP. ","pontos":1},{"corpo":" There's no point using a beta version in dev if you aren't certain you'll use it in production. That just seems like a wasted exercise Good point, I was also considering the scenario of evaluation of the pre-release version in dev, but I supposed that taints the dev -> test/qa -> prod path. I'll use the patch. Why write code for something you've paid for? What if it's not a commercial library, but an open source one? What if the patch to be applied is not from the releasing entity (e.g. your own patch)? ","pontos":0},{"corpo":"I'm not a database expert, and I do not speak from experience. However: MyISAM tables use table-level locking. Based on your traffic estimates, you have close to 200 writes per second. With MyISAM, only one of these could be in progress at any time. You have to make sure that your hardware can keep up with these transaction to avoid being overrun, i.e., a single query can take no more than 5ms. That suggests to me you would need a storage engine which supports row-level locking, i.e., InnoDB. On the other hand, it should be fairly trivial to write a few simple scripts to simulate the load with each storage engine, then compare the results. ","pontos":213},{"corpo":"+1 for PuTTy... been using it for the last decade and never needed anything else! ","pontos":0},{"corpo":"I use: Infragistics (.NET WinForms controls) LeadTools (video capture) Xtreme ToolkitPro (MFC controls) National Instruments Measurement Studio (computational libraries, plotting, and DAQ) I've found significant bugs in every one of these, so I try to limit their use as much as possible. Infragisitcs is pretty good for what it is, and National Instruments is by far the best, although quite limited. I would avoid LeadTools at all cost. ","pontos":0},{"corpo":"I just use simple questions that anyone can answer: What color is the sky? What color is an orange? What color is grass? It makes it so that someone has to custom program a bot to your site, which probably isn't worth the effort. If they do, you just change the questions. ","pontos":10},{"corpo":"By far the most painful part of moving an application from XP to Vista (from my point of view) is dealing with the numerous services and IPv6 stuff that uses ports which were previously free, and dealing with the Wireless Provisioning -> Native WiFi transition. The UAC stuff is basically a moot point; there is very little the application developer needs to do. ","pontos":0},{"corpo":"Interestingly, if you click on the screen (remove the focus from the textbox) on second example with only one textbox, the event onClick fires... So it's not an expected behaviour since it only occurs when you have just one textbox and you have the focus on the textbox. I'm afraid you've found a bug on the browser and you'll have to find a workaround, or avoid using the onClick event in that case. I use the onSubmit event for validations because it's a \"safer\" event that is more likely to work on different browsers and situations. ","pontos":1},{"corpo":"Out of curiosity, are you using a DOCTYPE, and if so, which one? I'm not saying incompatabilities with the DOCTYPE are the issue, but quirks mode is something to rule out before trying anything else. ","pontos":1},{"corpo":"Lose the parentheses and commas. Calling your function as: $s = CreateAppPoolScript \"name\" \"user\" \"pass\" gives: cscript adsutil.vbs CREATE \"w3svc/AppPools/name\" IIsApplicationPool cscript adsutil.vbs SET \"w3svc/AppPools/name/WamUserName\" \"user\" cscript adsutil.vbs SET \"w3svc/AppPools/name/WamUserPass\" \"pass\" cscript adsutil.vbs SET \"w3svc/AppPools/name/AppPoolIdentityType\" 3 ","pontos":31},{"corpo":"I'll have to look into that and get back to you. The problem on my end seems to be that there is code running in a different class, in a different feature, being controlled by a different thread, all of which are trying to access the same record. I am trying to avoid using a fixed delay. With any threading issue, there is the pathological possibility that one thread can delay or block beyond what we expect. With deployments on different server hardware with different loads, this is a very real possibility. On the other end of the spectrum, even if I were to go with a delay, I don't want it to be very high, especially not 30 seconds. My client will be importing tens of thousands of documents, and a delay of any significant length will cause the import to take literally all day. ","pontos":0},{"corpo":"Sounds like the controls aren't being databound properly after the postback. Are you databinding the first dropdown in the page or in the codebehind? If codebehind, are you doing it in oninit or onload every time? There might be an issue of the SelectedValue of the second drop down being set to a non-existent item after the postback. ","pontos":0},{"corpo":"Eric Z Beard: I do store all dates in GMT. Here's the use case: something happened at 11:00 PM EST on the 1st, which is the 2nd GMT. I want to see activity for the 1st, and I am in EST so I will want to see the 11PM activity. If I just compared raw GMT datetimes, I would miss things. Each row in the report can represent an activity from a different time zone. Right, but when you say you're interested in activity for Jan 1st 2008 EST: SELECT @activityDateMidnight = '1/1/2008', @activityDateTZ = 'EST' you just need to convert that to GMT (I'm ignoring the complication of querying for the day before EST goes to EDT, or vice versa): Table: TimeZone Fields: TimeZone, Offset Values: EST, -4 --Multiply by -1, since we're converting EST to GMT. --Offsets are to go from GMT to EST. SELECT @activityGmtBegin = DATEADD(hh, Offset * -1, @activityDateMidnight) FROM TimeZone WHERE TimeZone = @activityDateTZ which should give you '1/1/2008 4:00 AM'. Then, you can just search in GMT: SELECT * FROM EventTable WHERE EventTime = @activityGmtBegin --1/1/2008 4:00 AM AND EventTime (@activityGmtBegin + 1) --1/2/2008 4:00 AM The event in question is stored with a GMT EventTime of 1/2/2008 3:00 AM. You don't even need the TimeZone in the EventTable (for this purpose, at least). Since EventTime is not in a function, this is a straight index scan - which should be pretty efficient. Make EventTime your clustered index, and it'll fly. ;) Personally, I'd have the app convert the search time into GMT before running the query. ","pontos":2},{"corpo":"Set a short timeout? Does not get you what you want? You could always build a class that spins up in its own and repeatedly tries to write empty strings to the until that raises a . ","pontos":0},{"corpo":"As with most issues, it's not as simple as it sounds. There are cases where it would make sense to store the images in the database. You are storing images that are changing dynamically, say invoices and you wanted to get an invoice as it was on 1 Jan 2007? The government wants you to maintain 6 years of history Images stored in the database do not require a different backup strategy. Images stored on filesystem do It is easier to control access to the images if they are in a database. Idle admins can access any folder on disk. It takes a really determined admin to go snooping in a database to extract the images On the other hand there are problems associated Require additional code to extract and stream the images Latency may be slower than direct file access Heavier load on the database server ","pontos":140},{"corpo":"@Eric: No you won't miss anything. If you want to see what happened at 11pm EST, you look for things that happened at the corresponding time in GMT. If all the records are converted into GMT before saving, it shouldn't matter. So long as you convert the requested time (i.e. 11pm) to GMT before using it in the query. ","pontos":0},{"corpo":"That is terrible, take a look at Only In A Database Can You Get 1000% + Improvement By Changing A Few Lines Of Code to see how you can optimize this since that is not sargable Also check out Get Datetime Without Time and Query Optimizations With Dates ","pontos":1},{"corpo":"I'm in the object oriented architects camp. It's not necessarily a crime to put code in the database, as long as you understand the caveats that go along with that. Here are some: It's not debuggable It's not subject to source control Permissions on your two sets of code will be different It will make it more difficult to track where an error in the data came from if you're accessing info in the database from both places ","pontos":5},{"corpo":"I think it's a business logic vs. data logic thing. If there is logic that ensures the consistency of your data, put it in a stored procedure. Same for convenience functions for data retrieval/update. Everything else should go into the code. A friend of mine is developing a host of stored procedures for data analysis algorithms in bioinformatics. I think his approach is quite interesting, but not the right way in the long run. My main objections are maintainability and lacking adaptability. ","pontos":6},{"corpo":"I'd recommend you stick with PuTTY too. You might find it useful to run Pageant in conjunction with Plink to avoid having to type in the passphrase. But if you want to research alternatives you should review this Wikipedia resource: http://en.wikipedia.org/wiki/Comparison_of_SSH_clients ","pontos":2},{"corpo":"This is CS101, but since no one else has mentioned it, while loops evaluate their condition before the code block, and do-while evaluates after the code block, so do-while loops are always guaranteed to run their code block at least once, regardless of the condition. ","pontos":1},{"corpo":"In most firewall setups, the TCP connection will be torn down by the firewall if it is idle to conserve resources. The idle timeout is probably not something you can control. Some will tear them down if they are idle and a resource limit is being hit. Most corp environments won't allow any machines to make an outbound TCP connection anyway. Also, using this mechanism means you are going to have scaling problems. I think more reliable solution is to queue up information and have your clients poll for them regularly. Utilize caching if possible such that a subsequent client poll will get the cached data from the customers proxy cache, if they are using one. If you have to push data in a timely manner, in sub-second land (i.e. financial services), then consider some messaging infrastructure such an NServiceBus distributor on client side, but that will require a customer install... So have you tried using Toredo? Having read that it would appear there it is prob too complicated for a user to setup. ","pontos":1},{"corpo":"No, due to page splits. You're essentially defining rows that can be 1KB - n MB so your database will have a lot of empty spaces in its pages which is bad for performance. ","pontos":-1},{"corpo":"As another person just mentioned, it's a base64 encoded string. In the past, I've used this website to decode it: http://www.motobit.com/util/base64-decoder-encoder.asp ","pontos":7},{"corpo":"You can ignore the URL field and simply paste the viewstate into the Viewstate string box. It does look like you have an old version; the serialisation methods changed in ASP.NET 2.0, so grab the 2.0 version ","pontos":1},{"corpo":"Well, this one is difficult. As a programmer, you'll want to avoid TSQL and such \"Database languages\" as much as possible, because they are horrendous, difficult to debug, not extensible and there's nothing you can do with them that you won't be able to do using code on your application. The only reasons I see for writing stored procedures are: Your database isn't great (think how SQL Server doesn't implement LIMIT and you have to work around that using a procedure. You want to be able to change a behaviour by changing code in just one place without re-deploying your client applications. The client machines have big calculation-power constraints (think small embedded devices). For most applications though, you should try to keep your code in the application where you can debug it, keep it under version control and fix it using all the tools provided to you by your language. ","pontos":-3},{"corpo":"To reduce the risk you can also associate the originating IP with the session. That way an attacker has to be within the same private network to be able to use the session. Checking referer headers can also be an option but those are more easily spoofed. ","pontos":0},{"corpo":"Prefixing the contents of the cell with ' forces Excel to see it as text instead of a number. The ' won't be displayed in Excel. ","pontos":1},{"corpo":"Hmm, none that I know of. You can always retrieve the definitions as SQL and then run a diff tool on them, but it's a bit of a pain in the rear. Probably the best solution for this is using some kind of \"Migrations\" tool, so you can keep your database definitions together with your code, and version them, etc. ","pontos":0},{"corpo":"@Thomas Owens: (re source control) Yes, but that's not source control in the same sense that I can check in a .cs file (or .cpp file or whatever) and go and pick out any revision I want. To do that with database code requires a potentially-significant amount of effort to either retrieve the procedure from the database and transfer it to somewhere in the source tree, or to do a database backup every time a minor change is made. In either case (and regardless of the amount of effort), it's not intuitive; and for many shops, it's not a good enough solution either. There is also the potential here for developers who may not be as studious at that as others to forget to retrieve and check in a revision. It's technically possible to put ANYTHING in source control; the disconnect here is what I would take issue with. (re debuggable) Fair enough, though that doesn't provide much integration with the rest of the application (where the majority of the code could live). That may or may not be important. ","pontos":0},{"corpo":"My answer from a different post: Stored Procedures are MORE maintainable because: You don't have to recompile your C# app whenever you want to change some SQL You end up reusing SQL code. Code repetition is the worst thing you can do when you're trying to build a maintainable application! What happens when you find a logic error that needs to be corrected in multiple places? You're more apt to forget to change that last spot where you copy pasted your code. In my opinion, the performance security gains are an added plus. You can still write insecure/inefficient SQL stored procedures. Easier to port to another DB - no procs to port It's not very hard to script out all your stored procedures for creation in another DB. In fact - it's easier than exporting your tables because there are no primary/foreign keys to worry about. ","pontos":2},{"corpo":"URL Rewriting in ASP.NET article must work for you ","pontos":1},{"corpo":"Normally, ViewState should be decryptable if you have the machine-key, right? After all, ASP.net needs to decrypt it, and that is certainly not a black box. ","pontos":0},{"corpo":"Saving the file as a tab delimited text file has also worked well. ---old Unfortunately, we can't rely on the columns of the excel doc to stay in a particular format as the users will be pasting data into it regularly. I don't want the app to crash if we're relying on a certain datatype for a column. prefixing with ' would work, is there a reasonable way to do that programatically once the data already exists in the excel doc? ","pontos":0},{"corpo":"I know this is going to seem old-fashioned, but I don't think much of using online tutorials to learn programming languages or platforms. These generally give you no more than a little taste of the language. To really learn a language, you need the equivalent of a \"book\", and in many cases, this means a real dead-tree book. If you want to learn C, read K R. If you want to learn C++, read Stroustrup. If you want to learn Lisp/Scheme, read SICP. Etc. If you're not willing to spend more than $30 and a few hours to learn a language, you probably aren't going to learn it. ","pontos":33},{"corpo":"I don't believe you can. You might be better off aliasing commonly used commands in a script that you call from your profile script. Example - Set-Alias np c:\\windows\\notepad.exe Then you have your short, easily typeable name available from the command line. ","pontos":2},{"corpo":"Parametized SQL or SPROC...doesn't matter from a performance stand point...you can query optimize either one. For me the last remaining benefit of a SPROC is that I can eliminate a lot SQL rights management by only granting my login rights to execute sprocs...if you use Parametized SQL the login withing your connection string has a lot more rights (writing ANY kind of select statement on one of the tables they have access too for example). I still prefer Parametized SQL though... ","pontos":1},{"corpo":"Unfortunately I'm using an SQLEngine for embedded systems so it does not support BULK INSERT or OLEDB datasources, which is why I was thinking of taking the sql statement generation approach. ","pontos":0},{"corpo":"In my experience writing mostly WinForms Client/Server apps these are the simple conclusions I've come to: Use Stored Procedures: For any complex data work. If you're going to be doing something truly requiring a cursor or temp tables it's usually fastest to do it within SQL Server. When you need to lock down access to the data. If you don't give table access to users (or role or whatever) you can be sure that the only way to interact with the data is through the SP's you create. Use ad-hoc queries: For CRUD when you don't need to restrict data access (or are doing so in another manner). For simple searches. Creating SP's for a bunch of search criteria is a pain and difficult to maintain. If you can generate a reasonably fast search query use that. In most of my applications I've used both SP's and ad-hoc sql, though I find I'm using SP's less and less as they end up being code just like C#, only harder to version control, test, and maintain. I would recommend using ad-hoc sql unless you can find a specific reason not to. ","pontos":56},{"corpo":"This was answered here. ","pontos":0},{"corpo":"On my Vista system typing S won't launch a lnk file unless I have the environment variable PATHEXT set with .lnk in the list. When I do. S will work in cmd.exe and I have to do .\\S in powershell. ","pontos":5},{"corpo":"Thanks to jsight (and Mark Biek for pointing out the connection between plink and putty) I decided to investigate more fully. It turned out that plink had been using the \"Default Settings\" stored Session that I set up for putty and wasn't allowing them to be overridden. edit: The Geek: Also, this is a good example why you should always, always use DNS/hostnames instead of the IP address directly. The problem was nothing to do with the IP address change, and in this case the DNS changed as well. I can see your point, but this isn't the 'good example' you are looking for. ","pontos":2},{"corpo":"Are you initially loading the data only when !Page.IsPostBack? Also, is view state enabled for the text box? ","pontos":8},{"corpo":"Stored procedures are definitely the way to go...they are compiled, have execution plan before hand and you could do rights management on them. I do not understand this whole source control issue on stored procedure. You definitely can source control them, if only you are a little disciplined. Always start with a .sql file that is the source of your stored procedure. Put it in version control once you have written your code. The next time you want to edit your stored procedure get it from your source control than your database. If you follow this, you will have as good source control as your code. I would like to quote Tom Kyte from Oracle here...Here's his rule on where to write code...though a bit unrelated but good to know I guess. Start with stored procedures in PL/SQL... If you think something can't be done using stored procedure in PL/SQL, use Java stored procedure. If you think something can't be done using Java Stored procedure, consider Pro*c. If you think you can't achieve something using Pro*C, you might want to rethink what you need to get done. ","pontos":4},{"corpo":"Use the TCPClient Class to create a generic function that connects in TCP to a given IP address. Then iterate over the list of servers you want to test and try to open a connection to port 1433. ","pontos":2},{"corpo":"I would certainly go with Vincent's answer. Just make absolutely certain you are closing and disposing the tcp connections properly etc. WMI seems a bit of overkill to me if that is all you're after. ","pontos":0},{"corpo":"Umm no you don't; you can accept information cards on a web site using a cheap and cheerful certificate (but not self signed) or no certificate at all. And yes, I've used it as part of a production system which grew out of a proof of concept I did at Microsoft. Cons: If you don't have an EV SSL certificate you get warnings. The code for parsing a card is incomplete at best (you have to hack it around for no-SSL), you have to explain to users what one is. Pros: Well that's more interesting; I was using managed cards and issuing them and then having 3rd parties use those to check claims; but for self issued cards; well, it's stronger than username password and doesn't have the same vulnerabilities OpenID has. ","pontos":2},{"corpo":"When hacking something together for myself, I test at the end. Bad practice, but these are usually small things that I'll use a few times and that's it. On a larger project, I write tests before I write a class and I run the tests after every change to that class. ","pontos":0},{"corpo":"Store procedures should be used as much as possible, if your writing SQL into code your already setting yourself up for headaches in the futures. It takes about the same time to write a SPROC as it does to write it in code. Consider a query that runs great under a medium load but once it goes into fulltime production your badly optimized query hammers the system and brings it to a crawl. In most SQL servers you are not the only application/service that is using it. Your application has now brought a bunch of angry people at your door. If you have your queries in SPROCs you also allow your friendly DBA to manage and optimize with out recompiling or breaking your app. Remember DBA's are experts in this field, they know what to do and not do. It makes sense to utilise their greater knowledge! EDIT: someone said that recompile is a lazy excuse! yeah lets see how lazy you feel when you have to recompile and deploy your app to 1000's of desktops, all because the DBA has told you that your ad-hoc Query is eating up too much Server time! ","pontos":2},{"corpo":"Well, if you want to follow the TDD guys, before you start to code ;) I am very much in the same position as you. I want to get more into testing, but I am currently in a position where we are working to \"get the code out\" rather than \"get the code out right\" which scares the crap out of me. So I am slowly trying to integrate testing processes in my development cycle. Currently, I test as I code, trying to bust the code as I write it. I do find it hard to get into the TDD mindset.. Its taking time, but that is the way I would want to work.. EDIT: I thought I should probably expand on this, this is my basic \"working process\"... Plan what I want from the code, possible object design, whatever. Create my first class, add a huge comment to the top outlining what my \"vision\" for the class is. Outline the basic test scenarios.. These will basically become the unit tests. Create my first method.. Also writing a short comment explaining how it is expected to work. Write an automated test to see if it does what I expect. Repeat steps 4-6 for each method (note the automated tests are in a huge list that runs on F5). I then create some beefy tests to emulate the class in the working environment, obviously fixing any issues. If any new bugs come to light following this, I then go back and write the new test in, make sure it fails (this also serves as proof-of-concept for the bug) then fix it.. I hope that helps.. Open to comments on how to improve this, as I said it is a concern of mine.. ","pontos":6},{"corpo":"@Vincent: That also requires that your servers are running on port 1433. That's not necessarily a foregone conclusion if they're not under your control. ","pontos":0},{"corpo":"I've only recently added unit testing to my regular work flow but I write unit tests: to express the requirements for each new code module (right after I write the interface but before writing the implementation) every time I think \"it had better ... by the time I'm done\" when something breaks, to quantify the bug and prove that I've fixed it when I write code which explicitly allocates or deallocates memory---I loath hunting for memory leaks... I run the tests on most builds, and always before running the code. ","pontos":0},{"corpo":"Start with unit testing. Specifically, check out TDD, Test Driven Development. The concept behind TDD is you write the unit tests first, then write your code. If the test fails, you go back and re-work your code. If it passes, you move on to the next one. I take a hybrid approach to TDD. I don't like to write tests against nothing, so I usually write some of the code first, then put the unit tests in. It's an iterative process, one which you're never really done with. You change the code, you run your tests. If there's any failures, fix and repeat. The other sort of testing is integration testing, which comes along later in the process, and might typically be done by a QA testing team. In any case, integration testing addresses the need to test the pieces as a whole. It's the working product you're concerned with testing. This one is more difficult to deal with b/c it usually involves having automated testing tools (like Robot, for ex.). Also, take a look at a product like CruiseControl.NET to do continuous builds. CC.NET is nice b/c it will run your unit tests with each build, notifying you immediately of any failures. ","pontos":0},{"corpo":"I set up a task to do this. I'm not aware of any way to make CruiseControl be that specific. I usually just chain a batch file to do the copy to the CC.net task. ","pontos":3},{"corpo":"First and often. If I'm creating some new functionality for the system I'll be looking to initially define the interfaces and then write unit tests for those interfaces. To work out what tests to write consider the API of the interface and the functionality it provides, get out a pen and paper and think for a while about potential error conditions or ways to prove that it is doing the correct job. If this is too difficult then it's likely that your API isn't good enough. In regards to the tests, see if you can avoid writing \"integration\" tests that test more than one specific object and keep them as \"unit\" test. Then create a default implementation of your interface (that does nothing, returns rubbish values but doesn't throw exceptions), plug it into the tests to make sure that the tests fail (this tests that your tests work! :) ). Then write in the functionality and re-run the tests. This mechanism isn't perfect but will cover a lot of simple coding mistakes and provide you with an opportunity to run your new feature without having to plug it into the entire application. Following this you then need to test it in the main application with the combination of existing features. This is where testing is more difficult and if possible should be partially outsourced to good QA tester as they'll have the knack of breaking things. Although it helps if you have these skills too. Getting testing right is a knack that you have to pick up to be honest. My own experience comes from my own naive deployments and the subsequent bugs that were reported by the users when they used it in anger. At first when this happened to me I found it irritating that the user was intentionally trying to break my software and I wanted to mark all the \"bugs\" down as \"training issues\". However after reflecting on it I realised that it is our role (as developers) to make the application as simple and reliable to use as possible even by idiots. It is our role to empower idiots and thats why we get paid the dollar. Idiot handling. To effectively test like this you have to get into the mindset of trying to break everything. Assume the mantle of a user that bashes the buttons and generally attempts to destroy your application in weird and wonderful ways. Assume that if you don't find flaws then they will be discovered in production to your companies serious loss of face. Take full responsibility for all of these issues and curse yourself when a bug you are responsible (or even part responsible) for is discovered in production. If you do most of the above then you should start to produce much more robust code, however it is a bit of an art form and requires a lot of experience to be good at. ","pontos":1},{"corpo":"I went to a presentation on unit testing at FoxForward 2007 and was told never to unit test anything that works with data. After all, if you test on live data, the results are unpredictable, and if you don't test on live data, you're not actually testing the code you wrote. Unfortunately, that's most of the coding I do these days. :-) I did take a shot at TDD recently when I was writing a routine to save and restore settings. First, I verified that I could create the storage object. Then, that it had the method I needed to call. Then, that I could call it. Then, that I could pass it parameters. Then, that I could pass it specific parameters. And so on, until I was finally verifying that it would save the specified setting, allow me to change it, and then restore it, for several different syntaxes. I didn't get to the end, because I needed-the-routine-now-dammit, but it was a good exercise. ","pontos":0},{"corpo":"Definitely - Option B. I wouldn't mix students and classes in the XML just the same way that I wouldn't mix students and classes in the same table in a database. ","pontos":4},{"corpo":"I haven't found any compelling argument for using ad-hoc queries. Especially those mixed up with your C#/Java/PHP code. ","pontos":1},{"corpo":"yeah everything you described (except maybe perf monitoring) can be done with database maintenance plans, back ups, shrinking log files etc. ","pontos":0},{"corpo":"Another compelling reason to use option B is error checking. If the original file is modified outside an XML application, or if no XSD schema is applied, there could be the case where you have an uneven number of students and classes. At least if you have the students and classes grouped together, you will easily be able to tell if each record is complete, independently of any other record. ","pontos":2},{"corpo":"It sounds like you are trying to allow the \"special content creators\" save files in TFS Source Control without having to buy them a license to a Visual Studio Team Edition -- correct me if I'm wrong. If that's the case, unfortunately I believe that you can't quite do that. Your users still need a Client Access License (\"CAL\") to access TFS. I think that you can acquire just CALs for your users without having to buy Visual Studio for them (I presume for less than a full blown Visual Studio would cost). At that point, you can just distribute to them the Team Explorer, which is a VS shell with nothing but TFS access components. That is available in your TFS server media. I found this via Google. You might want to review it to decide your best options: Visual Studio Team System 2008 Licensing White Paper The only exception to the CAL rules I'm aware of is access to Work Items. Assuming properly licensed servers, anyone in your organization can create new Work Items or view and update existing ones created by them, using the Work Item Web Access component. ","pontos":2},{"corpo":" What do you do if you are given a pile of crap and seem like you are stuck in a perpetual state of cleanup that you know with the addition of any new feature or code can break the current set because the current software is like a house of cards? How can we do unit testing then? You start small. The project I just got into had no unit testing until a few months ago. When coverage was that low, we would simply pick a file that had no coverage and click \"add tests\". Right now we're up to over 40%, and we've managed to pick off most of the low-hanging fruit. (The best part is that even at this low level of coverage, we've already run into many instances of the code doing the wrong thing, and the testing caught it. That's a huge motivator to push people to add more testing.) ","pontos":0},{"corpo":"Having your own license (usually a variant on one of the existing ones) allows you full control over it. I suspect that things like the huge change between GPL2 and GPL3 (especially if you deal with web services) make people leery of licensing with an agreement outside of one's control. ","pontos":5},{"corpo":"The most common are probably database injection attacks and cross-site scripting attacks; mainly because those are the easiest to accomplish (that's likely because those are the ones programmers are laziest about). ","pontos":0},{"corpo":"Just to confuse things a bit more, sometimes you have to work with handles instead of pointers. Handles are pointers to pointers, so that the back end can move things in memory to defragment the heap. If the pointer changes in mid-routine, the results are unpredictable, so you first have to lock the handle to make sure nothing goes anywhere. http://arjay.bc.ca/Modula-2/Text/Ch15/Ch15.8.html#15.8.5 talks about it a bit more coherently than me. :-) ","pontos":0},{"corpo":"You can see even on this site that the most damaging things you'll be looking after involve code injection into your application, so XSS (Cross Site Scripting) and SQL injection (@Patrick's suggestions) are your biggest concerns. Basically you're going to want to make sure that if your application allows for a user to inject any code whatsoever, it's regulated and tested to be sure that only things you're sure you want to allow (an html link, image, etc) are passed, and nothing else is executed. ","pontos":0},{"corpo":"This is also a short little presentation on security by one of wordpress's core developers. Security in wordpress it covers all of the basic security problems in web apps. ","pontos":1},{"corpo":"Make sure you are debuging using the debug configuration, not the release one. Also make sure optimizations are disabled in debug configuration. Optimizations must be off when you debug else it can lead to very erratic behaviours like these. For C# projects, which I am assuming the question is about looking at the tags, the optimization option would be located in the \"Build\" tab of \"Project > Properties...\" Last option of \"General\" it's called \"Optimize Code\". ","pontos":3},{"corpo":"@Mark Brackett - A co-lo facility isn't running illegal installs of Windows on their server hardware. ","pontos":0},{"corpo":"The following will work %= Post.find_unread_by(current_user).size % or %= Post.find_unread_by(current_user).length % However if you check your development.log you should see that it gets the unread count by Retrieving all the posts Retrieving all the posts read by the user Removing all of 2. from 1. in ruby This will be very bad performance wise with lots of posts. A better way would be to retrieve the posts read by the current user and then use ActiveRecord::Calculations to get a count without retrieving all the posts in the database Post.count(:conditions = [ \"id NOT IN (?)\", Post.find_read_by(current_user)]) This should go into your Post model to follow best practices of not having finders in the view or controller Post.rb def self.unread_post_count_for_user(user) count(:conditions = [ \"id NOT IN (?)\", Post.find_read_by(user)]) end Then your view will just be %= Post.unread_post_count_for_user(current-user) % ","pontos":10},{"corpo":"Git is superior to subversion, but it's a little bit out on the bleeding edge. I'd say, if you're just getting started, jump on the edge; setup a free account @ http://github.com They have educational material on site for setting up using git. ","pontos":3},{"corpo":"Open Dialect and Salasaga seem to be the main FOSS IDEs for this. They should both be cross-platform with mono and GTK respectively (not completely sure about OSX). I think Open Dialect also does AIR. I've no idea how they compare to the commercial IDEs so you might have to try each of them to compare. ","pontos":1},{"corpo":"I guess the tool I was looking for was under my nose the whole time! I've used Maintenance Plans for backups but I think I set those up at least 4 years ago or more, long before I knew anything about shrinking files and defragging indexes. Thanks! ","pontos":0},{"corpo":"Actually, by colllapsing the colums you already summed them, so the dimension doesn't matter at all for your example. Did I miss something or did you? ","pontos":0},{"corpo":"YUI Connection Manager allows you to introduce slowdown in your Javascript to test AJAX against latency. ","pontos":1},{"corpo":"Javascript doesn't really have namespace or packages like other languages. Instead it has closures. If you have an application that consists of multiple functions, variables and objects, then you should put them inside a single global object. This will have the same effect as a namespace. For example: var namespace = { this.foo: function(){ ... }, this.foo.prototype.getLength: function(){ ... } } You could also create a set of nested objects and simulate packages: loadPackage = function(){ var path = arguments[0]; for(var i=1; i arguments.length; i++){ if(!path[arguments[i]]){ path[arguments[i]] = {}; } path = path[arguments[i]]; } return path; } loadPackage(this, \"com\", \"google\", \"mail\") = { username: \"gundersen\", login: function(password){ ... } } this.com.google.mail.login(\"mySecretPassword\"); ","pontos":5},{"corpo":"Downside? It's fairly limited - you trigger a \"GET\" request and get back some script that's executed. You don't get error handling if your server throws an error, so you need to wrap all errors in JSON as well. You can't really cancel or retry the request. You're at the mercy of the various browser author opinions of \"correct\" behavior for dynamically-generated tags. Debugging is somewhat more difficult. That said, i've used it on occasion, and haven't suffered. YMMV. ","pontos":7},{"corpo":"These are standard library references. Make sure that all libraries (including the standard library) are using the same linkage. E.g. you can't link statically while linking the standard lib dynamically. The same goes for the threading model used. Take special care that you and the 3rd party library use the same linkage options. This can be a real pain in the *ss. ","pontos":5},{"corpo":"This is what I use to read from a Magtek card reader: //Open file on the device deviceHandle = CreateFile (deviceDetail- DevicePath, GENERIC_READ, FILE_SHARE_READ | FILE_SHARE_WRITE, NULL, OPEN_EXISTING, 0, NULL); Try those options and see if you can at least read from the device. I understand your pain here... I found the USB HID documentation to be basically wrong in several places. [Edit] There's not much out there on this problem. Here's a codeproject link that lightly touches on the subject in a thread at the bottom. Sounds like maybe if it's a keyboard or mouse windows grabs it exclusively. ","pontos":1},{"corpo":"Probably nothing in your example. My understanding is that \"javascript:\" is for anchor tags (in place of an actual href). You'd use it so that your script can execute when the user clicks the link, but without initiating a navigation back to the page (which a blank href coupled with an onclick will do). For example: a href=\"javascript:someFunction();\" Blah /a Rather than: a href=\"\" onclick=\"someFunction();\" Blah /a ","pontos":17},{"corpo":"I beg to differ, there is ALWAYS another way.. And if you really cannot refactor, then you need to break the problem down into smaller parts.. Like I said, establish which dimensions you need to sum, then hit them one at a time.. Also, stop changing the edits, they are correcting your spelling errors, they are trying to help you ;) ","pontos":0},{"corpo":"Because the Format method has nothing to do with a string's current value. The value of the string isn't used. It takes a string and returns one. ","pontos":4},{"corpo":"I am no authority in JavaScript, and perhaps more of a dunce than the asker, but AFAIK, the difference is that the \"javascript:\" prefix is preferred/required in URI-contexts, where the argument may be as well a traditional HTTP URL as a JavaScript trigger. So, my intuitive answer would be that, since onChange expects JavaScript, the \"javascript:\" prefix is redundant (if not downright erroneous). You can, however, write \"javascript:myFunction(this)\" in your address bar, and that function is run. Without the \"javascript:\", your browser would try to interpret \"myFunction(this)\" as a URL and tries to fetch the DNS info, browse to that server, etc... ","pontos":1},{"corpo":"I don't know if the \"javascript:\" prefix means anything within the onevent attributes but I know they are annoying in anchor tags when trying to open the link in a new tab. The href should be used as a fall back and never to attach javascript to links. ","pontos":0},{"corpo":"I see nothing wrong with it being static.. The semantics of the static method seem to make a lot more sense to me. Perhaps it is because it is a primitive. Where primitives are used to often, you want to make the utility code for working with them as light as possible.. Also, I think the semantics are a lot better with String.Format over \"MyString BLAH BLAH {0}\".Format ... ","pontos":1},{"corpo":" It should only be used in the href tag. That's ridiculous. The accepted way is this: a href=\"/non-js-version/\" onclick=\"someFunction(); return false\" Blah /a But to answer the OP, there is generally no reason to use \"javascript:\" anymore. In fact, you should attach the javascript event from your script, and not inline in the markup. But, that's a purist thing I think :-D ","pontos":4},{"corpo":"Cool - I'll try those options, as they're probably better defaults given my intentions. Unfortunately, I know my device is there and I'll eventually need read/write access later on (once I inspect the descriptors and have verifed it is infact my device). Which means that my real goal IS to know what's using it, so I can inform the customer/user: \"Hey man, 'iexplore.exe' is currently using your SuperWidget device. You'll have to close that down in order to use SuperWidget application.\" (if not at the application-level, then at least at the phone support level.) I forgot to mention that the windows error reported by GetLastError() is: 0x20. The process cannot access the file because it is being used by another process. (So your sharing alternatives will probably get the file open, assuming no FILESHARENONE on behalf of the other process). [edit] Yeah, it's painful alright. I have seen mice and keyboards get locked by whatever Windows uses to read from them. I've also seen a lot of people have trouble inside a VM like Paralells on OS X, where the HID class driver has the device open exclusively preventing the VM from using standard USB requests. I've seen some code that recreates what ProcessMonitor does. Maybe SysInternals is just electing to ignore device handles, but the same method (or a slight variation) can be employed here to determine the PID. Mike ","pontos":0},{"corpo":"I haven't tried it yet but you could make an extension method for what you want. I wouldn't do it, but I think it would work. Also I find more in line with other patterned static methods like , , etc. You cloud also just use a if you want a non static format. ","pontos":1},{"corpo":"I think it looks better in general to use String.Format, but I could see a point in wanting to have a non-static function for when you already have a string stored in a variable that you want to \"format\". As an aside, all functions of the string class don't act on the string, but return a new string object, because strings are immutable. ","pontos":2},{"corpo":"I tend to underscore fields with _ so don't really ever need to use this. Also R# tends to refactor them away anyway... ","pontos":1},{"corpo":"I only use it when absolutely necessary, ie, when another variable is shadowing another. Such as here: class Vector3 { float x; float y; float z; public Vector3(float x, float y, float z) { this.x = x; this.y = y; this.z = z; } } Or as Ryan Fox points out, when you need to pass this as a parameter. ","pontos":77},{"corpo":"DejaVu Sans Mono (also known as Panic Sans), size 11, anti-alised. Previously I only used fonts that weren't anti-aliased, but it just seems to work for this font. ","pontos":5},{"corpo":"I think it says somewhere in the MS Coding Guidelines that generally you should always access via this ... I do on most occasions but sometimes when working on close-knit code like loops and stuff with lots of variable, I find it gets messy.. ","pontos":-3},{"corpo":"You're doing this in c/c++... so you have an array of array of array... you don't have to visualize 20 dimensions since that isn't how the data is laid out in memory, for a 2 dimensional: [1] -- [1,2,3,4,5,6,...] [2] -- [1,2,3,4,5,6,...] [3] -- [1,2,3,4,5,6,...] [4] -- [1,2,3,4,5,6,...] [5] -- [1,2,3,4,5,6,...] . . . . . . so, why can't you iterate across the first one summing it's contents? If you are trying to find the size, then is a risky approach. You must know the dimension to be able to process this data, and set the memory up, so you know the depth of recursion to sum. Here is some pseudo code of what it seems you should do, sum( n_matrix, depth ) running_total = 0 if depth = 0 then foreach element in the array running_total += elm else foreach element in the array running_total += sum( elm , depth-1 ) return running_total ","pontos":0},{"corpo":"Not sure what the confusion is. Sites on your intranet are in the intranet zone, web sites are in the internet zone, and sites on your computer are in the local zone, unless you've specifically overridden something in the browser's preferences. ","pontos":-2},{"corpo":"I pretty much only use this when referencing a type property from inside the same type. As another user mentioned, I also underscore local fields so they are noticeable without needing this. ","pontos":1},{"corpo":"It depends on the coding standard I'm working under. If we are using _ to denote an instance variable then \"this\" becomes redundant. If we are not using _ then I tend to use this to denote instance variable. ","pontos":0},{"corpo":"Behaviour is the same when a window finishes flashing for as long as it's supposed to: the taskbar button stays coloured. I don't think this is a bug. If you think about it, when you use FLASHW_STOP, the flashing does in fact stop, but the point of the flashing is to get the user's attention. The button stays coloured because the user still may not have looked down and discovered which window was trying to get her attention. Keeping the button coloured keeps that information available. ","pontos":4},{"corpo":"While I obviously cannot speak to the specifics of your application, in most instances you should not tie your caching implementation to some perceived expectation for how the GC will work. As Stu mentions, calling GC.Collect() will force a collection (with overloads for a specific generation) but more often than not doing so will result in worse performance than just letting the GC manage itself. If you do find (after doing some real performance testing) that you need to interact with the GC make sure you take into account the different types of GC's that the framework currently has (see here for more information). ","pontos":1},{"corpo":"I can't believe all of the people that say using it always is a \"best practice\" and such. Use \"this\" when there is ambiguity, as in Corey's example or when you need to pass the object as a parameter, as in Ryan's example. There is no reason to use it otherwise because being able to resolve a variable based on the scope chain should be clear enough that qualifying variables with it should be unnecessary. EDIT: The C# documentation on \"this\" indicates one more use, besides the two I mentioned, for the \"this\" keyword - for declaring indexers EDIT: @Juan: Huh, I don't see any inconsistency in my statements - there are 3 instances when I would use the \"this\" keyword (as documented in the C# documentation), and those are times when you actually need it. Sticking \"this\" in front of variables in a constructor when there is no shadowing going on is simply a waste of keystrokes and a waste of my time when reading it, it provides no benefit. ","pontos":31},{"corpo":"x = number_of_dimensions; while (x 1) { switch (x) { case 20: reduce20DimensionArray(); x--; break; case 19: ..... } } (Sorry, couldn't resist.) ","pontos":0},{"corpo":"Never. Ever. If you have variable shadowing, your naming conventions are on crack. I mean, really, no distinguishing naming for member variables? Facepalm ","pontos":-5},{"corpo":"No. Emailing a few hundred or thousand lines of code to somebody and saying \"Please review this\" is never going to result in a thorough review. If you think people aren't reviewing the code when you do this, you're right. Intentionally putting bugs into the code is just turning this ridiculous practice into a game. The only way to properly review code is to get people together and go through it together. ","pontos":4},{"corpo":"I wanna say \"Are you serious?\" but I can kinda see your point... I probably would not do this though, but rather actually wave the code in their face and ask for actual answers and get them to engage their brain... Maybe even plant one to get their attention there and then, maybe they will then feel more compelled to review it properly after check in... I wouldn't like to check in bugs on purpose, just out of fear of me losing track of where the bug is ^_^ ","pontos":0},{"corpo":"I think it would be good to store somewhere all possible primes smaller then n and just iterate through them to find the biggest divisior. You can get primes from prime-numbers.org. Of course I assume that your number isn't too big :) ","pontos":-2},{"corpo":"something about intentionally adding bugs to your code to catch your co-workers just doesn't sit right with me. I say you just do Formal Inspections. Then you know your code was reviewed, plus they have been shown to find more bugs. ","pontos":2},{"corpo":"Silverlight programmer's don't know what they're missing out on, when it comes to Flex. Silverlight lacks the component model and event triggering capabilites that Flex has. Using XNA, and C#, a friend of mine has to jump through all kinds of hoops to get his Silverlight application to work. Then, it has to be handed off to a designer to get it to look half way decent. Listen to the deepfriedbytes.com podcasts on Silverlight, and you'll hear how even a couple guys that really push Silverlight, acknowledge some of these issues. (I think, if I recall correctly, one of the guys works for Microsoft, but I could be wrong - I listened to it last week). They agree that Silverlight isn't quite ready for any huge applications, in its current state. I would go with Flex, for a nice clean, straightforward approach - especially if you're already familiar with Flash and ActionScript 3.0. Flex makes alot more sense, in my opinion - Silverlight still has to mature. ","pontos":6},{"corpo":"javascript: in JS code (like in an onclick attribute) is just a label for use with continue/goto label statements that may or may not be supported by the browser (probably not anywhere). It could be zipzambam: instead. Even if the label can't be used, browsers still accept it so it doesn't cause an error. This means that if someone's throwing a useless label in an onclick attribute, they probably don't know what they're doing and are just copying and pasting or doing it out of habit from doing the below. javascript: in the href attribute signifies a Javascript URI. Example: javascript:(function()%7Balert(%22test%22)%3B%7D)()%3B ","pontos":1},{"corpo":"I remember seeing someone once suggest that you should not compile your code before a code review, and then try to find compile errors at the review. The theory was, once the review was over, you can actually compile the code and see how many compile errors you didn't find in the review. It is then safe to say that you missed that many logic errors as well. Don't know if I could ever force myself to not type \"make\" but it did make me think, and it would help with this problem as well. ","pontos":0},{"corpo":"You definitely want to test physically pulling the cable out. Lots of networking code will throw different exceptions in that scenario vs when the connection has just been lost. ","pontos":0},{"corpo":"To add to TimK's answer, if you have a router, test pulling the upstream link on the router, this will test a bad connection without your system knowing that you lost the physical link. ","pontos":0},{"corpo":"If I understand correctly, you want to sum all values in the cross section defined at each \"bin\" along 1 dimension. I suggest making a 1D array for your destination, then looping through each element in your array adding the value to the destination with the index of the dimension of interest. If you are using arbitrary number of dimensions, you must have a way of addressing elements (I would be curious how you are implementing this). Your implementation of this will affect how you set the destination index. But an obvious way would be with if statements checked in the iteration loops. ","pontos":0},{"corpo":"To expand on Konrad's comment: and the order of evaluation is not well-defined Some functional languages have what is called Lazy Evaluation. Which means a function is not executed until the value is needed. Until that time the function itself is what is passed around. Procedural languages are step 1 step 2 step 3... if in step 2 you say add 2 + 2, it does it right then. In lazy evaluation you would say add 2 + 2, but if the result is never used, it never does the addition. ","pontos":3},{"corpo":" To add to TimK's answer, if you have a router, test pulling the upstream link on the router, this will test a bad connection without your system knowing that you lost the physical link. Also if you plug it back in after a few seconds it's possible that the connection won't be lost*. This can simulate a very high latency. *this depends on your ISP and your router. ","pontos":1},{"corpo":"Why don't you swap stacks and look at the LAMP stack? Or how about a functional language like haskell? Or write a DSL? Or an app for your phone? ","pontos":0},{"corpo":"I would vote for Option B. If you go with Option A and the assumption that if a user exists, they can get in, then you'll eventually run into the problem that you'll want to deny access to a user, without removing the user record. There will be lots of cases where you'll want to lock a user out, but won't want to completely destroy their account. One such instance (not necessarily linked to your use case), is when you fail to pay, and they cut off your account until you start paying again. They don't want to delete the record, because they still want to enable it when you pay up again, instead of recreating the account from scratch, and losing all user history. ","pontos":1},{"corpo":"Possibly a version of spawn() for python? http://en.wikipedia.org/wiki/Spawn_(operating_system) ","pontos":0},{"corpo":"There are a few ambiguities in your question. What operation needs to be successful? For everything you want to know about drag and drop, browse through these search results (multiple pages worth): Raymond Chen on drag and drop ","pontos":1},{"corpo":"So, you intend to modify the data being dropped based on the drop target? I don't think this is possible; after all, you populate the data when the drag is initiated. ","pontos":0},{"corpo":"If we're talking Microsoft platform, then I'd always develop a separate Windows Service to handle such batch tasks. You can always reference the same assemblies that are being used by your web application to avoid any nasty code duplication. ","pontos":3},{"corpo":"A couple of years ago I found an ARM disassembler I used while doing some embedded work. However, I don't remember its name - though I think it was part of a larger package like an emulator or something. In your case, could you ask your compiler to generate an assembly listing of the compiled code? That might help give you some scope. Failing that, you could break up your function into one or more new functions, if all you can get is the stack trace. Then break up the new function into one or more again. This is the tried-and-true \"divide and conquer\" method. And if you have 35 calls to memset() in one function, it might be a good idea from a design standpoint too! Update: I found the package I used: ARMphetamine. It worked for the ARM9 code I was developing, but it looks like it hasn't been updated in quite some time. ","pontos":0},{"corpo":"A very simple method that we've used where I work is this: Set up a webservice/web method that executes the task. This webservice can be secured with username/pass if desired. Create a console app that calls this web service. If desired, you can have the console app send parameters and/or get back some sort of metrics for output to the console or external logging. Schedule this executable in the task scheduler of choice. It's not pretty, but it is simple and reliable. Since the console app is essentially just a heartbeat to tell the app to go do its work, it does not need to share any libraries with the application. Another plus of this methodology is that it's fairly trivial to kick off manually when needed. ","pontos":1},{"corpo":"Jeff discussed this on the Stack Overflow blog - http://blog.stackoverflow.com/2008/07/easy-background-tasks-in-aspnet/ Basically, Jeff proposed using the CacheItemRemovedCallback as a timer for calling certain tasks. I personally believe that automated tasks should be handled as a service, a Windows scheduled task, or a job in SQL Server. Under Linux, checkout cron. ","pontos":4},{"corpo":"Approach A, but I would also include a explicit deny in addition to you implicit deney. I would make some use cases to be sure your end logic works but here are some examples. User1 is in group1 and group2. User2 is in group1 User3 is in group2 Folder1 allows group1 and deny group2. User1 is denied. User2 is allowed. User3 is denied. I believe your approach users1 would be allowed. ","pontos":0},{"corpo":"Our network/server closet is a spaghetti-mess of wires; I'm not going to walk in there and start unplugging stuff lest I hit something mission-critical. (At least I have access to it; I'm sure many readers don't even know where their routers are.) Similarly, both ends of the ethernet cable require a hands-and-knees adventure to reach. I tested enabling/disabling the network adapter, and I'm going to test from my cable internet connection from home as well. Also, I had the idea of installing Tor to create a high latency connection. For wireless connections, I have a metal box to test what happens when the signal dies, but I notice that network connection behavior is very different depending on how I test: put the transmitter/reciever in a metal box go stand next to the microwave in the kitchen and turn it on go stand in a little closet which has concrete walls ","pontos":0},{"corpo":"I cannot live without Eclipse and Mylyn ","pontos":1},{"corpo":"Firebug. ","pontos":3},{"corpo":"You can find an implementation of md5crypt in the tcllib package. Download is available from sourceforge. You can also find an example of an apache-compatible md5crypt in the source code for the CAS Generic Handler ","pontos":3},{"corpo":"Is there any way that you could include the child nant file as opposed to executing it as a full-fledged child nant project? This would prevent the overwrite, but not sure if it's possible in your situation. ","pontos":0},{"corpo":" Another vote for notepad++ Firebug or the dev toolbar in IE Lifehackers Texter (for text expansion) I couldn't live my life on a computer without humanized's Enso product ","pontos":1},{"corpo":"I think the purpose of ms deploy is to take the precompiled web output of a .net project and deploy that (i could be wrong though). I'm sure it assumes that you have compiled as a perquisite. ","pontos":0},{"corpo":"This is a very passive-aggressive way of solving a problem which can probably be handled better directly. If you think you need better and more formal processes for code reviews, say so. ","pontos":4},{"corpo":"id:[a* TO z*] id:[0* TO 9*] etc. I just did this in lukeall on my index and it worked, therefore it should work in Solr which uses the standard query parser. I don't actually use Solr. In base Lucene there's a fine reason for why you'd never query for every document, it's because to query for a document you must use a and apply a query to it. Therefore you could totally skip applying a query to it and use the methods to get a count of all the documents, and to retrieve any of the documents. ","pontos":3},{"corpo":"IISReset stops and restarts the entire web server (including non-ASP.NET apps) Recycling an app pool will only affect applications running in that app pool. Editing the web.config in a web application only affects that web application (recycles just that app). Editing the machine.config on the machine will recycle all app pools running. IIS will monitor the /bin directory of your application. Whenever a change is detected in those dlls, it will recycle the app and re-load those new dlls. It also monitors the web.config machine.config in the same way and performs the same action for the applicable apps. ","pontos":67},{"corpo":"Application Pool recycling restarts the w3wp.exe process for that application pool, hence it will only affect web sites running in that application pool. IISReset restarts ALL w3wp.exe processes and any other IIS related service, i.e. the NNTP or FTP Service. I think changing or does not recycle the whole application pool, but I'm not sure on that. ","pontos":3},{"corpo":"A very simple formula for converting from CMYK to RGB ignoring all color profiles is: R = ( (255-C)*(255-K) ) / 255; G = ( (255-M)*(255-K) ) / 255; B = ( (255-Y)*(255-K) ) / 255; This code requires CMYK values to be in rage of 0-255. If you have 0 to 100 or 0.0 to 1.0 you'll have to convert the values. Hope this will get you started. As for the java and ColdFusion interfacing, I'm sorry, but I have no idea how to do that. ","pontos":8},{"corpo":"IISReset restarts the entire webserver (including all associated sites). If you're just looking to reset a single ASP.NET website, you should just recycle that AppDomain. The most common way to reset an ASP.NET website is to edit the web.config file, but you can also create an admin page with the following: public partial class Recycle : System.Web.UI.Page { protected void Page _Load(object sender, EventArgs e) { HttpRuntime.UnloadAppDomain(); } } Here's a blog post I wrote with more info: Avoid IISRESET in ASP.NET Applications ","pontos":22},{"corpo":"It operates on the whole IIS process tree, as opposed to just your application pools. C:\\ iisreset /? IISRESET.EXE (c) Microsoft Corp. 1998-1999 Usage: iisreset [computername] /RESTART Stop and then restart all Internet services. /START Start all Internet services. /STOP Stop all Internet services. /REBOOT Reboot the computer. /REBOOTONERROR Reboot the computer if an error occurs when starting, stopping, or restarting Internet services. /NOFORCE Do not forcefully terminate Internet services if attempting to stop them gracefully fails. /TIMEOUT:val Specify the timeout value ( in seconds ) to wait for a successful stop of Internet services. On expiration of this timeout the computer can be rebooted if the /REBOOTONERROR parameter is specified. The default value is 20s for restart, 60s for stop, and 0s for reboot. /STATUS Display the status of all Internet services. /ENABLE Enable restarting of Internet Services on the local system. /DISABLE Disable restarting of Internet Services on the local system. ","pontos":17},{"corpo":"According to the Pro*C/C++ Programmer's Guide (chapter 5 \"Advanced Topics\"), Pro*C silently ignores a number of preprocessor directives including #error and #pragma, but sadly not #warning. Since your warning directives are included in a header file, you might be able to use the ORA_PROC macro: #ifndef ORA_PROC #include irrelevant.h #endif For some reason, Pro*C errors out if you try to hide a straight #warning that way, however. ","pontos":4},{"corpo":" Loading assemblies from GAC mean less overhead and security that your application will always load correct version of .NET library You shouldn't ngen assemblies that are outside of GAC, because there will be almost no performance gain, in many cases even loss in performance. You're already using GAC, because all standard .NET assemblies are actually in GAC and ngened (during installation). Using GAC for your own libraries adds complexity into deployment, I would try to avoid it at all costs. Your users need to be logged as administrators during installation if you want to put something into GAC, quite a problem for many types of applications. So to sum it all, start simple and if you later see major performance gains if you put your assemblies into GAC and NGEN them, go for it, otherwise don't bother. GAC is more suitable for frameworks where there is expectation for library to be shared among more applications, in 99% of cases, you don't need it. ","pontos":36},{"corpo":"Advantage: Only one place to update your assemblys You use a little less hard drive space Disadvantage: If you need to update only one website, you can't. You may end with the other websites in the webserver broken Recommendation: Leave the GAC to MS and friends. The gigabyte is very cheap now. ","pontos":14},{"corpo":"OU is an Organizational Unit (sort of like a Subfolder in Explorer), not a Group, Hence group1, 2 and 3 are not actually groups. You are looking for the DN Attribute, also called \"distinguishedName\". You can simply use DOMAIN\\DN once you have that. Edit: For groups, the CN (Common Name) could also work. The full string from Active Directory normally looks like this: cn=Username,cn=Users,dc=DomainName,dc=com (Can be longer or shorter, but the important bit is that the \"ou\" part is worthless for what you're trying to achieve. ","pontos":0},{"corpo":"Of all the things you could spend your time doing to add value to your software development process, this has got to be very near the bottom of the list if it would even add value at all, which is extremely debatable. I think the problem here is that you are misunderstanding the fundamental value add of a code review. The point of code reviews is not specifically to find bugs. You should have other processes in place such as unit testing, integration testing, continuous integration builds, QA tools/teams, etc to find bugs. Code reviews provide value by identifying issues at different levels -- obviously you CAN identify specific bugs during code reviews, and that's great, but a code review can also help identify problems at a higher or lower level. For example, at a slightly higher level someone may be able to point out that there is a requirement that all currency must be stored as cents in integers rather than as dollars in floating point and that the code under review fails to meet that requirement (while otherwise being perfectly correct). At a a lower level, it gives more experienced developers an opportunity to give the more junior developers advice on how they could have solved problems better/more simply/etc. For example, perhaps the developer has a lot of nested for loops that could be replaced with some simple list comprehensions or higher order functions. Likewise it might also give a younger more energetic developer a chance to let an older more experienced, but also more set-in-his-ways developer know about some new cutting edge technology that would simplified their code drastically, etc. At the end of the day it also serves to just keep everyone up to date on what is going on in the code base, catch any egregious departures from what is expected, make sure everyone is on the right track, marching in the same direction, and to help the developers involved grow and evolve. ","pontos":13},{"corpo":"As much as I despise Crystal Reports (we describe digging deep into it the seven layers of Crystal hell) -- it seems to be the best/most-flexible tool for the job. I hope someone comes along and knocks them off the block though. Microsoft Reporting Services is an alternative, but didn't have the features we needed. ","pontos":0},{"corpo":"Just keep in mind that every Bug could be used against you. Either in a way where people simply think you're incompetent for making stupid mistakes, or in a way where people think you're actively sabotaging the project. Outside of the Olympic Games, Sabotage and Cheating is something that is strongly discouraged and something that can actually backfire badly. ","pontos":0},{"corpo":"I haven't gotten through all the webcasts myself, so I can't attest to how well Rob Conery has implemented TDD, but his MVC Storefront series is supposed to be using TDD. ","pontos":1},{"corpo":"I'm tackling exactly this problem, and I had completely spaced iCalendar (rfc 2445) up until reading this thread, so I have no idea how well this will or won't integrate with that. Anyway the design I've come up with so far looks something like this: You can't possibly store all the instances of a recurring event, at least not before they occur, so I simply have one table that stores the first instance of the event as an actual date, an optional expiration, and nullable repeat_unit and repeat_increment fields to describe the repetition. For single instances the repition fields are null, otherwise the units will be 'day', 'week', 'month', 'year' and increment is simply the multiple of units to add to start date for the next occurrence. Storing past events only seems advantageous if you need to establish relationships with other entities in your model, and even then it's not necessary to have an explicit \"event instance\" table in every case. If the other entities already have date/time \"instance\" data then a foreign key to the event (or join table for a many-to-many) would most likely be sufficient. To do \"change this instance\"/\"change all future instances\", I was planning on just duplicating the events and expiring the stale ones. So to change a single instances, you'd expire the old one at it's last occurrence, make a copy for the new, unique occurrence with the changes and without any repetition, and another copy of the original at the following occurrence that repeats into the future. Changing all future instances is similar, you would just expire the original and make a new copy with the changes and repition details. The two problems I see with this design so far are: It makes MWF-type events hard to represent. It's possible, but forces the user to create three separate events that repeat weekly on M,W,F individually, and any changes they want to make will have to be done on each one separately as well. These kind of events aren't particularly useful in my app, but it does leave a wart on the model that makes it less universal than I'd like. By copying the events to make changes, you break the association between them, which could be useful in some scenarios (or, maybe it would just be occasionally problematic.) The event table could theoretically contain a \"copied_from\" id field to track where an event originated, but I haven't fully thought through how useful something like that would be. For one thing, parent/child hierarchical relationships are a pain to query from SQL, so the benefits would need to be pretty heavy to outweigh the cost for querying that data. You could use a nested-set instead, I suppose. Lastly I think it's possible to compute events for a given timespan using straight SQL, but I haven't worked out the exact details and I think the queries usually end up being too cumbersome to be worthwhile. However for the sake of argument, you can use the following expression to compute the difference in months between the given month and year an event: (:month + (:year * 12)) - (MONTH(occursOn) + (YEAR(occursOn) * 12)) Building on the last example, you could use MOD to determine whether difference in months is the correct multiple: MOD(:month + (:year * 12)) - (MONTH(occursOn) + (YEAR(occursOn) * 12), repeatIncrement) = 0 Anyway this isn't perfect (it doesn't ignore expired events, doesn't factor in start / end times for the event, etc), so it's only meant as a motivating example. Generally speaking though I think most queries will end up being too complicated. You're probably better off querying for events that occur during a given range, or don't expire before the range, and computing the instances themselves in code rather than SQL. If you really want the database to do the processing then a stored procedure would probably make your life a lot easier. ","pontos":1},{"corpo":"Let me be general [then specific]: Your IDE of choice [VS 2008 here] Your debugger [It is usually part of your IDE, but sometimes WinDbg is needed] Its plugins for refactoring and source control [Resharper 4+ and Ankh SVN 2+] Your OS's addons for source control [Tortoise SVN] A better Diff and Merge Tool to plug into the above SCM tools [WinMerge] A fast loading text editor for when your IDE is too much [vim, Notepad++] If you're doing web development, get tools for that [Firefox 3 with Add-ons: Web Developer, Firebug, TamperData, Poster, Firecookie, FireFTP, FirePHP, Rainbow for Firebug, ReloadEvery, Selenium IDE] Requisite tools for working with text [GNU TextUtils, via cygwin or gnuwin32.sf.net] Scripting tools [Perl, Python, zsh, all those GNU base packages in cygwin] A Regular Expression testing tool for when your eyes hurt [Expresso, RegexBuddy] For Java I swap out 1 and 3 with Eclipse, and its plugins for Maven and SVN, I haven't found a refactoring plug in... you'd think I'd use IntelliJ IDEA but I never started using it. ","pontos":45},{"corpo":"Both mechanisms have value. Any decent test framework will catch the standard assert() anyway, so a test run that causes the assert to fail will result in a failed test. I typically have a series of asserts at the start of each c++ method with a comment '// preconditions'; it's just a sanity check on the state I expect the object to have when the method is called. These dovetail nicely into any TDD framework because they not only work at runtime when you're testing functionality but they also work at test time. ","pontos":2},{"corpo":"+1 SSRS and ActiveReports. ryw, use ActiveReports and close the gates of Crystal Hell behind you forever. ","pontos":2},{"corpo":"<p>I think the first part is your Application. If you decide to go PHP, you almost automatically end up with LAMP, as WIMP or WISP stacks are quite rare (I think blog.stackoverflow.com runs on WIMP), and with .net you definitely want to go WISA.</p> <p>So normally, it boils down to .net vs. PHP. (Ignoring Ruby, Python and all the other stuff for a moment). When you made that decision, the rest comes naturally or adapts into your environment (i.e. if all your admins in the company are windows admins, maybe WAMP works better for you)</p> <p>I switched from PHP to .net about a year ago and I never looked back at PHP, but I never had to look at the bill for Windows and SQL Server licenses to be fair. Deployment on WISA has a much higher initial cost due to the licenses involved, whereas a LAMP Stack is free (Yes, MySQL is also free for commercial use).</p> <hr> <p>Addendum:<br> All the funny acronyms stand for the combination of technologies: (L)inux or (W)indows, (A)pache or (I)IS, (M)ySQL or (S)QL Server, (P)hp or (A)SP.net.</p> ","pontos":10},{"corpo":"Well, AdExplorer runs on your Local Workstation (which is why I prefer it) and I believe that most users have read access to AD anyway because that's actually required for stuff to work, but I'm not sure about that. ","pontos":0},{"corpo":"For one, the shortcut is not \"s\" it is \"s.lnk\". E.g. you are not able to open a text file (say with notepad) by typing \"t\" when the name is \"t.txt\" :) Technet says The PATHEXT environment variable defines the list of file extensions checked by Windows NT when searching for an executable file. The default value of PATHEXT is .COM;.EXE;.BAT;.CMD You can dot-source as described by others here, or you could also use the invocation character \" \". This means that PS treats your string as something to execute rather than just text. This might be more important in a script though. I'd add that you should pass any parameters OUTSIDE of the quotes (this one bit me before) note that the \"-r\" is not in the quoted string, only the exe. \"C:\\WINDOWS\\Microsoft.NET\\Framework\\v2.0.50727\\aspnet_regiis.exe\" -r | out-null ","pontos":2},{"corpo":"Basically the two styles, are like Yin and Yang. One is organized, while the other chaotic. There are situations when Functional programming is the obvious choice, and other situations were Procedural programming is the better choice. This is why there is at least two languages that are coming up with a new version, of their languages to better embrace both programming styles. ( Perl 6 and D 2.0 ) Procedural: The output of a routine does not always have a direct correlation with the input. Everything is done in a specific order. Execution of a routine may have side effects. Tends to emphasize implementing solutions in a linear fashion. Perl 6 sub factorial ( int $n ){ my $result = 1; loop ( ; $n 0; $n-- ){ $result *= $n; } return $result; } D 1.0 D 2.0 int factorial( int n ){ int result = 1; for( ; n 0; n-- ){ result *= n; } return result; } Functional: Often recursive. Always returns the same output for a given input. Order of evaluation is usually undefined. Must be stateless. i.e. No operation can have side effects. Good fit for parallel execution Tends to emphasize a divide and conquer approach. May have the feature of Lazy Evaluation. Haskell ( copied from Wikipedia ); fac :: Integer - Integer fac 0 = 1 fac n | n 0 = n * fac (n-1) or in one line: fac n = if n 0 then n * fac (n-1) else 1 Perl 6 sub factorial ( int $n ){ return 1 unless $n 0; return $n * factorial( $n-1 ); } D 2.0 pure int factorial( invariant int n ){ if( n = 1 ){ return 1; }else{ return n * factorial( n-1 ); } } ( in D 1.0 just remove the keyword. ) ","pontos":45},{"corpo":"You do not need domain admin rights to look at the active directory. By default, any (authenticated?) user can read the information that you need from the directory. If that wasn't the case, for example, a computer (which has an associated account as well) could not verify the account and password of its user. You only need admin rights to change the contents of the directory. I think it is possible to set more restricted permissions, but that's not likely the case. ","pontos":2},{"corpo":"I would argue that from a TDD purist standpoint (i.e. one that thinks that unit tests should be written before implementation), senior developers should be writing more unit tests than lackeys, not less. The reason being that since unit tests come first, writing them requires intimate knowledge of the code base. If you let the lackeys write them, you're essentially letting those who know the least about your domain dictate the structure of your code base. That sounds like a bad idea to me. ","pontos":20},{"corpo":"The person writing the test = defining how the system should work = the \"boss\" The people implementing the tests are the so called \"lackeys\" Sounds like a case of an old dog who doesn't like new tricks. And as the saying goes, it's tough to get them to change... TFD (test-first development) is very fun once you start doing it, maybe have an internal 1-day workshop on TDD or TFD involving the whole team. ","pontos":5},{"corpo":"If a senior developer isn't doing their own testing, then they're not a senior developer. A lack of willingness to test is almost always a sign of laziness or ineptitude (or both), and neither is a trait that should be found in a senior developer. The only scenario I can think of where it would be appropriate for a senior developer to have someone else write their unit tests would be in the case where a junior new hire is being brought up to speed on things. It could be a good task for getting their feet wet while writing some code. ","pontos":2},{"corpo":"TinyMCE only goes out of its way to disable spell-checking when you don't specify the option (i verified this with their example code). Might want to double-check your call - it should look something like this: tinyMCE.init({ mode : \"textareas\", theme : \"simple\", gecko_spellcheck : true }); ","pontos":4},{"corpo":"Just an idea of something to try to see if it gives you more info: Try resizes the list object before the exception line and see if that also throws an exception. If not, try and resize the range object to the new size of the DataTable. You say that this happens when the ListObject shrinks and grows. Does it also happen if the ListObject remains the same size? ","pontos":0},{"corpo":"When accessing the elements of an array, for clarity I would use a foreach whenever possible, and only use a for if you need the actual index values (for example, the same index in multiple arrays). This also minimizes the chance for typo mistakes since for loops make this all too easy. In general, PHP might not be the place be worrying too much about performance. And last but not least, for and foreach have (or should have; I'm not a PHP-er) the same Big-O time (O(n)) so you are looking possibly at a small amount more of memory usage or a slight constant or linear hit in time. ","pontos":0},{"corpo":"This entirely depends on what varies and what stays the same. For example, I am working on a (non-OOP) framework where the find algorithm is different depending both on the type of the needle and the haystack. Apart from the fact that this would require double-dispatch in an object-oriented environment, it also means that it isn't meaningful to write either or to write . On the other hand, your application could happily delegate finding to either of both classes, or stick with one algorithm altogether in which case the decision is arbitrary. In that case, I would prefer the way because it seems more logical to apply the finding to the haystack. ","pontos":4},{"corpo":" Should senior developers be exempt from unit testing Absolutely not. They should not be senior developers at all then. Senior developers should be leaders showing the way, the idea that lackeys do it seems absurd - why bother testing at all then. ","pontos":5},{"corpo":"In the past I have used triggers to construct db update/insert/delete logging. You could insert a record each time one of the above actions is done on a specific table into a logging table that keeps track of the action, what db user did it, timestamp, table it was preformed on, and previous value. There is probably a better answer though as this would require you to cache the value before the actual delete or update was preformed I think. But you could use this to do rollbacks. ","pontos":6},{"corpo":"I suppose you are trying to connect to postfix from some other machine - do you get the same message when logged in to the server directly? Can you try sending mail through \"telnet localhost 25\". Do you have permitmynetworks in smtpdrecipient_restrictions? You might want to read http://www.postfix.org/postconf.5.html#smtpd_recipient_restrictions if you haven't done so already. Among other things, it says you \"need to specify at least one of the following restrictions in smtpdrecipientrestrictions, otherwise Postfix will refuse to receive mail: reject, defer, deferifpermit, rejectunauthdestination\". That seems to be the reason why postfix stopped listening when you removed rejectunauthdestination. ","pontos":1},{"corpo":" will work, but only in PHP 5. ","pontos":0},{"corpo":"We use Programming Research's QAC for our C code. Works OK. Recently we have been talking about checking out some of the more advanced and static/dynamic code analyzers like Coverity's Prevent or the analysis tool by GrammaTech. They claim to not only do static analysis but also find runtime errors etc. One major selling point is supposed to be fewer false positives. ","pontos":1},{"corpo":"You might find piston provides a solution It's primarily used for importing ruby on rails plugins, but I don't see why it shouldn't work for any subversion repositories. Basically what it does is this: svn export latest revision of the remote path commit these files into your local svn as if they were local files attach metadata in the form of svn properties about the remote path and revision This means you can keep a reference to a particular version of a remote repo without having to have it constantly updated like with an svn external. if you want to update your local copy of the library to the latest remote version, you just do You should also be able to look at the history of updates, by simply looking at the metadata - svn properties are versioned just like files and everything else ","pontos":2},{"corpo":"To get rid of the _AFXDLL error, have you tried changing to the settings to use MFC as a static lib instead of a DLL? This is similar to what you're already doing in changing the runtime libs to static instead of DLL. ","pontos":2},{"corpo":"If you are using Hibernate, take a look at JBoss Envers. From the project homepage: The Envers project aims to enable easy versioning of persistent JPA classes. All that you have to do is annotate your persistent class or some of its properties, that you want to version, with @Versioned. For each versioned entity, a table will be created, which will hold the history of changes made to the entity. You can then retrieve and query historical data without much effort. This is somewhat similar to Eric's approach, but probably much less effort. Don't know, what language/technology you use to access the database, though. ","pontos":10},{"corpo":"I used to use it a lot. This designer worked good for stubbing out prototype projects, but ultimately I found myself wasting a lot of time moving the mouse around when I could be typing. It seemed like an awesome idea to be able to print out the class diagrams to show APIs to other developers while I was prototyping, but it proved quite limiting and it looks awful on a non-color printer. Now I just use the text editor and some AutoHotkey macros to get everything done. ","pontos":2},{"corpo":"I am with Brad on this one. The more I work on immensely complex systems, the more I see the need to truly decouple objects. He's right. It's obvious that a needle shouldn't know anything about haystack, so 1 is definitely out. But, a haystack should know nothing about a needle. If I were modeling a haystack, I might implement it as a collection -- but as a collection of hay or straw -- not a collection of needles! However, I would take into consideration that stuff does get lost in a haystack, but I know nothing about what exactly that stuff. I think it's better to not make the haystack look for items in itself (how smart is a haystack anyway). The right approach to me is to have the haystack present a collection of things that are in it, but are not straw or hay or whatever gives a haystack its essence. class Haystack : ISearchableThingsOnAFarm { ICollection Hay myHay; ICollection IStuffSmallEnoughToBeLostInAHaystack stuffLostInMe; public ICollection Hay Hay { get { return myHay; } } public ICollection IStuffSmallEnoughToBeLostInAHayStack LostAndFound { get { return stuffLostInMe; } } } class Needle : IStuffSmallEnoughToBeLostInAHaystack { } class Farmer { Search(Haystack haystack, IStuffSmallEnoughToBeLostInAHaystack itemToFind) } There's actually more I was going to type and abstract into interfaces and then I realized how crazy I was getting. Felt like I was in a CS class in college... :P You get the idea. I think going as loosely coupled as possible is a good thing, but maybe I was getting a bit carried away! :) ","pontos":11},{"corpo":"@ Burton: I think he meant the other way, at least from the example on the linked page: Chronic.parse('tomorrow') #= Mon Aug 28 12:00:00 PDT 2006 Chronic.parse('monday', :context = :past) #= Mon Aug 21 12:00:00 PDT 2006 Chronic.parse('this tuesday 5:00') #= Tue Aug 29 17:00:00 PDT 2006 I thought I would take a stab at it too until I realized! (nice implementation though) ","pontos":0},{"corpo":"Dependency Walker is super useful for finding out which dll is missing from the installer. Once you know the dll, you can find what merge module it is in using the Merge Module Finder. ","pontos":4},{"corpo":"LOLCODE! http://lolcode.com/ HAI CAN HAS STDIO? I HAS A VAR GIMMEH VAR IZ VAR BIGGER THAN 10? YARLY BTW this is true VISIBLE \"BIG NUMBER!\" NOWAI BTW this is false VISIBLE \"LITTLE NUMBER!\" KTHX KTHXBYE ","pontos":33},{"corpo":"Of the suggestions so far, I'm partial to Kevin's, but it doesn't need to be absolute. I see a couple different options to use with __autoload. Put all class files into a single directory. Name the file after the class, ie, or . Kevin's idea of putting models into one directory, controllers into another, etc. Works well if all of your classes fit nicely into the MVC framework, but sometimes, things get messy. Include the directory in the classname. For example, a class called Model User would actually be located at . Your __autoload function would know to translate an underscore into a directory separator to find the file. Just parse the whole directory structure once. Either in the __autoload function, or even just in the same PHP file where it's defined, loop over the contents of the directory and cache what files are where. So, if you try to load the class, it doesn't matter if it's in or or . Once it finds somewhere in the directory, it will know what file to include when the class needs to be autoloaded. ","pontos":0},{"corpo":"It still depends on whoever is coding. I mean, someone somewhere in the world can still understand LOLCODE or Brainfuck or Haskell or whatever.. I still vote for Brainfuck, though. ","pontos":0},{"corpo":"Do you get a 1 unit straight line? It seems that 90deg rot. around Y is going to have you looking at the side of a triangle with no depth. You should try rotating around the Z axis instead and see if you get something that makes more sense. OpenGL has two matrices related to the display of geometry, the ModelView and the Projection. Both are applied to coordinates before the data becomes visible on the screen. First the ModelView matrix is applied, transforming the data from model space into view space. Then the Projection matrix is applied with transforms the data from view space for \"projection\" on your 2D monitor. ModelView is used to position multiple objects to their locations in the \"world\", Projection is used to position the objects onto the screen. Your code seems fine, so I assume from reading the documentation you know what the nature of functions like glPushMatrix() is. If rotating around Z still doesn't make sense, verify that you're editing the ModelView matrix by calling glMatrixMode. ","pontos":5},{"corpo":"I don't know what ruby would do if you used extended UTF8 characters as identifiers in your source code, but I know what I would do, which would be to slap you upside the back of the head and tell you DON'T DO THAT ","pontos":2},{"corpo":"What language is this? It doesnt overflow anything in c... Also, you can try creating a lookup table on the heap, or use a map ","pontos":1},{"corpo":"Yes your insight is correct. This is called dynamic programming. It is usually a common memory runtime trade-off. In the case of fibo, you don't even need to cache everything : [edit] The author of the question seems to be looking for a general method to cache rather than a method to compute Fibonacci. Search wikipedia or look at the code of the other poster to get this answer. Those answers are linear in time and memory. *Here is a linear-time algorithm O(n), constant in memory * in OCaml: let rec fibo n = let rec aux = fun | 0 - (1,1) | n - let (cur, prec) = aux (n-1) in (cur+prec, cur) let (cur,prec) = aux n in prec;; in C++: int fibo(int n) { if (n == 0 ) return 1; if (n == 1 ) return 1; int p = fibo(0); int c = fibo(1); int buff = 0; for (int i=1; i n; ++i) { buff = c; c = p+c; p = buff; }; return c; }; This perform in linear time. But log is actually possible !!! Roo's program is linear too, but way slower, and use memory. Here is the log algorithm O(log(n)) Now for the log-time algorithm (way way way faster), here is a method : If you know u(n), u(n-1), computing u(n+1), u(n) can be done by applying a matrix: | u(n+1) | = | 1 1 | | u(n) | | u(n) | | 1 0 | | u(n-1) | So that you have : | u(n) | = | 1 1 |^(n-1) | u(1) | = | 1 1 |^(n-1) | 1 | | u(n-1) | | 1 0 | | u(0) | | 1 0 | | 1 | Computing the exponential of the matrix has a logarithmic complexity. Just implement recursively the idea : M^(0) = Id M^(2p+1) = (M^2p) * M M^(2p) = (M^p) * (M^p) // of course don't compute M^p twice here. You can also just diagonalize it (not to difficult), you will find the gold number and its conjugate in its eigenvalue, and the result will give you an EXACT mathematical formula for u(n). It contains powers of those eigenvalues, so that the complexity will still be logarithmic. Fibo is often taken as an example to illustrate Dynamic Programming, but as you see, it is not really pertinent. @John: I don't think it has anything to do with do with hash. @John2: A map is a bit general don't you think? For Fibonacci case, all the keys are contiguous so that a vector is appropriate, once again there are much faster ways to compute fibo sequence, see my code sample over there. ","pontos":17},{"corpo":"The first thing I did when I got to upgrade to VS2008 and C#3, was to do this public static string F( this string format, params object[] args ) { return String.Format(format, args); } So I can now change my code from String.Format(\"Hello {0}\", Name); to \"Hello {0}\".F(Name); which I preferred at the time. Nowadays (2014) I don't bother because it's just another hassle to keep re-adding that to each random project I create, or link in some bag-of-utils library. As for why the .NET designers chose it? Who knows. It seems entirely subjective. My money is on either Copying Java The guy writing it at the time subjectively liked it more. There aren't really any other valid reasons that I can find ","pontos":7},{"corpo":"Visual Studio optimisations: http://stackoverflow.com/questions/8440/visual-studio-optimizations#8453 ","pontos":5},{"corpo":"Is this a deliberately chosen example? (eg. an extreme case you're wanting to test) As it's currently O(1.6^n) i just want to make sure you're just looking for answers on handling the general case of this problem (caching values, etc) and not just accidentally writing poor code :D Looking at this specific case you could have something along the lines of: var cache = []; function fib(n) { if (n 2) return 1; if (cache.length n) return cache[n]; var result = fib(n - 2) + fib(n - 1); cache[n] = result; return result; } Which degenerates to O(n) in the worst case :D [Edit: * does not equal + :D ] [Yet another edit: the Haskell version (because i'm a masochist or something) fibs = 1:1:(zipWith (+) fibs (tail fibs)) fib n = fibs !! n ] ","pontos":1},{"corpo":"If you're using a language with first-class functions like Scheme, you can add memoization without changing the initial algorithm: (define (memoize fn) (letrec ((get (lambda (query) '(#f))) (set (lambda (query value) (let ((old-get get)) (set! get (lambda (q) (if (equal? q query) (cons #t value) (old-get q)))))))) (lambda args (let ((val (get args))) (if (car val) (cdr val) (let ((ret (apply fn args))) (set args ret) ret)))))) (define fib (memoize (lambda (x) (if ( x 2) x (+ (fib (- x 1)) (fib (- x 2))))))) The first block provides a memoization facility and the second block is the fibonacci sequence using that facility. This now has an O(n) runtime (as opposed to O(2^n) for the algorithm without memoization). Note: the memoization facility provided uses a chain of closures to look for previous invocations. At worst case this can be O(n). In this case, however, the desired values are always at the top of the chain, ensuring O(1) lookup. ","pontos":0},{"corpo":"lolcode: sorry I couldn't resist xD HAI CAN HAS STDIO? I HAS A VAR I HAS A INT I HAS A CHEEZBURGER I HAS A FACTORIALNUM IM IN YR LOOP UP VAR!!1 TIEMZD INT!![CHEEZBURGER] UP FACTORIALNUM!!1 IZ VAR BIGGER THAN FACTORIALNUM? GTFO IM OUTTA YR LOOP U SEEZ INT KTHXBYE ","pontos":124},{"corpo":"What extra bits? They are going from 6 to 4. EDIT: Whoops! I'm an idiot. This is kinda like a 2nd grade multiplication table. They strip the outer bits off of the 6-bit block to be encypted, and leave the middle 4. Just like a table for an arithmatic operation, they go down one side, and find the outer bit sequence, then across the top and find the middle ones. To answer your question, it could input and output the same number of bits, but this s-box is just set up to do it the way it does. Its arbitrary. ","pontos":1},{"corpo":"A few things that have bitten me: -- RDoc uses only the last one evaluated; best to make sure there's only one in your project and you don't also use the command-line argument. same as previous, but for doesn't work very well ","pontos":4},{"corpo":"It is the way s-boxes work. They can be m * n ==> m bit input , n bit output. For example, in the AES S-box the number of bits in input is equal to the number of bits in output. In DES, m=6 and n=4. The input is expanded from 32 to 48 bits in the first stages of DES. So it is be reduced to 32 bits again by applying one round of S-box substitution. Thus no information is lost here. The Wikipedia article on itself can be a bit confusing. It will make people think that information is lost. You should read the article in conjuncture with implementation details of some encryption algorithm using s-boxes. ","pontos":3},{"corpo":"I can't speak to anything other than SQL Server, but the performance argument is not significantly valid there unless you're on 6.5 or earlier. SQL Server has been caching ad-hoc execution plans for roughly a decade now. ","pontos":17},{"corpo":"Personally, I think you should know how databases work as well as the relational model and the rhetoric behind it, including all forms of normalization (even though I rarely see a need to go beyond third normal form). The core concepts of the relational model do not change from relational database to relational database - implementation may, but so what? Developers that don't understand the rationale behind database normalization, indexes, etc. are going to suffer if they ever work on a non-trivial project. ","pontos":3},{"corpo":"I think you should consider a different development strategy to prevent issues like this. One that seems to work best for me is to never do development directly on my master branch. Regardless of the changes I'm making, I always create a new branch for new code: git checkout -b topic/topic_name master From there, I can push out the changes to public repositories: git push pu topic/topic_name or eventually just merge it back in with my master branch: git checkout master && git merge topic/topic_name If you truly need to go back to an older point in time and set that as your master, you can rename the current branch to something else and then check out an older version to be your master: git branch -m master junk git co -b master old_sha1_value ","pontos":30},{"corpo":".NET Strings are Immutable Therefore having an instance method makes absolutely no sense. String foo = new String(); foo.Format(\"test {0}\",1); // Makes it look like foo should be modified by the Format method. string newFoo = String.Format(foo, 1); // Indicates that a new string will be returned, and foo will be unaltered. ","pontos":-1},{"corpo":"I used the MVC framework to build a small site, and I found myself frequently frustrated by the tag soup views, and lack of the server controls I had come to love. I went back to using webforms. WebForms, once mastered, are great...They just take a very long time to learn all the tricks. ","pontos":1},{"corpo":"Non-overloaded, non-inherited static methods (like Class.b(a,c)) that take an instance as the first variable are semantically equivalent to a method call (like a.b(c)) so the platform team made an arbitrary, aesthetic choice. (Assuming it compiles to the same CIL, which it should.) The only way to know would be to ask them why. Possibly they did it to keep the two strings close to each other lexigraphically, i.e. String.Format(\"Foo {0}\", \"Bar\"); instead of \"Foo {0}\".Format(\"bar\"); You want to know what the indexes are mapped to; perhaps they thought that the \".Format\" part just adds noise in the middle. Interestingly, the ToString method (at least for numbers) is the opposite: number.ToString(\"000\") with the format string on the right hand side. ","pontos":1},{"corpo":" Why the choice of NHibernate over anything else? It's a very powerful tool, and is (relatively) easy to learn. It takes away all the monotony and repetitiveness of manually implementing object-relational mapping. ","pontos":0},{"corpo":" The problem with this code is that it will generate stack overflow error for any number greater than 15 (in most computers). Really? What computer are you using? It's taking a long time at 44, but the stack is not overflowing. In fact, your going to get a value bigger than an integer can hold (~4 billion unsigned, ~2 billion signed) before the stack is going to over flow (Fibbonaci(46)). This would work for what you want to do though (runs wiked fast) class Program { public static readonly Dictionary int,int Items = new Dictionary int,int (); static void Main(string[] args) { Console.WriteLine(Fibbonacci(46).ToString()); Console.ReadLine(); } public static int Fibbonacci(int number) { if (number == 1 || number == 0) { return 1; } var minus2 = number - 2; var minus1 = number - 1; if (!Items.ContainsKey(minus2)) { Items.Add(minus2, Fibbonacci(minus2)); } if (!Items.ContainsKey(minus1)) { Items.Add(minus1, Fibbonacci(minus1)); } return (Items[minus2] + Items[minus1]); } } ","pontos":0},{"corpo":" Markup is a generic term for a language that describes a document's formatting Markdown is a specific markup library: http://daringfireball.net/projects/markdown/ ","pontos":59},{"corpo":" .NET Strings are Immutable Therefore having an instance method makes absolutely no sense. By that logic the string class should have no instance methods which return modified copies of the object, yet it has plenty (Trim, ToUpper, and so on). Furthermore, lots of other objects in the framework do this too. I agree that if they were to make it an instance method, seems like it would be a bad name, but that doesn't mean the functionality shouldn't be an instance method. Why not this? It's consistent with the rest of the .NET framework \"Hello {0}\".ToString(\"Orion\"); ","pontos":2},{"corpo":"I have no idea what's causing the problem but I know who might be able to help you. Safari is built on Webkit and short of Apple (who are not so community minded) the Webkit team might know what the issue is. It's not a stupid question at all. ","pontos":3},{"corpo":"Today's web browsers only handle GETS + POSTS. In Rails, for example, PUTS + DELETES are \"faked\" through hidden form fields. Unless your framework has some workaround to \"support\" PUTS + DELETES, don't worry about them for now. ","pontos":1},{"corpo":"I've noticed something very similar. I think it is because Firefox and IE, when going back, are retrieving the page from the server again and Safari is not. Have you tried adding a page expiry/no cache header? I was going to look into it when I discovered the behaviour but haven't had time yet. ","pontos":3},{"corpo":"@Autodidact: It's definitely not a stupid question, any time when the behaviour of webkit differs from both IE and Firefox is a bug a should be filed at http://bugs.webkit.org (I would file it myself, but then i'd be the one who had to confirm the fix, rather than you, which would be rather silly given you're the person experiencing this bug :D) [Edit: I just realised that your example will be in the back/forward cache -- the onload won't fire again as the entire JS state will be stored, it seems unlikely in this case that that is causing a bug, so when you file a bug report, if at all possible you should try to include the code or the url that fails] @Teifon: Um, Apple engineers do almost all of the active development on WebKit (WebKit is a MacOS system framework after all, and apple started the project (as a fork of khtml, but they are now substantially diverged)), non-apple developers focus almost entirely on their respective back and front ends (eg. gtk, qt, wx) -- if you look at http://trac.webkit.org/ you can see that fairly clearly the majority of dev work is from apple -- and the most active irc-ers are apple engineers, so i'm really not sure how you've come to the conclusion that webkit is somehow community minded when apple is not :D (Sorry for long reply, I'm just tired of seeing this particular misconception repeated :-/ ) [Edit: @Stefan Koenig I believe that any place where the caching behaviour differs from IE and Firefox in a way that actually breaks a site is a bug] ","pontos":8},{"corpo":"An iframe solves the problem: !DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" html head title Safari Back Button Test /title meta http-equiv=\"Content-Type\" content=\"text/html; charset=iso-8859-1\" /head body onload=\"alert('Hello');\" a href=\"http://www.codinghorror.com\" Coding Horror /a iframe style=\"height:0px;width:0px;visibility:hidden\" src=\"about:blank\" this prevents back forward cache /iframe /body /html more details ","pontos":7},{"corpo":"To be honest, I understand closures perfectly well except I've never been clear about what exactly is the thing which is the \"closure\" and what's so \"closure\" about it. I recommend you give up looking for any logic behind the choice of term. Anyway, here's my explanation: def foo(): x = 3 def bar(): print x x = 5 return bar bar = foo() bar() # print 5 A key idea here is that the function object returned from foo retains a hook to the local var 'x' even though 'x' has gone out of scope and should be defunct. This hook is to the var itself, not just the value that var had at the time, so when bar is called, it prints 5, not 3. Also be clear that Python 2.x has limited closure: there's no way I can modify 'x' inside 'bar' because writing 'x = bla' would declare a local 'x' in bar, not assign to 'x' of foo. This is a side-effect of Python's assignment=declaration. To get around this, Python 3.0 introduces the nonlocal keyword: def foo(): x = 3 def bar(): print x def ack(): nonlocal x x = 7 x = 5 return (bar, ack) bar, ack = foo() ack() # modify x of the call to foo bar() # print 7 ","pontos":11},{"corpo":"I used VisualSVN until Ankh hit 2.0, and ever since, I've abandoned VisualSVN. Ankh has surpassed VisualSVN in functionality, in my mind, and all the 1.x perf and integration issues are gone. ","pontos":48},{"corpo":"Block the finalizer thread. No other objects will be garbage collected until the finalizer thread is unblocked. Thus the amount of memory used will grow and grow. Further reading: http://dotnetdebug.net/2005/06/22/blocked-finalizer-thread/ ","pontos":5},{"corpo":"If JConsole can't be used you can press CTRL+BREAK under Windows send under Linux to get a full Thread Dump. This doesn't affect performance and can always be run in production. ","pontos":2},{"corpo":"@Jared: Non-overloaded, non-inherited static methods (like Class.b(a,c)) that take an instance as the first variable are semantically equivalent to a method call (like a.b(c)) No, they aren't. (Assuming it compiles to the same CIL, which it should.) That's your mistake. The CIL produced is different. The distinction is that member methods can't be invoked on values so the CIL inserts a check against values. This obviously isn't done in the static variant. However, does not allow values so the developers had to insert a check manually. From this point of view, the member method variant would be technically superior. ","pontos":2},{"corpo":"Mark-up is a term from print editing - the editor would go through the text and add annotations (i.e. this in italic, that in bold) for the printers to use when producing the final version. This was called marking up the text. A computer mark-up language is just a standardised short-hand for these sorts of annotations. HTML is basically the web's standard mark-up language, but it's rather verbose. A list in HTML: ul li Item one /li li Item two /li /ul Markdown is a specific markup language, having its own simple syntax. A list in Markdown: * Item one * Item two Both of these will work in your stackoverflow posts. Markdown can't do everything HTML can, but both are mark-up languages. ","pontos":33},{"corpo":"Always, always, always parameterise any user input. Don't assume sprocs are automatically safe - they can be just as prone. ","pontos":1},{"corpo":" Isn't it a security flaw of the site to let hackers throw everything in their arsenal against the site? Well, you should focus on closing holes, rather than trying to thwart scanners (which is a futile battle). Consider running such tests yourself. ","pontos":2},{"corpo":"It's good that you block bad request after a couple of trials, but you should let it continue. If you block it after 5 bad requests you won't know if the 6th request wouldn't crash your site. EDIT: I meant that some attacker might send only one request but similar to one of those 1495 that You didn't test because you blocked., and this one request might chrash your site. ","pontos":1},{"corpo":"I'm no expert, but from what I learned so far the golden rule is not to trust any user data (GET, POST, COOKIE). Common attack types and how to save yourself: SQL Injection Attack: Use prepared queries Cross Site Scripting: Send no user data to browser without filtering/escaping first. This also includes user data stored in database, which originally came from users. ","pontos":0},{"corpo":"I my applications I usually have file that includes all core classes (i.e. framework and accompanying libraries). My custom classes are loaded using autoloader aided by directory layout map. Each time new class is added I run command line builder script that scans whole directory tree in search for model classes then builds associative array with class names as keys and paths as values. Then, __autoload function looks up class name in that array and gets include path. Here's the code: autobuild.php define('MAP', 'var/cache/autoload.map'); error_reporting(E_ALL); require 'setup.php'; print(buildAutoloaderMap() . \" classes mapped\\n\"); function buildAutoloaderMap() { $dirs = array('lib', 'view', 'model'); $cache = array(); $n = 0; foreach ($dirs as $dir) { foreach (new RecursiveIteratorIterator(new RecursiveDirectoryIterator($dir)) as $entry) { $fn = $entry- getFilename(); if (!preg_match('/\\.class\\.php$/', $fn)) continue; $c = str_replace('.class.php', '', $fn); if (!class_exists($c)) { $cache[$c] = ($pn = $entry- getPathname()); ++$n; } } } ksort($cache); file_put_contents(MAP, serialize($cache)); return $n; } autoload.php define('MAP', 'var/cache/autoload.map'); function __autoload($className) { static $map; $map or ($map = unserialize(file_get_contents(MAP))); $fn = array_key_exists($className, $map) ? $map[$className] : null; if ($fn and file_exists($fn)) { include $fn; unset($map[$className]); } } Note that file naming convention must be [class_name].class.php. Alter the directories classes will be looked in . You can also run autobuilder from autoload function when class not found, but that may get your program into infinite loop. Serialized arrays are darn fast. @JasonMichael: PHP 4 is dead. Get over it. ","pontos":6},{"corpo":" Code::Blocks Eclipse CDT Soon you'll find that IDEs are not enough, and you'll have to learn the GCC toolchain anyway (which isn't hard, at least learning the basic functionality). But no harm in reducing the transitional pain with the IDEs, IMO. ","pontos":66},{"corpo":"I am a Mac man myself so I could be wrong about this, I have been told that Fraps might be of use. ","pontos":0},{"corpo":"It depends exactly what you mean by 'better'. I'd go for the object oriented way (using classes) because I find it makes for cleaner code (at least in my opinion). However, I'm not sure what the speed penalties might be for that option. ","pontos":4},{"corpo":"I recommend that if VS Express is not good enough, use Professional. Standard is missing some really useful features, like a Remote Debugger. Here is a detailed comparison: http://msdn.microsoft.com/en-us/vs2008/products/cc149003.aspx I'd say cancel TechNet and get one of the bottom two MSDN Subscriptions, Visual Studio Professional with either MSDN Professional or with MSDN Premium. ","pontos":5},{"corpo":"Most people here have mentioned SQL Injection and XSS, which is kind of correct, but don't be fooled - the most important things you need to worry about as a web developer is INPUT VALIDATION, which is where XSS and SQL Injection stem from. For instance, if you have a form field that will only ever accept integers, make sure you're implementing something at both the client-side AND the server-side to sanitise the data. Check and double check any input data especially if it's going to end up in an SQL query. I suggest building an escaper function and wrap it around anything going into a query. For instance: $query = \"SELECT field1, field2 FROM table1 WHERE field1 = '\" . myescapefunc($userinput) . \"'\"; Likewise, if you're going to display any user-inputted information onto a webpage, make sure you've stripped any script tags or anything else that might result in Javascript execution (such as onLoad= onMouseOver= etc. attributes on tags). ","pontos":3},{"corpo":"This is to avoid confusion with methods. For instance: double test = 1.54d; //string.Format pattern string.Format(\"This is a test: {0:F1}\", test ); //ToString pattern \"This is a test: \" + test.ToString(\"F1\"); If Format was an instance method on string this could cause confusion, as the patterns are different. String.Format() is a utility method to turn multiple objects into a formatted string. An instance method on a string does something to that string. Of course, you could do: public static string FormatInsert( this string input, params object[] args) { return string.Format( input, args ); } \"Hello {0}, I have {1} things.\".FormatInsert( \"world\", 3); ","pontos":2},{"corpo":"Another possibility could be from side effects. Most min/max macros will include the parameters multiple times and may not do what you expect. Errors and warnings could also be generated. max(a,i++) expands as ((a) > (i++) ? (a) : (i++)) afterwards i is either plus 1 or plus 2 The () in the expansion are to avoid problems if you call it with formulae. Try expanding max(a,b+c) ","pontos":2},{"corpo":"I just installed Community Clips from Microsoft Office Labs. It seems to do the job. ","pontos":0},{"corpo":"As an old-time UNIX guy, I always use Emacs. But that has a pretty steep and long learning curve, so I'm not sure I can recommend it to newcomers. There really isn't a \"good\" IDE for Linux. Eclipse is not very good for C/C++ (CDT is improving, but is not very useful yet). The others are missing all the features you are going to be looking for. It really is important to learn how all the individual tools (gcc, make, gdb, etc.) work. After you do so, you may find the Visual Studio way of doing things to be very limiting. ","pontos":21},{"corpo":"lint is constantly updated... so why would you want a more recent one. BTW flexelint is lint ","pontos":1},{"corpo":"Just tossing out a second recommendation for Working Effectively with Legacy Code, an excellent book that really opened my eyes to the fact that almost any old / crappy / untestable code can be wrangled! ","pontos":0},{"corpo":"@ESRogs: lookup is O(log n) which makes it slow here. Better use a vector. vector unsigned int fib_cache; fib_cache.push_back(1); fib_cache.push_back(1); unsigned int fib(unsigned int n) { if (fib_cache.size() = n) fib_cache.push_back(fib(n - 1) + fib(n - 2)); return fib_cache[n]; } ","pontos":1},{"corpo":"I realise that this doesn't apply to the asker but it it is relevent to the question. Any student developers out there try Microsfts Dream Spark scheme. Visual Studio, Expression Studio, XNA and Server 2003 for free! Office is also available to students for less than 60 bucks in Microsfts `Ultimate Steal' ","pontos":2},{"corpo":"The first thing that jumps to mind is the possibility of your git history having a nonlinear history. You might have difficulty determining a sensible sequence of commits. Having said that, it seems like you could keep a log of commit ids and the corresponding lines of code in that commit. In a post-commit hook, starting from the HEAD revision, work backwards (branching to multiple parents if necessary) until all paths reach a commit that you've already seen before. That should give you the total lines of code for each commit id. Does that help any? I have a feeling that I've misunderstood something about your question. ","pontos":3},{"corpo":"Set based queries are (usually) faster because: They have more information for the query optimizer to optimize They can batch reads from disk There's less logging involved for rollbacks, transaction logs, etc. Less locks are taken, which decreases overhead Set based logic is the focus of RDBMSs, so they've been heavily optimized for it (often, at the expense of procedural performance) Pulling data out to the middle tier to process it can be useful, though, because it removes the processing overhead off the DB server (which is the hardest thing to scale, and is normally doing other things as well). Also, you normally don't have the same overheads (or benefits) in the middle tier. Things like transactional logging, built-in locking and blocking, etc. - sometimes these are necessary and useful, other times they're just a waste of resources. A simple cursor with procedural logic vs. set based example (T-SQL) that will assign an area code based on the telephone exchange: --Cursor DECLARE @phoneNumber char(7) DECLARE c CURSOR LOCAL FAST_FORWARD FOR SELECT PhoneNumber FROM Customer WHERE AreaCode IS NULL OPEN c FETCH NEXT FROM c INTO @phoneNumber WHILE @@FETCH_STATUS = 0 BEGIN DECLARE @exchange char(3), @areaCode char(3) SELECT @exchange = LEFT(@phoneNumber, 3) SELECT @areaCode = AreaCode FROM AreaCode_Exchange WHERE Exchange = @exchange IF @areaCode IS NOT NULL BEGIN UPDATE Customer SET AreaCode = @areaCode WHERE CURRENT OF c END FETCH NEXT FROM c INTO @phoneNumber END CLOSE c DEALLOCATE c END --Set UPDATE Customer SET AreaCode = AreaCode_Exchange.AreaCode FROM Customer JOIN AreaCode_Exchange ON LEFT(Customer.PhoneNumber, 3) = AreaCode_Exchange.Exchange WHERE Customer.AreaCode IS NULL ","pontos":10},{"corpo":" Also, are they unique to Java, is there a C++ equivalent? No, but VB and C# have attributes which are the same thing. Their use is quite diverse. One typical Java example, has no effect on the code but it can be used by the compiler to generate a warning (or error) if the decorated method doesn't actually override another method. Similarly, methods can be marked obsolete. Then there's reflection. When you reflect a type of a class in your code, you can access the attributes and act according to the information found there. I don't know any examples in Java but in .NET this is used by the compiler to generate (de)serialization information for classes, determine the memory layout of structures and declare function imports from legacy libraries (among others). They also control how the IDE form designer works. /EDIT: Attributes on classes are comparable to tag interfaces (like Serializable in Java). However, the .NET coding guidelines say not to use tag interfaces. Also, they only work on class level, not on method level. ","pontos":14},{"corpo":"In addition to the above \"let the DBMS do the work\" (which is a great solution), there are a couple other good reasons to leave the query in the DBMS: It's (subjectively) easier to read. When looking at the code later, would you rather try and parse a complex stored procedure (or client-side code) with loops and things, or would you rather look at a concise SQL statement? It avoids network round trips. Why shove all that data to the client and then shove more back? Why thrash the network if you don't need to? It's wasteful. Your DBMS and app server(s) will need to buffer some/all of that data to work on it. If you don't have infinite memory you'll likely page out other data; why kick out possibly important things from memory to buffer a result set that is mostly useless? Why wouldn't you? You bought (or are otherwise using) a highly reliable, very fast DBMS. Why wouldn't you use it? ","pontos":13},{"corpo":"I've been a long time user of CodeRush and Refactor! Pro. CodeRush is way more than refactoring. Once you learn the rules it sets out, coding speed increases. However, even before you learn the rules, it intelligently applies itself to existing things you do and makes doing them easier. Indeed, the thing I miss the most about coding in Ruby on Rails is that I don't have an IDE with CodeRush and Refactor! TextMate bundles get me part way, but it's not the same. They have a free trial available, so I encourage you to give it a run and see how you like it. I've never looked back. ","pontos":9},{"corpo":"I don't understand what you are trying to do here. Are you trying to execute a Python script that generates a C# file and then compile that with the project? Or are you trying to compile a Python script to C#? ","pontos":1},{"corpo":"Red-Gate SQL Data Compare will do this. Just create a blank data base with the same schema, and run a compare against the original and the blank database. It will generate scripts to insert all of your test data. ","pontos":1},{"corpo":"This problem has been studied in some detail. There are a set of very up-to-date implementations in the classes of ROOT (a nuclear/particle physics analysis tool). The code works in one- to three-dimensional data. The ROOT source code is available, so you can grab this implementation if you want. From the TSpectrum class documentation: The algorithms used in this class have been published in the following references: [1] M.Morhac et al.: Background elimination methods for multidimensional coincidence gamma-ray spectra. Nuclear Instruments and Methods in Physics Research A 401 (1997) 113- 132. [2] M.Morhac et al.: Efficient one- and two-dimensional Gold deconvolution and its application to gamma-ray spectra decomposition. Nuclear Instruments and Methods in Physics Research A 401 (1997) 385-408. [3] M.Morhac et al.: Identification of peaks in multidimensional coincidence gamma-ray spectra. Nuclear Instruments and Methods in Research Physics A 443(2000), 108-125. The papers are linked from the class documentation for those of you who don't have a NIM online subscription. The short version of what is done is that the histogram flattened to eliminate noise, and then local maxima are detected by brute force in the flattened histogram. ","pontos":6},{"corpo":"Lint-like tools generally suffer from a \"false alarm\" problem: they report a lot more issues than really exist. If the proportion of genuinely-useful warnings is too low, the user learns to just ignore the tool. More modern tools expend some effort to focus on the most likely/interesting warnings. ","pontos":1},{"corpo":"It seems you have misplaced the parameters in File.Copy(), it should be File.Copy(string source, string destination). Also is \"C:\\Test2\" a directory? You can't copy file to a directory. Use something like that instead: File.Copy( sourceFile, Path.Combine(destinationDir,Path.GetFileName(sourceFile)) ); ","pontos":2},{"corpo":"I'm kinda guessing here, but could it be because: You are trying to perform file operations in C: root? (there may be protection on this by Vista if you are using it - not sure?) You are trying to copy to a non-existant directory? The file already exists and may be locked? (i.e you have not closed another application instance)? Sorry I cant be of more help, I have rarely experienced problems with File.Copy. ","pontos":0},{"corpo":"@CodingTheWheel But to the extent that OOP has been a waste of time, I'd say it's because of lack of programmer training, compounded by the steep learning curve of learning a language specific OOP mapping. Some people \"get\" OOP and others never will. I dunno if that's really surprising, though. I think that technically sound approaches (LSP being the obvious thing) make hard to use, but if we don't use such approaches it makes the code brittle and inextensible anyway (because we can no longer reason about it). And I think the counterintuitive results that OOP leads us to makes it unsurprising that people don't pick it up. More significantly, since software is already fundamentally too hard for normal humans to write reliably and accurately, should we really be extolling a technique that is consistently taught poorly and appears hard to learn? If the benefits were clear-cut then it might be worth persevering in spite of the difficulty, but that doesn't seem to be the case. ","pontos":5},{"corpo":"Yes you are correct in thinking that C is a non-functional language. C is a procedural language. ","pontos":3},{"corpo":"@Konrad OOP may be flawed and it certainly is no silver bullet but it makes large-scale applications much simpler because it's a great way to reduce dependencies That is the dogma. I am not seeing what makes OOP significantly better in this regard than procedural programming of old. Whenever I make a procedure call I am isolating myself from the specifics of the implementation. ","pontos":6},{"corpo":"Its a programming paradigm.. Designed to make it easier for us mere mortals to break down a problem into smaller, workable pieces.. If you dont find it useful.. Don't use it, don't pay for training and be happy. I on the other hand do find it useful, so I will :) ","pontos":14},{"corpo":"I prefer to use functional programming to save myself repeated work, by making a more abstract version and then using that instead. Let me give an example. In Java, I often find myself creating maps to record structures, and thus writing getOrCreate structures. SomeKindOfRecord T getOrCreate(T thing) { if(localMap.contains(t)) { return localMap.get(t); } SomeKindOfRecord T record = new SomeKindOfRecord T (t); localMap = localMap.put(t,record); return record; } This happens very often. Now, in a functional language I could write RT T getOrCreate(T thing, Function RT T thingConstructor, Map T,RT T localMap) { if(localMap.contains(t)) { return localMap.get(t); } RT T record = thingConstructor(t); localMap = localMap.put(t,record); return record; } and I would never have to write a new one of these again, I could inherit it. But I could do one better then inheriting, I could say in the constructor of this thing getOrCreate = myLib.getOrCreate(*, SomeKindOfRecord T .constructor( T ), localMap); (where * is a kind of \"leave this parameter open\" notation, which is a sort of currying) and then the local getOrCreate is exactly the same as it would have been if I wrote out the whole thing, in one line, with no inheritance dependencies. ","pontos":2},{"corpo":"The IRC Specification is laid out in RFC 1459 http://www.irchelp.org/irchelp/rfc/rfc.html ","pontos":10},{"corpo":" In my second year of University we were \"taught\" Haskell [] What is functional programming [] and am I correct in thinking that C is a non-functional programming language? Man, your course must really have sucked. Sorry for being so cynical. Anyway, have a look at these related questions: What's the difference between functional and procedural programming? Recursion, Memoization ","pontos":4},{"corpo":"@Jeff Relative to straight procedural programming, the first fundamental tenet of OOP is the notion of information hiding and encapsulation. This idea leads to the notion of the class that seperates the interface from implementation. Which has the more hidden implementation: C++'s iostreams, or C's FILE*s? I think the use of opaque context objects (HANDLEs in Win32, FILE*s in C, to name two well-known examples--hell, HANDLEs live on the other side of the kernel-mode barrier, and it really doesn't get much more encapsulated than that) is found in procedural code too; I'm struggling to see how this is something particular to OOP. I suppose that may be a part of why I'm struggling to see the benefits: the parts that are obviously good are not specific to OOP, whereas the parts that are specific to OOP are not obviously good! (this is not to say that they are necessarily bad, but rather that I have not seen the evidence that they are widely-applicable and consistently beneficial). ","pontos":4},{"corpo":"CodeRush is where it's at man. I didn't like resharpers intellisense, so i turned it off, which makes resharper less useful. ","pontos":14},{"corpo":" I found this gem on Wikipedia. Sounds intimidating. It's actually not. Telnet onto an IRC Server and witness the simplicity of the protocol first hand. The hardest part is the handshake, after that its very simple. ","pontos":6},{"corpo":"Not sure if there is a way of an event actually being raised by the standard class, but I eas experiencing similar problems on some recent work I was doing. In short, I was trying to write to a file that was locked at the time. I ended up wrapping the write method up so it would automatically try the write again in a few ms after.. Thinking out loud, Can you probe the file for a ReadOnly status? May be worth then having a wrapper for file IO which can stack up delegates for pending file operations or something.. Thoughts? ","pontos":0},{"corpo":" I think the use of opaque context objects (HANDLEs in Win32, FILE*s in C, to name two well-known examples--hell, HANDLEs live on the other side of the kernel-mode barrier, and it really doesn't get much more encapsulated than that) is found in procedural code too; I'm struggling to see how this is something particular to OOP. s (and the rest of the WinAPI) is OOP! C doesn't support OOP very well so there's no special syntax but that doesn't mean it doesn't use the same concepts. WinAPI is in every sense of the word an object-oriented framework. See, this is the trouble with every single discussion involving OOP or alternative techniques: nobody is clear about the definition, everyone is talking about something else and thus no consensus can be reached. Seems like a waste of time to me. ","pontos":21},{"corpo":"Anders gives a good summary, and here's an example of a JUnit annotation @Test(expected=IOException.class) public void flatfileMissing() throws IOException { readFlatFile(\"testfiles\"+separator+\"flatfile_doesnotexist.dat\"); } Here the @Test annotation is telling JUnit that the flatfileMissing method is a test that should be executed and that the expected result is a thrown IOException. Thus, when you run your tests, this method will be called and the test will pass or fail based on whether an IOException is thrown. ","pontos":11},{"corpo":"Use CreateFile in a loop with OPEN_ EXISTING flag and FILE_ ALL_ ACCESS (or you might need only a subset, see http://msdn.microsoft.com/en-us/library/aa364399(VS.85).aspx Examine the handle returned against -1 (INVALID_ HANDLE_ VALUE) for failure. It's still polling, but this will save the cost of an exception throw. EDIT: this editor/markup can't handle underscores! bah! ","pontos":0},{"corpo":"I have never used it. I completely agree, it's bloatware. I usually end up using the repeater with custom controls that i made. ","pontos":1},{"corpo":" HANDLEs (and the rest of the WinAPI) is OOP! Are they, though? They're not inheritable, they're certainly not substitutable, they lack well-defined classes... I think they fall a long way short of \"OOP\". ","pontos":1},{"corpo":"@Jonathan: I don't think internal means what you think it means. The internal modifier limits access to only within the assembly, not just self or parent. That said, declaring the constructors internal may solve the OP's problem if he only wants to disallow instantiation from outside the assembly. ","pontos":0},{"corpo":" HANDLEs (and the rest of the WinAPI) is OOP! Are they, though? They're not inheritable, they're certainly not substitutable, they lack well-defined classes... I think they fall a long way short of \"OOP\". Have you ever created a window using WinAPI? Then you should know that you define a class (), create an instance of it (), call virtual methods () and base-class methods () and so on. WinAPI even takes the nomenclature from SmallTalk OOP, calling the methods messages (Window Messages). Handles may not be inheritable but then, there's in Java. They don't lack a class, they are a placeholder for the class: That's what the word handle means. Looking at architectures like MFC or .NET WinForms it's immediately obvious that except for the syntax, nothing much is different from the WinAPI. ","pontos":11},{"corpo":"Python uses pass-by-value, but since all such values are object references, the net effect is something akin to pass-by-reference. However, Python programmers think more about whether an object type is mutable or immutable. Mutable objects can be changed in-place (e.g., dictionaries, lists, user-defined objects), whereas immutable objects can't (e.g., integers, strings, tuples). The following example shows a function that is passed two arguments, an immutable string, and a mutable list. def do_something(a, b): ... a = \"Red\" ... b.append(\"Blue\") ... a = \"Yellow\" b = [\"Black\", \"Burgundy\"] do_something(a, b) print a, b Yellow ['Black', 'Burgundy', 'Blue'] The line merely creates a local name, , for the string value and has no effect on the passed-in argument (which is now hidden, as must refer to the local name from then on). Assignment is not an in-place operation, regardless of whether the argument is mutable or immutable. The parameter is a reference to a mutable list object, and the method performs an in-place extension of the list, tacking on the new string value. (Because string objects are immutable, they don't have any methods that support in-place modifications.) Once the function returns, the re-assignment of has had no effect, while the extension of clearly shows pass-by-reference style call semantics. As mentioned before, even if the argument for is a mutable type, the re-assignment within the function is not an in-place operation, and so there would be no change to the passed argument's value: a = [\"Purple\", \"Violet\"] do_something(a, b) print a, b ['Purple', 'Violet'] ['Black', 'Burgundy', 'Blue', 'Blue'] If you didn't want your list modified by the called function, you would instead use the immutable tuple type (identified by the parentheses in the literal form, rather than square brackets), which does not support the in-place method: a = \"Yellow\" b = (\"Black\", \"Burgundy\") do_something(a, b) Traceback (most recent call last): File \" stdin \", line 1, in module File \" stdin \", line 3, in do_something AttributeError: 'tuple' object has no attribute 'append' ","pontos":18},{"corpo":"Even if you progress beyond the express edition, the standard version of VS is only $250. That's less than most people pay for coffee and food in a month...Just don't eat. =) ","pontos":1},{"corpo":" Have you ever created a window using WinAPI? More times than I care to remember. Then you should know that you define a class (RegisterClass), create an instance of it (CreateWindow), call virtual methods (WndProc) and base-class methods (DefWindowProc) and so on. WinAPI even takes the nomenclature from SmallTalk OOP, calling the methods messages (Window Messages). Then you'll also know that it does no message dispatch of its own, which is a big gaping void. It also has crappy subclassing. Handles may not be inheritable but then, there's final in Java. They don't lack a class, they are a placeholder for the class: That's what the word handle means. Looking at architectures like MFC or .NET WinForms it's immediately obvious that except for the syntax, nothing much is different from the WinAPI. They're not inheritable either in interface or implementation, minimally substitutable, and they're not substantially different from what procedural coders have been doing since forever. Is this really it? The best bits of OOP are just... traditional procedural code? That's the big deal? ","pontos":4},{"corpo":"Holy wars! Ok let me see.. Last time I checked the design police said.. Singletons are bad because they hinder auto testing - instances cannot be created afresh for each test case. Instead the logic should be in a class (A) that can be easily instantiated and tested. Another class (B) should be responsible for constraining creation. Single Responsibility Principle to the fore! It should be team-knowledge that you're supposed to go via B to access A - sort of a team convention. I concur mostly.. ","pontos":4},{"corpo":"You can use a file system watcher to check when the file has been changed. It only becomes \"changed\" after whichever program had the file previously closes the file. I know you asked for C#, but my VB.Net is much better. Hope you or someone else can translate. It tries to open the file, if it isn't available, it adds a watcher, and waits for the file to be changed. After the file is changed, it tries to open again. It throws an exception if it waits more than 120 seconds, because you may get caught in a situation where the file is never released. Also, I decided to add a timeout of waiting for the file change of 5 seconds, in case of the small possibility that the file was closed prior to the actual file watcher being created. Public Sub WriteToFile(ByVal FilePath As String, ByVal FileName As String, ByVal Data() As Byte) Dim FileOpen As Boolean Dim File As System.IO.FileStream = Nothing Dim StartTime As DateTime Dim MaxWaitSeconds As Integer = 120 StartTime = DateTime.Now FileOpen = False Do Try File = New System.IO.FileStream(FilePath FileName, IO.FileMode.Append) FileOpen = True Catch ex As Exception If DateTime.Now.Subtract(StartTime).TotalSeconds MaxWaitSeconds Then Throw New Exception(\"Waited more than \" MaxWaitSeconds \" To Open File.\") Else Dim FileWatch As System.IO.FileSystemWatcher FileWatch = New System.IO.FileSystemWatcher(FilePath, FileName) FileWatch.WaitForChanged(IO.WatcherChangeTypes.Changed,5000) End If FileOpen = False End Try Loop While Not FileOpen If FileOpen Then File.Write(Data, 0, Data.Length) File.Close() End If End Sub ","pontos":5},{"corpo":"OOP isn't about creating re-usable classes, its about creating Usable classes. ","pontos":43},{"corpo":"I've found that using contracts is a great approach. Metaprogramming contracts are generally lower-level than the types of integration tests you describe, but the two are certainly not mutually exclusive. I find contracts help keep documentation, implementation, and testing all in sync -- this is a major problem of TDD (not that it isn't a problem in non-TDD). ","pontos":1},{"corpo":"In Perl, use of a label to \"goto\" from a loop - using a \"last\" statement, which is similar to break. This allows better control over nested loops. The traditional goto label is supported too, but I'm not sure there are too many instances where this is the only way to achieve what you want - subroutines and loops should suffice for most cases. ","pontos":1},{"corpo":"Since makes reasoning about program flow hard1 (aka. spaghetti code), is generally only used to compensate for missing features: The use of may actually be acceptable, but only if the language doesn't offer a more structured variant to obtain the same goal. Take Doubt's example: The rule with goto that we use is that goto is okay to for jumping forward to a single exit cleanup point in a function. This is true  but only if the language doesn't allow structured exception handling with cleanup code (such as RAII or ), which does the same job better (as it is specially built for doing it), or when there's a good reason not to employ structured exception handling (but you will never have this case except at a very low level). In most other languages, the only acceptable use of is to exit nested loops. And even there it is almost always better to lift the outer loop into an own method and use instead. Other than that, is a sign that not enough thought has gone into the particular piece of code. 1 Modern languages which support implement some restrictions (e.g. may not jump into or out of functions) but the problem fundamentally remains the same. Incidentally, the same is of course also true for other language features, most notably exceptions. And there are usually strict rules in place to only use these features where indicated, such as the rule not to use exceptions to control non-exceptional program flow. ","pontos":29},{"corpo":"I think you want to add the AllowPartiallyTrustedCallers attribute to your assembly. The error message implies that something that's calling into your boo.exe assembly is not fully trusted, and boo.exe doesn't have this attribute allowing it. ","pontos":0},{"corpo":"Update On Sourceforge I found Whiz SQL Structure Compare with this description: Whiz is a database diff utility which will be useful to find difference between two MS-SQL Server databases. It also able to generate SQL script to update the changes from one database to another database. However, I've been unsuccessful in getting it to work so far... ","pontos":0},{"corpo":"if you're a java progammer, check out the Struts framework by the Apache folks. ","pontos":1},{"corpo":"Take a look at the 'caspol.exe' program (provided with .NET runtimes). You will have to do this on the machine you are trying to run the application from. I wasn't able to 'mark' and assembly (probably just me). However, using caspol and setting up the proper permission for my app, LocalIntranet_Zone, fix my similar issue. I have heard (but haven't tried it yet), that .NET 3.5 sp1 removed this tighten security requirement (not allowing .NET assemblies to reside on a share by default). ","pontos":2},{"corpo":"Just came across a link that discusses this subject in detail so I wanted to post it back here: How To Inject a Managed .NET Assembly (DLL) Into Another Process ","pontos":7},{"corpo":"The best way to diagnose these kinds of WCF errors (the ones that really don't tell you much) is to enable tracing. In your web.config file, add the following: system.diagnostics sources source name=\"System.ServiceModel\" switchValue=\"Information\" propagateActivity=\"true\" listeners add name=\"ServiceModelTraceListener\" type=\"System.Diagnostics.XmlWriterTraceListener, System, Version=2.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089\" initializeData=\"wcf-traces.svclog\"/ /listeners /source /sources /system.diagnostics You can then open the resulting file in the SvcTraceViewer.exe utility which comes in the .NET Framework SDK (or with Visual Studio). On my machine, it can be found at %PROGRAMFILES%\\Microsoft SDKs\\Windows\\v6.0A\\Bin\\SvcTraceViewer.exe. Just look for an error message (in bold red) and that will tell you specifically what your problem is. ","pontos":11},{"corpo":" Passive View - http://martinfowler.com/eaaDev/PassiveScreen.html Supervising Controller - http://martinfowler.com/eaaDev/SupervisingPresenter.html Model-View-Presenter - http://martinfowler.com/eaaDev/ModelViewPresenter.html My personal favorite is the Passive View. More testable than others I've seen including MVC. ","pontos":26},{"corpo":"We run DB40 .NET version in a large client/server project. Our experiences is that you can potentially get much better performance than typical relational databases. However, you really have to tweak your objects to get this kind of performance. For example, if you've got a list containing a lot of objects, DB4O activation of these lists is slow. There are a number of ways to get around this problem, for example, by inverting the relationship. Another pain is activation. When you retrieve or delete an object from DB4O, by default it will activate the whole object tree. For example, loading a Foo will load Foo.Bar.Baz.Bat, etc until there's nothing left to load. While this is nice from a programming standpoint, performance will slow down the more nesting in your objects. To improve performance, you can tell DB4O how many levels deep to activate. This is time-consuming to do if you've got a lot of objects. Another area of pain was text searching. DB4O's text searching is far, far slower than SQL full text indexing. (They'll tell you this outright on their site.) The good news is, it's easy to setup a text searching engine on top of DB4O. On our project, we've hooked up Lucene.NET to index the text fields we want. Some APIs don't seem to work, such as the GetField APIs useful in applying database upgrades. (For example, you've renamed a property and you want to upgrade your existing objects in the database, you need to use these \"reflection\" APIs to find objects in the database. Other APIs, such as the [Index] attribute don't work in the stable 6.4 version, and you must instead specify indexes using the Configure().Index(\"someField\"), which is not strongly typed. We've witnessed performance degrade the larger your database. We have a 1GB database right now and things are still fast, but not nearly as fast as when we started with a tiny database. We've found another issue where Db4O.GetByID will close the database if the ID doesn't exist anymore in the database. We've found the Native Query syntax (the most natural, language-integrated syntax for queries) is far, far slower than the less-friendly SODA queries. So instead of typing: // C# syntax for \"Find all MyFoos with Bar == 23\". // (Note the Java syntax is more verbose using the Predicate class.) IList MyFoo results = db4o.Query MyFoo (input = input.Bar == 23); Instead of that nice query code, you have to an ugly SODA query which is string-based and not strongly-typed. For .NET folks, they've recently introduced a LINQ-to-DB4O provider, which provides for the best syntax yet. However, it's yet to be seen whether performance will be up-to-par with the ugly SODA queries. DB4O support has been decent: we've talked to them on the phone a number of times and have received helpful info. Their user forums are next to worthless, however, almost all questions go unanswered. Their JIRA bug tracker receives a lot of attention, so if you've got a nagging bug, file it on JIRA on it often will get fixed. (We've had 2 bugs that have been fixed, and another one that got patched in a half-assed way.) If all this hasn't scared you off, let me say that we're very happy with DB4O, despite the problems we've encountered. The performance we've got has blown away some O/RM frameworks we tried. I recommend it. ","pontos":52},{"corpo":"Plain freeform text. Validating all the world's post/zip codes is too hard; a fixed list of countries is too politically sensitive; mandatory state/region/other administrative subdivision is just plain inappropriate (all too often I'm asked which county I live in--when I don't, because Greater London is not a county at all). More to the point, it's simply unnecessary. Your application is highly unlikely to be modelling addresses in any serious way. If you want a postal address, ask for the postal address. Most people aren't so stupid as to put in something other than a postal address, and if they do, they can kiss their newly purchased item bye-bye. The exception to this is if you're doing something that's naturally constrained to one country anyway. In this situation, you should ask for, say, the { postcode, house number } pair, which is enough to identify a postal address. I imagine you could achieve similar things with the extended zip code in the US. ","pontos":22},{"corpo":"Well, there's Model-View-Presenter, but I think you'll find that the most common \"alternative\" to MVC is really a lack of proper separation. As an extreme example, consider classic ASP pages where HTML, VBScript and SQL are found side-by-side in the same file. (That's not a bash of ASP  you'll find plenty of such examples in other languages.) ","pontos":4},{"corpo":" If so, why? C has no multi-level/labelled break, and not all control flows can be easily modelled with C's iteration and decision primitives. gotos go a long way towards redressing these flaws. Sometimes it's clearer to use a flag variable of some kind to effect a kind of pseudo-multi-level break, but it's not always superior to the goto (at least a goto allows one to easily determine where control goes to, unlike a flag variable), and sometimes you simply don't want to pay the performance price of flags/other contortions to avoid the goto. libavcodec is a performance-sensitive piece of code. Direct expression of the control flow is probably a priority, because it'll tend to run better. ","pontos":2},{"corpo":"Beware of clbuttic mistakes. ","pontos":36},{"corpo":"The first one (format) looks better to me. It's more readable and you are not creating extra temporary string objects. ","pontos":0},{"corpo":"The raised eyebrows should tell you enough to stop doing it. You don't write the code for the compiler, you write it for your fellow programmers first and then for the compiler. Even if the compilers work, surprising other people is not what you want - bitwise operators are for bit operations not for bools. I suppose you also eat apples with a fork? It works but it surprises people so it's better not to do it. ","pontos":4},{"corpo":"Wink ","pontos":1},{"corpo":"|| and are boolean operators and are guaranteed to return either 1 or 0. Nothing else. |, and ^ are bitwise operators. When the domain of numbers you operate on is just 1 and 0, then they are exactly the same, but in cases where your booleans are not strictly 1 and 0--as is the case with the c language--you may end up with some behavior you didn't want. For instance: BOOL two = 2; BOOL one = 1; BOOL and = two one; //and = 0 BOOL cand = two one; //cand = 1 In c++, however, the bool type is guaranteed to be only either a 1 or a 0, so it's less of a worry from this stance, but the fact that people aren't used to seeing such things in code makes a good argument for not doing it. Just say b = b x and be done with it. ","pontos":30},{"corpo":"I'm amazed that so many people immediately want to find the code that executes the fastest. If ONE MILLION iterations STILL takes less than a second to process, is this really going to be in ANY WAY noticeable to the end user? Not very likely. Premature optimization = FAIL. I'd go with the String.Format option, simply because it makes the most sense from an architectural standpoint. I don't care about the performance until it actually becomes an issue (and if it did, I'd ask myself: Do I really need to concatenate a million names at once? Surely they won't all fit on the screen...) Consider if your customer later wants to change it so that they can configure whether to display \"Firstname Lastname\" or \"Lastname, Firstname\". With the Format option, this is easy - just swap out the format string. With the concat, you'll need extra code. Sure that doesn't sound like a big deal in this particular example, but extrapolate. ","pontos":106},{"corpo":"I have found that VisualSVN is about 50% slower than running SVN as a native service. I always assumed that was because of accessing via http:// with Apache, which seems like it would have to be slower than accessing via svn://, which is native TCP/IP. The Experiment In the last 30 minutes, here's what I did: Installed VisualSVN on port 8080, side-by-side with my existing SVN install Imported three existing repos into VisualSVN Kicked everyone else off the server Did side-by-side comparisons of a full svn checkout Results Repo 1: 652 files, 273 directories, 60.1MB 23 seconds for VisualSVN over http:// 16 seconds for SVN over svn:// Repo 2: 4623 files, 964 directories, 127.9MB 2 minutes, 18 seconds for VisualSVN over http:// 1 minute, 30 seconds for SVN over svn:// This is on identical hardware, with the exact same repository. I like how easy VisualSVN is, but AD integration and GUI aren't worth a 50% performance hit. Anyone else seen this difference? Am I doing something wrong just following along with the default installation options? ","pontos":2},{"corpo":"Because Wikipedia is blocking the HTTP user-agent string used by LWP::Simple. You will get a \"403 Forbidden\"-response if you try using it. Try the LWP::UserAgent module to work around this, setting the agent-attribute. ","pontos":4},{"corpo":"Unfortunately, the only answer I can come up with means increasing the complexity of the grammar. split into and allow only or in an APPLY The first step turns your reduce/reduce conflict into a shift/reduce conflict, but the parentheses resolve that. You're going to have the same problem with 'a b c': is it or ? You'll need to also break off and required in the grammar. I think this will do it, but I'm not sure: expr := INT | parenthesized_expr | expr MINUS expr parenthesized_expr := ( expr ) | ( applied_expr ) | ( expr_with_prefix ) applied_expr := expr expr expr_with_prefix := MINUS expr ","pontos":8},{"corpo":"Though it's certainly not a direct answer, in the past I've found I prefer to use RedCloth (or a Markdown parser if you don't enjoy Textile) and use a simple textarea with an AJAXy preview. Generally speaking, WYSIWYG editors have a long history of creating redundant tags and similar, leading to potentially broken pieces of HTML. ","pontos":24},{"corpo":"This may not apply to your code, but a lot of classes within the .NET framework are sealed purposely so that no one tries to create a sub-class. There are certain situations where the internals are complex and require certain things to be controlled very specifically so the designer decided no one should inherit the class so that no one accidentally breaks functionality by using something in the wrong way. ","pontos":1},{"corpo":"Because you always want to be handed a reference to the class and not to a derived one for various reasons: i. invariants that you have in some other part of your code ii. security etc Also, because it's a safe bet with regards to backward compatibility - you'll never be able to close that class for inheritance if it's release unsealed. Or maybe you didn't have enough time to test the interface that the class exposes to be sure that you can allow others to inherit from it. Or maybe there's no point (that you see now) in having a subclass. Or you don't want bug reports when people try to subclass and don't manage to get all the nitty-gritty details - cut support costs. ","pontos":0},{"corpo":"@jjnguy Another user may want to re-use your code by sub-classing your class. I don't see a reason to stop this. If they want to use the functionality of my class they can achieve that with containment, and they will have much less brittle code as a result. Composition seems to be often overlooked; all too often people want to jump on the inheritance bandwagon. They should not! Substitutability is difficult. Default to composition; you'll thank me in the long run. ","pontos":1},{"corpo":"I use FCKEditorOnRails plugin: http://github.com/UnderpantsGnome/fckeditor_on_rails/tree/master Note that you can generally drop in the latest version of FCKEditor without much tweaking if you're running into bugs in the older version. ","pontos":4},{"corpo":"I want to give you this message from \"Code Complete\": Inheritance - subclasses - tends to work against the primary technical imperative you have as a programmer, which is to manage complexity.For the sake of controlling complexity, you should maintain a heavy bias against inheritance. ","pontos":8},{"corpo":"Generally with my systems I use a DIR constant which is gwtcwd(). This is called in construct.php (a page startup file). I agree that include_path is probably a more concrete solution but I still use my DIR constants out of habit. ","pontos":0},{"corpo":"I suspect they can - here's an example of Singleton: The singleton design pattern in JavaScript ","pontos":0},{"corpo":"What if I told you, it depends? I in general initialize everything and do it in a consistent way. Yes it's overly explicit but it's also a little easier to maintain. If we are worried about performance, well then I initialize only what has to be done and place it in the areas it gives the most bang for the buck. In a real time system, I question if I even need the variable or constant at all. And in C++ I often do next to no initialization in either place and move it into an Init() function. Why? Well, in C++ if you're initializing something that can throw an exception during object construction you open yourself to memory leaks. ","pontos":2},{"corpo":" I exposed a minimal interface to interact with the client API, and it would have been awesome to extend the client API class and then just add an implements clause with my new interface. The methods that I had in the interface that matched the actual interface would then need no further details and so I wouldn't have to explicitly implement them. However, the class was sealed, so I had to instead proxy calls to an internal reference to this class. The result: more work and a lot more code for no real good reason. Well, there is a reason: your code is now somewhat insulated from changes to the memcached interface. ","pontos":0},{"corpo":"My guess is that this is not possible, I did find this which is for monitoring operations (including rename) on a folder, but there does not appear to be a similar method for files. @Richard, FileSystemWatcher is good if you only need to monitor changes, but he needs to interrupt them which it cannot do. ","pontos":0},{"corpo":" Performance: () if the JIT compiler sees a call to a virtual method using a sealed types, the JIT compiler can produce more efficient code by calling the method non-virtually.() That's a great reason indeed. Thus, for performance-critical classes, and friends make sense. All the other reasons I've seen mentioned so far boil down to \"nobody touches my class!\". If you're worried someone might misunderstand its internals, you did a poor job documenting it. You can't possibly know that there's nothing useful to add to your class, or that you already know every imaginable use case for it. Even if you're right and the other developer shouldn't have used your class to solve their problem, using a keyword isn't a great way of preventing such a mistake. Documentation is. If they ignore the documentation, their loss. ","pontos":0},{"corpo":" The singleton design pattern in JavaScript Oh my god. I'm speechless. To OP: yes, of course you can in some sense, but some patterns, as you're used to them, are not as visible, as in Java. For example, singleton would simply be an object: var singleton = { sayHello: function() { alert(\"Hello!\") } }; [edit] factory: http://en.wikipedia.org/w/index.php?title=Factory_method_pattern oldid=229607677#JavaScript (edited the link to point to the version I originally linked to, since the version as of 2010-06-02 is convoluted.) ","pontos":3},{"corpo":" <a href=\"http://rads.stackoverflow.com/amzn/click/0596005903\">Linux Device Drivers Linux Core Kernel Commentary Operating Systems Design and Implementation I had previously bought these books on recommendation for the same purpose but I never got to studying them myself so only take them as second-hand advice. ","pontos":5},{"corpo":"You can probably solve this by using the FileSystemWatcher class in .NET framework. From the class remarks: You can watch for renaming, deletion, or creation of files or directories. For example, to watch for renaming of text files, set the Filter property to \"*.txt\" and call the WaitForChanged method with a Renamed specified for its parameter. ","pontos":5},{"corpo":"My guess would be to not bother with integration and just use Tortoise SVN in Windows Explorer. As for file types to ignore, give it a test, checkout, build, and see if any files changed (for modern Visual Studio I tend to ignore the .suo files) ","pontos":3},{"corpo":"I would agree that Tortoise SVN in Windows Explorer would be the best way to use SVN with VB6. The biggest change you will find migrating to SVN is the idea of \"Check out\" and \"Check in\" aren't exactly the same as \"Update\" and \"Commit\". . . thus, any IDE integration with VB6 is limited because VB6 supports MSSCCI, a check-out/check-in mechanism. I once used TamTam SVN (http://www.daveswebsite.com/software/tamtamsvn/index.shtml) with Visual Studio 2003, but stopped since I found it limiting. Merging/branching/blaming, etc. are very powerful features Tortoise SVN provides that weren't in TamTam. Tigris also has http://svnvb6.tigris.org/, but I have not tried it. Again, while you quite possibly get an IDE to work with VB6, I would not recommend it since the greatest strength of migrating to SVN is to break the Source Safe philosophy of check-in/check-out. ","pontos":14},{"corpo":"Abstraction allows you to treat a complex process as a simple process. For example, the standard \"file\" abstraction treats files as a contiguous array of bytes. The user/developer does not even have to think about issues of clusters and fragmentation. (Abstraction normally appears as classes or subroutines.) Information hiding is about protecting your abstractions from malicious/incompetent users. By restricting control of some state (hard drive allocations, for example) to the original developer, huge amounts of error handling becomes redundant. If nobody else besides the file system driver can write to the hard drive, then the file system driver knows exactly what has been written to the hard drive and where. (The usual manifestation of this concept is and keywords in OO languages.) ","pontos":0},{"corpo":"IMO, the only reasons to show version numbers are: To show progress is being made To help bug reports be localized to the version they were discovered in So if these things are important for your bug reports, then expose them. If not, then don't. ","pontos":0},{"corpo":"You might need to add a XmlNamespaceManager. XmlDocument document = new XmlDocument(); XmlNamespaceManager nsmgr = new XmlNamespaceManager(document.NameTable); nsmgr.AddNamespace(\"creativeCommons\", \"http://backend.userland.com/creativeCommonsRssModule\"); // AddNamespace for other namespaces too. document.Load(feed); It is needed if you want to call SelectNodes on a document that uses them. What error are you seeing? ","pontos":5},{"corpo":"The regex shown in your example, should work regardless of language. So is it the regex you want, or the java code to put this logic around the regex? ","pontos":4},{"corpo":"I ran into this a long time ago with working in ASP. I found this knowledge base article and it helped me out. I hope it solves your problem. http://support.microsoft.com/kb/269495 If this doesn't work and everything checks out, then it is probably your connection string. I would try these steps next: Remove: DRIVER={SQL Server}; Edit the Provider to this: Provider=SQLOLEDB; ","pontos":3},{"corpo":"@Kyle: Your query should be more like: SELECT object WHERE tag IN ('fruit', 'food'); Your query was looking for rows where the tag was both fruit AND food, which is impossible seeing as the field can only have one value, not both at the same time. ","pontos":0},{"corpo":"Given: object table (primary key id) objecttags table (foreign keys objectId, tagid) tags table (primary key id) SELECT distinct o.* from object o join objecttags ot on o.Id = ot.objectid join tags t on ot.tagid = t.id where t.Name = 'fruit' or t.name = 'food'; This seems backwards, since you want and, but the issue is, 2 tags aren't on the same row, and therefore, an and yields nothing, since 1 single row cannot be both a fruit and a food. This query will yield duplicates usually, because you will get 1 row of each object, per tag. If you wish to really do an and in this case, you will need a , and a in your query for example. SELECT distinct o.name, count(*) as count from object o join objecttags ot on o.Id = ot.objectid join tags t on ot.tagid = t.id where t.Name = 'fruit' or t.name = 'food' group by o.name having count = 2; ","pontos":4},{"corpo":"I don't believe in blacklists. I looked at the blacklist linked to in the question, and for one thing it lists \"gay\" as a bad word. You obviously need to know the context of things. Unless the website is for a conservative religious community in which case many words don't need a context to be considered offensive, I'd suggest using an \"Offensive?\" link as common in forums. This should be effective and have many less false positives. ","pontos":4},{"corpo":"I would say to just remove posts as you become aware of them, and block users who are overly explicit with their postings. You can say very offensive things without using any swear words. If you block the word ass (aka donkey), then people will just type a$$ or /\\55, or whatever else they need to type to get past the filter. ","pontos":2},{"corpo":" is the closest supported thing I know of. Unfortunately, it's not a hook into Explorer - so you can only use it for your own actions. Depending on your needs, you can write a shell extension to do your own (or something), and branch from there. Otherwise, you're looking at hooking , I think. This would have to be done in unmanaged code, as you'll be loaded into Explorer.exe. For Vista, this has been changed to - which probably means you'll have to hook the creation of it and pass out your mock. Personally, I think since you're talking a rename, wilhelmtell's idea of confirming after the change, and undoing it if necessary is the best idea. ","pontos":0},{"corpo":"I'm actually on the silverlight team.. so I can also pass along suggestions. Not really sure how much i can divulge, but webcam is being worked on. I can definitely agree with the desire to gen wav files. I wanted to speed up/slow down sounds for a piano demo.. Carl - that's the plan. Though linux support is being handled by the mono team. Brian - while parity with WPF isn't a goal, subset compatibility is. Silverlight's 'minimality' is indeed at times pretty annoying. ","pontos":10},{"corpo":" Any references or value types that an object own live in the heap. Only if you're casting ints to Objects. ","pontos":2},{"corpo":"Preventing security breaches requires different strategies for different attacks. For instance, it would not be unusual to block traffic from certain sources during a denial of service attack. If a user fails to provide proper credentials more than 3 times the IP address is blocked or the account is locked. When ScanAlert issues hundreds of requests which may include SQL injection--to name one--it certainly matches what the site code should consider \"malicious behavior\". In fact, just putting UrlScan or eEye SecureIIS in place may deny many such requests, but is that a true test of the site code. It's the job of the site code to detect malicious users/requests and deny them. At what layer is the test valid? ScanAlert presents in two different ways: the number of requests which are malformed and the variety of each individual request as a test. It's seems like the 2 pieces of advice that emerge are as follows: The site code should not try to detect malicious traffic from a particular source and block that traffic, because that is a futile effort. If you do attempt such a futile effort, as least make an exception for requests from ScanAlert in order to test lower layers. ","pontos":1},{"corpo":"You need to use setTimeout and pass it a callback function. The reason you can't use sleep in javascript is because you'd block the entire page from doing anything in the meantime. Not a good plan. Use Javascript's event model and stay happy. Don't fight it! ","pontos":10},{"corpo":"There is the setTimeout( function_reference, timeoutMillis ); function which can be passed the time after which the function will be executed. ","pontos":75},{"corpo":"If you're escaping for HTML, there are only three that I can think of that would be really necessary: html.replace(/ /g, \" amp;\").replace(/ /g, \" lt;\").replace(/ /g, \" gt;\"); Depending on your use case, you might also need to do things like \" to . If the list got big enough, I'd just use an array: var escaped = html; var findReplace = [[/ /g, \" amp;\"], [/ /g, \" lt;\"], [/ /g, \" gt;\"], [/\"/g, \" quot;\"]] for(var item in findReplace) escaped = escaped.replace(findReplace[item][0], findReplace[item][1]); will only escape it for URLs, not for HTML. ","pontos":47},{"corpo":" Do value types within objects live on the stack or the heap? On the heap. They are part of the allocation of the footprint of the object, just like the pointers to hold references would be. Is boxing/unboxing value types in an object a concern? There's no boxing here. Are there any detailed, yet understandable, resources on this topic? +1 vote for Richter's book. ","pontos":1},{"corpo":"The reason can be slightly faster than is that can require a local copy of the value of i before it gets incremented, while never does. In some cases, some compilers will optimize it away if possible... but it's not always possible, and not all compilers do this. I try not to rely too much on compilers optimizations, so I'd follow Ryan Fox's advice: when I can use both, I use . ","pontos":8},{"corpo":"I've gotten this error too. for (int i=0;i 10;i++) { .. is not valid in the C89/C90 standard. As OysterD says, you need to do: int i; for (i=0;i 10;i++) { .. Your original code is allowed in C99 and later standards of the C language. ","pontos":9},{"corpo":"It's not essential, but advisable. However, if string manipulation works for you, then go for it! There are plenty of cases where small or simple XML text can be safely built by hand. Just be aware that creating XML text is harder than it looks. Here's some criteria I would consider: First: how much control do you have on the information that goes into the xml? The less control you have on the source data, the more likely you will have trouble, and the more advantageous the library becomes. For example: (a) Can you guarantee that the element names will never have a character that is illegal in a name? (b) How about quotes in an attribute's content? Can they happen, and are you handling them? (c) Does the data ever contain anything that might need to be encoded as an entity (like the less-than which often needs to be output as lt;); are you doing it correctly? Second, maintainability: is the code that builds the XML easy to understand by someone else? You probably don't want to be stuck with the code for life. I've worked with second-hand C++ code that hand-builds XML and it can be surprisingly obscure. Of course, if this is a personal project of yours, then you don't need to worry about \"others\": substitute \"in a year\" for \"others\" above. I wouldn't worry about performance. If your XML is simple enough that you can hand-write it, any overhead from the library is probably meaningless. Of course, your case might be different, but you should measure to prove it first. Finally, Yes; you can hand build XML text by hand if it's simple enough; but not knowing the libraries available is probably not the right reason. A modern XML library is a quite powerful tool, but it can also be daunting. However, learning the essentials of your XML library is not that hard, and it can be quite handy; among other things, it's almost a requisite in today's job marketplace. Just don't get bogged down by namespaces, schemas and other fancier features until you get the essentials. Good luck. ","pontos":11},{"corpo":"Which version of Delphi ? I just tried clean D7 application and TAggregateField was added. ","pontos":1},{"corpo":"There are two places where variables can be put in memory. When you create a variable like this: int a; char c; char d[16]; The variables are created in the \"stack\". Stack variables are automatically freed when they go out of scope (that is, when the code can't reach them anymore). You might hear them called \"automatic\" variables, but that has fallen out of fashion. Many beginner examples will use only stack variables. The stack is nice because it's automatic, but it also has two drawbacks: (1) The compiler needs to know in advance how big the variables are, and (b) the stack space is somewhat limited. For example: in Windows, under default settings for the Microsoft linker, the stack is set to 1 MB, and not all of it is available for your variables. If you don't know at compile time how big your array is, or if you need a big array or struct, you need \"plan B\". Plan B is called the \"heap\". You can usually create variables as big as the Operating System will let you, but you have to do it yourself. Earlier postings showed you one way you can do it, although there are other ways: int size; // ... // Set size to some value, based on information available at run-time. Then: // ... char *p = (char *)malloc(size); (Note that variables in the heap are not manipulated directly, but via pointers) Once you create a heap variable, the problem is that the compiler can't tell when you're done with it, so you lose the automatic releasing. That's where the \"manual releasing\" you were referring to comes in. Your code is now responsible to decide when the variable is not needed anymore, and release it so the memory can be taken for other purposes. For the case above, with: free(p); What makes this second option \"nasty business\" is that it's not always easy to know when the variable is not needed anymore. Forgetting to release a variable when you don't need it will cause your program to consume more memory that it needs to. This situation is called a \"leak\". The \"leaked\" memory cannot be used for anything until your program ends and the OS recovers all of its resources. Even nastier problems are possible if you release a heap variable by mistake before you are actually done with it. In C and C++, you are responsible to clean up your heap variables like shown above. However, there are languages and environments such as Java and .NET languages like C# that use a different approach, where the heap gets cleaned up on its own. This second method, called \"garbage collection\", is much easier on the developer but you pay a penalty in overhead and performance. It's a balance. (I have glossed over many details to give a simpler, but hopefully more leveled answer) ","pontos":164},{"corpo":"I have found that often times it seems difficult because I didn't really fully understand the problem. By going back to the real user/customer and listening to him describing what he really needs rather than reading a requirements document I'm often able to reduce the problem to something trivial. ","pontos":2},{"corpo":"If you are talking about the python interpreter or CMD.exe that is the 'parent' of your script then no, it isn't possible. In every POSIX-like system (now you're running Windows, it seems, and that might have some quirk I don't know about, YMMV) each process has three streams, standard input, standard output and standard error. Bu default (when running in a console) these are directed to the console, but redirection is possible using the pipe notation: python script_a.py | python script_b.py This ties the standard output stream of script a to the standard input stream of script B. Standard error still goes to the console in this example. See the article on standard streams on Wikipedia. If you're talking about a child process, you can launch it from python like so (stdin is also an option if you want two way communication): import subprocess # Of course you can open things other than python here :) process = subprocess.Popen([\"python\", \"main.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) x = process.stderr.readline() y = process.stdout.readline() process.wait() See the Python subprocess module for information on managing the process. For communication, the process.stdin and process.stdout pipes are considered standard file objects. For use with pipes, reading from standard input as lassevk suggested you'd do something like this: import sys x = sys.stderr.readline() y = sys.stdin.readline() sys.stdin and sys.stdout are standard file objects as noted above, defined in the sys module. You might also want to take a look at the pipes module. Reading data with readline() as in my example is a pretty nave way of getting data though. If the output is not line-oriented or indeterministic you probably want to look into polling which unfortunately does not work in windows, but I'm sure there's some alternative out there. ","pontos":9},{"corpo":"Xml is hard. Parsing yourself is a bad idea, it's even a worse idea to generate content yourself. Have a look at the Xml 1.1 spec. You have to deal with such things as proper encoding, attribute encoding (e.g., produces invalid xml), proper CDATA escaping, UTF encoding, custom DTD entities, and that's without throwing in the mix xml namespaces with the default / empty namespace, namespace attributes, etc. Learn a toolkit, there's plenty available. ","pontos":7},{"corpo":"From my own experience: Only test your own code, not the underlying framework's code. So if you're using a generic list then there's no need to test Add, Remove etc. There is no 2. Look over there! Monkeys!!! NUnit is the way to go. You definitely can't test every outcome. I test for what I expect to happen, and then test a few edge cases where I expect to get exceptions or invalid responses. If a bug comes up down the track because of something you forgot to test, the first thing you should do (before trying to fix the bug) is write a test to prove that the bug exists. ","pontos":6},{"corpo":"It was quite some time since I dug into those parts of Java, but... Why you can't do it was probably a design choice by the language developers. Still, due to the type erasure employed by Java, the generics information gets dropped at compile time anyway, so in your example it would create exactly the same byte code whether you had the type parameter or not. ","pontos":1},{"corpo":"C++ doesn't have an ecosystem in the sense of Java or .NET. There's no virtual machine, no runtime environment even, there's only a highly specialized standard library that by design doesn't operate well in a purely functional environment. C++ doesn't even have an ABI standard. All things considered, I'm not sure what you mean/expect. ","pontos":7},{"corpo":"It would probably help if you posted your app.config file, since this kind of error tends to point to a problem in the block. Make sure the contract attribute seems right to you. Edit: Try fully qualifying your contract value; use the full namespace. I think that is needed. ","pontos":0},{"corpo":"According to this MSDN forums posting, it seems to be a login issue. ","pontos":0},{"corpo":"As has been said, I'm not really sure about a C++ 'ecosystem'. But Haskell does have a Foreign Function Interface that allows you to call C functions from Haskell and Haskell functions from C. Then again, that's C, I'm not really sure how far along the C++ FFI is... ","pontos":3},{"corpo":"In reply to the follow-up question: As for creating exceptions becoming tedious, you kinda get used to it. Use of a good code generator or template can create the exception class with minimal hand editing within about 5 or 10 seconds. However, in many real world applications, error handling can be 70% of the work, so it's all just part of the game really. As tgmdbm suggests, in MVC/MVP applications I let all my unhandlable exceptions bubble up to the top and get caught by the dispatcher which delegates to an ExceptionHandler. I set it up so that it uses an ExceptionResolver that looks in the config file to choose an appropriate view to show the user. Java's Spring MVC library does this very well. Here's a snippet from a config file for Spring MVC's Exception resolver - its for Java/Spring but you'll get the idea. This takes a huge amount of exception handling out of your presenters/controllers altogether. bean id=\"exceptionResolver\" class=\"org.springframework.web.servlet.handler.SimpleMappingExceptionResolver\" property name=\"exceptionMappings\" props prop key=\"UserNotFoundException\" rescues/UserNotFound /prop prop key=\"HibernateJdbcException\" rescues/databaseProblem /prop prop key=\"java.net.ConnectException\" rescues/networkTimeout /prop prop key=\"ValidationException\" rescues/validationError /prop prop key=\"EnvironmentNotConfiguredException\" rescues/environmentNotConfigured /prop prop key=\"MessageRejectedPleaseRetryException\" rescues/messageRejected /prop /props /property property name=\"defaultErrorView\" value=\"rescues/general\" / /bean ","pontos":1},{"corpo":"I don't know that you can force buffering - but a reverse proxy server between you and the server would affect buffering (since the buffer then affects the proxy's connection - not your browser's). ","pontos":1},{"corpo":"No input is not the same as the end of the stream. You can usually simulate the end of the stream in a console by pressing Ctrl+D (AFAIK some systems use Ctrl+Z instead). But I guess this is not what you want so better test for empty strings additionally to null strings. ","pontos":2},{"corpo":" From my understanding of this, readLine should return null the first time no input is entered other than a line termination, like '\\r'. That is not correct. will return if the end of the stream is reached. That is, for example, if you are reading a file, and the file ends, or if you're reading from a socket and the socket closses. But if you're simply reading the console input, hitting the return key on your keyboard does not constitute an end of stream. It's simply a character that is returned ( or depending on your OS). So, if you want to break on both the empty string and the end of line, you should do: while (line != null !line.equals(\"\")) Also, your current program should work as expected if you pipe some file directly into it, like so: java -cp . Echo test.txt ","pontos":9},{"corpo":"Inline elements can't have heights (nor widths) like that. SPANs are already by default. Internet Explorer is actually the broken browser in this case. ","pontos":15},{"corpo":"The problem is that 'display: inline' can't get a height associated because, being inline, it gets its height from its the content. Anyway, how do you define the height of a box that is broken at the end of a line? You might try to set 'line-height' instead, or if this doesn't work to your satisfaction, set a padding: /* makes the whole box higher by inserting a space between the border and the content */ padding: 0.5em 0; ","pontos":1},{"corpo":"I suggest that you file a bug report at https://bugs.adobe.com/flashplayer/, because the event really shouldn't fire before all the bytes are loaded. In the meantime I guess you have to live with the timer. You might be able to do the same by listening at the progress event instead, that could perhaps save you from having to handle the timer yourself. ","pontos":0},{"corpo":"What you probably want to do is to assign your 0% to 100% some points in a HSV or HSL color-space. From there you can interpolate colors (and yellow just happens to be between red and green :) and convert them to RGB. That will give you a nice looking gradient between the two. Assuming that you will use the color as a status indicator and from a user-interface perspective, however, that is probably not such a good idea, since we're quite bad at seeing small changes in color. So dividing the value into, for example, three to seven buckets would give you more noticeable differences when things change, at the cost of some precision (which you most likely would not be able to appreciate anyway). So, all the math aside, in the end I'd recommend a look-up-table with the following colors with v being the input value: #e7241d for v = 12% #ef832c for v 12% and v = 36% #fffd46 for v 36% and v = 60% #9cfa40 for v 60% and v = 84% #60f83d for v 84% These have been very navely converted from HSL values (0.0, 1.0, 1.0), (30.0, 1.0, 1.0), (60.0, 1.0, 1.0), (90.0, 1.0, 1.0), (120.0, 1.0, 1.0), and you might want to adjust the colors somewhat to suit your purposes (some don't like that red and green aren't 'pure'). Please see: Using HSL Color (Hue, Saturation, Luminosity) To Create Better-Looking GUIs for some discussion and RGB and HSL Colour Space Conversions for sample C# source-code. ","pontos":6},{"corpo":"My C is a little rusty, so I apologize in advance. Speedwise, I can understand the results. But, I am confused as to how both files came out to the same MD5 hash. Maybe a for loop runs the same, but wouldn't the following 2 lines of code generate different assembly? myArray[i++] = \"hello\"; vs myArray[++i] = \"hello\"; The first one writes the value to the array, then increments i. The second increments i then writes to the array. I'm no assembly expert, but I just don't see how the same executable would be generated by these 2 different lines of code. Just my two cents. ","pontos":0},{"corpo":"Few people have said that CDATA blocks will allow you to retain line breaks. This is wrong. CDATA sections will only make markup be processed as character data, they will not change line break processing. Address 15 Sample St Example Bay Some Country /Address is exactly the same as Address ![CDATA[15 Sample St Example Bay Some Country]] /Address The only difference is how different APIs report this. ","pontos":3},{"corpo":"It's not entirely correct to say that the compiler can't optimize away the temporary variable copy in the postfix case. A quick test with VC shows that it, at least, can do that in certain cases. In the following example, the code generated is identical for prefix and postfix, for instance: #include stdio.h class Foo { public: Foo() { myData=0; } Foo(const Foo rhs) { myData=rhs.myData; } const Foo operator++() { this- myData++; return *this; } const Foo operator++(int) { Foo tmp(*this); this- myData++; return tmp; } int GetData() { return myData; } private: int myData; }; int main(int argc, char* argv[]) { Foo testFoo; int count; printf(\"Enter loop count: \"); scanf(\"%d\", count); for(int i=0; i count; i++) { testFoo++; } printf(\"Value: %d\\n\", testFoo.GetData()); } Whether you do ++testFoo or testFoo++, you'll still get the same resulting code. In fact, without reading the count in from the user, the optimizer got the whole thing down to a constant. So this: for(int i=0; i 10; i++) { testFoo++; } printf(\"Value: %d\\n\", testFoo.GetData()); Resulted in the following: 00401000 push 0Ah 00401002 push offset string \"Value: %d\\n\" (402104h) 00401007 call dword ptr [__imp__printf (4020A0h)] So while it's certainly the case that the postfix version could be slower, it may well be that the optimizer will be good enough to get rid of the temporary copy if you're not using it. ","pontos":17},{"corpo":" Depending how much you're planning to do on these legacy projects I would consider not switching. I would really advise you to switch to SVN. I know of a few projects that lost source code because the VSS database became corrupted. I think there are tools that perform the migration from SourceSafe to SVN. (Yes-- a quick Google search confirmed it.) That way you wouldn't be losing the revision history. ","pontos":5},{"corpo":"Does SimpleTest output JUnit XML style reports? If it does, you should be able to integrate it into CruiseControl or Bamboo. ","pontos":1},{"corpo":" First step would be to gather information on everything the app needs to run; this I usually accomplish by running systrace(1) and ldd(1) to find out what is needed to run the software. I'll give this a try. The big issue I've found with xinc is that while it is a PHP application, it wants to know application installation paths (yet it still spreads stuff into other folders) and runs some PHP scripts in daemon mode (those scripts being the hardest to get running). So, for example, I told it to install to /var/www/xinc and then made a symlink of /var/www/var/www/xinc -> /var/www/xinc and it partially worked. I got the GUI to come up bit it refused to recognize any projects that I had set up. I think the biggest problem is that part of it is running a chroot and the other half is running outside. If all else fails I'm going to just have to build something as we program inside chrooted environments since our production is chrooted. We've run into issues where we code outside of a chroot and then have to back track to find what we need to make it work inside a chroot. ","pontos":0},{"corpo":"You're really asking two overlapping questions. The title and first half of your question are philosophical/theoretical. I think the reason for accessing entities only through their \"aggregate root\" is to abstract away the kinds of implementation details you're describing. Access through the aggregate root is a way to reduce complexity by having a trusted point of access. You're eliminating friction/ambiguity/uncertainty by adhering to a convention. It doesn't matter how it's implemented within the root, you just know that when you ask for an entity it will be there. I don't think this perspective rules out a \"filtered repository\" as you describe. But to provide a pit of success for devs to fall into, it should be impossible instantiate the repository without being explicit about its \"filteredness;\" likewise, if shared access to a repository instance is possible, the \"filteredness\" should be explicit when coding in the caller. The second half of your question is about implementation on a specific platform. Not sure why you mention delayed execution, I think that's really orthogonal to the filtering question. The filtering itself could be a bit tricky to implement with LINQ. Maybe rather than inlining the Where lambdas, you set up a collection of them and select one depending on the filter you need. ","pontos":1},{"corpo":"In C# it doesn't matter. The two code samples you give are utterly equivalent. In the first example the C# compiler (or is it the CLR?) will construct an empty constructor and initialise the variables as if they were in the constructor. If there is already a constructor then any initialisation \"above\" will be moved into the top of it. In terms of best practice the former is less error prone than the latter as someone could easily add another constructor and forget to chain it. ","pontos":79},{"corpo":"If using XHTML, it's actually recommended not to use named entities ([citation needed]). Some browsers (Firefox ), when parsing this as XML (which they normally don't), don't read the DTD files and thus are unable to handle the entities. As it's best practice anyway to use UTF-8 as encoding if there are no compelling reasons to do otherwise, this only means that the creator of the documents needs a decent editor that can not only handle the documents but also provides a good way of entering the divers glyphs. OS X doesn't really have this problem because most needed glyphs can be reached via alt keys but Windows doesn't have this feature. @Konrad: Are you saying that, no, named entities are not needed? Precisely. Unless, of course, there are silly restrictions, e.g. legacy database drivers that choke on UTF-8 etc. ","pontos":2},{"corpo":"By not using a library, you risk generating or parsing data that isn't well-formed, which sooner or later will happen. For the same reason isn't allowed in XHTML, you shouldn't write your XML markup as a string. ","pontos":2},{"corpo":"I ran into this same issue a while back and found that if I created a simple abstract base class for data access that allowed me to inject a connection and transaction, I could unit test my sprocs to see if they did the work in SQL that I asked them to do and then rollback so none of the test data is left in the db. This felt better than the usual \"run a script to setup my test db, then after the tests run do a cleanup of the junk/test data\". This also felt closer to unit testing because these tests could be run alone w/out having a great deal of \"everything in the db needs to be 'just so' before I run these tests\". Here is a snippet of the abstract base class used for data access Public MustInherit Class Repository(Of T As Class) Implements IRepository(Of T) Private mConnectionString As String = ConfigurationManager.ConnectionStrings(\"Northwind.ConnectionString\").ConnectionString Private mConnection As IDbConnection Private mTransaction As IDbTransaction Public Sub New() mConnection = Nothing mTransaction = Nothing End Sub Public Sub New(ByVal connection As IDbConnection, ByVal transaction As IDbTransaction) mConnection = connection mTransaction = transaction End Sub Public MustOverride Function BuildEntity(ByVal cmd As SqlCommand) As List(Of T) Public Function ExecuteReader(ByVal Parameter As Parameter) As List(Of T) Implements IRepository(Of T).ExecuteReader Dim entityList As List(Of T) If Not mConnection Is Nothing Then Using cmd As SqlCommand = mConnection.CreateCommand() cmd.Transaction = mTransaction cmd.CommandType = Parameter.Type cmd.CommandText = Parameter.Text If Not Parameter.Items Is Nothing Then For Each param As SqlParameter In Parameter.Items cmd.Parameters.Add(param) Next End If entityList = BuildEntity(cmd) If Not entityList Is Nothing Then Return entityList End If End Using Else Using conn As SqlConnection = New SqlConnection(mConnectionString) Using cmd As SqlCommand = conn.CreateCommand() cmd.CommandType = Parameter.Type cmd.CommandText = Parameter.Text If Not Parameter.Items Is Nothing Then For Each param As SqlParameter In Parameter.Items cmd.Parameters.Add(param) Next End If conn.Open() entityList = BuildEntity(cmd) If Not entityList Is Nothing Then Return entityList End If End Using End Using End If Return Nothing End Function End Class next you will see a sample data access class using the above base to get a list of products Public Class ProductRepository Inherits Repository(Of Product) Implements IProductRepository Private mCache As IHttpCache 'This const is what you will use in your app Public Sub New(ByVal cache As IHttpCache) MyBase.New() mCache = cache End Sub 'This const is only used for testing so we can inject a connectin/transaction and have them roll'd back after the test Public Sub New(ByVal cache As IHttpCache, ByVal connection As IDbConnection, ByVal transaction As IDbTransaction) MyBase.New(connection, transaction) mCache = cache End Sub Public Function GetProducts() As System.Collections.Generic.List(Of Product) Implements IProductRepository.GetProducts Dim Parameter As New Parameter() Parameter.Type = CommandType.StoredProcedure Parameter.Text = \"spGetProducts\" Dim productList As List(Of Product) productList = MyBase.ExecuteReader(Parameter) Return productList End Function 'This function is used in each class that inherits from the base data access class so we can keep all the boring left-right mapping code in 1 place per object Public Overrides Function BuildEntity(ByVal cmd As System.Data.SqlClient.SqlCommand) As System.Collections.Generic.List(Of Product) Dim productList As New List(Of Product) Using reader As SqlDataReader = cmd.ExecuteReader() Dim product As Product While reader.Read() product = New Product() product.ID = reader(\"ProductID\") product.SupplierID = reader(\"SupplierID\") product.CategoryID = reader(\"CategoryID\") product.ProductName = reader(\"ProductName\") product.QuantityPerUnit = reader(\"QuantityPerUnit\") product.UnitPrice = reader(\"UnitPrice\") product.UnitsInStock = reader(\"UnitsInStock\") product.UnitsOnOrder = reader(\"UnitsOnOrder\") product.ReorderLevel = reader(\"ReorderLevel\") productList.Add(product) End While If productList.Count 0 Then Return productList End If End Using Return Nothing End Function End Class And now in your unit test you can also inherit from a very simple base class that does your setup / rollback work - or keep this on a per unit test basis below is the simple testing base class I used Imports System.Configuration Imports System.Data Imports System.Data.SqlClient Imports Microsoft.VisualStudio.TestTools.UnitTesting Public MustInherit Class TransactionFixture Protected mConnection As IDbConnection Protected mTransaction As IDbTransaction Private mConnectionString As String = ConfigurationManager.ConnectionStrings(\"Northwind.ConnectionString\").ConnectionString TestInitialize() _ Public Sub CreateConnectionAndBeginTran() mConnection = New SqlConnection(mConnectionString) mConnection.Open() mTransaction = mConnection.BeginTransaction() End Sub TestCleanup() _ Public Sub RollbackTranAndCloseConnection() mTransaction.Rollback() mTransaction.Dispose() mConnection.Close() mConnection.Dispose() End Sub End Class and finally - the below is a simple test using that test base class that shows how to test the entire CRUD cycle to make sure all the sprocs do their job and that your ado.net code does the left-right mapping correctly I know this doesn't test the \"spGetProducts\" sproc used in the above data access sample, but you should see the power behind this approach to unit testing sprocs Imports SampleApplication.Library Imports System.Collections.Generic Imports Microsoft.VisualStudio.TestTools.UnitTesting TestClass() _ Public Class ProductRepositoryUnitTest Inherits TransactionFixture Private mRepository As ProductRepository TestMethod() _ Public Sub Should-Insert-Update-And-Delete-Product() mRepository = New ProductRepository(New HttpCache(), mConnection, mTransaction) '** Create a test product to manipulate throughout **' Dim Product As New Product() Product.ProductName = \"TestProduct\" Product.SupplierID = 1 Product.CategoryID = 2 Product.QuantityPerUnit = \"10 boxes of stuff\" Product.UnitPrice = 14.95 Product.UnitsInStock = 22 Product.UnitsOnOrder = 19 Product.ReorderLevel = 12 '** Insert the new product object into SQL using your insert sproc **' mRepository.InsertProduct(Product) '** Select the product object that was just inserted and verify it does exist **' '** Using your GetProductById sproc **' Dim Product2 As Product = mRepository.GetProduct(Product.ID) Assert.AreEqual(\"TestProduct\", Product2.ProductName) Assert.AreEqual(1, Product2.SupplierID) Assert.AreEqual(2, Product2.CategoryID) Assert.AreEqual(\"10 boxes of stuff\", Product2.QuantityPerUnit) Assert.AreEqual(14.95, Product2.UnitPrice) Assert.AreEqual(22, Product2.UnitsInStock) Assert.AreEqual(19, Product2.UnitsOnOrder) Assert.AreEqual(12, Product2.ReorderLevel) '** Update the product object **' Product2.ProductName = \"UpdatedTestProduct\" Product2.SupplierID = 2 Product2.CategoryID = 1 Product2.QuantityPerUnit = \"a box of stuff\" Product2.UnitPrice = 16.95 Product2.UnitsInStock = 10 Product2.UnitsOnOrder = 20 Product2.ReorderLevel = 8 mRepository.UpdateProduct(Product2) '**using your update sproc '** Select the product object that was just updated to verify it completed **' Dim Product3 As Product = mRepository.GetProduct(Product2.ID) Assert.AreEqual(\"UpdatedTestProduct\", Product2.ProductName) Assert.AreEqual(2, Product2.SupplierID) Assert.AreEqual(1, Product2.CategoryID) Assert.AreEqual(\"a box of stuff\", Product2.QuantityPerUnit) Assert.AreEqual(16.95, Product2.UnitPrice) Assert.AreEqual(10, Product2.UnitsInStock) Assert.AreEqual(20, Product2.UnitsOnOrder) Assert.AreEqual(8, Product2.ReorderLevel) '** Delete the product and verify it does not exist **' mRepository.DeleteProduct(Product3.ID) '** The above will use your delete product by id sproc **' Dim Product4 As Product = mRepository.GetProduct(Product3.ID) Assert.AreEqual(Nothing, Product4) End Sub End Class I know this is a long example, but it helped to have a reusable class for the data access work, and yet another reusable class for my testing so I didn't have to do the setup/teardown work over and over again ;) ","pontos":11},{"corpo":"The company I work for has been using Symfony and the workaround that we've used is to trigger a warning with javascript before the user gets logged out. I suspect that there is a a way to make 'heartbeat' ajax calls to the server to trigger the timer to reset, but that may be a lot of trouble. I think that there may not be a full fix that's suitable for you though, except maybe re-writing the session handler. Sorry I couldn't be more specific, if I get the chance, I'll ask our Symfony devs if they know of a better solution. ","pontos":0},{"corpo":"There's also the way seems to do it... From what I gather, it seems to create dictionary-like row-proxies to map key lookup into the memory block returned by the query. In that case, fetching the whole answer and working with a similar proxy-factory over the rows seems like useful idea. Come to think of it though, it feels more like Lua than Python. Also, this should be applicable to all PEP-249 DBAPI2.0 interfaces, not just Oracle, or did you mean just fastest using Oracle? ","pontos":1},{"corpo":"Your problem could be that you're not actually overriding Autosize in your code (ie, in the same way that you're overriding Font or ForeColor). ","pontos":1},{"corpo":"@Andy http://se.php.net/array_merge That was my first thought but it doesn't quite work - however array_merge_recursive might work - too lazy to check right now. ","pontos":8},{"corpo":"I have a feeling you haven't finished typing your question yet, but I'll give it a shot still. ;) file1: file2: file3: 1 a A 2 b B 3 c C ~$ paste file{1,2,3} |sed 's/^\\|$/\"/g; s/\\t/\",\"/g' \"1\",\"a\",\"A\" \"2\",\"b\",\"B\" \"3\",\"c\",\"C\" Or, ~$ paste --delimiter , file{1,2,3} 1,a,A 2,b,B 3,c,C ","pontos":1},{"corpo":"@Andy I've already looked at that and didn't see how it can help merge multidimensional arrays. Maybe you could give an example. @kevin That is probably what I will need to do as I think the code below will be very slow. The actual code is a bit different because I'm using ADOdb (and ODBC for the other query) but I'll make it work and post my own answer. This works, however I think it will be very slow as it goes through the second loop every time: foreach($array as $animal) { foreach($array2 as $animal2) { if($animal['id'] === $animal2['id']) { $animal = array_merge($animal, $animal2); break; } } } ","pontos":0},{"corpo":"In the past before moving to ASP.NET MVC, I used this library Phil Haack created for Unit Testing anything that used the HttpApplication and HttpContext. It in turned used a Duck Typing library. Unfortunately, this was the best way to do it. ASP.NET was not made to be easily testable. When they worked on ASP.NET MVC, one of the goals is to get rid of these headaches by making the framework more testable. ","pontos":1},{"corpo":"I use the defaults, except for setting the background to a slightly off-white(#FAFAFA). I find that it much less tiring on the eyes than a white background. ","pontos":1},{"corpo":"Keep tests short, \"atomic\". Test the smallest assumption in each test. Make each TestMethod independent, for integration tests I even create a new database for each method. If you need to build some data for each test use an \"Init\" method. Use mocks to isolate the class your testing from it's dependencies. I always think \"what's the minimum amount of code I need to write to prove this works for all cases ?\" ","pontos":0},{"corpo":"I don't much about Ruby or Rails, but in Perl, this is what I would do: my $title = \"How do you change a title to be part of the url like Stackoverflow?\"; my $url = lc $title; # Change to lower case and copy to URL. $url =~ s/^\\s+//g; # Remove leading spaces. $url =~ s/\\s+$//g; # Remove trailing spaces. $url =~ s/\\s+/\\-/g; # Change one or more spaces to single hyphen. $url =~ s/[^\\w\\-]//g; # Remove any non-word characters. print \"$title\\n$url\\n\"; I just did a quick test and it seems to work. Hopefully this is relatively easy to translate to Ruby. ","pontos":3},{"corpo":"What about funny characters? What are you going to do about those? Umlauts? Punctuation? These need to be considered. Basically, I would use a white-list approach, as opposed to the black-list approaches above: Describe which characters you will allow, which characters you will convert (to what?) and then change the rest to something meaningfull (\"\"). I doubt you can do this in one regex... Why not just loop through the characters? ","pontos":2},{"corpo":"In the book \"SQL Performance Tuning\", the authors found that the UNION queries were slower in all 7 DBMS' that they tested (SQL Server 2000, Sybase ASE 12.5, Oracle 9i, DB2, etc.): http://books.google.com/books?id=3H9CC54qYeEC pg=PA32 vq=UNION dq=sql+performance+tuning source=gbs_search_s sig=ACfU3U18uYZWYVHxr2I3uUj8kmPz9RpmiA#PPA33,M1 The later DBMS' may have optimized that difference away, but it's doubtful. Also, the UNION method is much longer and more difficult to maintain (what if you want a third?) vs. the IN. Unless you have good reason to use UNION, stick with the OR/IN method. ","pontos":1},{"corpo":"Brian's code, in Ruby: title.downcase.strip.gsub(/\\ /, '-').gsub(/[^\\w\\-]/, '') turns the string to lowercase, removes leading and trailing whitespace, the first call globally substitutes spaces with dashes, and the second removes everything that isn't a letter or a dash. ","pontos":1},{"corpo":"As far as I've seen, it is not possible to do AND when using FREETEXT() under SQL 2005 (nor 2008, afaik). A FREETEXT query ignores Boolean, proximity, and wildcard operators by design. However you could do this: WHERE FREETEXT('You gotta love MS-SQL') 0 AND FREETEXT('You gotta love MySQL too...') 0 Or that's what I think :) -- The idea is make it evaluate to Boolean, so you can use boolean operators. Don't know if this would give an error or not. I think it should work. But reference material is pointing to the fact that this is not possible by design. The use of CONTAINS() instead of FREETEXT() could help. ","pontos":2},{"corpo":"I think you need to be a little more specific. There are several variations on hashtables with regards to the following options Is the hashtable fixed-size or dynamic? What type of hash function is used? Are there any performance constraints when the hashtable is resized? The list can go on and on. Each of these constraints could lead to multiple implementations in any language. Personally, I would just use the built-in hashtable that is available in my language of choice. The only reason I would even consider implementing my own would be due to performance issues, and even then it is difficult to beat most existing implementations. ","pontos":0},{"corpo":"You will need to prefix them with the @ symbol to use them. Here is the msdn page that explains it. -- Edit -- Sorry, nobody had answered when I saw the question. Since this is a duplicate answer, I can delete it if needed. I had a vote up, but somebody voted it down. ","pontos":8},{"corpo":"I just started reading about freetext so bear with me. If what you are trying to do is allow searches for a tag, say VB, also find things tagged as VB6, Visual Basic, VisualBasic and VB.Net, wouldn't those values be set as synonyms in the DB's Thesaurus rather than query parameters? If that is indeed the case, this link on MSDN explains how to add items to the Thesaurus. ","pontos":1},{"corpo":"Boxed values are data structures that are minimal wrappers around primitive types*. Boxed values are typically stored as pointers to objects on the heap. Thus, boxed values use more memory and take at minimum two memory lookups to access: once to get the pointer, and another to follow that pointer to the primitive. Obviously this isn't the kind of thing you want in your inner loops. On the other hand, boxed values typically play better with other types in the system. Since they are first-class data structures in the language, they have the expected metadata and structure that other data structures have. In Java and Haskell generic collections can't contain unboxed values. Generic collections in .NET can hold unboxed values with no penalties. Where Java's generics are only used for compile-time type checking, .NET will generate specific classes for each generic type instantiated at run time. Java and Haskell have unboxed arrays, but they're distinctly less convenient than the other collections. However, when peak performance is needed it's worth a little inconvenience to avoid the overhead of boxing and unboxing. * For this discussion, a primitive value is any that can be stored on the call stack, rather than stored as a pointer to a value on the heap. Frequently that's just the machine types (ints, floats, etc), structs, and sometimes static sized arrays. .NET-land calls them value types (as opposed to reference types). Java folks call them primitive types. Haskellions just call them unboxed. ** I'm also focusing on Java, Haskell, and C# in this answer, because that's what I know. For what it's worth, Python, Ruby, and Javascript all have exclusively boxed values. This is also known as the \"Everything is an object\" approach***. *** Caveat: A sufficiently advanced compiler / JIT can in some cases actually detect that a value which is semantically boxed when looking at the source, can safely be an unboxed value at runtime. In essence, thanks to brilliant language implementors your boxes are sometimes free. ","pontos":116},{"corpo":"Quick followup question - can you use the \"runas\" command from an MSBuild script? If so, wouldn't you be able to simply impersonate another user with runas /user:dsfsdf /password:dfdf sc.exe ... (or similiar - I haven't researched the command-line options)? ","pontos":0},{"corpo":" When implementing a needle search of a haystack in an object-oriented way, you essentially have three alternatives: needle.find(haystack) haystack.find(needle) searcher.find(needle, haystack) Which do you prefer, and why? Correct me if I'm wrong, but in all three examples you already have a reference to the needle you're looking for, so isn't this kinda like looking for your glasses when they're sitting on your nose? :p Pun aside, I think it really depends on what you consider the responsibility of the haystack to be within the given domain. Do we just care about it in the sense of being a thing which contains needles (a collection, essentially)? Then haystack.find(needlePredicate) is fine. Otherwise, farmBoy.find(predicate, haystack) might be more appropriate. ","pontos":5},{"corpo":"Your getting into really far out AI type domain. I have done extensive work in text transformation into machine knowledge mainly using Attempto Controlled English (see: http://attempto.ifi.uzh.ch/site/), it is a natural language (english) that is completely computer processable into several different ontologies, such as OWLDL. Seems like that would we way overkill though... Is there a reason for not just taking the first few sentences of your blog post and then appending an ellipse for your summary? ","pontos":0},{"corpo":"A hash table a data structure that allows lookup of items in constant time. It works by hashing a value and converting that value to an offset in an array. The concept of a hash table is fairly easy to understand, but implementing is obviously harder. I'm not pasting the whole hash table here, but here are some snippets of a hash table I made in C a few weeks ago... One of the basics of creating a hash table is having a good hash function. I used the djb2 hash function in my hash table: int ComputeHash(char* key) { int hash = 5381; while (*key) hash = ((hash 5) + hash) + *(key++); return hash % hashTable.totalBuckets; } Then comes the actual code itself for creating and managing the buckets in the table typedef struct HashTable{ HashTable* nextEntry; char* key; char* value; }HashBucket; typedef struct HashTableEntry{ int totalBuckets; // Total number of buckets allocated for the hash table HashTable** hashBucketArray; // Pointer to array of buckets }HashTableEntry; HashTableEntry hashTable; bool InitHashTable(int totalBuckets) { if(totalBuckets 0) { hashTable.totalBuckets = totalBuckets; hashTable.hashBucketArray = (HashTable**)malloc(totalBuckets * sizeof(HashTable)); if(hashTable.hashBucketArray != NULL) { memset(hashTable.hashBucketArray, 0, sizeof(HashTable) * totalBuckets); return true; } } return false; } bool AddNode(char* key, char* value) { int offset = ComputeHash(key); if(hashTable.hashBucketArray[offset] == NULL) { hashTable.hashBucketArray[offset] = NewNode(key, value); if(hashTable.hashBucketArray[offset] != NULL) return true; } else { if(AppendLinkedNode(hashTable.hashBucketArray[offset], key, value) != NULL) return true; } return false; } HashTable* NewNode(char* key, char* value) { HashTable* tmpNode = (HashTable*)malloc(sizeof(HashTable)); if(tmpNode != NULL) { tmpNode- nextEntry = NULL; tmpNode- key = (char*)malloc(strlen(key)); tmpNode- value = (char*)malloc(strlen(value)); strcpy(tmpNode- key, key); strcpy(tmpNode- value, value); } return tmpNode; } AppendLinkedNode finds the last node in the linked list and appends a new node to it. The code would be used like this: if(InitHashTable(100) == false) return -1; AddNode(\"10\", \"TEN\"); Finding a node is a simple as: HashTable* FindNode(char* key) { int offset = ComputeHash(key); HashTable* tmpNode = hashTable.hashBucketArray[offset]; while(tmpNode != NULL) { if(strcmp(tmpNode- key, key) == 0) return tmpNode; tmpNode = tmpNode- nextEntry; } return NULL; } And is used as follows: char* value = FindNode(\"10\"); ","pontos":14},{"corpo":".NET has a BigInteger class, but it is internal, unfortunately. However, several places have their own. You can grab an implementation from IronPython, or the one from CodeProject, or from Visual J#. I have to say, I've not tried these myself, so I don't know which one is the best. http://www.codeplex.com/IronPython http://www.codeproject.com/KB/cs/biginteger.aspx http://msdn.microsoft.com/en-us/magazine/cc163696.aspx ","pontos":13},{"corpo":"One interesting thing I've learned is that different parts of the framework and C# language were written at different times, hence inconsistencies. For example, the framework itself violates many FxCop rules because the rules weren't all in place when the framework was written. Also, the using statement was intended for delinieating \"scopes\" and not specifically for disposing resources. It was written after the lock statement. Eric Gunnerson once mentioned something along the lines of that if the using statement came first, they might have not needed to write the lock statement (though who knows, maybe they would have anyways), because the using statement might have been sufficient. ","pontos":4},{"corpo":"Test Driven Development has sort of taken over the term Unit Test. As an old timer I will mention the more generic definition of it. Unit Test also means testing a single component in a larger system. This single component could be a dll, exe, class library, etc. It could even be a single system in a multi-system application. So ultimately Unit Test ends up being the testing of whatever you want to call a single piece of a larger system. You would then move up to integrated or system testing by testing how all the components work together. ","pontos":1},{"corpo":"Notepad2 Syntax highlighting for html,c#,javascript,css,xml,sql,python,bat Rectangular selection, regular expressions Indentation, back/foreground customization Downside: No tabbed windows. ","pontos":8},{"corpo":"Check out the ASP.NET AJAX Calendar Extender or Steve Orr's drop down Calendar control. ","pontos":0},{"corpo":"I was actually trying to do this today, and I found typing this into the CLisp REPL worked: (EXT:SAVEINITMEM \"executable.exe\" :QUIET t :INIT-FUNCTION 'main :EXECUTABLE t :NORC t) where main is the name of the function you want to call when the program launches, :QUIET t suppresses the startup banner, and :EXECUTABLE t makes a native executable. It can also be useful to call (EXT:EXIT) at the end of your main function in order to stop the user from getting an interactive lisp prompt when the program is done. EDIT: Reading the documentation, you may also want to add :NORC t (read link). This suppresses loading the RC file (for example, ~/.clisprc.lisp). ","pontos":41},{"corpo":" is thrown by the framework when it is missing an assembly, or one of the references are of the wrong version. The first thing I would do is try uploading and referencing your code to the LINQ assemblies in your BIN, instead of the shared hosting providers GAC. ","pontos":2},{"corpo":"The web.config section is pretty useless as far as I can tell: authentication mode=\"Forms\" / I looked in IIS 7, and in the Authentication section it says: Anonymous Authentication = Enabled, ASP.NET Impersonation = Disabled, Basic Authentication = Disabled, Forms Authentication = Disabled. Also, I have made no changes to the code other than dragging a Login object onto the designer and changing the page it points at to index.html. Currently, the log in fails by displaying the log in failed text. EDIT: Earlier when I would try to navigate directly to a page that is restricted, I would receive a blue page saying that I had insufficient permissions. Now I can see the pages that are restricted without logging in even though I have anon access denied. ","pontos":0},{"corpo":" Then comes the multiple browser issue There is this that helps remove some inconsistencies from IE. You can also use jQuery to add some selectors via javascript. I agree with Dan, learn it and it's not so much of a problem, even fun. ","pontos":4},{"corpo":"Size is not the only thing that will be inconsistent here. In C++ bool is a keyword, and C++ guarantees that a bool can hold a value of either 1 or 0 and nothing else. C doesn't give you this guarantee. That said, if interoperability between C and C++ is important you can emulate C's custom-made boolean by defining an identical one for C++ and using that instead of the builtin bool. That will be a tradeoff between a buggy boolean and identical behaviour between the C boolean and the C++ boolean. ","pontos":1},{"corpo":"I usually just comment in two cases. When describing the functionality of a method or class in an API that is meant to be used by others. When a block of code is doing something that isn't immediately obvious. Of course I always try to give my variables and functions meaningful names, and minimize the need for comments that way. ","pontos":1},{"corpo":"You should use the antlrall.jar jar. You can go ahead and just drop it into your Ant installation but that does mean that it will only work for that one install. We check the jar in and use taskdef to load the jar file so that it doesn't become another step for developers when they start on the team or move to a new computer. Antlr http://ant.apache.org/manual/Tasks/antlr.html Using taskdef http://www.onjava.com/pub/a/onjava/2004/06/02/anttask.html ","pontos":2},{"corpo":"With MS Sql Server 2005, try the Service Broker and/or CLR stored procedures. I don't think there's anything built directly into TSQL. ","pontos":0},{"corpo":"It sounds like you need to put some scheduled jobs in place with Cron (or windows equiv). You could use the initial stored proc call to set some kind of flag in the DB, which is then checked periodically by a cron job. If you need to have a specific delay before the 2nd job executes, you should be able to do that by having the task scheduled by the cron job. ","pontos":0},{"corpo":"Creating a bunch of overlaid panels is a design-time nightmare. I would suggest using a tab control with each \"view\" on a separate tab, and then picking the correct tab at runtime. You can avoid showing the tab headers by putting something like this in your form's Load event: tabControl1.Top = tabControl1.Top - tabControl1.ItemSize.Height; tabControl1.Height = tabControl1.Height + tabControl1.ItemSize.Height; tabControl1.Region = new Region(new RectangleF(tabPage1.Left, tabPage1.Top, tabPage1.Width, tabPage1.Height + tabControl1.ItemSize.Height)); ","pontos":7},{"corpo":"To elaborate on my previous answer... When I first started using CSS I also thought it was a pain that it didn't support variables, expressions, etc. But as I started to use it more and more, I developed a different style to overcome these issues. Example, instead of this a { color: red } .entry { color: red } h1 { color: red } You can do a, .entry, h1 { color: red } You can keep the color declared in one spot by doing this... Also, once you use CSS enough you should be able to overcome most browser inconsistencies easily. If you find that you need to use a CSS hack...there is probably a better way to do it... ","pontos":6},{"corpo":"Seems like a textbook case for using FolderShare. ","pontos":1},{"corpo":"Why use Regex? If the groups are always split by a -, can't you use Split()? ","pontos":0},{"corpo":"Sorry if this isn't what you intended, but your string always has the hyphen separating the groups then instead of using regex couldn't you use the String.Split() method? Dim stringArray As Array = someString.Split(\"-\") ","pontos":0},{"corpo":"One way that I can think of would be to calculated the post position of each element through a function that vary gradually moved the large elements to the end and the small ones to the beginning. If you used a trig based function, you could make the elements osculate through the list instead of going directly toward their final position. After you've processed each element in the set, then do a full traversal to determine if the array is sorted or not. I'm not positive that this will give you O(n!) but it should still be pretty slow. ","pontos":0},{"corpo":" Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding I only get this when trying to make stuff work in IE. If you learn CSS to the point where you can code most things without having to look up the reference (if you're still looking up reference regularly you don't really know it and can't claim to complain I think), and then develop for firefox/safari, it's a pretty nice place to be in. Leave the pain and suffering of IE compatibilit to the end after it works in FF/Safari, so your mind will attribute the blame to IE, where it damn well belongs, rather than CSS in general. ","pontos":2},{"corpo":"I can understand your stipulation that your users (family) shouldn't have to sign up - but without a sign-in, your site will be a free-for-all for spammers, hackers and other bored Internet denizens. That said, my suggestion is to use WordPress for a front end - register your family members yourself, and use a very basic template - or better yet, create one. ","pontos":4},{"corpo":"You can use this pattern: Regex.Split(\"H3Y5NC8E-TGA5B6SB-2NVAQ4E0\", \"([ABCDEFGHJKLMNPQRSTVXYZ0123456789]{8}+)-?\") But you will need to filter out empty strings from resulting array. Citation from MSDN: If multiple matches are adjacent to one another, an empty string is inserted into the array. ","pontos":0},{"corpo":"OK, my joking answer didn't go down so well. This mailing list question, with answer from Matz indicates that Ruby 1.9's built in and methods will only handle ASCII characters. Without testing it myself, I would see this as strong evidence that all non-ascii characters in source code will likely be considered lowercase. Can someone download and compile the latest 1.9 and see? ","pontos":3},{"corpo":"What are the defining characteristics of a valid block? We'd need to know that in order to really be helpful. My generic suggestion, validate the charset in a first step, then split and parse in a seperate method based on what you expect. If this is in a web site/app then you can use the ASP Regex validation on the front end then break it up on the back end. ","pontos":0},{"corpo":"After reviewing your question and the answers given, I came up with this: RegexOptions options = RegexOptions.None; Regex regex = new Regex(@\"([ABCDEFGHJKLMNPQRSTVXYZ0123456789]{8})\", options); string input = @\"H3Y5NC8E-TGA5B6SB-2NVAQ4E0\"; MatchCollection matches = regex.Matches(input); for (int i = 0; i != matches.Count; ++i) { string match = matches[i].Value; } Since the \"-\" is optional, you don't need to include it. I am not sure what you was using the {4} at the end for? This will find the matches based on what you want, then using the MatchCollection you can access each match to rebuild the string. ","pontos":3},{"corpo":" Perl has a that allows you to implement poor-man's tail calls. :-P sub factorial { my ($n, $acc) = (@_, 1); return $acc if $n 1; @_ = ($n - 1, $acc * $n); goto factorial; } Okay, so that has nothing to do with C's . More seriously, I agree with the other comments about using for cleanups, or for implementing Duff's device, or the like. It's all about using, not abusing. (The same comment can apply to , exceptions, , and the like---they have legitimate uses, but can easily be abused. For example, throwing an exception purely to escape a deeply-nested control structure, under completely non-exceptional circumstances.) ","pontos":14},{"corpo":"Unless your 2nd dropdown is in a databound control (say, a Repeater) - I'm not sure what you're trying to bind SelectedValue to. Apparently, neither is .NET - since that's probably where the error is occurring. Where's Connect_ToProjectId supposed to come from? ","pontos":0},{"corpo":"Have you tried the award-winning rsyncrypto? ","pontos":0},{"corpo":"Edsger Dijkstra, a computer scientist that had major contributions on the field, was also famous for criticizing the use of GoTo. There's a short article about his argument on Wikipedia. ","pontos":1},{"corpo":"Create your own function to execute an OS command through the command line? For the sake of an example. But know where and why you'd want to use this as others note. public static void main(String arg[]) throws IOException{ Runtime runtime = Runtime.getRuntime(); Process proc = runtime.exec(\"shutdown -s -t 0\"); System.exit(0); } ","pontos":50},{"corpo":"The quick answer is no. The only way to do it is by invoking the OS-specific commands that will cause the computer to shutdown, assuming your application has the necessary privileges to do it. This is inherently non-portable, so you'd need either to know where your application will run or have different methods for different OSs and detect which one to use. ","pontos":19},{"corpo":"Logically, you are not able to share source code between C and C++ with conflicting declarations for bool and have them link to each other. The only way you can share code and link is via an intermediary datastructure. Unfortunately, from what I understand, you can't modify the code that defines the interface between your C++ program and C library. If you could, I'd suggest using something like: union boolean { bool value_cpp; int value_c; }; // padding may be necessary depending on endianness The effect of which will be to make the datatype the same width in both languages; conversion to the native data type will need to be performed at both ends. Swap the use of bool for boolean in the library function definition, fiddle code in the library to convert, and you're done. So, what you're going to have to do instead is create a shim between the C++ program and the C library. You have: extern \"C\" bool library_func_1(int i, char c, bool b); And you need to create: bool library_func_1_cpp(int i, char c, bool b) { int result = library_func_1(i, c, static_cast int (b)); return (result==true); } And now call library_func_1_cpp instead. ","pontos":0},{"corpo":"Had no idea what ASP.NET Dynamic Data was so you promted me to so some research :) Looks like the property you are looking for is [ScaffoldColumn(false)] There is also a similar property for tables [ScaffoldTable(false)] source ","pontos":20},{"corpo":"A better answer is that ++i will sometimes be faster but never slower. Everyone seems to be assuming that 'i' is a regular built-in type such as int. In this case there will be no measurable difference. However if 'i' is complex type then you may well find a measurable difference. For i++ you must make a copy of your class before incrementing it. Depending on what's involved in a copy it could indeed be slower since with ++it you can just return the final value. Foo Foo::operator++() { Foo oldFoo = *this; // copy existing value - could be slow // yadda yadda, do increment return oldFoo; } Another difference is that with ++i you have the option of returning a reference instead of a value. Again, depending on what's involved in making a copy of your object this could be slower. A real-world example of where this can occur would be the use of iterators. Copying an iterator is unlikely to be a bottle-neck in your application, but it's still good practice to get into the habit of using ++i instead of i++ where the outcome is not affected. ","pontos":21},{"corpo":"An the reason why you ought to use ++i even on built-in types where there's no performance advantage is to create a good habit for yourself. ","pontos":0},{"corpo":"Try PDFMiner. It can extract text from PDF files as HTML, SGML or \"Tagged PDF\" format. http://www.unixuser.org/~euske/python/pdfminer/index.html The Tagged PDF format seems to be the cleanest, and stripping out the XML tags leaves just the bare text. ","pontos":60},{"corpo":"I use SVN. It works (I think) over SSH and SSL. Full versioning, file syncing, what's not to like? ","pontos":0},{"corpo":"I ended up using Apache's ddlutils to perform the dropping for me, which sorted it out in my case, though a solution which worked only within sql server would be quite a bit simpler. @Derek Park, I didn't know you could comma separate tables there, so that's handy, but it doesn't seem to work quite as expected. Nether IF EXISTS nor CASCADE are recognised by sql server it seems, and running seems to work only if they should be dropped in the stated order. See also http://msdn.microsoft.com/en-us/library/ms173790.aspx, which describes the drop table syntax. ","pontos":0},{"corpo":"The thing holding you back from dropping the tables in any order are foreign key dependencies between the tables. So get rid of the FK's before you start. Using the INFORMATION_SCHEMA system views, retrieve a list of all foreign keys related to any of these tables Drop each of these foreign keys Now you should be able to drop all of the tables, using any order that you want. ","pontos":0},{"corpo":"A diferent approach could be: first get rid of the constraints, then drop the tables in a single shot. In other words, a DROP CONSTRAINT for every constraint, then a DROP TABLE for each table; at this point the order of execution shouldn't be an issue. ","pontos":1},{"corpo":"At the risk of sounding stupid, I don't believe SQL Server supports the delete / cascade syntax. I think you can configure a delete rule to do cascading deletes (http://msdn.microsoft.com/en-us/library/ms152507.aspx), but as far as I know the trick with SQL Server is to just to run your drop query once for each table you're dropping, then check it worked. ","pontos":2},{"corpo":" Can you try that? Or is it the same? ","pontos":1},{"corpo":"From Objective-C Tutorial: The @ Symbol, the reason it is on the front of various keywords: Using @ should make it easier to bolt an Objective-C compiler on to an existing C compiler. Because the @ isn't valid in any context in C except a string literal, the tokenizer (an early and simple step in the compiler) could be modified to simply look for the @ character outside of a string constant (the tokenizer understands string literals, so it is in a position to distinguish this). When @ is encountered the tokenizer would put the rest of the compiler in \"Objective-C mode.\" (The Objective-C parser would be responsible for returning the compiler back to regular C mode when it detects the end of the Objective-C code). Also when seen in front of a string literal, it makes an NSString rather than a 'char *' in C. ","pontos":46},{"corpo":"Isnt #160 the entity for space? select option #160;option 1 /option option option 2 /option /select Works for me.. EDIT: Just checked this out, there may be compat issues with this on older browsers, but all seems to work fine for me here. Just thought I should let you know as you may want to replace with ","pontos":12},{"corpo":"OK, this doesn't answer your question, but doesn't your current code leave you open to SQL Injection? I could be wrong, never worked in PHP, just saw the use of strings in the SQL and alarm bells started ringing! Edit: I am not trying to tamper with your post, I was correcting a spelling error, please do not roll back. ","pontos":0},{"corpo":"I am not sure what you mean by \"large amounts of data\", but it looks to me like you are only initializing data for one user? If so, I don't see any reason to optimize this unless you have hundreds of columns in your database with several megabytes of data in them. Or, to put it differently, why do you need to optimize this? Are you having performance problems? What you are doing now is the straight-forward approach, and I can't really see any reason to do it differently unless you have some specific problems with it. Wrapping the user data in a user object might help some on the program structure though. Validating your input is probably also a good idea. ","pontos":0},{"corpo":"Try using json for example: $_SESSION['data'] = json_encode(mysql_fetch_array($result)); Edit Later you then json_decode the $_SESSION['data'] variable and you got an array with all the data you need. Clarification: You can use json_encode and json_decode if you want to reduce the number of lines of code you write. In the example in the question, a line of code was needed to copy each column in the database to the SESSION array. Instead of doing it with 50-75 lines of code, you could do it with 1 by json_encoding the entire database record into a string. This string can be stored in the SESSION variable. Later, when the user visits another page, the SESSION variable is there with the entire json string. If you then want to know the first name, you can use the following code: $fname = json_decode($_SESSION['data'])['fname']; This method won't be faster than a line by line copy, but it will save coding and it will be more resistant to changes in your database or code. BTW Does anyone else have trouble entering ] into markdown? I have to paste it in. ","pontos":0},{"corpo":"Try using json for example: Is the implementation of that function faster than what he is already doing? Does anyone else have trouble entering ] into markdown? I have to paste it in Yes, it's bugged. ","pontos":0},{"corpo":"@Anders - there are something like 50-75 columns. Again, unless this is actually causing performance problems in your application I would not bother with optimizing it. If, however, performance is a problem I would consider only getting some of the data initially and lazy-loading the other columns as they are needed. ","pontos":0},{"corpo":"If the filenames don't have spaces, this will work: ls -C1 -t| awk 'NR 5'|xargs rm If the filenames do have spaces, something like ls -C1 -t | awk 'NR 5' | sed -e \"s/^/rm '/\" -e \"s/$/'/\" | sh Basic logic: get a listing of the files in time order, one column get all but the first 5 (n=5 for this example) first version: send those to rm second version: gen a script that will remove them properly ","pontos":5},{"corpo":" Write your own AOP library. Use reflection to generate a logging proxy over your instances (not sure if you can do it without changing some part of your existing code). Rewrite the assembly and inject your logging code (basically the same as 1). Host the CLR and add logging at this level (i think this is the hardest solution to implement, not sure if you have the required hooks in the CLR though). ","pontos":0},{"corpo":"Take a look at this - Pretty heavy stuff..http://msdn.microsoft.com/en-us/magazine/cc164165.aspx Essential .net - don box had a chapter on what you need called Interception. I scraped some of it here (Sorry about the font colors - I had a dark theme back then...)http://madcoderspeak.blogspot.com/2005/09/essential-interception-using-contexts.html ","pontos":4},{"corpo":"C# is not an AOP oriented language. It has some AOP features and you can emulate some others but making AOP with C# is painful. I looked up for ways to do exactly what you wanted to do and I found no easy way to do it. As I understand it, this is what you want to do: [Log()] public void Method1(String name, Int32 value); and in order to do that you have two main options Inherit your class from MarshalByRefObject or ContextBoundObject and define an attribute which inherits from IMessageSink. This article has a good example. You have to consider nontheless that using a MarshalByRefObject the performance will go down like hell, and I mean it, I'm talking about a 10x performance lost so think carefully before trying that. The other option is to inject code directly. In runtime, meaning you'll have to use reflection to \"read\" every class, get its attributes and inject the appropiate call (and for that matter I think you couldn't use the Reflection.Emit method as I think Reflection.Emit wouldn't allow you to insert new code inside an already existing method). At design time this will mean creating an extension to the CLR compiler which I have honestly no idea on how it's done. The final option is using an IoC framework. Maybe it's not the perfect solution as most IoC frameworks works by defining entry points which allow methods to be hooked but, depending on what you want to achive, that might be a fair aproximation. ","pontos":38},{"corpo":"Without any client side additions? As per IEMobile Team Blog, the only way for that would be wait for the next release :( ","pontos":1},{"corpo":"Try Jochen Kalmbach's Memory Leak Detector on Code Project. The URL to the latest version was somewhere in the comments when I last checked. ","pontos":1},{"corpo":"I personally use Visual Leak Detector, though it can cause large delays when large blocks are leaked (it displays the contents of the entire leaked block). ","pontos":32},{"corpo":"As UDP is not connection oriented there's no way to indicate that two packets belong together. As a result you're limited by the maximum size of a single IP packet (65535). The data you can send is somewhat less that that, because the IP packet size also includes the IP header (usually 20 bytes) and the UDP header (8 bytes). Note that this IP packet can be fragmented to fit in smaller packets (eg. ~1500 bytes for ethernet). I'm not aware of any OS restricting this further. ","pontos":1},{"corpo":"This page claims that a flag for gcc () should do the trick. Give it a whirl, and if you need any more help, post back here. ","pontos":0},{"corpo":"There's a (proven!) worst sorting algorithm called slow sort that uses the multiply and surrender paradigm and runs in exponential time. While your algorithm is slower, it doesn't progress steadily but instead performs random jumps. Additionally, slow sort's best case is still exponential while yours is constant. ","pontos":7},{"corpo":"@Brian I'm nearly certain you can accomplish this with CSS padding, as well. Then you won't be married to the space characters being hard-coded into all of your tags. Good thinking - but unfortunately it doesn't work in (everyone's favourite browser...) IE7 :-( Here's some code that will work in Firefox (and I assume Op/Saf). select option style=\"padding-left: 0px;\" Blah /option option style=\"padding-left: 5px;\" Blah /option option style=\"padding-left: 10px;\" Blah /option option style=\"padding-left: 0px;\" Blah /option option style=\"padding-left: 5px;\" Blah /option /select ","pontos":4},{"corpo":"Be aware that you may run into issues with your apache modules. If they are compiled in 32-bit mode, then you will not be able to load them into a 64-bit apache. I had this issue with mod_python, took a bit of thinking to figure out this was the reason. ","pontos":0},{"corpo":"You can't help the memory problems much until Flash adds destructors and explicit object deletion, unfortunately. See this thread: http://stackoverflow.com/questions/34/unloading-a-bytearray-in-actionscript-3 There's a limit to how much memory Flash applets can use; the GC seems to fire upon reaching that limit. I've seen my memory-easy applets use as much as ~200MB, just because they run for hours on end and the GC doesn't want to kick in. Oh, and I don't think using a single instance is an elegant solution, either. Currently I just write a dispose() function for my custom classes, waiting for some day when it can be turned into a proper destructor. ","pontos":1},{"corpo":"RMS performance and implementation varies wildly between devices, so if platform portability is a problem, you may find that your code works well on some devices and not others. RMS is designed to store small amounts of data (High score tables, or whatever) not large amounts. You might find that some platforms are faster with files stored in multiple record stores. Some are faster with multiple records within one store. Many are ok for storage, but become unusably slow when deleting large amounts of data from the store. Your best bet is to use JSR-75 instead where available, and create your own file store interface that falls back to RMS if nothing better is supported. Unfortunately when it comes to JavaME, you are often drawn into writing device-specific variants of your code. ","pontos":4},{"corpo":"I'd say the most famous programming game there has been is the core wars. I don't know if you can still find active \"rings\" although there was a lot when I tried it some time ago (4 or 5 years). ","pontos":2},{"corpo":"Emacs has a folding minor mode, but I only fire it up occasionally. Mostly when I'm working on some monstrosity inherited from another physicist who evidently had less instruction or took less care about his/her coding practices. ","pontos":0},{"corpo":"Well, not to answer your question directly, but I have seen this happen. Microsoft recently launched a tool called PhotoSynth which does something very similar to determine overlapping areas in a large number of pictures (which could be of different aspect ratios). I wonder if they have any available libraries or code snippets on their blog. ","pontos":1},{"corpo":"I wonder (and I'm really just throwing the idea out there to be shot down) if something could be derived by subtracting one image from the other, and then compressing the resulting image as a jpeg of gif, and taking the file size as a measure of similarity. If you had two identical images, you'd get a white box, which would compress really well. The more the images differed, the more complex it would be to represent, and hence the less compressible. Probably not an ideal test, and probably much slower than necessary, but it might work as a quick and dirty implementation. ","pontos":2},{"corpo":"I've never really liked the components, they're a bit dodgy. This particular problem seems to be common, and the somewhat annoying solution is, as you're suggesting, to only have one FLVPlayback and reuse that. Here's a blog post about it ","pontos":2},{"corpo":"This is just one of those silly discussions that lead to nowhere. If you like regions, use them. If you don't, configure your editor to turn them off. There, everybody is happy. ","pontos":2},{"corpo":"I honestly don't think it's possible. I've done it before using pretty simple key encryption with a compressed binary which worked well enough for the security I required but I honestly think if somebody considers cracking your online high score table a hack it will be done. There are some pretty sad people out there who also happen to be pretty bright unless you can get them all laid it's a lost cause. ","pontos":6},{"corpo":"I've been doing some of this with my Flash games, and it's a losing battle really. Especially for ActionScript that can be decompiled into somewhat readable code without too much effort. The way I've been doing it is a rather conventional approach of sending the score and player name in plain text and then a hash of the two (properly salted). Very few people are determined enough to take the effort to figure that out, and the few who are would do it anyway, negating all the time you put into it. To summarize, my philosophy is to spend the time on making the game better and just make it hard enough to cheat. One thing that might be pretty effective is to have the game submit the score to the server several times as you are playing, sending a bit of gameplay information each time, allowing you to validate if the score is \"realistic\". But that might be a bit over-the-top really. ","pontos":5},{"corpo":"I don't recommend Oracle XE. My co-workers and I have been doing a project in Oracle and got severely tripped up after trying to use XE for our local development instances. The database worked fine until we started running local stress tests, at which point it started dropping connections. I don't know whether this is an intentional, documented limitation or if perhaps we each just hit a weird bug, but I strongly recommend that you stay away from XE. When we both switched over to the full version, our problems immediately went away. Also, Oracle doesn't require any kind of licensing confirmation for the full server; you have to click something to say that you have indeed acquired a license, but it doesn't make you prove it. So if you indeed have a license to use Oracle, there's no reason why you can't just install the full version on your development machines. ","pontos":1},{"corpo":"I'm not sure I understand the problem. Do you know the loop? Why not simply nest it? foreach ($array as $i = $values) { print \"$i {\\n\"; foreach ($values as $key = $value) { print \" $key = $value\\n\"; } print \"}\\n\"; } ","pontos":27},{"corpo":"No solution is ever going to be perfect while the game is running on a system under the user's control, but there are a few steps you could take to make hacking the system more trouble. In the end, the goal can only be to make hacking the system more trouble than it's worth. Send some additional information with the high score requests to validate one the server side. If you get 5 points for every X, and the game only contains 10 Xs, then you've got some extra hoops to make the hacker to jump through to get their score accepted as valid. Have the server send a random challenge which must be met with a few bytes of the game's binary from that offset. That means the hacker must keep a pristine copy of the binary around (just a bit more trouble). If you have license keys, require high scores to include them, so you can ban people caught hacking the system. This also lets you track invalid attempts as defined above, to ban people testing out the protocol before the ever even submit a valid score. All in all though, getting the game popular enough for people to care to hack it is probably a far bigger challenge. ","pontos":22},{"corpo":"@Ryan Fox In fact, how does one represent i (or j for the engineers) in a conventional programming language? Native complex data types are far from unknown. Fortran had it by the mid-sixties, and the OP exhibits a variety of other languages that support them in hist followup. And complex numbers can be added to other languages as libraries (with operator overloading they even look just like native types in the code). But unless you provide a special case for this problem, the \"non-agreement\" is just an expression of imprecise machine arithmetic, no? It's like complaining that float r = 2/3; float s = 3*r; float t = s - 2; ends with (t != 0) (At least if you use an dumb enough compiler)... ","pontos":2},{"corpo":"As the other answer says, you are forced to trust a potentially malicious client, and a simple deterant plus a little human monitoring is going to be enough for a small game. If you want to get fancy, you then have to look for fraud patterns in the score data, simmular to a credit card company looking at charge data. The more state the client communicates onto your server, the potentially easier it is to find a pattern of correct or incorrect behavior via code. For example. say that the client had to upload a time based audit log of the score (which maybe you can also use to let another clients watch the top games), the server can then validate if the score log breaks any of the game rules. In the end, this is still about making it expensive enough to discourage cheating the scoreboard. You would want a system where you can always improve the (easier to update)server code to deal with any new attacks on your validation system. ","pontos":2},{"corpo":"Your question seems a little odd to me, as you seem to be suggesting that the Floating Point math is implemented by the language. That's generally not true, as the FP math is done using a floating point processor in hardware. But software or hardware, floating point will always be inaccurate. That's just how floats work. If you need better precision you need to use a different number representation. Just like if you're doing integer math on numbers that don't fit in an int or long. Some languages have libraries for that built in (I know java has BigInteger and BigDecimal), but you'd have to explicitly use those libraries instead of native types, and the performance would be (sometimes significantly) worse than if you used floats. ","pontos":3},{"corpo":"That's a really hard question. I've never implemented such thing but here's a simple aproximmation. Your main concern is due to hackers guessing what is it your application is doing and then sending their own results. Well, first of all, unless your application has a great success I wouldn't be worried. Doing such thing is extremely difficult. Encryption won't help with the problem. You see, encryption helps to protect the data on its way but it doesn't protect either of the sides of the transaction before the data is encrypted (which is where the main vulnerability may be). So if you encrypt the sure, the data will remain private but it won't be safe. If you are really worried about it I will suggest obfuscating the code and designing the score system in a way which is not completely obvious what is doing. Here we can borrow some things from an encryption protocol. Here is an example: Let's say the score is some number m Compute some kind of check over the score (for example the CRC or any other system you see feet. In fact, if you just invent one, no matter how lame is it it will work better) Obtain the private key of the user (D) from your remote server (over a secure connection obviously). You're the only one which know this key. Compute X=m^D mod n (n being the public module of your public/private key algorithm) (that is, encrypt it :P) As you see that's just obfuscation of another kind. You can go down that way as long as you want. For example you can lookup the nearest two prime numbers to X and use them to encrypt the CRC and send it also to the server so you'll have the CRC and the score separately and with different encryption schemes. If you use that in conjunction with obfuscation I'd say that would be difficult to hack. Nontheless even that could be reverse engingeered, it all depends on the interest and ability of the hacker but ... seriously, what kind of freak takes so much effort to change its results on a game? (Unless is WoW or something) One last note Obfuscator for .NET Obfuscator for Delphi/C++ Obfuscator for assembler (x86) ","pontos":3},{"corpo":"I can't see a way to add delay outside of JavaScript - but if you're going to use JavaScript you may as well use a JavaScript controlled menu. If you follow a semantically-correct nav pattern and set it up so it display's normally (e.g. static) when JavaScript is not present you should be fine with whatever you use. It's all about your target audience - who's larger? JS-disabled or users with co-ordination difficulties? I would guess that the latter require the priority (if not for percentage use then disability laws). ","pontos":0},{"corpo":"You can also set the environment variable I use , so that I can pump colorized output from into it, and maintain the ANSI colour sequences. Another little used feature of less that I found is starting it with as an argument (or hitting SHIFT+F while in less). This causes it to follow the file you've opened, in the same way that will. Very handy if you're watching log files from an application, and are likely to want to page back up (if it's generating 100's of lines of logging every second, for instance). ","pontos":49},{"corpo":"Using the built-in features of a language work for me. Java has and , and Python automagicaly switches to an object similar to Java's if a number gets out of the range of an or whatnot. As for other languages though, I have no idea. I hate re-inventing the wheel. ","pontos":3},{"corpo":"Do you get a different error without the ISAPI filter in place? ","pontos":0},{"corpo":"I try to make a standards-compliant page and do all my testing in Firefox (since it has some excellent development extensions such as Web Developer and Firebug). Then when I'm finished I test the site in IE, then make whatever small changes are necessary. I find that I need to make very few changes, since I don't do anything extraordinarily complex with CSS. I used to have more problems with Javascript differences, but after I started using Javascript libraries (such as jQuery) I stopped having any serious problems with that. ","pontos":0},{"corpo":"Padding. IE6 can get a little hinky when using margin to place elements horizontally on a page. If you size your elements and space the content within using padding, you can make many layouts work great in IE6/7, FF, Safari, and Opera without any hacks. IE5.5 makes things a little stickier because of the broken box model, but I think we can pretty much count it out in most circumstances now. ","pontos":0},{"corpo":" I try to make a standards-compliant page and do all my testing in Firefox (since it has some excellent development extensions such as Web Developer and Firebug). Then when I'm finished I test the site in IE, then make whatever small changes are necessary. I find that I need to make very few changes, since I don't do anything extraordinarily complex with CSS. The same here, except I don't tend to need to use Firebug and such. I've only had problems with IE6 recently however - which are solved by simple CSS bypasses: /* All browsers read: */ html body { margin: 10px; } /* FF, IE7, Op etc. read: */ html body { margin: 0; } ","pontos":0},{"corpo":"Use a css reset to level the field across browsers. YUI and Eric Meyer have good ones. ","pontos":3},{"corpo":"Function overloading is a C++ feature that relies on name mangling (the cryptic function names in the linker error messages). By writing the mangled names into the def file, I can get my test project to link and run: LIBRARY \"TestDLL\" EXPORTS ?Foo@@YAXH@Z ?Foo@@YAXHH@Z seems to work for void Foo( int x ); void Foo( int x, int y ); So copy the C++ function names from the error message and write them into your def file. However, the real question is: Why do you want to use a def file and not go with __declspec(dllexport) ? The mangled names are non-portable, I tested with VC++ 2008. ","pontos":10},{"corpo":"I do not understand your question all the way. If you need an overall summary that is repeated, you would need a sub-report that have shown in the report multiple times. ","pontos":0},{"corpo":"One practice I use (and one that not everyone would even agree with) is always surrounding code blocks (in C++) with { and }. So instead of this: if( true ) DoSomething(); else DoSomethingElse(); I would write this: if( true ) { DoSomething(); } else { DoSomethingElse(); } This way, if I (or someone else) comes back to this code later to add more code to one of the branches, I won't have to worry about forgetting to surround the code in braces. Our eyes will visually see the indenting as clues to what we're trying to do, but most languages won't. ","pontos":25},{"corpo":"It certainly is possible. All you need to do is register the Mozilla ActiveX control (mozctlx.dll I believe), and you can drag it onto your form as any ActiveX control. The programming interface is similar (though not identical) to the IE one, and you can even use the Microsoft.MSHTML.dll managed library for control in some cases. I believe this is packaged with Firefox. If not, you can get just the embeddable bits from Mozilla as well. Just do a Google search for Mozilla ActiveX control or Mozilla Embedding C# and that should take you down the right path. ","pontos":10},{"corpo":"A stack overflow in real code occurs very rarely. Most situations in which it occurs are recursions where the termination has been forgotten. It might however rarely occur in highly nested structures, e.g. particularly large XML documents. The only real help here is to refactor the code to use an explicit stack object instead of the call stack. ","pontos":5},{"corpo":"Infinite recursion is a common way to get a stack overflow error. To prevent - always make sure there's an exit path that will be hit. :-) Another way to get a stack overflow (in C/C++, at least) is to declare some enormous variable on the stack. char hugeArray[100000000]; That'll do it. ","pontos":3},{"corpo":"Along the same lines as your original example is this string literal comparison trick. If you compare a string reference variable to a string literal you have a chance of throwing a . if(variable.equals(\"literal\")) { // NullPointerExceptionpossible ... } You can avoid that possibility if you flip things around and put the literal first. if(\"literal\".equals(variable)) { // avoids NullPointerException ... } ","pontos":7},{"corpo":"I find it important to make wrong code look wrong to the compiler. In practice (and only when using strongly typed languages), this means omitting any kind of variable prefixes (even Apps Hungarian) in favour of distinct types. To use Joel's example, if there are two distinct types to represent raw strings and sanitized strings, and there's no implicit conversion between the two, then the problem that Apps Hungarian addresses can't even occur. The same goes for the Word document coordinates. In a way, Apps Hungarian is only a workaround for compilers/languages that have no strict enough type checking. ","pontos":29},{"corpo":"After trying to get this stuff to compile under VS 2008, I tried earlier versions of VS - 2005 worked with warnings, and 2003 just worked. I double checked the linkages and couldn't find any problems, so either I just couldn't find it, or that wasn't the problem. So to reiterate, downgrading to VS 2003 fixed it. ","pontos":-2},{"corpo":"I looked into it, and my coworker agrees that a heartbeat page call should work, you just have to make sure that the action invoked does reset the session timer (things like ajax field completion don't do this on their own). ","pontos":1},{"corpo":"That is going to be blazingly fast. Is it causing your system to slow? Is is a huge list? Otherwise, I wouldn't worry. ","pontos":0},{"corpo":"I used Harvest during a short gig in the banking industry a few years ago. I agree that it was practically unusable, but the people in charge of QA seemed to love it. ","pontos":4},{"corpo":"Matz ruby 1.8.6 is much slower when it comes to performance and 1.9 and JRuby do alot to speed it up. But the performance isn't such that it will prevent you from doing anything you want in a web application. There are many large Ruby on Rails sites that do just fine with the \"slower interpreted\" language. When you get to scaling out web apps there are many more pressing performance issues than the speed of the language you are writing it in. ","pontos":2},{"corpo":"You can use the FindAll method of the List, providing a delegate to filter on. Though, I agree with @IainMH that it's not worth worrying yourself too much unless it's a huge list. ","pontos":2},{"corpo":"Check this on MSDN: /MD Causes your application to use the multithread- and DLL-specific version of the run-time library. /MT Causes your application to use the multithread, static version of the run-time library. Note: \"... so that the linker will use LIBCMT.lib to resolve external symbols\" So you'll need a different set of libraries. How I went about finding out which libraries to link: Find a configuration that does link, and add /verbose option. Pipe the output to a text file. Try the configuration that doesn't link. Look in the verbose output from step 2 for the symbols that are unresolved (\"_declspec(dllimport) public: void thiscall std::locale::facet::Register(void)\" in your case) and find the used libraries. Add those libraries to the list of libraries you're linking to. Old skool but it worked for me. Jan ","pontos":2},{"corpo":"As people have been mentioning previously, when you use expression trees parens are not necessary. The order of operations becomes trivial and obvious when you're looking at an expression tree. The parens are hints to the parser. While the accepted answer is the solution to one half of the problem, the other half - actually parsing the expression - is still unsolved. Typically, these sorts of problems can be solved using a recursive descent parser. Writing such a parser is often a fun exercise, but most modern tools for language parsing will abstract that away for you. The parser is also significantly harder if you allow floating point numbers in your string. I had to create a DFA to accept floating point numbers in C -- it was a very painstaking and detailed task. Remember, valid floating points include: 10, 10., 10.123, 9.876e-5, 1.0f, .025, etc. I assume some dispensation from this (in favor of simplicty and brevity) was made in the interview. ","pontos":0},{"corpo":"As indicated by @Gatekiller and others, the correct solution is the label tag. Click-in-the-text is nice, but there is another reason to use the label tag: accessibility. The tools that visually-impaired people use to access the web need the label s to read-out the meaning of checkboxes and radio buttons. Without label s, they have to guess based on surrounding text, and they often get it wrong or have to give up. It is very frustrating to be faced with a form that reads \"Please select your shipping method, radio-button1, radio-button2, radio-button3\". Note that web accessibility is a complex topic; label s are a necessary step but they are not enough to guarantee accessibility or compliance with government regulations where it applies. ","pontos":2},{"corpo":"It's obviously pretty difficult to remotely debug you're unknown application... but here are some things I'd look at: What happens when you only run one of the services at a time? Do you still see the slow-down? This may indicate that there is some contention between the services. Does the problem always occur around the same time, regardless of how long the service has been running? This may indicate that something else (a backup, virus scan, etc) is causing the machine (or db) as a whole to slow down. Do you have logging or some other mechanism to be sure that the service is only doing work as often as you think it should? If you can see the performance degradation over a short time period, try running the service for a while and then attach a profiler to see exactly what is pegging the CPU. You don't mention anything about memory usage. Do you have any of this information for the services? It's possible that your using up most of the RAM and causing the disk the trash, or some similar problem. Best of luck! ","pontos":2},{"corpo":"To the best of my knowledge, Visio can only forward-engineer code from class models. As sequence diagrams only really show paths of communication between objects, I suspect that they do not contain the necessary information, except perhaps in trivial cases, for generating code. Objects with any sort of complex behaviour patterns are likely to involve changing run-time states, of which sequence diagrams aren't really capable of capturing. ","pontos":0},{"corpo":"'Fraid this answer is only going to suggest some directions for you to look in, but having seen similar problems in .NET Windows Services I have a couple of thoughts you might find helpful. My first suggestion is your services might have some bugs in either the way they handle memory, or perhaps in the way they handle unmanaged memory. The last time I tracked down a similar issue it turned out a 3rd party OSS libray we were using stored handles to unmanaged objects in static memory. The longer the service ran the more handles the service picked up which caused the process' CPU performance to nose-dive very quickly. The way to try and resolve this sort of issue to ensure your services store nothing in memory inbetween the timer invocations, although if your 3rd party libraries use static memory you might have to do something clever like create an app domain for the timer invocation and ditch the app doamin (and its static memory) once processing is complete. The other issue I've seen in similar circumstances was with the timer synchronization code being suspect, which in effect allowed more than one thread to be running the processing code at once. When we debugged the code we found the 1st thread was blocking the 2nd, and by the time the 2nd kicked off there was a 3rd being blocked. Over time the blocking was lasting longer and longer and the CPU usage was therefore heading to the top. The solution we used to fix the issue was to implement proper synchronization code so the timer only kicked off another thread if it wouldn't be blocked. Hope this helps, but apologies up front if both my thoughts are red herrings. ","pontos":1},{"corpo":"Have you turned on tracing in your web.config? ","pontos":1},{"corpo":"Although this have been already answered I think it would be a good idea to explain why it is to be expected. A padding scheme is usually applied because most cryptographic filters are not semantically secure and to prevent some forms of cryptoatacks. For example, usually in RSA the OAEP padding scheme is used which prevents some sorts of attacks (such as a chosen plaintext attack or blinding). A padding scheme appends some (usually) random garbage to the message m before the message is sent. In the OAEP method, for example, two Oracles are used (this is a simplistic explanation): Given the size of the modulus you padd k1 bits with 0 and k0 bits with a random number. Then by applying some transformation to the message you obtain the padded message wich is encrypted and sent. That provides you with a randomization for the messages and with a way to test if the message is garbage or not. As the padding scheme is reversible, when you decrypt the message whereas you can't say anything about the integrity of the message itself you can, in fact, make some assertion about the padding and thus you can know if the message has been correctly decrypted or you're doing something wrong (i.e someone has tampered with the message or you're using the wrong key) ","pontos":23},{"corpo":"Sounds like a threading issue with the timer. You might have one unit of work blocking another running on different worker threads, causing them to stack up every time the timer fires. Or you might have instances living and working longer than you expect. I'd suggest refactoring out the timer. Replace it with a single thread that queues up work on the ThreadPool. You can Sleep() the thread to control how often it looks for new work. Make sure this is the only place where your code is multithreaded. All other objects should be instantiated as work is readied for processing and destroyed after that work is completed. STATE IS THE ENEMY in multithreaded code. Another area where the design is lacking appears to be that you have multiple services that are polling resources to do something. I'd suggest unifying them under a single service. They might do seperate things, but they're working in unison; you're just using the filesystem, database, etc as a substitution for method calls. Also, 2003? I feel bad for you. ","pontos":1},{"corpo":"If you are playing in HTML land, try to get validating code - there has been a few times the little red x from the HTML validator plugin has given me a handy shortcut to fix a problem that I hadn't even noticed yet. It may not always be possible to get valid HTML, but it is usually worth aiming for. ","pontos":0},{"corpo":"I found this but apparently these guys had some problems with it. Edit: (It works!) I have now done my own testing and found that it works, I don't know C# so I can't give you a C# answer but I do know PHP and here's the matches array I got back from running it on this: a href=\"pages/index.php\" title=\"the title\" Text /a array(3) { [0]= string(52) \"Text\" [1]= string(15) \"pages/index.php\" [2]= string(4) \"Text\" } ","pontos":1},{"corpo":"As long as there are no nested tags (and no line breaks), the following variant works well: a\\s+href=(?:\"([^\"]+)\"|'([^']+)').*? (.*?) /a As soon as nested tags come into play, regular expressions are unfit for parsing. However, you can still use them by applying more advanced features of modern interpreters (depending on your regex machine). E.g. .NET regular expressions use a stack; I found this: (?: a.*?href=[\"\"'](? url .*?)[\"\"'].*? )(? name (? a[^ ]* (? DEPTH )| /a (? -DEPTH )|.)+)(?(DEPTH)(?!))(?: /a ) Source: http://weblogs.asp.net/scottcate/archive/2004/12/13/281955.aspx ","pontos":6},{"corpo":"You class should implement ILaunchShortcut. Check out the Javadoc. What exception are you getting? Check the error log. ","pontos":0},{"corpo":"A stack overflow occurs when Jeff and Joel want to give the world a better place to get answers to technical questions. It's too late to prevent this stack overflow. That \"other site\" could have prevented it by not being scuzzy. ;) ","pontos":2},{"corpo":"PDO is also very slow and its API is pretty complicated. No one in their sane mind should use it if portability is not a concern. And let's face it, in 99% of all webapps it is not. You just stick with MySQL or PostrgreSQL, or whatever it is you are working with. As for the PHP question and what to take into account. I think premature optimization is the root of all evil. ;) Get your application done first, try to keep it clean when it comes to programming, do a little documentation and write unit tests. With all of the above you will have no issues refactoring code when the time comes. But first you want to be done and push it out to see how people react to it. ","pontos":3},{"corpo":"One other measure of defensive programming is always to use a statement in each code block (i.e. do not let a statement \"fall through\" to the next one). The only exception is if multiple case statements are to be handled identically. switch( myValue ) { case 0: // good... break; case 1: case 2: // good... break; case 3: // oops, no break... SomeCode(); case 4: MoreCode(); // WARNING! This is executed if myValue == 3 break; } There are times when this may be the desired behavior, but from a code-readility standpoint, I would argue it would be better to refactor that \"shared\" code to prevent this ambiguity. ","pontos":3},{"corpo":"I suggest to hack the problem into pieces. First, find a way to reproduce the problem 100% of the times and quickly. Lower the timer so that the services fire up more frequently (for example, 10 times quicker than normal). If the problem arises 10 times quicker, then it's related to the number of iterations and not to real time or to real work done by the services). And you will be able to do the next steps quicker than once a day. Second, comment out all the real work code, and let only the services, the timers and the synchronization mechanism. If the problem still shows up, than it will be in that part of the code. If it doesn't, then start adding back the code you commented out, one piece at a time. Eventually, you should find out what part of the code is causing the problem. ","pontos":2},{"corpo":"For me, the simple swap in Kelly Pohl's A Book on C to demonstrate call-by-reference flipped me out when I first saw it. I looked at that, and pointers snapped into place. Verbatim. . . void swap(int *p, int *q) { int temp; temp = *p; *p = *q; *q = temp; } ","pontos":0},{"corpo":"@Euro Micelli One negative to add is that pointers to the stack are no longer valid when the function returns, so you cannot return a pointer to a stack variable from a function. This is a common error and a major reason why you can't get by with just stack variables. If your function needs to return a pointer, then you have to malloc and deal with memory management. ","pontos":0},{"corpo":"I'd go down the folder list you posted except for the product version. You don't want the settings reset after an update is released. I'm actually moving away from the registry for user settings because of the debug/footprint factor. I'm currently only storing a few basic settings (window size, position, version of a data file) in the registry, and I've run into more problems if an update goes bad or a user loses a second monitor and that is where the application was opening to. A few of them are savvy enough to understand regedit, but for the rest they have to do a reinstall, which is quick, but I think they grumble a bit. With the file based version, all I'd have to do is have them open up an XML file in Notepad and make a quick tweak. In addition, I'm looking to make my application runnable off a USB flash drive, and having the settings tied into the file seems much friendlier to that process. I'm sure I can do some code to check/clean the registry, but I think most of us are already tired of the registry clutter that seems to eat up our machines nowadays. I know there are some security tradeoffs to this, but none of the data I'm sorting is that critical to that cause, and I'm not suffering any performance hits due to the size of the application. ","pontos":0},{"corpo":"@Zack: So, you're saying that rather than using a prefix naming convention to instead create and always use two new classes: SafeString and UnsafeString? Sounds like a much better choice to me. Compile errors are much better than run-time errors. Exactly. Bruce Eckel wrote an essay arguing that static typing is superfluously because, hey, you're writing test cases anyway, right? Wrong. Of course I'm writing test cases but writing good test cases is hard and a lot of work. It's good to take all the help you can get and compile-time type checking is pretty much the best help you can get. Additionally, when using tests, even when using an automated test-on-checkin process, the failed test will be signalled much later than a compile-time error, resulting in delayed error correction. Compilers can give a more direct feedback. That's not to say that I don't see the advantages of interpreted languages I do  but dynamic typing can be a huge disadvantage. I'm actually disappointed that there is no modern interpreted language with static typing, because as Joel shows, this makes writing correct code so much harder and forces us to resort to second-class hacks like Apps Hungarian. ","pontos":7},{"corpo":"My usual approach is to use contract to handle any kind of error due to \"client\" invocation, that is, due to an external error (i.e ArgumentNullException). Every error on the arguments is not handled. An exception is raised and the \"client\" is in charge of handling it. On the other hand, for internal errors always try to correct them (as if you can't get a database connection for some reason) and only if you can't handle it reraise the exception. It's important to keep in mind that most unhandled exception at such level will not be able to be handled by the client anyway so they will just probably go up to the most general exception handler, so if such an exception occurs you are probably FUBAR anyway. ","pontos":1},{"corpo":"For some reason Bubble Sort has always stood out to me. Not because it's elegant or good just because it had/has a goofy name I suppose. ","pontos":0},{"corpo":"@Matt Dillard: One other measure of defensive programming is always to use a break statement in each switch code block (i.e. do not let a case statement \"fall through\" to the next one). The only exception is if multiple case statements are to be handled identically. Sometimes handling case X and case Y means doing almost the same thing, in which case falling through to the next case makes for code that's easier to read. It's a good idea to specifically indicate that with a comment though: switch( type ) { case TypeA: do some stuff specific to type A // FALL THROUGH case TypeB: do some stuff that applies to both A and B break case TypeC: ... } If you use this convention, all case statements should then have a break, a return, a continue or a comment indicating that it's falling through. An empty case without the comment is OK though: case TypeA: case TypeB: // code for both types ","pontos":9},{"corpo":"Just make sure you have 'Disable Script Debugging' unchecked, and just hit F5 to start debugging in VS2005 or 2008. I would also note that if you have your JavaScript inside the .aspx page you will have to find it via the script explore. However if you have it in a separate .js file you can just put a break point on it like you would any .cs file. ","pontos":0},{"corpo":"The initial slowness is a couple things: The appDomain is being setup ASP.NET is parsing and compiling the ASPX pages. Global Contexts are being initialized. This is normal behavior for ASP.NET. ","pontos":0},{"corpo":" I usually use Firebug to deal with debugging JS. Unless you need to debug in IE, there's no need to stop using Firebug. It works with JavaScript in ASP.NET pages just as well as it does with any other type of page. Visual Studio's JavaScript debugging is alright, but really cannot compete with the full range of client-side information that Firebug aggregates. ","pontos":0},{"corpo":"In the no-cost category, newer versions of gzip and bzip2 are supposed to include large file support (someone on the internet tells me that bzip2 1.0.1 and beyond is large file compatible thanks to Cyril Pilsko, while gzip 1.2 can be patched which the dowloadable binaries are, and the gzip 1.3 beta includes support). While I use 7zip on my windows pc for convenience, I tend to prefer bzip2 for speed vs compression. I have also heard of tricking the non-large-file versions by doing something like . Generally you're trading off time with compression level, but one of bzip2's claims is that it uncompresses very quickly, which in a disaster recovery situation should be your most important metric. In that regard, I believe EMC's tape backup solution (ELM?) used to skip compression on DB partitions by default. Also If you're really serious about packing it into a tiny space, you might try something like rzip, but I've never known anyone to actually use it. ","pontos":0},{"corpo":"Avoid nested loops, and avoid indenting code more than a couple of levels. Nested loops or deeply-nested code can generally be refactored by extracting the nested code into a function/method. This usually makes the code easier to reason about. ","pontos":1},{"corpo":"Have you tried calling .SaveOrUpdateCopy()? It should work in all instances, if there is an entity by the same id in the session or if there is no entity at all. This is basically the catch-all method, as it converts a transient object into a persistent one (Save), updates the object if it is existing (Update) or even handles if the entity is a copy of an already existing object (Copy). Failing that, you may have to identify and .Evict() the existing object before Attaching (.Update()) your \"new\" object. This should be easy enough to do: IPersistable entity = Whatever(); // This is the object we're trying to update // (IPersistable has an id field) session.Evict(session.Get(entity.GetType(), entity.Id)); session.SaveOrUpdate(entity); Although the above code could probably do with some null checking for the .Get() call. ","pontos":4},{"corpo":"You should make sure that neither IIS nor any other filter is trying to compress your response. It is very possible that your production server has IIS compression enabled for dynamic pages such as those with the .aspx suffix, and your development server does not. If this is the case, IIS may be waiting for the entire response (or a sizeable chunk) before it attempts to compress and send any result back to the client. I suggest using Fiddler to monitor the response from your production server and figure out if responses are being gzip'd. If response compression does turn out to be the problem, you can instruct IIS to ignore compression for specific responses via the Content-Encoding:Identity header. ","pontos":1},{"corpo":" I've always had problems with OpenGL implementations from Intel This is kind of what I'm worried about, but I have a hard time believing they'd screw up something as basic as glDrawPixels, and also, since I can \"duplicate\" the problem by changing the raster position vector, it makes me think it's my fault and I'm missing something basic. I think you're running into some byte-order issues That was my first inclination, and I've tried packing differently, with no result. I also tried packing the buffer with values that would present a usable alpha if swizzled, with no result. This is why I'm barking up the raster pos tree, but I'm still honestly not 100% sure. Note that I'm targeting only Intel Macs if that makes a difference. Thanks for the link, it was a good read, and good to tuck away for future reference. I'd upmod but I can't until I get 3 more rep points :) ","pontos":1},{"corpo":"Hey, Jason. Sorry you're still having trouble with this. What I would do is set up a simple page like: protected void Page_Load(object sender, EventArgs e) { for (int i = 0; i 10; i++) { Response.Write(i + \" br / \"); Response.Flush(); Thread.Sleep(1000); } } As we discussed before, make sure the .aspx file is empty of any markup other than the @Page declaration. That can sometimes trigger page buffering when it wouldn't have normally happened. Then, point the tech support guys to that file and describe the desired behavior (10 updates, 1 per second). I've found that giving them a simple test case goes a long way toward getting these things resolved. Definitely let us know what it ends up being. I'm guessing some sort of inline caching or reverse proxy, but I'm curious. ","pontos":4},{"corpo":"I'd like to add another vote for the StringFormat object. You can use this simply to specify \"centre, centre\" and the text will be drawn centrally in the rectangle or points provided: StringFormat format = new StringFormat(); format.LineAlignment = StringAlignment.Center; format.Alignment = StringAlignment.Center; However there is one issue with this in CF. If you use Center for both values then it turns TextWrapping off. No idea why this happens, it appears to be a bug with the CF. ","pontos":26},{"corpo":"I used to belong to my local Linux User Group which I co-founded but I treated it more as a social event than anything else but obviously a social event full of geeks is still a great way to get a great debate going :) Conventions and the like I've not got much out of other than being pestered by businesses who can offer me nothing that is apart from a bunch of Linux and Hacker ones where I've met loads of people who I consider friends offline, again great for the social aspect but pretty worthless to me in other respects. That's not to say I never got any business out of attending various events it's just that treating them as social occasions meant any business that did come my way was a bonus so I never left an event feeling like it was a waste of time. ","pontos":0},{"corpo":"The manual seems to suggest that you should still be using to release the memory. I believe the reasoning is that is freeing the memory in MySQL, not in PHP. Since PHP can't garbage-collect for MySQL, you need to call . ","pontos":4},{"corpo":"heh, I was half way through typing this and wondering if it was really that useful, but since Matt and Graeme have both posted answers about this I'll continue. A few days ago while adding a new case to a switch I forgot to end the case with a break. Once I found the error I changed the indentation of my switch statement from: switch(var) { case CONST1: statement; statement; statement; break; case CONST2: statement; statement; statement; case CONST3: statement; statement; break; default: statement; } (which is how guess most people would normally indent) to this: switch(var) { case CONST1: statement; statement; statement; break; case CONST2: statement; statement; statement; case CONST3: statement; statement; break; default: statement; } To make the missing break stand out, and to make me more likely not to forget to add one when I'm adding a new case. (of course you can't do this if your breaking conditionally in more than one place, which I've done on occasion) If I'm only doing something trivial like setting a variable or calling functions from the case statements then I often structure them like this: switch(var) { case CONST1: func1(); break; case CONST2: func2(); break; case CONST3: func3(); break; default: statement; } That makes it super obvious if you miss a break. If your statements aren't the same length add whitespace till the breaks align, along with anything else that makes sense: switch(var) { case CONST1: func1(\"Wibble\", 2); break; case CONST2: longnamedfunc2(\"foo\" , 3); break; case CONST3: variable = 2; break; default: statement; } Although if I'm passing the same parameters to each function I would use a function pointer (the following is actual code from a work project): short (*fnExec) ( long nCmdId , long * pnEnt , short vmhDigitise , short vmhToolpath , int *pcLines , char ***prgszNCCode , map string, double *pmpstrd ) = NULL; switch(nNoun) { case NOUN_PROBE_FEED: fnExec = ExecProbeFeed; break; case NOUN_PROBE_ARC: fnExec = ExecProbeArc; break; case NOUN_PROBE_SURFACE: fnExec = ExecProbeSurface; break; case NOUN_PROBE_WEB_POCKET: fnExec = ExecProbeWebPocket; break; default: ASSERT(FALSE); } nRet = (*fnExec)(nCmdId, nEnt, vmhDigitise, vmhToolpath, cLines, rgszNCCode, mpstrd); ","pontos":7},{"corpo":"You can use to get notified when the property of the combo box changes: BindingUtils.bindSetter(comboBoxDataProviderChanged, comboBox, \"dataProvider\"); lives in the package. I have a longer description of how to work with here: Does painless programmatic data binding exist? ","pontos":0},{"corpo":"So what's the problem with implementing a retry mechanism? There will always be the possibility of a deadlock ocurring so why not have some logic to identify it and just try again? Won't at least some of the other options introduce performance penalties that are taken all the time when a retry system will kick in rarely? Also, don't forget some sort of logging when a retry happens so that you don't get into that situation of rare becoming often. ","pontos":1},{"corpo":"And it's not just the network traffic that is reduced. There is a boost internal to SQL Server because the execution plan can be optimized due to reduction of an extra query to figure out how many rows were affected. ","pontos":7},{"corpo":"I don't think functions can have default values in functions in SS2K. What happens when you run this SQL in SS2K? select val from dbo.fnSplitStringToInt('1,2,3', default) ","pontos":0},{"corpo":"This one might sound trivial but it was a revelation for me at the time. I was in my very first programming class(VB6) and the Prof had just taught us about random numbers and he gave the following instructions: \"Create a virtual lottery machine. Imagine a glass ball full of 100 ping pong balls marked 0 to 99. Pick them randomly and display their number until they have all been selected, no duplicates.\" Everyone else wrote their program like this: Pick a ball, put its number into an \"already selected list\" and then pick another ball. Check to see if its already selected, if so pick another ball, if not put its number on the \"already selected list\" etc.... Of course by the end they were making hundreds of comparisons to find the few balls that had not already been picked. It was like throwing the balls back into the jar after selecting them. My revelation was to throw balls away after picking. I know this sounds mind-numbingly obvious but this was the moment that the \"programming switch\" got flipped in my head. This was the moment that programming went from trying to learn a strange foreign language to trying to figure out an enjoyable puzzle. And once I made that mental connection between programming and fun there was really no stopping me. ","pontos":9},{"corpo":"Beware that Marshal.SizeOf is for unsafe code... I don't think it's possible for managed code though, maybe you can explain your problem, there may be another way to solve it ","pontos":1},{"corpo":"I've used mod_rewrite on sites that get millions/hits/month without any significant performance issues. You do have to know which rewrites get applied first depending on your rules. Using mod_rewrite is most likely faster than parsing the URL with your current language. If you are really worried about performance, don't use htaccess files, those are slow. Put all your rewrite rules in your Apache config, which is only read once on startup. htaccess files get re-parsed on every request, along with every htaccess file in parent folders. ","pontos":31},{"corpo":"Everything that Christian Lescuyer wrote is correct. Notice, however, that he said \"I would\" and not \"you should\". The choice is not that easy. First of all, security is not an issue in the choice. You should have security check on server when you execute an action. Which code decides to show/hide the button that leads to the action is irrelevant. That leaves us with only one drawback of doing show/hide logic in Javascript - the HTML sent to user is bigger than necessary. This may not be a big deal. Having show/hide logic in PHP does have a minus, though. The PHP code required is usually a tag soup. Akira's code provides a good example of how it is usually done. Corresponding Javascript code would probably look something like this: if (logged()) { elementSecretArea.style.display = \"list-item\"; } (assuming that elements that could be hidden have display:none by default). This style also allows nice \"Ajax\" scenario: user sees a page w/o secret area, inputs password, sees the secret area all without refreshing the page. So, if you already have a script that runs when your document load for other reasons, I would seriously consider having show/hide logic there. ","pontos":0},{"corpo":"If you're worried about apache's performance, one thing to consider if you have a lot of rewrite rules is to use the \"skip\" flag. It is a way to skip matching on rules. So, whatever overhead would have been spent on matching is saved. Be careful though, I was on a project which utilized the \"skip\" flag a lot, and it made maintenance painful, since it depends on the order in which things are written in the file. ","pontos":3},{"corpo":" always returns if it compares the same object instance Whereas is ultimately determined by the method i.e. >>> class foo(object): def __eq__(self, other): return True >>> f = foo() >>> f == None True >>> f is None False ","pontos":204},{"corpo":"Aliases are great if you consider that my organization has table names like: SchemaName.DataPointName_SubPoint_Sub-SubPoint_Sub-Sub-SubPoint... My team uses a pretty standard set of abbreviations, so the guesswork is minimized. We'll have say ProgramInformationDataPoint shortened to pidp, and submissions to just sub. The good thing is that once you get going in this manner and people agree with it, it makes those HAYUGE files just a little smaller and easier to manage. At least for me, fewer characters to convey the same info seems to go a little easier on my brain. ","pontos":2},{"corpo":"If you run into problems with Vista and Visual Studio 2003 or 2005, try running it as administrator (Right-click, Run as Administrator). That solves the vast majority of the issues, especially when working with IIS, BizTalk, etc. ","pontos":0},{"corpo":"I have tried HTML Parser which is dead simple. ","pontos":7},{"corpo":"You could change the call to to take branches into account. That shouldn't be to hard. It bit harder would to change the whole function and make the branch your working a variable (argument, session, global or otherwise). ","pontos":0},{"corpo":"For None there shouldn't be a difference between equality (==) and identity (is). The NoneType probably returns identity for equality. Since None is the only instance you can make of NoneType (I think this is true), the two operations are the same. In the case of other types this is not always the case. For example: list1 = [1, 2, 3] list2 = [1, 2, 3] if list1==list2: print \"Equal\" if list1 is list2: print \"Same\" This would print \"Equal\" since lists have a comparison operation that is not the default returning of identity. ","pontos":3},{"corpo":"There is no built-in support for constants in T-SQL. You could use SQLMenace's approach to simulate it (though you can never be sure whether someone else has overwritten the function to return something else), or possibly write a table containing constants, as suggested over here. Perhaps write a trigger that rolls back any changes to the column? ","pontos":7},{"corpo":"I think that you'll probably have to use if you want to change the encoding, see the param below (the and callbacks assume you have and in the html): $.ajax({ type: \"POST\", url: \"SomePage.aspx/GetSomeObjects\", contentType: \"application/json; charset=utf-8\", dataType: \"json\", data: \"{id: '\" + someId + \"'}\", success: function(json) { $(\"#success\").html(\"json.length=\" + json.length); itemAddCallback(json); }, error: function (xhr, textStatus, errorThrown) { $(\"#error\").html(xhr.responseText); } }); I actually just had to do this about an hour ago, what a coincidence! ","pontos":27},{"corpo":"If anyone else is having this problem, I have found the cause of this exception. ListObjects will automatically re-size on binding, as long as they do not affect any other objects on the sheet. Keep in mind that ListObjects can only affect the Ranges which they wrap around. In my case, the list object which was above the other one had fewer columns than the one below it. Let's say the top ListObject had 2 columns, and the bottom ListObject had 3 columns. When the top ListObject changed its number of rows, it had no ability to make any changes to the third column since it wasn't in it's underlying Range. This means that it couldn't shift any cells in the third column, and so the second ListObject couldn't be properly moved, resulting in my exception above. Changing the positions of the ListObjects to place the wider one above the smaller one works fine. Following the logic above, this now means that the wider ListObject can shift all of the columns of the second ListObject, and since there is nothing below the smaller one it can also shift any cells necessary. The reason I wasn't having any trouble on the initial binding is that both ListObjects were a single cell. Since this is not optimal in my case, I will probably use empty columns or try to play around with invisible columns if that's possible, but at least the cause is now clear. ","pontos":4},{"corpo":"@Herms The listener is definitely added before the web service call, here is an example of what my code look like (I simplified lots of things...): I have this flex component: public class FooComboBox extends ComboBox { private var service:HTTPService = null; public function ProjectAutoComplete() { service = new HTTPService(); service.url = Application.application.poxmlUrl; service.addEventListener(FaultEvent.FAULT,serviceFault); service.addEventListener(ResultEvent.RESULT,resultReturned); this.addEventListener(FlexEvent.DATA_CHANGE,dataChange); } public function init():void { var postdata:Object = {}; postdata[\"key\"] = \"ProjectName\"; postdata[\"accountId\"] = Application.application.accountId service.send(postdata); } private function resultReturned(event:ResultEvent):void { this.dataProvider = service.lastResult.Array.Element; // thought I could do it here...but no luck... } private function dataChange(e:FlexEvent):void { // combobox has been databound mx.controls.Alert.show(\"databound!\"); } ... } and then in a mxml file I have the FooComboBox with id \"foo\" and I call: foo.init(); I need to execute some code after the combobox is completely databound...any ideas? ","pontos":0},{"corpo":"What if you used a combination of the captcha ideas you had (choose any of them - or select one of them randomly): ASCII text captcha: \\/\\/(_)\\/\\/ math puzzles: what is 7 minus 3 times 2? trivia questions: what tastes better, a toad or a popsicle? with the addition of placing the exact same captcha in a css hidden section of the page - the honeypot idea. That way, you'd have one place where you'd expect the correct answer and another where the answer should be unchanged. ","pontos":5},{"corpo":"One solution, which is a hack of limited usefulness, is when a drag is initiated, store the dragged data in a global or static reference somewhere. This way, in the OnEnter and OnDragOver handlers, it is possible to get a reference to the data being dragged. This is of course only useful for drags within the same application (the same instance of the application, actually). ","pontos":1},{"corpo":"I've been working on a similar script here: http://github.com/ghewgill/vim-scmdiff (in fact, they may have the same ancestry). I haven't used scmdiff with cvs, but it should do a diff against the branch you have checked out. You can also specify that you want to diff against a particular revision (with :D revision). Hopefully this helps, and feel free to contribute if you've got improvements! ","pontos":3},{"corpo":"AFAIK, you need to restart IIS for it to get a fresh reference to the updated DLL. Your best bet is to perform the reset at a low traffic time. If you are running multiple servers with load balancing, you can prevent new connections from hitting one server until all connections have been closed. Afterwards, update the DLL, restart IIS, and bring the server back into the connection pool. Repeat for each server with no visible downtime to the end users. ","pontos":3},{"corpo":"The apparent randomness of the memory corruption sounds very much like a thread synchronization issue - a bug is reproduced depending on machine speed. If objects (chuncks of memory) are shared among threads and synchronization (critical section, mutex, semaphore, other) primitives are not on per-class (per-object, per-class) basis, then it is possible to come to a situation where class (chunk of memory) is deleted / freed while in use, or used after deleted / freed. As a test for that, you could add synchronization primitives to each class and method. This will make your code slower because many objects will have to wait for each other, but if this eliminates the heap corruption, your heap-corruption problem will become a code optimization one. ","pontos":1},{"corpo":"Actually it could be an idea to have a programming related captcha set. For example: There is the possibility of someone building a syntax checker to bypass this but it's a lot more work to bypass a captcha. You get the idea of having a related captcha though. ","pontos":5},{"corpo":"To echo what Ryan says above, rules in a htaccess can really hurt your load times on a busy site in comparison to having the rules in your config file. We initially tried this (~60million pages/month) but didn't last very long until our servers started smoking :) The obvious downside to having the rules in your config is you have to reload the config whenever you modify your rules. The last flag (\"L\") is useful for speeding up execution of your rules, once your more frequently-accessed rules are towards the top and assessed first. It can make maintenance much trickier if you've a long set of rules though - I wasted a couple of very frustrating hours one morning as I was editing mid-way down my list of rules and had one up the top that was trapping more than intended! We had difficulty finding relevant benchmarks also, and ended up working out our own internal suite of tests. Once we got our rules sorted out, properly ordered and into our Apache conf, we didn't find much of a negative performance impact. ","pontos":6},{"corpo":"Are TimeSpan.Parse and TimeSpan.TryParse not options? If you aren't using an \"approved\" format, you'll need to do the parsing manually. I'd probably capture your two integer values in a regular expression, and then try to parse them into integers, from there you can create a new TimeSpan with its constructor. ","pontos":1},{"corpo":"I have experience using a Perforce derivative. It seemed hard to manage from the admin's perspective, but it was fine to use from a programmer's perspective. Then again, I'm big on command line version control so can't speak for VS integration. ","pontos":0},{"corpo":"If your controls are inside a panel, try setting the AutoScroll property of the Panel to False. This will hide the scrollbars. I hope this points you in the right direction. myPanel.AutoScroll = False ","pontos":0},{"corpo":" All important files are in version control (Subversion) My subversion layout generally matches the file layout on my web server so I can just do a checkout and all of my library files and things are in the correct places. Twice-daily backups to an external hard drive Nightly rsync backups to a remote server. This means that I send stuff on my home server over to my webhost and all files databases on my webhost back home so I'm not screwed if I lose either my house or my webhost. ","pontos":10},{"corpo":"If you are talking absolute least amount of restore time... I've often setup machines to do Ghost (Symantec or something similar) backups on a nightly basis to either an image or just a direct copy to another drive. That way all you have to do is reimage the machine from the image or just swap the drives. You can be back up in under 10 minutes... The setup I did before was in situation where we had some production servers that were redundant and it was acceptable for them to be offline long enough to clone the drive...but only at night. During the day they had to be up 100%...it saved my butt a couple times when a main drive failed... I just opened the case, swapped the cables so the backup drive was the new master and was back online in 5 minutes. ","pontos":1},{"corpo":"I tend to use HttpContext.Current to get the page, then run any page/web control methods off that. ","pontos":3},{"corpo":"I use Mozy, and rarely think about it. That's one weight off my shoulders that I won't ever miss. ","pontos":6},{"corpo":"Yes, they will. However, if you are using unmanaged resources in those threads, you may end up in a lot of trouble. ","pontos":2},{"corpo":"Maybe just a simple hardware hard disk raid would be a good start. This way if one drive fails, you still have the other drive in the raid. If something other than the drives fail you can pop these drives into another system and get your files quickly. ","pontos":0},{"corpo":"I've taken to building my own 'helpers' (e.g. template compiler) as I use them. I have used Zend before but felt it was too large for my requirements. I used to spend a lot of time making a worthwhile DAL but I don't even need that anymore. At the moment most of my helper classes are datamanager or file parsers - most of what I use is built into PHP. ","pontos":1},{"corpo":"I think there's probably a bug somewhere in your composition of sec and usec. I can't really say what exactly without knowing the kinds of errors you're seeing. A rough guess would be that usec can never be > 999999, so you're relying on overflow to know when to adjust sec. It could also just be a problem with your duration output format. Anyway. Why not store the utime and stime components as float seconds rather than trying to build your own rusage on output? I'm pretty sure the following will give you proper seconds. static int timeval_diff_ms(timeval const end, timeval const start) { int micro_seconds = (end.tv_sec - start.tv_sec) * 1000000 + end.tv_usec - start.tv_usec; return micro_seconds; } static float timeval_diff(timeval const end, timeval const start) { return (timeval_diff_ms(end, start)/1000000.0f); } If you want to decompose this back into an rusage, you can always int-div and modulo. ","pontos":2},{"corpo":"You don't need to abort them. When your application exits, .NET will kill any threads with IsBackground = true. The .NET threadpool has all its threads set to IsBackground = true, so you don't have to worry about it. Now if you're creating threads by newing up the Thread class, then you'll either need to abort them or set their IsBackground property to true. ","pontos":14},{"corpo":"I have done a bit of SharePoint development, and I must tell you that messing with the 12-hive is a ticket to a world of pain if you ever want to move the app. I'd rather hack up some javascript to hide it, at least that can be bound to the master page, which is much more portable. And remember, you never know when the next service pack comes around and nukes your changes :) ","pontos":2},{"corpo":"The threadpool uses background threads. Hence, they will all be closed automatically when the application exits. If you want to abort a thread yourself, you'll have to either manage the thread yourself (so you can call Thread.Abort() on the thread object) or you will have to set up some form of notification mechanism which will let you tell the thread that it should abort itself. ","pontos":2},{"corpo":"Have you tried this? In Visual Studio go to Tools > Import and Export Settings > Reset all settings ","pontos":84},{"corpo":"For my home and development machines I use Acronis True Image. In my opinion, with the HD cheap prices nothing replaces a full incremental daily HD backup. ","pontos":2},{"corpo":"Separation of concerns is the biggy. Being able to tease these components apart makes the code easier to re-use and independently test. If you don't actually know what MVC is, be careful about trying to understand people's opinions as there is still some contention about what the \"Model\" is (whether it is the business objects/DataSets/DataTables or if it represents the underlying service layer). I've seen all sorts of implementations that call themselves MVC but aren't exactly and as the comments in Jeff's article show MVC is a contentious point that I don't think developers will ever fully agree upon. A good round up of all of the different MVC types is available here. ","pontos":9},{"corpo":" Are screen readers really so primitive that they would read text that isn't even displayed on the screen? What you have to remember is that any HTML parser doesn't read the screen - it reads the source markup. Whta you see on the screen is the browser's attempt to apply CSS to the source code. It's irrelevant. You could probably even identify parts of the page that are menus or table of contents, and give some sort of easy way for those parts to be read exclusively or skipped over. You could, if there were a standard for such a thing. I'm not very hot on the limitations of screen readers, however I've read a lot about them not being ideal. The best thing I can reccommend is to put your source in order - how you'd read it. There are a set of CSS properties you should also look at for screen readers. ","pontos":3},{"corpo":" Using Subversion Subversion isn't distributed, so that makes me think I need a wikipedia link in case people aren't sure what I'm talking about :) ","pontos":0},{"corpo":"I don't think there's any difference. Certainly resharper says the first line has redundant code. ","pontos":2},{"corpo":"Perhaps I got the wrong end of the stick but wouldn't, work? IIRC Perl text processing is pretty quick. @lennysan Ah sure yes of course. Sorry I can't help, my Perl is pretty rusty. ","pontos":0},{"corpo":"I think the one way to really tell would be to look at the MSIL produced for the code.. Tends to be a good acid test.. I have funny concerns that it may somehow mess with GC.. Seems odd that there would be all the overhead of declaring the new delegate type if it never needed to be done this way, you know? ","pontos":-1},{"corpo":"There are lots of ways to obscure a password: you could store the credentials in rot13 format, or BASE64, or use the same password-scrambling algorithm that CVS uses. The real trick though is making your applications aware of the scrambling algorithm. For the environment variables in you could store them encoded and then decode them before setting the variables, e.g.: encodedcreds=\"sbbone:cnffjbeq\" creds=`echo \"$encodedcreds\" | tr n-za-mN-ZA-M a-zA-Z` That will set to , which you can then embed in etc. I assume you know this, but it bears repeating: this doesn't add any security. It just protects against inadvertently seeing another user's password. ","pontos":2},{"corpo":"Not using distributed source control myself, but maybe these related questions and answers give you some insights: Distributed source control options Why is git better than Subversion ","pontos":4},{"corpo":"Editra may be worth a look, the code colouring isn't bad, and I believe it has plugins to enable script execution.. Although I have not used this myself. ","pontos":1},{"corpo":"Have you tried to modify the Request.QueryString[] on the SelectedIndexChanged for the DropDown? That should do the trick. ","pontos":0},{"corpo":"I don't think so. You also can't use an abstract class for this. ","pontos":0},{"corpo":"I am sorry I do not have time to trouble-shoot your code, so this is from the hip. There is a good chance that this a client-side action that is failing. Make certain that your page has the correct doctype tag if you took it out of your page or masterPage. Furthermore, attempt to set the ClientState as well: DDE.ClientState = true; The issue is you have that thing wrapped inside of your TemplateField. I have ran into issues using the AjaxControlToolkit on repeated fields and usually side with using a lighter weight client-side option, up to and including rolling your own show/hide method that can be reused just by passing in an DOM understood id. ","pontos":3},{"corpo":"Wasn't the require until C#2003, and you were allowed to omit the redundant code in C#2005? ","pontos":0},{"corpo":"Step in to Xcode may be the book you're looking for. It's got a whole section devoted to using AppleScript to automate configuration includes. I've been going through the book myself on O'Reilly Safari as I've found myself in a situation similar to yourself! ","pontos":3},{"corpo":"I don't. We do continuous integration, submit code often to the central source control system (which is backed up like crazy!). If my machine dies at most I've lost a couple of days work. And all I need to do is get a clean disk at setup the dev environment from a ghost image or by spending a day sticking CDs in, rebooting after Windows update, etc. Not a pleasant day but I do get a nice clean machine. ","pontos":0},{"corpo":"One of two ways. If you're already using an MSBuild file or something similar, add the action to the MSBuild file. Instead of directly executing some command, create a batch file that executes that command and then deletes the directory, and have CCnet call that batch file instead. ","pontos":3},{"corpo":"You need to turn off autopostback on the dropdown - then, you need to hook up some javascript code that will take over that role - in the event handler code for the onchange event for the dropdown, you would create a URL based on the currently-selected value from the dropdown and use javascript to then request that page. EDIT: Here is some quick and dirty code that is indicative of what would do the trick: script function changeReport(dropDownList) { var selectedReport = dropDownList.options[dropDownList.selectedIndex]; window.location = (\"scratch.htm?SelectedReport=\" + selectedReport.value); } /script select id=\"SelectedReport\" onchange=\"changeReport(this)\" option value=\"foo\" foo /option option value=\"bar\" bar /option option value=\"baz\" baz /option /select Obviously you would need to do a bit more, but this does work and would give you what it seems you are after. I would recommend using a JavaScript toolkit (I use MochiKit, but it isn't for everyone) to get some of the harder work done - use unobtrusive JavaScript techniques if at all possible (unlike what I use in this example). @Ray: You use ViewState?! I'm so sorry. :P Why, in this instance, do you need to preserve it. pray tell? ","pontos":3},{"corpo":"Sorry but the selected answer here is incorrect. As a few people have stated subsequently Dispose and implementing IDisposable has nothing to do with freeing the memory associated with a .NET class. It is mainly and traditionally used to free unmanaged resources such as file handles etc. While your application can call GC.Collect() to try to force a collection by the garbage collector this will only really have an effect on those items that are at the correct generation level in the freachable queue. So it is possible that if you have cleared all references to the object it might still be a couple of calls to GC.Collect() before the actual memory is freed. You don't say in your question WHY you feel the need to free up memory immediately. I understand that sometimes there can be unusual circumstances but seriously, in managed code it is almost always best to let the runtime deal with memory management. Probably the best advice if you think your code is using up memory quicker than the GC is freeing it then you should review your code to ensure that no objects that are no longer needed are referenced in any data structures you have lying around in static members etc. Also try to avoid situations where you have circular object references as it is possible that these may not be freed either. ","pontos":1},{"corpo":"Back in my Mac LC days I swore by Monaco 9pt, mostly for it's slashed 0. I never quite got used to the default line-height though. It's a little hard to track down in the original non-OS-X version. ","pontos":4},{"corpo":" can take a remote URL and give you the source. You can then use regular expressions (with the Perl-compatible functions) to grab what you need. Out of curiosity, what are you trying to scrape? ","pontos":0},{"corpo":"A common Python saying is that it's easier to ask forgiveness than permission. While I'm not a fan of this statement in real life, it does apply in a lot of cases. Usually you want to avoid code that chains two system calls on the same file, because you never know what will happen to the file in between your two calls in your code. A typical mistake is to write something like: if os.path.exists(path): os.unlink(path) The second call (os.unlink) may fail if something else deleted it after your if test, raise an Exception, and stop the rest of your function from executing. (You might think this doesn't happen in real life, but we just fished another bug like that out of our codebase last week - and it was the kind of bug that left a few programmers scratching their head and claiming 'Heisenbug' for the last few months) So, in your particular case, I would probably do: try: os.stat(path) except OSError, e: if e.errno == errno.ENOENT: print 'path %s does not exist or is a broken symlink' % path else: raise e The annoyance here is that stat returns the same error code for a symlink that just isn't there and a broken symlink. So, I guess you have no choice than to break the atomicity, and do something like if not os.path.exists(os.readlink(path)): print 'path %s is a broken symlink' % path ","pontos":17},{"corpo":"Here's an OK tutorial (link removed, see below) on web scraping using and . Besure to read the next few parts as well. (direct hyperlink removed due to malware warnings) ","pontos":5},{"corpo":"@Jason: I recommend using something more along the lines of if foo: #foo isn't None else: #foo is None I don't like using \"if foo:\" unless foo truly represents a boolean value (i.e. 0 or 1). If foo is a string or an object or something else, \"if foo:\" may work, but it looks like a lazy shortcut to me. If you're checking to see if x is None, say \"if x is None:\". ","pontos":4},{"corpo":"I am really struggling with this too. One thing that I realised is that if I do not make myself available at all times to the team, then bad code starts to get written and technical debt accumulates. I've therefore taken an active decision to write less code myself and spend more time helping out my teammates and reviewing their code. ","pontos":5},{"corpo":"At my workplace we switched to Git from CVS about two months ago (the majority of my experience is with Subversion). While there was a learning curve involved in becoming familiar with the distributed system, I've found Git to be superior in two key areas: flexibility of working environment and merging. I don't have to be on our VPN, or even have network connectivity at all, to have access to full versioning capabilities. This means I can experiment with ideas or perform large refactorings wherever I happen to be when the urge strikes, without having to remember to check in that huge commit I've built up or worrying about being unable to revert when I make a mess. Because merges are performed client-side, they are much faster and less error-prone than initiating a server-side merge. ","pontos":5},{"corpo":"Brendan, I should have clarified that I can't guarantee what the relative path is going to look like. It could be pretty tricky (e.g. has a slash at the front, doesn't have a slash, has \"../\", etc). Peter, that's what I'm using now. Or is that faster then using the URI::URL->new($path)->abs? ","pontos":1},{"corpo":"My best guess based on what you've written is that you're wrapping that URL in double quotes. The position 0 in that error message probably refers to the character directly before http ","pontos":0},{"corpo":"I use version control a lot for common files, because I have one laptop, a desktop machine at work and a home desktop on which I do a lot of work too (I work from home two days a week). A new session at any of them starts with a script called 'start' that updates a bunch of checkouts, and ends with a script called 'stop' that commits some things to VCS, or shows me at least the modifications. I use it for: my one-file Getting Things Done task list (see yagtd, the tool I use) my password database (I should have sent in that suggestion to the StackOverflow podcast in reply to Joel's question) all of my random notes and files on projects a bunch of spreadsheets (including one that tracks some personal things day by day) some images (like the web avatars I use) In addition, I've written something on top of Subversion to manage configuration files for both systems and my user accounts. I have so many accounts on so many machines, and I was tired of always relearning how to configure my shell/vim/... so I now store most of those things in version control too. That includes email signature files, a bunch of shell scripts in $HOME/bin, ... ","pontos":2},{"corpo":"I did attempt to use SWIG to wrap a project C++ for using in .NET a few years ago. I didn't get very far as it was a massive giant pain to produce the configuration that SWIG required. At the time I just wanted a solution, not to learn another language/api/etc. SWIG may be easier to use these days, I couldn't tell you. We ended up using Managed C++ to wrap the C++ project. It worked really well. If you're just invoking functions straight out of a dll, I'd suggest not worrying about either of the above, and just using P/Invoke ","pontos":3},{"corpo":"We check the following with our hook scripts: That a commit log message has been supplied That a reviewer has been specified for the commit That no automatically generated code or banned file types land up in the repository Send an email out when a branch / tag is created We still want to implement the following: Send an email when a user acquires a lock on a file Send an email when your lock has been stolen Send an email to everyone when a revision property has been changed ","pontos":0},{"corpo":"Rewrite your code in a passing style! Seriously, an old code base will have hundreds of errors - but that's why we have novice/intern programmers. Correcting FxCop violations is a great way to get an overview of the code base and also learn how to write conforming .NET code. So just bite the bullet, drink lots of caffeine, and just get through it in a couple days! ","pontos":2},{"corpo":"There are several reasons why doing it this way is not a good idea. A lot of them have been mentioned, so I'll just stick with one specific point. Command-line tools are usually not interactive at all, while GUI's are. This is a fundamental difference. This is for example painful for long-running tasks. Your command-line tool will at best print out some kind of progress information - newlines, a textual progress bar, a bunch of output, ... Any kind of error it can only output to the console. Now you want to slap a GUI on top of that, what do you do ? Parse the output of your long-running command line tool ? Scan for WARNING and ERROR in that output to throw up a dialog box ? At best, most UI's built this way throw up a pulsating busy bar for as long as the command runs, then show you a success or failure dialog when the command exits. Sadly, this is how a lot of UNIX GUI programs are thrown together, making it a terrible user experience. Most repliers here are correct in saying that you should probably abstract the actual functionality of your program into a library, then write a command-line interface and the GUI at the same time for it. All your business logic should be in your library, and either UI (yes, a command line is a UI) should only do whatever is necessary to interface between your business logic and your UI. A command line is too poor a UI to make sure you develop your library good enough for GUI use later. You should start with both from the get-go, or start with the GUI programming. It's easy to add a command line interface to a library developed for a GUI, but it's a lot harder the other way around, precisely because of all the interactive features the GUI will need (reporting, progress, error dialogs, i18n, ...) ","pontos":0},{"corpo":"If you want to use $.getJSON() you can add the following before the call : $.ajaxSetup({ scriptCharset: \"utf-8\" , contentType: \"application/json; charset=utf-8\"}); You can use the charset you want instead of utf-8. The options are explained here. contentType : When sending data to the server, use this content-type. Default is \"application/x-www-form-urlencoded\", which is fine for most cases. scriptCharset : Only for requests with 'jsonp' or 'script' dataType and GET type. Forces the request to be interpreted as a certain charset. Only needed for charset differences between the remote and local content. You may need one or both ... ","pontos":34},{"corpo":"A little offtopic : You could instantiate a delegate and (if appropriate) reuse that instance. ","pontos":2},{"corpo":"You have to get the Visio that for users of Visual Studio. See this link: Visio for Enterprise Architects for more details. The code generation capabilities are fairly weak and you might end up getting Visio into an inconsistent state. I know that Visio will let you forward and reverse engineer both code and databases, but both capabilities are very limited and I don't recommend doing it. In my opinion, Visio is a diagramming tool and it should be treated as such. ","pontos":1},{"corpo":"Ditch all API's and use a serial port API directly. Talk the printers language and you can get decent results. Every other approach leads to frustration. Not so pretty, but that is the way my old factory worked. 4k print jobs per day, and none ever missed. ","pontos":0},{"corpo":"You might be better off using wildcards. For instance, if you want to find all ksh scripts in the current directory: $ ls *.ksh ","pontos":3},{"corpo":"Recommended listening: Hanselminutes It's an interview with a blind programmer. ","pontos":2},{"corpo":"If you guys are still coding for IE6, you're making a mistake. I use IE7.js to get IE6 to render pages like IE7. IE7 is not perfect, but at least it has some semblance of standards. Since I only have to code for IE7 and FF it makes me 33% more efficient in terms of testing against browsers, something I think makes good business sense. Link: IE7.js ","pontos":2},{"corpo":"I believe svn's merging has been somewhat overhauled in the latest release. ","pontos":0},{"corpo":"Stack A stack, in this context, is the last in, first out buffer you place data while your program runs. Last in, first out (LIFO) means that the last thing you put in is always the first thing you get back out - if you push 2 items on the stack, 'A' and then 'B', then the first thing you pop off the stack will be 'B', and the next thing is 'A'. When you call a function in your code, the next instruction after the function call is stored on the stack, and any storage space that might be overwritten by the function call. The function you call might use up more stack for its own local variables. When it's done, it frees up the local variable stack space it used, then returns to the previous function. Stack overflow A stack overflow is when you've used up more memory for the stack than your program was supposed to use. In embedded systems you might only have 256 bytes for the stack, and if each function takes up 32 bytes then you can only have function calls 8 deep - function 1 calls function 2 who calls function 3 who calls function 4 .... who calls function 8 who calls function 9, but function 9 overwrites memory outside the stack. This might overwrite memory, code, etc. Many programmers make this mistake by calling function A that then calls function B, that then calls function C, that then calls function A. It might work most of the time, but just once the wrong input will cause it to go in that circle forever until the computer recognizes that the stack is overblown. Recursive functions are also a cause for this, but if you're writing recursively (ie, your function calls itself) then you need to be aware of this and use static/global variables to prevent infinite recursion. Generally, the OS and the programming language you're using manage the stack, and it's out of your hands. You should look at your call graph (a tree structure that shows from your main what each function calls) to see how deep your function calls go, and to detect cycles and recursion that are not intended. Intentional cycles and recursion need to be artificially checked to error out if they call each other too many times. Beyond good programming practices, static and dynamic testing, there's not much you can do on these high level systems. Embedded systems In the embedded world, especially in high reliability code (automotive, aircraft, space) you do extensive code reviews and checking, but you also do the following: Disallow recursion and cycles - enforced by policy and testing Keep code and stack far apart (code in flash, stack in RAM, and never the twain shall meet) Place guard bands around the stack - empty area of memory that you fill with a magic number (usually a software interrupt instruction, but there are many options here), and hundreds or thousands of times a second you look at the guard bands to make sure they haven't been overwritten. Use memory protection (ie, no execute on the stack, no read or write just outside the stack) Interrupts don't call secondary functions - they set flags, copy data, and let the application take care of processing it (otherwise you might get 8 deep in your function call tree, have an interrupt, and then go out another few functions inside the interrupt, causing the blowout). You have several call trees - one for the main processes, and one for each interrupt. If your interrupts can interrupt each other... well, there be dragons... High-level languages and systems But in high level languages run on operating systems: Reduce your local variable storage (local variables are stored on the stack - although compilers are pretty smart about this and will sometimes put big locals on the heap if your call tree is shallow) Avoid or strictly limit recursion Don't break your programs up too far into smaller and smaller functions - even without counting local variables each function call consumes as much as 64 bytes on the stack (32 bit processor, saving half the CPU registers, flags, etc) Keep your call tree shallow (similar to the above statement) Web servers It depends on the 'sandbox' you have whether you can control or even see the stack. Chances are good you can treat web servers as you would any other high level language and operating system - it's largely out of your hands, but check the language and server stack you're using. It is possible to blow the stack on your SQL server, for instance. ","pontos":26},{"corpo":"Nick, while I agree that the problem is 'not sharing your work', the main argument is that tools promote a certain work flow and not all tools apply to all problems with equal friction. My concern is that a DVCS makes it easier to not share your work since you don't have the drawbacks of not sharing your work you get with SVN. If the friction of not sharing is lower than the friction of not sharing (which it is in DVCS), a developer, all else being equal, might easily choose the path of least friction. I don't think I'm confused about distributed source control. I know that there is no 'central location' by default. But most projects using DVCS still have the concept of a 'master' branch at a 'central location' that they release from. For the purpose of my question though, I only make the distinction between 'private' (only accessible by the developer) and 'public' (accessible by all other developers) branches. ","pontos":2},{"corpo":"@robertmyers CSS contains the aural media type specifically to control the \"rendering\" of things when screen readers are doing their work. So, for you example, you would only set it as visible for the aural media type. @Ross I'm quite aware that the screen reader doesn't actually read the screen, but you would think that to work well, it would have to build a model of what a person with sight would see, otherwise, it seems like it would do a really poor job of getting across to the user what's actually on the page. Also , putting things in the order you would read them doesn't really work, as a sighted person would scan the page quickly and read the section they want to read. Do you put the contents first so that the user has to listen to them every time, or do you put them at the end so that they can get to the content first? Also, putting content in order would mean some tricky CSS to get things positioned where you wanted them to be for sighted users. It seems to me that most web pages contain very similar construction, and that it should be possible to, in many cases, pick out where the repeated headers and side columns are. When viewing many subsequent pages on the same site with the same formatting, it should be easy to figure out which sections are navigation, and which are content. Doing this, the screen reader could completely skip the navigation sections, and move right onto the content, as most sighted users would do. I realize there are limitations, and that doing these types of things wouldn't be easy. However, I feel like as far as screen readers go, we only did the bare minimum and left it at that. ","pontos":0},{"corpo":"At work NetBackup or PureDisk depending on the box, at home rsync. ","pontos":0},{"corpo":"Ok, I disabled anon authentication and enabled Forms Authentication in IIS. Now the whole site (including Login.aspx itself) is blocked, even though only one folder should be. Thanks for everyone's help so far! EDIT: I've got it so that it only blocks access on the right folder, but it still won't accept my credentials. ","pontos":0},{"corpo":"The yellow screen of death is served by the default ASP.NET HTTPHandler. In order to intercept it, you would need to add another HTTPHandler in front of it that intercepts all uncaught exceptions. At that point, you could do whatever you want for your error layout. Creating a way to directly jump to Visual Studio would be tricky. I could see it done in IE via a COM/ActiveX object. ","pontos":0},{"corpo":"I agree with Lars. Sometimes you will not be able to avoid it, depending on your needs. But, in general the best policy is to avoid modification if at all possible. I know that some of the other menu items in the current user menu (change login, my settings, etc) can be changed by removing permissions from the user. Under Users and Groups there is an option for permissions. I can't remember the exact setting (develop at work, not at home), but there are reasonable descriptions next to each of the 30+ permissions. Remove it and you start hiding menu options. No modifications to the 12-hive needed. ","pontos":1},{"corpo":"The yellow screen of death is just a 500 error as far as the server is concerned, you can redirect to a custom screen using the error section of the web.config. To make a whole server change in the same manner you could probably override it at the iis level? Or perhaps even set the default behaviour in the machine.config file (not 100% sure about that one though) ","pontos":0},{"corpo":" The yellow screen of death is just a 500 error as far as the server is concerned, you can redirect to a custom screen using the error section of the web.config. To make a whole server change in the same manner you could probably override it at the iis level? Or perhaps even set the default behaviour in the machine.config file (not 100% sure about that one though) If you let it bubble up all the way to IIS you will not have any way to access the Exception information. Its better to catch the Exception before the YSOD and serve your own. This can be done at the application level. ","pontos":0},{"corpo":"Sorry I can't give you more useful info, but as far as mono goes, I think everything should work just the same as it does on a desktop pc. As long as mono is compiled for the ps3, that is. Also, I've also noticed the lack of documentation on many of the google code projects. I wonder if there is a good way to go about fixing that ","pontos":-1},{"corpo":"It sounds like you need to allow anonymous users. Can you connect from other machines on your network? Try changing your virtual directory's authentication settings, so that anonymous users are allowed (MyVirtualDir > Properties > Authentication, I think). Apologies for vague answer. I'm working from memory, because I'm currently using IIS 7. ","pontos":1},{"corpo":"Controllers don't have to map to specific models or views. Your model doesn't have to map one-to-one to a database table. That's sort of the idea of the framework. Seperation of concerns that can all be tested in isolation. ","pontos":1},{"corpo":"Instead of using a std::string, you could use a std::wstring. EDIT: Sorry this is not more explanatory, but I have to run. Use std::wstring::c_str() ","pontos":5},{"corpo":"Don't forget that you need the Program Debug Database (pdb) file to find the source code line number. An application in release mode won't have the same level of information as a debug release. ","pontos":0},{"corpo":"It depends on whether the code that catches the exception needs to differentiate between exceptions or whether you are just using exceptions to fail out to an error page. If you need to differentiate between a NullReference exception and your custom MailException higher up in the call stack, then spend the time and write it. But most of the time programmers just use exceptions as a catch all to throw up an error on the web page. In this case you are just wasting effort on writing a new exception. ","pontos":0},{"corpo":"SimplePie is a PHP library that supports merging RSS feeds into one combined feed. I don't believe it does dupe checking out-of-the-box, but I found it trivial to write a little function to eliminate duplicate content via their GUIDs. ","pontos":1},{"corpo":"I got in the habit of using it liberally in Visual C++ since doing so would trigger IntelliSense ones I hit the '>' key, and I'm lazy. (and prone to typos) But I've continued to use it, since I find it handy to see that I'm calling a member function rather than a global function. ","pontos":2},{"corpo":"I think a combination of the above is going to give you the best result. You can throw different exceptions depending on the problem. e.g. Missing email address = ArgumentException. But then in the UI layer you can check the exception type and, if need be, the message and then display a appropriate message to the user. I personally tend to only show a informational message to the user if a certain type of exception is thrown (UserException in my app). Of course you should scrub and verify user input as much as possible further up the stack to make sure any exceptions are generated by truly unlikely scenarios, not as a filter for malformed emails which can easily be checked with a regex. I also wouldn't worry about the performance implications of catching an exception from user input. The only time you are going to see performance problems from exceptions is when they are being thrown and caught in a loop or similar. ","pontos":1},{"corpo":"PDFminer gave me perhaps one line [page 1 of 7...] on every page of a pdf file I tried with it. The best answer I have so far is pdftoipe, or the c++ code it's based on Xpdf. see my question for what the output of pdftoipe looks like. ","pontos":0},{"corpo":"I don't know that there's a good answer to this one other than \"apply your judgement, based on your experience.\" Failing that, get help, which I guess is what you're doing here ;) Seriously, though, if you find that you're creating a gazillion classes to do what seems like a simple job, then you're probably being too granular. If your classes all seem collossal, then you're probably being too coarse. Please pardon me if that's a statement of the obvious. I think this is one of those fuzzy, no-hard-and-fast-rules cases that show us why we need human programmers. Just try something, seeking balance, and refactor if you find you're going too far in one direction or the other. And remember: if it's worth doing, it's worth doing badly. ","pontos":1},{"corpo":"I'm not sure it's true that any given ssh packet \"looks\" the same as any given https packet. However, over their lifetime they don't behave the same way. The session set up and tear down don't look alike (SSH offer a plain text banner during initial connect, for one thing). Also, typically wouldn't an https session be short lived? Connect, get your data, disconnect, whereas ssh would connect and persist for long periods of time? I think perhaps using 443 instead of 22 might get past naive filters, but I don't think it would fool someone specifically looking for active attempts to bypass their filters. Is throttling ssh a common occurrence? I've experienced people blocking it, but I don't think I've experienced throttling. Heck, I usually use ssh tunnels to bypass other blocks since people don't usually care about it. ","pontos":5},{"corpo":"For manipulating the DOM i think that what you're looking for is this. I've used to parse HTML documents from the web and it worked fine for me. ","pontos":1},{"corpo":"I've always ended up using their C# API and little scripts to do this. I'm not sure why S3Fox can't do it, but that functionality appears to be broken within it at the moment. I'm sure that many of the other S3 tools can do it as well, though. ","pontos":0},{"corpo":"If you are in an ATL/MFC environment, You can use the ATL conversion macro: #include atlbase.h #include atlconv.h . . . string myStr(\"My string\"); CA2W unicodeStr(myStr); You can then use unicodeStr as an LPCWSTR. The memory for the unicode string is created on the stack and released then the destructor for unicodeStr executes. ","pontos":6},{"corpo":"Any source control solution you pick is going to have problems if people are moving, deleting, or adding files and not telling the source control system about it. I'm not aware of any source control item that could solve this problem. In the case where you just can't educate the people working on the project[1], then you may just have to go with daily snapshots. Something as simple as batch file using xcopy to a network drive, and possibly 7-zip on the command line to compress it so it doesn't take up too much space would probably be the simplest solution. [1] I would highly disbelieve this, probably just more a case of people being too stubborn and not willing to learn, or do \"extra work\". Nevermind how much time source control could save them when they have to go back to previous versions, or 2 people have edited the same file. ","pontos":1},{"corpo":"It looks reasonable enough to me, unless something is imposing a 4096 character limit [you list 4020 characters] A 4096 limit to me seems a bit absurd, it'd be 2048 or 32767 or 8192 from stuff I've found by searching for the command-line limits. ","pontos":0},{"corpo":"Is it a runtime error or compile-time, Jonas? Looking at the documentation, ScaleX and ScaleY are dependency properties, so you should be able to write ScaleTransform ScaleX=\"{Binding Foo}\" ScaleY=\"{Binding Bar}\" / ... where Foo and Bar are of the appropriate type. Edit: Of course, that's the WPF documentation. I suppose it's possible that they've changed ScaleX and ScaleY to be standard properties rather than dependency properties in Silverlight. I'd love to hear more about the error you're seeing. ","pontos":1},{"corpo":"We use option 3. Rsync. I wrote a bash script to do this along with some extra checking, but here are the basics of what it does. Make a tag for pushing to live. Run svn export on that tag. rsync to live. So far it has been working out. We don't have to worry about user conflicts or have a separate user for running svn up on the production machine. ","pontos":2},{"corpo":"see msdn for the options to sgen.exe [you have the command line, you can play with it manually... delete your .XmlSerializers.dll or use /force though] Today I also ran across how to more manually specify the sgen options. I wanted this to not use the /proxy switch, but it appears it can let you specify the output directory. I don't know enough about msbuild to make it awesome, but this should get you started [open your .csproj/.vbproj in your non-visual studio editor of choice, look at the bottom and you should be able to figure out how/where this goes] [the below code has had UseProxyTypes set to true for your convenience] Target Name=\"GenerateSerializationAssembliesForAllTypes\" DependsOnTargets=\"AssignTargetPaths;Compile;ResolveKeySource\" Inputs=\"$(MSBuildAllProjects);@(IntermediateAssembly)\" Outputs=\"$(OutputPath)$(_SGenDllName)\" SGen BuildAssemblyName=\"$(TargetFileName)\" BuildAssemblyPath=\"$(OutputPath)\" References=\"@(ReferencePath)\" ShouldGenerateSerializer=\"true\" UseProxyTypes=\"true\" KeyContainer=\"$(KeyContainerName)\" KeyFile=\"$(KeyOriginatorFile)\" DelaySign=\"$(DelaySign)\" ToolPath=\"$(SGenToolPath)\" Output TaskParameter=\"SerializationAssembly\" ItemName=\"SerializationAssembly\" / /SGen /Target !-- Target Name=\"BeforeBuild\" /Target -- Target Name=\"AfterBuild\" DependsOnTargets=\"GenerateSerializationAssembliesForAllTypes\" /Target ","pontos":4},{"corpo":"Breaking changes in NHibernate 2.0 If you have good test coverage it's busywork. Edit: We upgraded this morning. There is nothing major. You have to Flush() the session after you delete. The Expression namespace got renamed to Criterion. All these are covered in the link above. Mappings need no change. It's quite transparent. Oh, and transactions everywhere, but you were probably doing that already. By the way, here's an interesting look at the changes: http://codebetter.com/blogs/patricksmacchia/archive/2008/08/26/nhibernate-2-0-changes-overview.aspx ","pontos":8},{"corpo":"EDIT: Fixed answer, see below. Really you need to know what oldFunction is going to be doing with pStuff. If pStuff is a pointer to some unmanaged data you can try wrapping the definition of m_pStuff with: #pragma unmanaged void* m_pStuff #pragma managed This will make the pointer unmanaged which can then be passed into unmanaged functions. Of course you will not be able to assign any managed objects to this pointer directly. Fundamentally unmanaged and managed pointers are not the same and can't be converted without some sort of glue code that copies the underlying data. Basically managed pointers point to the managed heap and since this is garbage collected the actual memory address they point to can change over time. Unmanaged pointers do not change the memory address without you explicitly doing so. Scratch that, you can't define unmanaged / managed inside a class definition. But this test code seems to work just fine: // TestSol.cpp : main project file. #include \"stdafx.h\" using namespace System; #pragma unmanaged void oldFunction(void** pStuff) { return; } #pragma managed ref class Test { public: void* m_test; }; int main(array System::String ^ ^args) { Console::WriteLine(L\"Hello World\"); Test^ test = gcnew Test(); void* pStuff = test- m_test; oldFunction( pStuff); test- m_test = pStuff; return 0; } Here I copy the pointer out of the managed object first and then pass that in by to the oldFunction. Then I copy the result (probably updated by oldFunction) back into the managed object. Since the managed object is on the managed heap, the compiler won't let you pass a reference to the pointer contained in that object as it may move when the garbage collector runs. ","pontos":1},{"corpo":"My first thought is this. I don't know if it would work but it would only take a few minutes to try. Create two IIS web sites on the same server. The first site is bound to the public IP, but the second site is bound to the private IP. Both point to the same folder on the file system. Your VPN users will be accessing via the private IP, so you can setup a \"site-wide\" rule on that site that will only affect VPN users. This should work for almost any IIS6 setting, including bandwidth throttling. Worth a try, at least. -- Edit: Tried this and it worked flawlessly. ","pontos":6},{"corpo":" What do you think would be the best method of transferring data to the IHttpHandler? Should I added variables to the query string or POST the data I need to send? The only thing I think I have to send is a single ID, but I can't decide what the best method is to send the ID and have the IHttpHandler handle it. I'd like to come up with a solution that would prevent a person with basic computer skills from accidentally or intentionally accessing the page directly Considering the callback is buried in the client code, it would take someone with equal determination to get either the querystring or the POST request. IE, if they have firebug, your equally screwed. So, in that case, do whatever is easiest to you (Hint: I'd just use the querystring). To handle repeating requests/direct access, I'd generate a key that is sent with each request. Perhaps a hash of the current time (Fuzzy, I'd go down to minutes, but not seconds due to network latency) + the client IP. Then in the HTTPHandler, perform the same hash, and only run if they match. ","pontos":3},{"corpo":"searchdotnet rulz! check this out: http://www.eggheadcafe.com/forumarchives/SQLServerdatawarehouse/Dec2005/post25052042.asp Updated: that link is dead. So here's a better one http://msdn.microsoft.com/en-us/library/ms345146(SQL.90).aspx#sql2k5parti_topic6 From above: Some of the performance and manageability benefits (of partioned tables) are Simplify the design and implementation of large tables that need to be partitioned for performance or manageability purposes. Load data into a new partition of an existing partitioned table with minimal disruption in data access in the remaining partitions. Load data into a new partition of an existing partitioned table with performance equal to loading the same data into a new, empty table. Archive and/or remove a portion of a partitioned table while minimally impacting access to the remainder of the table. Allow partitions to be maintained by switching partitions in and out of the partitioned table. Allow better scaling and parallelism for extremely large operations over multiple related tables. Improve performance over all partitions. Improve query optimization time because each partition does not need to be optimized separately. ","pontos":0},{"corpo":"Never use on Mac OS X or any other operating system. If you do that, you'll have to figure out how to properly quote all argument strings and so on; it's a pain and very error-prone. Instead, use which takes an array of already-separated arguments. This is much more appropriate for virtually all uses. ","pontos":3},{"corpo":"@Dale I have not inspected nInject closely, but from my high level understanding of dependency injection, I believe it would be accomplishing the same thing as ChanChans suggestion, only with more layers of cruft (er abstraction). In a one off situation where I just need it here, I think using some handrolled reflection code is a better approach than having an additional library to link against and only calling it one place... But maybe I don't understand the advantage nInject would give me here. ","pontos":1},{"corpo":"A quick google led me to this bash script that can check if a filesystem is mounted. It seems that grepping the output of df or mount is the way to go: if df |grep -q '/mnt/mountpoint$' then echo \"Found mount point, running task\" # Do some stuff else echo \"Aborted because the disk is not mounted\" # Do some error correcting stuff exit -1 fi ","pontos":3},{"corpo":"Kevin, this cannot be done with pure HTML. You must rely on JavaScript for this trick. However, if you place two forms on the HTML page you can do this. Form1 would have the previous button. Form2 would have any user inputs + the next button. When the user presses Enter in Form2, the Next submit button would fire. ","pontos":6},{"corpo":"Raw HTML does just that. Are you changing your data so that it doesn't render so good in random sized windows? In the olden days, everyone had VGA screens. Now, that resolution is most uncommon. Who knows what resolutions are going to be common in the future? And why expect a certain minimum width or height? From a usability viewpoint, demanding a certain resolution from your users is just going to create a degraded experience for anyone not using that resolution. Another thing that comes from this is what is fixed width? I've seen plenty of fixed size windows (popups) that just don't render right because my fonts are different from the designer's. ","pontos":10},{"corpo":"Sourcegear Vault is the best SCM for migrating VSS users to. And its cheap. ","pontos":3},{"corpo":"If I can't find an exception that has a name describing what type of error was caused then I make my own. That's my rule-o-thumb. ","pontos":3},{"corpo":"A note to future readers: The text below was last edited in August 2008. That's nearly 5 years ago as of this edit. Software can change rapidly from version to version, so before you go choosing a DBMS based on the advice below, do some research to see if it's still accurate. Better? MySQL is much more commonly provided by web hosts. PostgreSQL is a much more mature product. There's this discussion addressing your \"better\" question Apparently, according to this web page, MySQL is fast when concurrent access levels are low, and when there are many more reads than writes. On the other hand, it exhibits low scalability with increasing loads and write/read ratios. PostgreSQL is relatively slow at low concurrency levels, but scales well with increasing load levels, while providing enough isolation between concurrent accesses to avoid slowdowns at high write/read ratios. It goes on to link to a number of performance comparisons, because these things are very... sensitive to conditions. So if your decision factor is, \"which is faster?\" Then the answer is \"it depends. If it really matters, test your application against both.\" And if you really, really care, you get in two DBAs (one who specializes in each database) and get them to tune the crap out of the databases, and then choose. It's astonishing how expensive good DBAs are; and they are worth every cent. When it matters. Which it probably doesn't, so just pick whichever database you like the sound of and go with it; better performance can be bought with more RAM and CPU, and more appropriate database design, and clever stored procedure tricks and so on - and all of that is cheaper and easier for random-website-X than agonizing over which to pick, MySQL or PostgreSQL, and specialist tuning from expensive DBAs. Joel also said in that podcast that comment would come back to bite him because people would be saying that MySQL was a piece of crap - Joel couldn't get a of rows back. The plural of anecdote is not data. He said: MySQL is the only database I've ever programmed against in my career that has had data integrity problems, where you do queries and you get nonsense answers back, that are incorrect. and he also said: It's just an anecdote. And that's one of the things that frustrates me, actually, about blogging or just the Internet in general. [...] There's just a weird tendency to make anecdotes into truths and I actually as a blogger I'm starting to feel a little bit guilty about this ","pontos":112},{"corpo":"If you are writing an application which may get distributed quite a bit on different servers, MySQL carries a lot of weight over PostgreSQL because of the portability. PostgreSQL is difficult to find on less than satisfactory web hosts, albet there are a few. In most regards, PostgreSQL is slower than MySQL, especially when it comes to fine tuning in the end. All in all, I'd say to give PostgreSQL a shot for a short amount of time, that way you aren't completely avoiding it, and then make a judgement. ","pontos":0},{"corpo":"The below script is a simplified version taken from eycap, specifically from this file. set :dbuser \"user\" set :dbhost \"host\" set :database \"db\" namespace :db do desc \"Get the database password from user\" task :get_password do set(:dbpass) do Capistrano::CLI.ui.ask \"Enter mysql password: \" end end task :backup_name, :only = { :primary = true } do now = Time.now run \"mkdir -p #{shared_path}/db_backups\" backup_time = [now.year,now.month,now.day,now.hour,now.min,now.sec].join('-') set :backup_file, \"#{shared_path}/db_backups/#{database}-snapshot-#{backup_time}.sql\" end desc \"Dump database to backup file\" task :dump, :roles = :db, :only = {:primary = true} do backup_name run \"mysqldump --add-drop-table -u #{dbuser} -h #{dbhost} -p#{dbpass} #{database} | bzip2 -c #{backup_file}.bz2\" end end Edit: Yeah, I guess I missed the point that you were looking for a rake task and not a capistrano task, but I don't have a rake one on hand, sorry. ","pontos":2},{"corpo":"Not sure if there is much use pitching in, as everyone else pretty much has it covered, but I would also say don't do it. As tempting as it is, its just impossible to know the full impact of that little change you have made. From a support perspective you will make it difficult for Microsoft support (patches/hotfixes). From a maintenance perspective you are also opening yourself up to long term costs. Go the javascript route. ","pontos":0},{"corpo":"Juan Manuel said: that's one of the reasons I don't understand why it cannot be a part of the contract in the interface It's an indirect mechanism. The generic allows you to \"cheat\" and send type information along with the interface. The critical thing to remember here is that the constraint isn't on the interface that you are working with directly. It's not a constraint on the interface itself, but on some other type that will \"ride along\" on the interface. This is the best explanation I can offer, I'm afraid. By way of illustration of this fact, I'll point out a hole that I have noticed in aku's code. It's possible to write a class that would compile fine but fail at runtime when you try to instantiate it: public class Something : ITest String { private Something() { } } Something derives from ITest T , but implements no parameterless constructor. It will compile fine, because String does implement a parameterless constructor. Again, the constraint is on T, and therefore String, rather than ITest or Something. Since the constraint on T is satisfied, this will compile. But it will fail at runtime. To prevent some instances of this problem, you need to add another constraint to T, as below: public interface ITest T where T : ITest T , new() { } Note the new constraint: T : ITest T . This constraint specifies that what you pass into the argument parameter of ITest T must also derive from ITest T . Even so this will not prevent all cases of the hole. The code below will compile fine, because A has a parameterless constructor. But since B's parameterless constructor is private, instantiating B with your process will fail at runtime. public class A : ITest A { } public class B : ITest A { private B() { } } ","pontos":5},{"corpo":"443, when used for HTTPS, relies on SSL (not SSH) for its encryption. SSH looks different than SSL, so it would depend on what your ISP was actually looking for, but it is entirely possible that they could detect the difference. In my experience, though, you'd be more likely to see some personal firewall software block that sort of behavior since it's nonstandard. Fortunately, it's pretty easy to write an SSL tunnel using a of some type. In general, they can see how much bandwidth you are using, whether or not the traffic is encrypted. They'll still know the endpoints of the connection, how long it's been open, and how many packets have been sent, so if they base their shaping metrics on this sort of data, there's really nothing you can do to prevent them from throttling your connection. ","pontos":4},{"corpo":"In your example code, try running in the method. That will force the combo box to commit its properties. The thing is that even though the property is set the new value isn't used until is run, which it will do at the earliest on the next frame, forces it to be done at once. ","pontos":0},{"corpo":"ScaleTransform doesn't have a data context so most likely the binding is looking for SelectedDive.Visibility off it's self and not finding it. There is much in Silverlight xaml and databinding that is different from WPF... Anyway to solve this you will want to set up the binding in code**, or manually listen for the PropertyChanged event of your data object and set the Scale in code behind. I would choose the latter if you wanted to do an animation/storyboard for the scale change. ** i need to check but you may not be able to bind to it. as i recall if the RenderTransform is not part of an animation it gets turned into a matrix transform and all bets are off. ","pontos":1},{"corpo":" Precomputed lookup table: 16bit_integer = products[another_16bit_integer]; That's not going to work so good on the AVR, the 16bit address space is going to be exhausted. ","pontos":0},{"corpo":"The Real(TM) e-mail validation is trying to send something to the address, and seeing if it is rejected/bounced. So, you'll just have to send them away, and remove the addresses that fail from your mailing list. ","pontos":2},{"corpo":"Since you are using an 8 bit processor, you can probably only handle 16 bit results, not 32 bit results. To reduce 16 bit overflow issues I would restate the formula like this: result16 = operand16 - (operand16 * 3)/1000 This would give accurate results for unsigned integers up to 21845, or signed integers up to 10922. I am assuming the the processor can do 16 bit integer division. If you cannot then you need to do the division the hard way. Multiplying by 3 can be done by simple shifts adds, if no multiply instruction exists or if multiplication only works with 8 bit operands. Without knowing the exact microprocessor it is impossible to determine how long such a calculation would take. ","pontos":0},{"corpo":"Be aware that most MTAs (Mail Transfer Agent) will have the VRFY command turned off for spam protection reasons, they'll probably even block you if you try several RCPT TO in a row (see http://www.spamresource.com/2007/01/whatever-happened-to-vrfy.html). So even if you find a library to do that verification, it won't be worth a lot. Ishmaeel is right, the only way to really find out, is sending an email and see if it bounces or not. @Hrvoje: Yes, I'm suggesting you monitor rejected emails. BUT: not all the bounced mails should automatically end up on your \"does not exist\"-list, you also have to differentiate between temporary (e.g. mailbox full) and permanent errors. ","pontos":14},{"corpo":" When you have to use manage memory manually, make sure you call delete in the same scope/function/class/module, which ever applies first, e.g.: Let the caller of a function allocate the memory that is filled by it, do not return new'ed pointers. Always call delete in the same exe/dll as you called new in, because otherwise you may have problems with heap corruptions (different incompatible runtime libraries). ","pontos":0},{"corpo":"Why not ask here? Newer programmers looking for experience to fill a resume might jump on board. Us older geeks, well from my own experience, I work on what I like. For me it's mostly AI related or (don't laugh) Warcraft and Civ4 mods. ","pontos":0},{"corpo":" I have to stick to pure c++ because the framework I'm using forbids any use of generics. There's certainly a rationale behind this decision? I'd be interested to hear it because off the top of my head I can't think of any reason to forbid templates completely. ","pontos":0},{"corpo":"Regarding the formatting of your post: If you use the quote-button instead of code-button, people do not have to scroll to see the complete error message. ","pontos":1},{"corpo":" I have to stick to pure c++ because the framework I'm using forbids any use of generics. There's certainly a rationale behind this decision? I'd be interested to hear it because off the top of my head I can't think of any reason to forbid templates completely. The official answer to this is: They are not portable to different operating systems, especially in the way they are supported by compilers and link-editors. ","pontos":0},{"corpo":"in C#, try (double.maxvalue == (double.maxvalue - 100)) , you'll get true ... but thats what it is supposed to be: http://en.wikipedia.org/wiki/Floating_point#Accuracy_problems thinking about it, you have 64 bit representing a number greater than 2^64 (double.maxvalue), so inaccuracy is expected. ","pontos":2},{"corpo":"Don't take this the wrong way, but sending newsletters to more than a handful of people these days is a fairly serious matter. Yes, you need to be monitoring bounces (rejected emails) which can occur synchronously during the SMTP send (typically if the SMTP server you are connected to is authoritative), or asynchronously as a system-generated email message that occurs some amount of time after the SMTP send succeeded. Also keep the CAN-SPAM Act in mind and abide by the law when sending these emails; you've got to provide an unsub link as well as a physical street address (to both identify you and t0 allow users to send unsub requests via snail-mail if they so choose). Failure to do these things could get your IP null-routed at best and sued at worst. ","pontos":3},{"corpo":"Someone has to do the iterating part. AFAIK, there is no such method present in .NET already, so I guess that someone has to be you. ","pontos":0},{"corpo":"From A Java Learner: When an exception occurs, you have to either catch and handle the exception, or tell compiler that you can't handle it by declaring that your method throws that exception, then the code that uses your method will have to handle that exception (even it also may choose to declare that it throws the exception if it can't handle it). Compiler will check that we have done one of the two things (catch, or declare). So these are called Checked exceptions. But Errors, and Runtime Exceptions are not checked for by compiler (even though you can choose to catch, or declare, it is not required). So, these two are called Unchecked exceptions. Errors are used to represent those conditions which occur outside the application, such as crash of the system. Runtime exceptions are usually occur by fault in the application logic. You can't do anything in these situations. When runtime exception occur, you have to re-write your program code. So, these are not checked by compiler. These runtime exceptions will uncover in development, and testing period. Then we have to refactor our code to remove these errors. ","pontos":46},{"corpo":"@Curt Hagenlocher - that's back to front. I've no idea why so many have voted it up when it's wrong. is for managed resources. Finalisers are for unmanaged resources. As long as you only use managed resources both @Jon Limjap and myself are entirely correct. For classes that use unmanaged resources (and bear in mind that the vast majority of .Net classes don't) Patrik's answer is comprehensive and best practice. Avoid using GC.Collect - it is a slow way to deal with managed resources, and doesn't do anything with unmanaged ones unless you have correctly built your ~Finalizers. I've removed the moderator comment from the original question in line with http://stackoverflow.com/questions/14593/etiquette-for-modifying-posts ","pontos":0},{"corpo":"Well, from the module source it looks like that IO::Socket error is coming from get_https2 [...] unless ($ssl_socket) { $errors = sprintf \"error %s unable to connect https://%s:%s/\\n\", IO::Socket::SSL::errstr,$host,$port; return undef; } [...] which is called by callCAS, which is called by validateST. One option is to temporarily edit the module file to put some debug statements in if you can, but if I had to guess, I'd say the casUrl you are supplying isn't matching up to the _parse_url regex properly - maybe you have three slashes after the https? ","pontos":-1},{"corpo":"@Keith: IDisposable is for managed resources. Finalisers are for unmanaged resources. Sorry but that's just wrong. Normally, the finalizer does nothing at all. However, if the dispose pattern has been correctly implemented, the finalizer tries to invoke . has two jobs: Free unmanaged resources, and free nested managed resources. And here your statement comes into play because it's true that while finalizing, an object should never try to free nested managed resources as these may have already been freed. It must still free unmanaged resources though. Still, finalizers have no job other than to call and tell it not to touch managed objects. , when called manually (or via ), shall free all unmanaged resources and pass the message on to nested objects (and base class methods) but this will never free any (managed) memory. ","pontos":0},{"corpo":"Checked exceptions are useful for recoverable cases where you want to provide information to the caller (i.e. insufficient permissions, file not found, etc). Unchecked exceptions are used rarely, if at all, for informing the user or programmer of serious errors or unexpected conditions during run-time. Don't throw them if you're writing code or libraries that will be used by others, as they may not be expecting your software to throw unchecked exceptions since the compiler doesn't force them to be caught or declared. ","pontos":1},{"corpo":"I'm pretty uncomfortable about this question and the attendant answers. There's a lot of \"try this magic dust! No that magic dust!\" I can't see anywhere that you've anaylzed the locks that are taken, and determined what exact type of locks are deadlocked. All you've indicated is that some locks occur -- not what is deadlocking. In SQL 2005 you can get more info about what locks are being taken out by using: DBCC TRACEON (1222, -1) so that when the deadlock occurs you'll have better diagnostics. ","pontos":17},{"corpo":"Isn't that what is for? Note though, that it will find all the servers, if you iterate over the iterator - but you aren't going to do that (according to OP). ","pontos":0},{"corpo":" However, the same result will be returned regardless of which copy of the predicate is used (i.e. the predicate has no real state), so the original problem with state-keeping predicates is not relevant in this case. So where's the problem? Function objects don't necessarily have to be stateful. It's actually best practice to use function objects instead of function pointers in such situations because compilers are better at inlining them. In your case, the instantiation and call of the function object may have no overhead at all since is a function template and the compiler will generate an own version for your functor. On the other hand, using a function pointer would incur an indirection. ","pontos":0},{"corpo":"Delete all of the objects in the bucket first. Then you can delete the bucket itself. Apparently, one cannot delete a bucket with objects in it and S3Fox does not do this for you. I've had other little issues with S3Fox myself, like this, and now use a Java based tool, jets3t which is more forthcoming about error conditions. There must be others, too. ","pontos":0},{"corpo":"In MFC, TRACE is defined as ATLTRACE. And in release mode that is defined as: #define ATLTRACE __noop So, using the out-the-box TRACE from MFC, you won't actually be able to read any TRACE text, because it won't even be written out. You could write your own TRACE function instead, then re-define the TRACE macro. You could do something like this: void MyTrace(const CString text) { ::OutputDebugString(text); // Outputs to console, same as regular TRACE // TODO: Do whatever output you need here. Write to event log / write to text file / write to pipe etc. } ","pontos":1},{"corpo":" The rule I use is: never use unchecked exceptions! (or when you don't see any way around it) There's a very strong case for the opposite: Never use checked exceptions. I'm reluctant to take sides in the debate but there seems to be a broad consensus that introducing checked exceptions was a wrong decision in hindsight. Please don't shoot the messenger and refer to those arguments. ","pontos":40},{"corpo":"Konrad Rudolph - yup, normally the finaliser does nothing at all. You shouldn't implement it unless you are dealing with unmanaged resources. Then, when you do implement it, you use Microsoft's dispose pattern (as already described) calls - deals with both managed and unmanaged resources. Calling should suppress finalisation. calls - deals with unmanaged resources only. This prevents unmanaged memory leaks if you fail to call the is slow, and shouldn't be used unless you do have unmanaged resources to deal with. Managed resources can't memory leak, they can only waste resources for the current application and slow its garbage collection. Unmanaged resources can leak, and is best practice to ensure that they don't. In either case is best practice. ","pontos":0},{"corpo":"Complete explanation by Joe Duffy on \"Dispose, Finalization, and Resource Management\": Earlier in the .NET Frameworks lifetime, finalizers were consistently referred to as destructors by C# programmers. As we become smarter over time, we are trying to come to terms with the fact that the Dispose method is really more equivalent to a C++ destructor (deterministic), while the finalizer is something entirely separate (nondeterministic). The fact that C# borrowed the C++ destructor syntax (i.e. ~T()) surely had at least a little to do with the development of this misnomer. ","pontos":3},{"corpo":"G'day, I'd suggest reading the relevant sections of \"Effective C++\" by Scott Meyers. Easy to read and he covers some interesting gotchas to trap the unwary. I'm also intrigued by the lack of templates. So no STL or Boost. Wow. BTW Getting people to agree on conventions is an excellent idea. As is getting everyone to agree on conventions for OOD. BTW The latest edition of Effective C++ doesn't have the excellent chapter about OOD conventions that the first edition had which is a pity, e.g. conventions such as public virtual inheritance always models an \"isa\" relationship. Rob ","pontos":1},{"corpo":"You make a distinction between 'private' and 'public' branches, but the only real difference between these cases is whether the branch's repository is only available locally or company-wide. A central repository is only one way to have company-wide availability. Instead, why not say that all repositories must be publically available throughout the company? For example, you could make all developer run their own local VCS server, and share their branches via zeroconf. ","pontos":1},{"corpo":"DotNetCoders has a starter article on it: http://www.dotnetcoders.com/web/Articles/ShowArticle.aspx?article=50, they talk about how to set up the switches in the config file how to write the code, but it is pretty old (2002). There's another article on CodeProject: http://www.codeproject.com/KB/trace/debugtreatise.aspx but it's the same age. CodeGuru has another article on custom TraceListeners: http://www.codeguru.com/columns/vb/article.php/c5611 I can't think of any more recent articles, hopefully someone else here will have something ","pontos":2},{"corpo":"I just found one more, this one seems to have a lot of detail about setting up the listeners in the config file: http://olondono.blogspot.com/2008/01/about-trace-listeners.html ","pontos":30},{"corpo":"I setup two instances of my application on EC2, and have been using S3 in as a local-to-AWS backup and media asset delivery. We moved over about 15% of our applications content/traffic to EC2 in mid-June. The result is mixed, and we are moving the content heavy usage instance back to our hosted data center, and now are investigating other content delivery options. Do note that: My application is bandwidth hungry (starting at 100mbps per instance) My company and I are based in Switzerland and that surely has had an impact on our evaluation. I define bandwidth as a rate of flow (mbps, etc.) and traffic as volume (mb, gb, etc.) Pros: Traffic costs for low to medium volumes, assuming less than maybe a terabyte per month. Exceed that fuzzy line and either do it yourself or find a proper CDN Active user community Effectively unlimited bandwidth with S3/CloudFront-delivered content Flexibility (kick off an instance and have it running in minutes) CPU power available in an instance, even the small instance type, was always enough for my application. There are other high-CPU instance types for those who need it. Cons: We had an instance become unreachable (a not unheard of occurrence) and had execute our disaster recovery procedure. 12h. Network latency, for both S3 and EC2, can be unacceptably high (100s of ms) EC2 instance bandwidth is limited. Despite hours of search, I never found an official statement with hard numbers one what users can expect. Initially we saw a max of ~250mpbs in tests but that seems to have improved dramatically. Per HTTP connection bandwidth can be unacceptably low. 1-2mbps from even our Swiss data center with a 800mpbs connection and quality peering. EDIT: We have recently seen rates between our data center and EC2 in the 3-4mpbs range. S3 is not a 'normal' file system, and special software is required. We chose JungleDisk, which I now find inappropriate for a 24/7, moderately sized data set server environment. Strange things would happen (file listed twice with an 'ls' command) and unexpected crashes. Use EBS for persistent data, although that is not without caveats. S3 is not a CDN. My company, like many others, have tried to use Amazon S3 as a CDN. There are other low cost alternatives out there. (Akamai, voxel.net, easycache.com) I'm a fan of the cloud concept, and we will continue to run an instance out of EC2, but we found it inappropriate for our main production needs in its current form. AWS has some issues to sort out. ","pontos":28},{"corpo":"Killer app? Franz Inc. has a long list of success stories, but this list only includes users of AllegroCL... There are probably others. My favourite is the story about Naughty Dog, since I was a big fan of the Crash Bandicoot games. For learning Common Lisp, I'd recommend Practical Common Lisp. It has a hands-on approach that at least for me made it easier than other books I've looked at. ","pontos":2},{"corpo":"Here is an article describing what might be your problem. ","pontos":1},{"corpo":"If you accidentally 'add' a file in svn you haven't committed it, you can revert that file it will remove the add. ","pontos":5},{"corpo":"To remove a file already in source control: git rm filename and then git commit -m ... You should add every file you want to ignore to the .gitignore file. I additionally always check the .gitignore file to my repository, so if someone checks out the code on his machine, and the file gets generated again, he won't 'see' it as 'dirty'. Of course if you already committed the file and someone else got your changes on another machine, you would have to alter every local repository to modify the history. At least that's a possible solution with git. I don't think svn would let you do that. If the file is already on the master repository (git) or in the server (svn), I don't think there is a better solution than just deleting the file in another commit. ","pontos":2},{"corpo":"For SVN you can revert files you haven't committed yet. In TortoiseSVN you just right click the file in the commit window and choose Revert... On command line use svn revert [file] Don't know about GIT since I've never used it. ","pontos":0},{"corpo":"As far as I know there is no easy way to remove an added file from versioning control in svn once it is committed. You will have to save the file somewhere else and delete it from version control. Than copy the backup back again. It's a version control system after all... ;) ","pontos":0},{"corpo":"The biggest problem by using jeffs code is the @ which currently isnt available. I would probably just take the \"raw\" regexp from jeffs code if i needed it and paste it into http://www.cis.upenn.edu/~matuszek/General/RegexTester/regex-tester.html and see the things needing escape get escaped and then use it. Taking the usage of this regex in mind I would personally make sure I understood exactly what I was doing, why and what consequences would be if I didnt succeed, before copy/pasting anything, like the other answers try to help you with. (Thats propbably pretty sound advice for any copy/paste) ","pontos":0},{"corpo":"I always add Thumbs.db in as well, because I hate having those files versioned. Probably more of an issue for web developers ","pontos":4},{"corpo":"As far as local, static html goes, unless you specify it, most browsers will take the location of the html file you are viewing as the root. So any css put in there can just be referenced by it's name only. The lazy way to get the correct reference for your css file is to open it in your browser. Then just grab the url that you see there - something like: Either that or you can just take the url for the html file and amend it to refer to the stylesheet. Then your local page should load fine with the local stylesheet. ","pontos":0},{"corpo":"Without having tried it... In git, if your changes haven't been propagated to another repository, you should be able to the affected file(s), to reorder the deletion commit to be just after the commit in which you accidentally added the offending files, and then squash those two commits together. Of course, this won't help if someone else has pulled your changes. ","pontos":5},{"corpo":"It sounds like you have already added and committed the file to subversion (I assume that you are using Subversion). If that is the case, then there are only two ways to remove that file: Mark the file as deleted and commit. Perform an , filter out the revision where you accidentally committed the file and perform an . Trust me, you don't really want to do number 2. It will invalidate all working copies of the repository. The best is to do number 1, mark the file as ignored and apologise. ","pontos":4},{"corpo":"The only problem with Magnus' solution is that it forks off a new \"cp\" process for every file, which is not terribly efficient especially if there is a large number of files. On Linux (or other systems with GNU coreutils) you can do: find . -name \"*.xml\" -print0 | xargs -0 echo cp -t a (The -0 allows it to work when your filenames have weird characters -- like spaces -- in them.) Unfortunately I think Macs come with BSD-style tools. Anyone know a \"standard\" equivalent to the \"-t\" switch? ","pontos":12},{"corpo":" Is there a way to open file in a non-exclusive way, Yes, using Win32, passing the various FILE_SHARE_Xxxx flags to CreateFile. is it cross platform? No, it requires platform-specific code. Due to annoying backwards compatibility concerns (DOS applications, being single-tasking, assume that nothing can delete a file out from under them, i.e. that they can fclose() and then fopen() without anything going amiss; Win16 preserved this assumption to make porting DOS applications easier, Win32 preserved this assumption to make porting Win16 applications easier, and it's awful), Windows defaults to opening files exclusively. The underlying OS infrastructure supports deleting/renaming open files (although I believe it does have the restriction that memory-mapped files cannot be deleted, which I think isn't a restriction found on *nix), but the default opening semantics do not. C++ has no notion of any of this; the C++ operating environment is much the same as the DOS operating environment--no other applications running concurrently, so no need to control file sharing. ","pontos":3},{"corpo":"I read the heading and immediately thought \"obsolete atribute\". How about /// summary /// do not use /// /summary /// param name=\"item\" don't pass it anything -- you shouldn't use it. /param /// returns nothing - you shouldn't use it /returns public bool Include(T item) { .... ","pontos":2},{"corpo":" will probably work in your situation -- you can even cause the build to break if that method is used. Since obsolete warnings occur at compile time, and since the reflection needed for serialization occurs at runtime, marking that method obsolete won't break serialization, but will warn developers that the method is not there to be used. ","pontos":1},{"corpo":"What you're looking for is the \"ObsoleteAttribute\" class: http://msdn.microsoft.com/en-us/library/system.obsoleteattribute.aspx using System; public sealed class App { static void Main() { // The line below causes the compiler to issue a warning: // 'App.SomeDeprecatedMethod()' is obsolete: 'Do not call this method.' SomeDeprecatedMethod(); } // The method below is marked with the ObsoleteAttribute. // Any code that attempts to call this method will get a warning. [Obsolete(\"Do not call this method.\")] private static void SomeDeprecatedMethod() { } } ","pontos":1},{"corpo":"subdomain and domain are difficult because the subdomain can have several parts, as can the top level domain, http://sub1.sub2.domain.co.uk/ the path without the file : http://[^/]+/((?:[^/]+/)*(?:[^/]+$)?) the file : http://[^/]+/(?:[^/]+/)*((?:[^/.]+\\.)+[^/.]+)$ the path with the file : http://[^/]+/(.*) the URL without the path : (http://[^/]+/) (Markdown isn't very friendly to regexes) ","pontos":4},{"corpo":"Here is a link to the PostgreSQL doc page on MVCC. The choice quote (emphasis mine): The main advantage to using the MVCC model of concurrency control rather than locking is that in MVCC locks acquired for querying (reading) data do not conflict with locks acquired for writing data, and so reading never blocks writing and writing never blocks reading. This is why Jeff was so confounded by his deadlocks. A read should never be able to cause them. ","pontos":1},{"corpo":"Wow, that problem is bugging me too. You also need default constructors for NHibernate, but I want to force people to NOT use C# 3.0 object initializers so that classes go through constructor code. ","pontos":0},{"corpo":"I think you may be getting confused between TAggregate and TAggregateField objects, and the Delphi documentation probably isn't helping. AFAICT, TAggregateField objects are automatically 'recalculated' and can be bound to data-aware controls like TDBText, but don't have any OnUpdate event. \"TAggregate\" objects, on the other hand, do have an OnUpdate event, but can't be bound to data-aware controls. This may be enlightening: http://dn.codegear.com/article/29272 ","pontos":4},{"corpo":"Java offers a URL class that will do this. Query URL Objects. On a side note, PHP offers parse_url(). ","pontos":1},{"corpo":"If a class is serialisable (i.e. it can be copied around the place as needed) the param-less constructor is needed to deserialise. I'm guessing that you want to force your code's access to pass defaults for your properties to a parameterised constructor. Basically you're saying that it's OK for the to make a copy and then set properties, but you don't want your own code to. To some extent I think this is over-designing. Just add XML comments that detail what properties need initialising (and what to). Don't use , because it isn't. Reserve that for genuinely deprecated methods. ","pontos":8},{"corpo":"The syntax you want is: create table #tablename The # prefix identifies the table as a temporary table. ","pontos":0},{"corpo":"You can create table variables (in memory), and two different types of temp table: --visible only to me, in memory (SQL 2000 and above only) declare @test table ( Field1 int, Field2 nvarchar(50) ); --visible only to me, stored in tempDB create table #test ( Field1 int, Field2 nvarchar(50) ) --visible to everyone, stored in tempDB create table ##test ( Field1 int, Field2 nvarchar(50) ) Edit: Following feedback I think this needs a little clarification. and will always be in TempDB. variables will normally be in memory, but are not guaranteed to be. SQL decides based on the query plan, and uses TempDB if it needs to. ","pontos":13},{"corpo":" And I seem to be completely overlooking where the system tells me about resizes. Likewise the hit testing. For the resizing you're indeed missing the SizeChanged event. AFAIK there is sadly no OnSizeChanging, OnLocationChanging and OnStateChanging event on a Window in .NET I saw that one, but as far as I can tell it only fires after the size has changed, whereas I need the event to fire during the resize. Unless I'm misreading the docs and it actually fires continuously? It does not fire continuously but you can probably use the ResizeBegin and ResizeEnd events and be able to do that. Aren't they WinForms events? Hmm, you're right. ","pontos":1},{"corpo":"Many issues can cause that error. It's usually a Response.Write call, but anything that modifies the response can cause it. We probably won't be able to help you unless you post some pertinent code-behind. ","pontos":3},{"corpo":"You can watch the graph you created using GraphEdit, a tool from the DirectShow SDK. In GraphEdit, select File->Connect to remote Graph... In order to find your graph in the list, you have to register it in the running object table: void AddToRot( IUnknown *pUnkGraph, DWORD *pdwRegister ) { IMoniker* pMoniker; IRunningObjectTable* pROT; GetRunningObjectTable( 0, pROT ); WCHAR wsz[256]; swprintf_s( wsz, L\"FilterGraph %08p pid %08x\", (DWORD_PTR)pUnkGraph, GetCurrentProcessId() ); CreateItemMoniker( L\"!\", wsz, pMoniker ); pROT- Register( 0, pUnkGraph, pMoniker, pdwRegister ); // Clean up any COM stuff here ... } After destroying your graph, you should remove it from the ROT by calling IRunningObjectTable::Revoke ","pontos":13},{"corpo":"@Keith This is a common misconception: Table variables are NOT necessarily stored in memory. In fact SQL Server decides whether to keep the variable in memory or to spill it to TempDB. There is no reliable way (at least in SQL Server 2005) to ensure that table data is kept in memory. For more detailed info look here ","pontos":12},{"corpo":"If you are compiling Apache2 for a particular location but want your clients to be able to install it somewhere else (and I'm assuming they have the same architecture and OS as your build machine) then you can do it but the apachectl script will need some after-market hacking. I just tested these steps: Unpacked the Apache2 source (this should work with Apache 1.3 as well though) and ran ./configure --prefix=/opt/apache2 Ran make then sudo make install to install on the build machine. Switch to the install directory (/opt/apache2) and tar and gzip up the binaries and config files. I used cd /opt/apache2; sudo tar cf - apache2 | gzip -c > ~/apache2.tar.gz Move the tar file to the target machine. I decided to install in /opt/mynewdir/dan/apache2 to test. So basically, your clients can't use rpm or anything like that -- unless you know how to make that relocatable (I don't :-) ). Anyway, your client's conf/httpd.conf file will be full of hard-coded absolute paths -- they can just change these to whatever they need. The apachectl script also has hard coded paths. It's just a shell script so you can hack it or give them a sed script to convert the old paths from your build machine to the new path on your clients. I skipped all that hackery and just ran ./bin/httpd -f /opt/mynewdir/dan/conf/httpd.conf :-) Hope that helps. Let us know any error messages you get if it's not working for you. ","pontos":1},{"corpo":"@wcm - actually to nit pick the Table Variable isn't Ram only - it can be partially stored on disk. A temp table can have indexes, whereas a table variable can only have a primary index. If speed is an issue Table variables can be faster, but obviously if there are a lot of records, or the need to search the temp table of a clustered index, then a Temp Table would be better. Good background article ","pontos":11},{"corpo":"I would actually be inclined to disagree with everyone that is advocating the use of the ObsoleteAttribute as the MSDN documentation says that: Marking an element as obsolete informs the users that the element will be removed in future versions of the product. Since the generic constructors for XML serialization should not be removed from the application I wouldn't apply it just in case a maintenance developer down the road is not familiar with how XML serialization works. I have actually been using Keith's method of just noting that the constructor is used for serialization in XML documentation so that it shows up in Intellisense. ","pontos":1},{"corpo":"I would suggest reading this thread from 2006 (On Amazon web services developers connection). It seems there's no easy solution to this. ","pontos":2},{"corpo":"Thanks. A load of -s added to our custom chart code seems to have done it. ","pontos":0},{"corpo":"I think those tools are very good, but for my purpose I have written a custom own. The main reason for this was because of I'm working on a SQL Server Compact 3.5 database, so none of the listed tools worked. Of course it isn't as powerful as the tools from Redgate but you get the most important features very quick. It's able to rename all kinds of database objects and migrating columns to other tables and create a diff script for 2 databases. ","pontos":0},{"corpo":"For all of you who believe the myth that temp variables are in memory only First, the table variable is NOT necessarily memory resident. Under memory pressure, the pages belonging to a table variable can be pushed out to tempdb. Read the article here: TempDB:: Table variable vs local temporary table ","pontos":5},{"corpo":"It rather depends how accurate you want to be and what datum the lat and long are defined on. Very, very approximately you do a little spherical trig, but correcting for the fact that the earth is not a sphere makes the formulae more complicated. ","pontos":5},{"corpo":" In which scenarios does one out-perform the other? For smaller tables (less than 1000 rows) use a temp variable, otherwise use a temp table. ","pontos":8},{"corpo":"I did, and I think it helped me at the time. It doesn't help me day to day anymore, but I think it would depend on your job. I learned assembler 20 years ago on a Commodore and again in University on an IBM mainframe. I can't say it helps me in my current job. ","pontos":1},{"corpo":"G'day, We actually faced this problem at a site where I was contracting previously. One bloke sat down and wrote tools, mainly shell scripts, to check out the current code base every hour or so and do a build to check if it was broken, and check out the latest good build and do a complete build and run about 8,000 regression tests. We just couldn't find anything commercially available to do this and so Charlie sat down and wrote this in bash shell scripts and it was running on HP-UX. cheers, Rob ","pontos":1},{"corpo":"Probably namespace issues and maybe one with current context. For source (with added namespace declaration to make it well-formed xml) svc:ElementList xmlns:svc=\"svc\" svc:Element Year 2007 /Year /svc:Element svc:Element Year 2006 /Year /svc:Element svc:Element Year 2005 /Year /svc:Element /svc:ElementList the stylesheet xsl:stylesheet xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:svc=\"svc\" version=\"1.0\" xsl:template match=\"svc:ElementList\" xsl:element name=\"{local-name()}\" xsl:for-each select=\"svc:Element\" xsl:element name=\"{concat('NewTag', Year)}\"/ /xsl:for-each /xsl:element /xsl:template /xsl:stylesheet will give you the output you need. Note that needs to be selected using namespace prefixed and that the context when generating the new tags is , not . ","pontos":9},{"corpo":"Just happened across this article which point out shortcomings in Redhat/Centos/Fedora implementations of Perl which affect profoundly. If you are running one of these Linux flavours, you might want to recompile Perl from original source (not RPM source). I realized that anyone running perl code with the distribution perl interpretter on Redhat 5.2, Centos 5.2 or Fedora 9 is likely a victim. Yes, even if your code doesnt use the fancy bless/overload idiom, many CPAN modules do! This google search shows 1500+ modules use the bless/overload idiom and they include some really popular ones like URI, JSON. ... ... At this point, I decided to recompile perl from source. The bug was gone. And the difference was appalling. Everything got seriously fast. CPUs were chilling at a loadavg below 0.10 and we were processing data 100x to 1000x faster! ","pontos":4},{"corpo":"Not necessarily, it depends what you want to do. Could you elaborate a bit? AJAX doesn't need access to cookies to work, it can make requests on its own to extract information, the page request that the AJAX call makes could access the cookie data pass that back to the calling script without Javascript having to directly access the cookies ","pontos":1},{"corpo":"No, the page that the AJAX call requests has access to cookies too that's what checks whether you're logged in. You can do other authentication with the Javascript, but I wouldn't trust it, I always prefer putting any sort of authentication checking in the back-end. ","pontos":0},{"corpo":"You probably meant to have some rounding in there, rather than truncating the result to an integer, otherwise the purpose of the operation is really limited. But since you asked the question with that specific formula, it brought to mind that your result set is really coarse. For the first 333 numbers, the result is: another_16bit_integer-1. You can approximate it (maybe even exactly, when not performed in my head) with something like: 16bit_integer = another_16bit_integer - 1 - (another_16bit_integer/334); edit: unsigned int, and you handle 0 on your own. ","pontos":2},{"corpo":"I use some macros to mark the code for import or export #ifdef ISDLL #define DLL __declspec(dllexport) #endif #ifdef USEDLL #define DLL __declspec(dllimport) #endif Then declare the class in a header file: class DLL MyClassToExport { ... } Then in the libary, and before including the header file in the place you want to use the class. I don't know if you might need to do anything differently for working with ","pontos":12},{"corpo":"Cookies are automatically handled by the browser when you make an AJAX call, so there's no need for your Javascript to mess around with cookies. ","pontos":1},{"corpo":"You should look at the article C++ Programming/Type Casting. It contains a good description of all of the different cast types. The following taken from the above link: const_cast const_cast(expression) The const_cast >() is used to add/remove const(ness) (or volatile-ness) of a variable. static_cast static_cast(expression) The static_cast >() is used to cast between the integer types. 'e.g.' char->long, int->short etc. Static cast is also used to cast pointers to related types, for example casting void* to the appropriate type. dynamic_cast Dynamic cast is used to convert pointers and references at run-time, generally for the purpose of casting a pointer or reference up or down an inheritance chain (inheritance hierarchy). dynamic_cast(expression) The target type must be a pointer or reference type, and the expression must evaluate to a pointer or reference. Dynamic cast works only when the type of object to which the expression refers is compatible with the target type and the base class has at least one virtual member function. If not, and the type of expression being cast is a pointer, NULL is returned, if a dynamic cast on a reference fails, a bad_cast exception is thrown. When it doesn't fail, dynamic cast returns a pointer or reference of the target type to the object to which expression referred. reinterpret_cast Reinterpret cast simply casts one type bitwise to another. Any pointer or integral type can be casted to any other with reinterpret cast, easily allowing for misuse. For instance, with reinterpret cast one might, unsafely, cast an integer pointer to a string pointer. ","pontos":35},{"corpo":"Static Cast static_cast doesn't do any run time checking of the types involved, which means that unless you know what you are doing, they could be very unsafe. It also only allows casting between related types, such as pointers or references between Base and Derived, or between fundamental types, such as long to int or int to float. It does not allow casts between fundamentally different types, such as a cast between a BaseA and BaseB if they are not related. This will result in a compile time error. Dynamic Cast dynamic_cast will do run time checking as well, and if the instance cannot be cast into another derived type, it will return a null pointer. Note: dynamic cast works only when the source type is polymorphic.Otherwise, compiler will give an error such as * error: cannot dynamic_cast 'b' (of type 'class base*') to type 'class inh1*' (source type is not polymorphic)* Examples If we have the following classes class B {}; class D : B {}; then you can do the following B* b = new D(); D* d1 = static_cast D* b; // Valid! d1 is a valid and correct pointer to a D D* d2 = dynamic_cast D* b; // Valid! d2 is a valid and correct pointer to a D In this example both pointers d1 and d2 will point to a correct typed version of b The problem comes in the following example: B* b = new B(); D* d1 = static_cast D* b; // Invalid! D* d2 = dynamic_cast D* b; // Valid, but d2 is now a null pointer Now d1 will point to a data segment of type D*, but the actual data is B*, and will lead to memory issues and corruption. d2 on the other hand will be a null pointer and can be checked for and handled correctly. Because dynamic_cast performs runtime type checking it is also slower. EDIT: Since dynamic_cast can incurr extra runtime, it can be turned off by instructing the compiler not to include Runtime Type Information. There are also other cast operators. Reinterpret Cast This is the ultimate cast, which disregards all kind of type safety, allowing you to cast anything to anything else, basically reassigning the type information of the bit pattern. int i = 12345; MyClass* p = reinterpret_cast MyClass* i; It is very dangerous unless you know what you are doing, and is basically the equivilant of C-cast. Like so; int i = 0; void *v = 0; int c = (int)v; // is valid int d = static_cast int (v); // is not valid, different types int e = reinterpret_cast int (v); // is valid, but very dangerous And then we have the const_cast > which removes the const-ness of a variable. ","pontos":152},{"corpo":"A word of caution: if foo: # do something Is not exactly the same as: if x is not None: # do something The former is a boolean value test and can evaluate to false in different contexts. There are a number of things that represent false in a boolean value tests for example empty containers, boolean values. None also evaluates to false in this situation but other things do too. ","pontos":19},{"corpo":"May I refer you to my earlier answer on another FOSS query (What level of programming should I have to contribute to open source) and add that scratch your own itch rather than attempt to conform to somebodies elses ideas. If a project doesn't interest you unless you have a quick bug fix or feature addition and want to submit a patch move along and find something you'll enjoy more. ","pontos":1},{"corpo":"I think the reasons for doing this vary from person to person, so I can't tell you why to do it. Here's why I did it: We were using eXist-db for a Small Business Innovative Research project. We had data in a few databases that was unacceptable to lose. It turned out that the internal handling of URIs was not ideal, which meant we could not access the data. After talking to the development team, none of them could put in the time necessary to fix things. So, I dug in full time for a few weeks and got everything fixed and committed. My contribution came from a business need, and was made possible by the fact that my boss was willing to let me work on it for that time, and donate it back to the community. ","pontos":1},{"corpo":"I'm afraid I think the answer is no. From the help text on http://docs.google.com/support/spreadsheets/bin/answer.py?answer=71291 query=arrayformula topic= type= The real power of ARRAYFORMULA comes when you take the result from one of those computations and wrap it inside a formula that does take array or range arguments: SUM, MAX, MIN, CONCATENATE, As vlookup takes a single cell to lookup (in the first argument) I don't think you can get it to work, without using a separate range of lookups. ","pontos":2},{"corpo":"Quicksort in Haskell: qsort [] = [] qsort (x:xs) = qsort (filter ( x) xs) ++ [x] ++ qsort (filter ( = x) xs) Although I couldn'd write Haskell at the time, I did understand this code and with it recursion and the quicksort algorithm. It just made click and there it was... ","pontos":4},{"corpo":"For primitives just use or print this variable straight away. PHP is dynamically typed language and variable will be casted to string on the fly. If you want to convert objects to strings you will need to define method that returns string. This method is forbidden to throw exceptions. ","pontos":11},{"corpo":"If you consider a warning (which is what [Obsolete] throws up) build-breaking, then just use the #warning compiler directive. Edit: I've never used it, but #error is also available. ","pontos":3},{"corpo":"How about writing a cursor to loop through the contents, attempting the cast for each entry? When an error occurs, output the primary key or other identifying details for the problem record. I can't think of a set-based way to do this. Edit - ah yes, I forgot about ISDATE(). Definitely a better approach than using a cursor. +1 to SQLMenace. ","pontos":1},{"corpo":"It's common practice to do this, especially to be able to include .h in the files that need it. Of course the performance is affected but try not to think about this problem until it arises :). It's better to start with the files separated and after that try to merge the .h's that are commonly used together to improve performance if you really need to. It all comes down to dependencies between files and this is very specific to each project. ","pontos":2},{"corpo":" Wouldn't the isdate() check take care of this? Run this to see what happens select isdate('20080131') select isdate('01312008') ","pontos":0},{"corpo":"You could create a user control (.ascx) to house the listbox. Then add a public event for the page. Public Event btnRemove() Then on the button click event in the usercontrol RaiseEvent btnRemove() You can also pass objects through the event just like any other method. This will allow your user control to tell your page what to delete. ","pontos":0},{"corpo":"Why not just make something up? An unknown attribute would surely break the build. [MyMadeUpAttributeThatBreaksTheBuildForSure] public class NotDoneYet {} ","pontos":-1},{"corpo":"It appears that the VSMDI problem is a known bug and has been around since VS2005 Team System but it has no clear fix as yet. Another reason to NOT use MS Test. An MSDN blog details how to run unit tests without VSMDI files. ","pontos":30},{"corpo":"For the PSP, I have seen the Software Process Dashboard, but it seems awfully difficult to use. ","pontos":3},{"corpo":" How about writing a cursor to loop through the contents, attempting the cast for each entry?When an error occurs, output the primary key or other identifying details for the problem record. I can't think of a set-based way to do this. Not totally setbased but if only 3 rows out of 1 million are bad it will save you a lot of time select * into BadDates from Yourtable where isdate(lastUpdate) = 0 select * into GoodDates from Yourtable where isdate(lastUpdate) = 1 then just look at the BadDates table and fix that ","pontos":2},{"corpo":"The ISDATE() would take care of the rows which were not formatted properly if it were indeed being executed first. However, if you look at the execution plan you'll probably find that the DATEDIFF predicate is being applied first - thus the cause of your pain. If you're using SQL Server Management Studio hit CTRL-L to view the estimated execution plan for a particular query. Remember, SQL isn't a procedural language and short circuiting logic may work, but only if you're careful in how you apply it. ","pontos":1},{"corpo":"What a gross DB structure. Anyway, I'd do something like this (note I prefer EXISTS to joins, but you can re-write them as joins if you like; most query analyzers will collapse them to the same query plan anyway). You may have to do some additional juggling one way or another to make it work... SELECT * FROM wp_posts p WHERE EXISTS( SELECT * FROM wp_term_relationship tr WHERE tr.object_id = p.id AND EXISTS( SELECT * FROM wp_term_taxonomy tt WHERE tt.term_taxonomy_id = tr.term_taxonomy_id AND tt.taxonomy = 'category' AND EXISTS( SELECT * FROM wp_terms t WHERE t.term_id = tt.term_id AND t.name = \"Category1\" ) ) AND EXISTS( SELECT * FROM wp_term_taxonomy tt WHERE tt.term_taxonomy_id = tr.term_taxonomy_id AND tt.taxonomy = 'post_tag' AND EXISTS( SELECT * FROM wp_terms t WHERE t.term_id = tt.term_id AND t.name = \"Nuclear\" ) AND EXISTS( SELECT * FROM wp_terms t WHERE t.term_id = tt.term_id AND t.name = \"Deals\" ) ) ) ","pontos":2},{"corpo":"I'd suggest you to use the #error directive. Another pretty unknown attribute that might do the work is the conditional attribute (depending on what you're trying to ahieve) [Conditional(\"CONDITION\")] public static void MiMethod(int a, string msg) which will remove the method invocation from the IL code itself if \"MY_CONDITION\" is defined. ","pontos":0},{"corpo":"If you can't modify the structures then you have no alternative to writing a manual conversion function because overloading conversion operators only works within the class body. There's no other way. ","pontos":2},{"corpo":"Create an FxCop rule, and add FxCop to your integration build in order to check for this. You'll get warnings, rather than a failing build. Attributes 'run' at reflection time rather than build time. Alternatively (and this is rather nasty) put a compiler directive around the method you don't want to be called. Then your code will break if you call it, but you can set up a build that passes the right compiler directive and doesn't. ","pontos":0},{"corpo":"Remove cursors wherever the are not neceesary. ","pontos":1},{"corpo":"<p>If my original post was the correct understanding and the discussion from Sun that was linked to is accurate (which I think it might be), then I think you have to make a trade off between clarity and performance.</p> <p>Ask yourself these questions:</p> <ol> <li>Does the Singleton object make what I'm doing more clear?</li> <li>Do I need an object to do this task or is it more suited to static methods?</li> <li>Do I need the performance that I can gain by not using a Singleton?</li> </ol> ","pontos":3},{"corpo":"@seanboy what OS are you running? Vista and gems are known for not playing nice... ","pontos":-2},{"corpo":"I'm developing .NET apps in a Vista VM under VMWare Fusion. Obviously you need a lot of memory, but other than not having Aero, I haven't run into any problems yet. ","pontos":1},{"corpo":"I don't think Kibbee advice is correct. VMware Fusion (for the mac) currently supports up to DirectX9. The Vista integration is very good. If you have any trouble, you can natively boot into your Virtual Machine (If you have set it up as a BootCamp partition on the mac). I don't see any trouble with this setup, although I would not do it myself. The only thing, that my be a problem to you, is the keyboard-layout. The mac-keyboard has a different layout to pc-keyboards. (Especially on a german mac running a german windows, some characters might be a bit harder to type). You will have to relearn some parts of the keyboard! ","pontos":0},{"corpo":"If you have 2 users hitting it at the same time they will get the same id. Why didn't you use an id table with an identity instead, insert into that and use that as the unique (which is guaranteed) id, this will also perform much faster sp_getNextID never ever prefix procs with sp_, this has performance implication because the optimizer first checks the master DB to see if that proc exists there and then th local DB, also if MS decide to create a sp_getNextID in a service pack yours will never get executed ","pontos":2},{"corpo":"I am developing .net applications using XP Pro in VMWare Fusion and I am not finding any issues. I am not even seeing any performance issues as the hardware in the MacBook Pro is much better than the hardware I had in my previous laptop. I found that there were a few things that I had to fiddle with to make the experience the same as working on my previous laptop. I had to install Sharp Keys to be able to access the right-click/context menu key on the keyboard, which I use often when in VS. I also made sure that some of the Mac OS keyboard and mouse shortcuts were not registered in VMWare Fusion, to stop strange things happening. I just noticed that I am only allowed my VM to use 1GB of memory, maybe I should up this just a little. There are posts out there that warn about assigning too much memory to a VM. One thing that is suggested for improving performance is to run the VM on another spindle. I haven't found a suitably priced 7200rpm portable drive yet, so I can't comment on this. [Edit] I knew I had seen this somewhere, Setting Up Windows Server 2008 VMWare Virtual Machines For .Net - This is something that I have been meaning to try out, I just haven't got around to it yet. (Too much time spent reading CrackOverflow) ","pontos":0},{"corpo":"You answered in your comment: equals returned false but identity hash code was same, assume o1 == o2 Unfortunately you cannot assume that. Most of the time that is going to work, but in some exceptionnal cases, it won't. And you cannot know when. When such a case appear, it would lead to lose instances in TreeSets for example. ","pontos":1},{"corpo":" Read up on Star schema's but starting out with one huge flat table is a quick and dirty place to start. Don't be afraid to replicates data for Performance. If you are not using a query tool MDX can be a hurdle, dumping your sprocs to flat tables and reporting from them may help get you to the next step. If your sprocs are providing live data any type of aggregate (cubes) will have some type of data delay and your users may be sensitive to that. ","pontos":1},{"corpo":"@sparkes The link to \"search for color on boxesandarrows\" is broken. I'm not sure how to get it to work without having the user go to the site and type color into the search box. ","pontos":0},{"corpo":"According to this guy, IIf can take up to 6x as long as If/Then. YMMV. ","pontos":5},{"corpo":"in ksh, in vi mode, if you hit 'v' while in command mode it will spawn a full vi session on the contents of your current command line. You can then edit using the full range of vi commands (global search and replace in your case). When :wq from vi, the edited command is executed. I'm sure something similar exists for bash. Since bash tends to extend its predecessors, there's probably something similar. ","pontos":2},{"corpo":"I'm not really sure about the . That's pretty much what the == is used for. You might rather want to use the - it's more in parallel with . ","pontos":0},{"corpo":"I've not used the Android Emulator but I have set the $http_proxy environment variable for perl and wget and a few cygwin tools on windows. That might work for you for android, but the slash in the domain name seems like a potential problem. I know I tried having my domain \"GLOBAL\" in there, but ended up taking it out and sticking with: One problem I run into a lot though is programs that cannot be told to use the proxy for DNS queries too. In cases where they don't I always get a host name not found. I'd like to find a local dns resolver that can use the proxy for all the programs that won't. ","pontos":1},{"corpo":"Strange that I did not see WireShark when I visited SourceForge. The top result of the 60 returned was a bizarre german thing. ","pontos":0},{"corpo":"IIf() runs both the true and false code. For simple things like numeric assignment, this isn't a big deal. But for code that requires any sort of processing, you're wasting cycles running the condition that doesn't match, and possibly causing side effects. Code illustration: Module Module1 Sub Main() Dim test As Boolean = False Dim result As String = IIf(test, Foo(), Bar()) End Sub Public Function Foo() As String Console.WriteLine(\"Foo!\") Return \"Foo\" End Function Public Function Bar() As String Console.WriteLine(\"Bar!\") Return \"Bar\" End Function End Module Outputs: Foo! Bar! ","pontos":37},{"corpo":" Please let me know, if you have any (good or bad) experience with model-driven approaches or why you think it's not interesting at all. I think the contributors here are part of the \"No Silver Bullet\" camp (I am definitely). If MDA worked (equals to \"huge savings\"), we would know it, that is for sure. The question is: how far \"meta\" can you go while keeping your system manageable? This was the turning point in UML 2.0 when they introduced a more formal meta-meta-model. So far, I haven't seen a real world usage of the modelisation power of UML 2.0 (but my world is rather limited). Besides, you have only two choices with a model-driven approach: generate code, or having a runtime exploiting your model. The ultimate constraint-free code generator is called \"human\", whereas the ultimate runtimes where found in the 4GLs (what is the current number nowadays?). Maybe that would explain the lack of enthousiasm. ","pontos":1},{"corpo":"You should probably raise an exception if it gets to that last line --when a hash collision happens. I do have a question though: you are doing a total ordering on the hash's, which I guess is fine, but shouldn't some function be passed to it to define a Lexicographical order? int h1 = System.identityHashCode(o1); int h2 = System.identityHashCode(o2); if (h1 != h2) { return h1 h2 ? -1 : 1; } I can imagine that you have the objects as a tuple of two integers that form a real number. But you wont get the proper ordering since you're only taking a hash of the object. This is all up to you if hashing is what you meant, but to me, it doesn't make much sense. ","pontos":1},{"corpo":"I would look into DeltaXML. It seems to have the features you're looking for. They even have a guide on how to compare schemas. ","pontos":4},{"corpo":"Since this is a development environment, I agree with Greg, just use trial and error. It's not that crucial to get it perfectly right. But if you do a lot of work in the VM, why not give it at least half of the 2GB? ","pontos":0},{"corpo":" I agree this is not ideal, hence the comment. Any suggestions? I think there is now way you can solve that, because you cannot access the one and only one thing that can distinguish two instances: their address in memory. So I have only one suggestion: reconsider your need of having a general total ordering process in Java :-) ","pontos":0},{"corpo":"I do it only when it helps with separation of concerns. Like maybe cross-project I would provide an interface for implementers in one of my library project and the implementing project would inject whatever specific implementation they want in. But that's about it... all the other cases it'd just make the system unnecessarily complex ","pontos":2},{"corpo":"Think about your design. DI allows you to change how your code functions via configuration changes. It also allows you to break dependencies between classes so that you can isolate and test objects easier. You have to determine where this makes sense and where it doesn't. There's no pat answer. A good rule of thumb is that if its too hard to test, you've got some issues with single responsibility and static dependencies. Isolate code that performs a single function into a class and break that static dependency by extracting an interface and using a DI framework to inject the correct instance at runtime. By doing this, you make it trivial to test the two parts separately. ","pontos":9},{"corpo":"Thanks for your answer. Some comments on that: PC-Lint: They do mention that they have \"no-holds-barred C++ exception analysis\" not sure what that means. And unfortunately they do not offer a trial version. And I don't have the money to buy $239 software without knowing that it will solve my problem. But I will mail them and ask. Coverity: Couldn't find any mention of exceptions at all in their description. They say they have a 3rd interface where it's possible to make a plugin to analyze that. Not really what I'm looking for. AQtime: Only have execution time analysis of exception. ","pontos":1},{"corpo":"Even with all the facts and processes in the world.. every decision boils down to a judgment call - Forgot where I read that I think it's more of a experience / flight time call. Basically if you see the dependency as a candidate object that may be replaced in the near future, use dependency injection. If I see 'classA and its dependencies' as one block for substitution, then I probably won't use DI for A's deps. ","pontos":1},{"corpo":" Hey, look at what I found! http://gafter.blogspot.com/2007/03/compact-object-comparator.html Oh yes, I forgot about the IdentityHashMap (Java 6 and above only). Just have to pay attention at releasing your comparator. ","pontos":2},{"corpo":"Damn, I really thought you were talking about the operator all along. ;-) Anyway  Does this If function perform better than the IIf function? Definitely. Remember, it's built into the language. Only one of the two conditional arguments has to be evaluated, potentially saving a costly operation. Does the If statement trump the If and IIf functions? I think you can't compare the two because they do different things. If your code semantically performs an assignment you should emphasize this, instead of the decision-making. Use the operator here instead of the statement. This is especially true if you can use it in the initialization of a variable because otherwise the variable will be default initialized, resulting in slower code: Dim result = If(a 0, Math.Sqrt(a), -1.0) ' versus Dim result As Double ' Redundant default initialization! If a 0 Then result = Math.Sqrt(a) Else result = -1 End If ","pontos":13},{"corpo":"TextMate + the Flex and ActionScript 3 bundles is a great combo. Throw in ProjectPlus and you have an almost full featured development environment. What's missing is visual design tools (which I'm sceptical of anyway), debugger (the command line version isn't very easy to work with) and a profiler. I've long used TextMate and the additions mentioned above for all my Flex development, but lately the lack of debugger and profiler has made me use FlexBuilder too, just to get those tools. ","pontos":6},{"corpo":"Hacky answer would be to grab the IE Developer Toolbar, find the tag that has the scrollbar, and alter your CSS file to add the overflow:hidden property to it. ","pontos":3},{"corpo":"How do you mean \"Test the database\"? If you are testing foreign keys, a simply script to insert invalid data is all you should need. Testing a database could imply a great number of issues. Does it have all the tables? Are the tables correct? Are the indexes in place? Did the latest updates get applied? Has the data been migrated? Is the even valid? Are the foreign keys correct? There is a lot to test in a database so you are unlikely to find a simple way to test it. I find that a combination of test stored procedures and some Nunit unit tests do most of the vetting of my databases. ","pontos":1},{"corpo":"Wireshark is great.. but another option would be via PowerShell. I've used the Get-Packet script from Jeff Hicks at Sapien Technologies as a really lightweight packet sniffer. You get custom objects representing your packets and can do whatever filtering you need to via PowerShell. The other script in the pair is Analyze-Packet, which can summarize the results of a packet capture. ","pontos":0},{"corpo":" Should I be throwing the errors in the ashx, or should I be returning a status code as part of the data returned by the call to userCreation.ashx, then using this to decide what action to take? How do you handle these situations? Personally, if possible, I would prefer to handle this on the server side and work up a message to the user there. This works very well in a scenario where you only want to display a message to the user telling them what happened (validation message, essentially). However, if you want to perform an action based on what happened on the server, you may want to use a status code and write some javascript to perform various actions based on that status code. ","pontos":9},{"corpo":"I started out with RadRails then moved to Aptana when they took it over, wasn't too bad. Got a macbook and have been using Textmate, never going back. ","pontos":1},{"corpo":"For debugging, I usually just create an element (in the case below: ) on the page and write the XmlHttpRequest to it: error: function (XMLHttpRequest, textStatus, errorThrown) { $(\"#error\").html(XMLHttpRequest.status + \"\\n hr / \" + XMLHttpRequest.responseText); } Then you can see the types of errors that are occurring and capture them correctly: if (XMLHttpRequest.status === 404) // display some page not found error if (XMLHttpRequest.status === 500) // display some server error In your ashx, can you throw a new exception (e.g \"Invalid User\" etc.) and then just parse that out of the ? For me when I get an error the isn't the standard Asp.Net error page, it's a JSON object containing the error like this: { \"Message\":\"Index was out of range. Must be non-negative and less than the size of the collection.\\r\\n Parameter name: index\", \"StackTrace\":\" at System.ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument argument, ExceptionResource resource)\\r\\n at etc...\", \"ExceptionType\":\"System.ArgumentOutOfRangeException\" } Edit: This could be because the function I'm calling is marked with these attributes: WebMethod() _ ScriptMethod() _ ","pontos":16},{"corpo":"have you tried doing things in elevated privileges mode? including reinstalling and all... ","pontos":0},{"corpo":" Is this just expected/undefined behaviour? Have I done something wrong or have I in fact found a Compiler Bug? No bug just the defined behaviour that optimisation options can produce odd code which might not work :) EDIT: If you think you have found a bug in GCC the mailing lists will be glad you dropped by but generally they find some hole in your knowledge is to blame and mock mercilessly :( In this case I think it's probably the -O options attempting shortcuts that break your code that need working around. ","pontos":-2},{"corpo":"You can move the files around in StarTeam also. Then merge after that. Whatever you do, make sure you don't delete the files and re-add in StarTeam. You'll lose the file history if you do that. ","pontos":3},{"corpo":"I think its VS2008 I am having all sorts of wierd things happen with it but im running xp. Not to the degree that you say where it is messing with volume controls. My wierd things are in VS2008. For example I place a gridview on page 1 go to page 2 then back to page 1 and my gridview will have moved.. Its just buggy.. really buggy ","pontos":0},{"corpo":"I seem to remeber having a similar problem a long time ago, the problem was related to accessing the smtp server to despatch the reports and was resolved by applying a patch to the server. ","pontos":0},{"corpo":"It is the cost of setting up the connection, transferring the data and then tearing it down. It will eat up your performance. Evidence is harder to come by but consider the following... Let's say it takes x microseconds to make a connection. Now you want to make several requests and get data back and forth. Let's say that the difference in transport time is negligable between one connection and many (just ofr the sake of argument). Now let's say it takes y microseconds to close the connection. Opening one connection will take x+y microseconds of overhead. Opening many will take n * (x+y). That will delay your execution. ","pontos":3},{"corpo":"I would assume that it is because your requests are not being sent asynchronously, since your requests are done iteratively on the server, blocking each time, you have to pay for the overhead of creating a connection each time, when you only have to do it once... In Flex, all web service calls are automatically called asynchronously, so you it is common to see multiple connections, or queued up requests on the same connection. Asynchronous requests mitigate the connection cost through faster request / response time...because you cannot easily achieve this in PHP without out some threading, then the performance hit is greater then simply reusing the same connection. that's my 2 cents... ","pontos":0},{"corpo":"Rob Conery's MVC Storefront webcast series has a video on this issue (he gets to the database around 5:30). He stores a list of cultures, and then has a Product table for non-localized data and a ProductCultureDetail table for localized text. ","pontos":1},{"corpo":"I personnally used phpMyID just for StackOverflow. It's a simple two-files PHP script to put somewhere on a subdomain. Of course, it's not as easy as installing a .deb, but since OpenID relies completely on HTTP, I'm not sure it's advisable to install a self-contained server... ","pontos":5},{"corpo":"Setting up a DB connection is usually quite heavy. A lot of things are going on backstage (DNS resolution/TCP connection/Handshake/Authentication/Actual Query). I've had an issue once with some weird DNS configuration that made every TCP connection took a few seconds before going up. My login procedure (because of a complex architecture) took 3 different DB connections to complete. With that issue, it was taking forever to log-in. We then refactored the code to make it go through one connection only. ","pontos":2},{"corpo":"Database connections are a limited resource. Some DBs have a very low connection limit, and wasting connections is a major problem. By consuming many connections, you may be blocking others for using the database. Additionally, throwing a ton of extra connections at the DB doesn't help anything unless there are resources on the DB server sitting idle. If you've got 8 cores and only one is being used to satisfy a query, then sure, making another connection might help. More likely, though, you are already using all the available cores. You're also likely hitting the same harddrive for every DB request, and adding additional lock contention. If your DB has anything resembling high utilization, adding extra connections won't help. That'd be like spawning extra threads in an application with the blind hope that the extra concurrency will make processing faster. It might in some certain circumstances, but in other cases it'll just slow you down as you thrash the hard drive, waste time task-switching, and introduce synchronization overhead. ","pontos":6},{"corpo":"Could be wrong but the exection stack is showing the last completed step. The current step has not completed. The Debugger is showing the currently executing step. ","pontos":-1},{"corpo":"I got an answer from PC-Lint. And while they do analyze exception, it seems more from a stand point of catching errors in your code. Actually, from the example page they sent me, the whole package seems to be to analyze the code for errors and mistakes. That's not what I want, I need something like a call graph but for exceptions. I guess my search continues... ","pontos":0},{"corpo":"Answering the purely subject question \"recommend me a better C IDE and compiler\" I find Ming32w and Code::blocks (now with combined installer) very useful on windows but YMMV as you are obviously used to the MS IDE and are just struggling with C. May I suggest you concentrate on console applications to get a feel for the language first before you attempt to tie it together with a windows UI which in my experience is the hardest bit of windows development. ","pontos":10},{"corpo":"Another item I wrestle with is where should I use dependency injection? Where do you take your dependency on StructureMap? Only in the startup application? Does that mean all the implementations have to be handed all the way down from the top-most layer to the bottom-most layer? ","pontos":0},{"corpo":"If it's not in the dictionary, probably not. ","pontos":0},{"corpo":"The problem is almost certainly the select. Is there anyway you could extract all the text at once then iterate over internal variables? ","pontos":1},{"corpo":"I'm darned if I can find a reference at the moment, but I'm 99% sure that you are always supposed to be able to take the address of an argument, and it's up to the compiler to finesse the details of calling conventions, register usage, etc. Indeed, I would have thought it to be such a common requirement that it's hard to see there can be general problem in this - I wonder if it's something about the volatile pointers which have upset the optimisation. Personally, I might do try this to see if it compiled better: void foo(unsigned int x) { volatile unsigned int* pArg = x; *(volatile unsigned int*)(0x4000000 + 0xd4) = (unsigned int)pArg; } ","pontos":1},{"corpo":" I used to do exactly the same thing.... then I switched to maven. Oh, it's Maven 2. I was afraid that someone was still seriously using Maven nowadays. Leaving the jokes aside: if you decide to switch to Maven 2, you have to take care while looking for information, because Maven 2 is a complete reimplementation of Maven, with some fundamental design decisions changed. Unfortunately, they didn't change the name, which has been a great source of confusion in the past (and still sometimes is, given the \"memory\" nature of the web). Another thing you can do if you want to stay in the Ant spirit, is to use Ivy to manage your dependencies. ","pontos":0},{"corpo":"I'd imagine any method of sending fonts with a web page would pose some sort of security risk. I have heard of methods where, in the case that the client doesn't have the required font, the text can be dynamically replaced with an image of or some sort a flash displayed. The only one like this I can find now is at AListApart but it may already be redundant. Said method would also require css, images and javascript to work and could be painful to implement across browsers. ","pontos":0},{"corpo":"@Sean Chambers FYI, the .NET Timer class is not for diagnostics, it generates events at a preset interval, like this (from MSDN): System.Timers.Timer aTimer; public static void Main() { // Create a timer with a ten second interval. aTimer = new System.Timers.Timer(10000); // Hook up the Elapsed event for the timer. aTimer.Elapsed += new ElapsedEventHandler(OnTimedEvent); // Set the Interval to 2 seconds (2000 milliseconds). aTimer.Interval = 2000; aTimer.Enabled = true; Console.WriteLine(\"Press the Enter key to exit the program.\"); Console.ReadLine(); } // Specify what you want to happen when the Elapsed event is // raised. private static void OnTimedEvent(object source, ElapsedEventArgs e) { Console.WriteLine(\"The Elapsed event was raised at {0}\", e.SignalTime); } So this really doesn't help you know how long something took, just that a certain amount of time has passed. The timer is also exposed as a control in System.Windows.Forms... you can find it in your designer tool box in VS05/VS08 ","pontos":5},{"corpo":"[C++] I agree with the \"use it when you have to\" brigade. Decorating code unnecessarily with this isn't a great idea because the compiler won't warn you when you forget to do it. This introduces potential confusion for people expecting this to always be there, i.e. they'll have to think about it. So, when would you use it? I've just had a look around some random code and found these examples (I'm not passing judgement on whether these are good things to do or otherwise): Passing \"yourself\" to a function. Assigning \"yourself\" to a pointer or something like that. Casting, i.e. up/down casting (safe or otherwise), casting away constness, etc. Compiler enforced disambiguation. ","pontos":4},{"corpo":"I would say don't create a huge ByteBuffer that contains ALL of the data at once. Create a much smaller ByteBuffer, fill it with data, then write this data to the FileChannel. Then reset the ByteBuffer and continue until all the data is written. ","pontos":6},{"corpo":"Thanks for the advice, the pointer is to an C style abstract structure which I think if I leave that structure exposed to the managed code is going to cause further pain due to its lack of defined structure. So what I think I will do is wrap the C library in C++ and then wrap the C++ wrapper with managed C++, which will prevent exposing those C structures to managed code. ","pontos":0},{"corpo":"Short answer: there's no way to do inline variable assignment in a while loop in Python. Meaning that I cannot say: while x=next(): // do something here! Since that's not possible, there are a number of \"idiomatically correct\" ways of doing this: while 1: x = next() if x != END: // Blah else: break Obviously, this is kind of ugly. You can also use one of the \"iterator\" approaches listed above, but, again, that may not be ideal. Finally, you can use the \"pita pocket\" approach that I actually just found while googling: class Pita( object ): __slots__ = ('pocket',) marker = object() def __init__(self, v=marker): if v is not self.marker: self.pocket = v def __call__(self, v=marker): if v is not self.marker: self.pocket = v return self.pocket Now you can do: p = Pita() while p( next() ) != END: // do stuff with p.pocket! Thanks for this question; learning about the idiom was really cool! :) EDIT: I'd like to give credit where credit is due. The 'pita pocket' idiom was found here ","pontos":4},{"corpo":"Longhorn213 almost has the right answer, but as as Sean Chambers and bdukes say, you should use ctrl is IInterfaceToFind instead of ctrl.GetType() == aTypeVariable The reason why is that if you use .GetType(), you will get the true type of an object, not necessarily what it can also be cast to in its inheritance/Interface implementation chain. Also, .GetType() will never return an abstract type/interface since you can't new up an abstract type or interface. GetType() returns concrete types only. The reason this doesn't work if(ctrl is typeToFind) Is because the type of the variable typeToFind is actually System.RuntimeType, not the type you've set its value to. Example, if you set a string's value to \"foo\", its type is still string not \"foo\". I hope that makes sense. It's very easy to get confused when working with types. I'm chronically confused when working with them. The most import thing to note about longhorn213's answer is that you have to use recursion or you may miss some of the controls on the page. Although we have a working solution here, I too would love to see if there is a more succinct way to do this with LINQ. ","pontos":7},{"corpo":"Go to Java/Editor/Content Assist/Advanced in Preferences, and make sure that the correct proposal kinds are selected. Same kind of thing happened to me when I first moved to 3.4. ","pontos":2},{"corpo":"Expression trees are useful when you need to access function logic in order to alter or reapply it in some way. Linq to SQL is a good example: //a linq to sql statement var recs ( from rec in LinqDataContext.Table where rec.IntField 5 select rec ); If we didn't have expression trees this statement would have to return all the records, and then apply the C# where logic to each. With expression trees that can be parsed into SQL: --SQL statment executed select * from [table] where [table].[IntField] 5 ","pontos":4},{"corpo":"I've been using XCache for more than a year now with no problems at all. I tried to switch to eAccelerator, but ended up with a bunch of segmentation faults (it's less forgiving of errors). The major benefit to eAccelerator is that it's not just an opcode cache, it's also an optimizer. You should fully test out your application with each one of them to make sure there aren't any problems, and then I'd use apachebench to test it under load. ","pontos":1},{"corpo":"My own rule of thumb: I never throw Exception, except in unit tests when what you throw is irrelevant and theres no reason to spend any extra time on it. I create my own custom exception type for errors occuring in my custom business logic. This exception type is used as much as possible for recasting other exceptions, except in cases where it makes sense for the client to have visibility into what actually occurred. ","pontos":0},{"corpo":"Does df --sync work? ","pontos":-1},{"corpo":"Are you sure that \"build automatically\" in the Project menu is checked? :-) Another thing: is the Problems view, unfiltered, completely clear of compilation errors and of classpath errors? ","pontos":1},{"corpo":"Someone else mentioned this, then deleted it. If you want to style all textareas and text inputs the same way without classes, use the following CSS (does not work in IE6): input[type=text], textarea { width: 80%; } ","pontos":3},{"corpo":"you will have to enumerate to get a count. Other constructs like the List keep a running count. ","pontos":8},{"corpo":"Yes, sort of. There is no support included in the trunk, you need to write your own dialect. Or you can port the Paradox dialect created for Hibernate. ","pontos":1},{"corpo":"Wrap it in an interface and mock it. ","pontos":0},{"corpo":"I would simply go with installing SVN, and using the SVN Daemon, and completely ignoring Apache. There should be no appliance needed. Very simple to install, very easy to configure. Just take a vanilla windows/linux box and install the subversion server. It'll probably take all of 1/2 and hour to set up. ","pontos":6},{"corpo":"I read the Wikipedia article, but I'm not sure how I might use it for .NET programming (web based or otherwise). ","pontos":0},{"corpo":"I work on windows mobile full time and have never really come across a good Windows Mobile scripting implementation unfortunately. For some reason MS has never seen the need for it. For example, even though you can actually get a command console on WM, it does not support running batch files, even though all the commands are still there and it would be relatively easy. There is definitely not a VBScript engine I've ever heard of nor JScript. There is PythonCE but the WM specific support is minimal and you don't get access to a lot of WM only things. Also, I've done a lot of work with a company called SOTI which has a product called MobiControl that does incorporate a basic scripting engine. Though most of the commands are specific to their system and actually have to be run from a desktop-side management console. Given all of the times I have tried to find a good scripting engine for WM myself you would think I would've just written one ;) So, sorry, but the basic answer is no, there is not a scripting engine available for VB in the context that you specified. ","pontos":5},{"corpo":"Are they participating in the stand-up meetings? You could propose to have a representative at each (or some) of them, to ask them for input before the end of the sprint ","pontos":0},{"corpo":" Good suggestions, but rest assured, we have tried all of the usual troubleshooting. What I'm hoping is that this is a .NET issue that someone might know about, that we can work on solving. My feeling is that no matter how bizarre the underlying cause, the usual troubleshooting steps are your best bet for locating the issue. Since this is a performance issue, good measurements are invaluable. The overall process CPU usage is far too broad a measurement. Where is your service spending its time? You could use a profiler to measure this, or just log various section start and stops. If you aren't able to do even that, then use Andrea Bertani's suggestion -- isolate sections by removing others. Once you've located the general area, then you can make even finer-grained measurements, until you sort out the source of the CPU usage. If it's not obvious how to fix it at that point, you at least have ammunition for a much more specific question. If you have in fact already done all this usual troubleshooting, please do let us in on the secret. ","pontos":0},{"corpo":"The finalize method is never invoked more than once by a JVM for any given object. You shouldn't be relying on finalize anyway because there's no guarantee that it will be invoked. If you're calling finalize because you need to execute clean up code then better to put it into a separate method and make it explicit, e.g: public void cleanUp() { . . . } myInstance.cleanUp(); ","pontos":1},{"corpo":"This is a CSS question: the width includes the border and padding widths, which have different defaults for INPUT and TEXTAREA in different browsers, so make those the same as well: !DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\" html head title width /title style type=\"text/css\" textarea, input { padding:2px; border:2px inset #ccc; width:20em; } /style /head body p input/ br/ textarea /textarea /p /body /html This is described in the Box dimensions section of the CSS specification, which says: The box width is given by the sum of the left and right margins, border, and padding, and the content width. ","pontos":3},{"corpo":"TBH, I have had a couple of instances like this where files \"seemed to go crazy\".. However, upon investigation it has appeared that the files have changed in some way, shape or form.. (e.g. sometimes changes can be made to the file by inadvertantly changing a property somewhere that seems unrelated). I think there are too many possible issues that could really cause this, and based on the fact that the problem has been resovled, it seems like an answer will not be found.. ","pontos":0},{"corpo":"OK, sorry that didn't work... I am no expert on ASP.NET impersonation, I tend to use app pools which I don't think you can do on W2K Have you tried writing a tiny little test app which does the same query, and then running that as various users? I am reluctant to post a chunk of MS framework code here, but you could use either Reflector or this: http://www.codeplex.com/NetMassDownloader to get the source code for the relevant bits of the framework so that you could try implementing various bits to see where it fails. Can you get any other info about the process without getting Access Denied? ","pontos":0},{"corpo":"The problem is I'm worried about breaking the build in the meantime while I'm moving folders in StarTeam. I suppose the only way to avoid that is to be ready to upload updated project files as soon as I move things around in StarTeam and do it as quickly as possible. ","pontos":0},{"corpo":"this is because if the data you insert is not in the order of the index, SQL will have to split pages to make room for additional rows to keep them together logically ","pontos":1},{"corpo":"In general, avoid allocating from the heap unless you have to. If you have to, use reference counting for objects that are long-lived and need to be shared between diverse parts of your code. Sometimes you need to allocate objects dynamically, but they will only be used within a certain span of time. For example, in a previous project I needed to create a complex in-memory representation of a database schema -- basically a complex cyclic graph of objects. However, the graph was only needed for the duration of a database connection, after which all the nodes could be freed in one shot. In this kind of scenario, a good pattern to use is something I call the \"local GC idiom.\" I'm not sure if it has an \"official\" name, as it's something I've only seen in my own code, and in Cocoa (see NSAutoreleasePool in Apple's Cocoa reference). In a nutshell, you create a \"collector\" object that keeps pointers to the temporary objects that you allocate using new. It is usually tied to some scope in your program, either a static scope (e.g. -- as a stack-allocated object that implements the RAII idiom) or a dynamic one (e.g. -- tied to the lifetime of a database connection, as in my previous project). When the \"collector\" object is freed, its destructor frees all of the objects that it points to. Also, like DrPizza I think the restriction to not use templates is too harsh. However, having done a lot of development on ancient versions of Solaris, AIX, and HP-UX (just recently - yes, these platforms are still alive in the Fortune 50), I can tell you that if you really care about portability, you should use templates as little as possible. Using them for containers and smart pointers ought to be ok, though (it worked for me). Without templates the technique I described is more painful to implement. It would require that all objects managed by the \"collector\" derive from a common base class. ","pontos":1},{"corpo":"After performing large data manipulation operations, you frequently have to update the underlying indexes. You can do that by using the UPDATE STATISTICS [table] statement. The other option is to drop and recreate the index which, if you are doing large data insertions, will likely perform the inserts much faster. You can even incorporate that into your stored procedure. ","pontos":2},{"corpo":"That may sound stupid, but why don't you try to get a DOMNode object in the first place and use the DOMNode property? How do you end up with a DOMElement object? ","pontos":0},{"corpo":"This due to the fact that when SQL Server indexes table with data it is able to produce exact statistics of values in indexed column. At some moments SQL Server will recalculate statistics, but when you perform massive inserts the distribution of values may change after the statistics was calculated last time. The fact that statistics is out of date can be discovered on Query Analyzer. When you see that on a certain table scan number of rows expected differs to much from actual numbers of rows processed. You should use UPDATE STATISTICS to recalculate distribution of values after you insert all the data. After that no performance difference should be observed. ","pontos":1},{"corpo":"According to this simple test program, the JVM will still make its call to finalize() even if you explicitly called it: private static class Blah { public void finalize() { System.out.println(\"finalizing!\"); } } private static void f() throws Throwable { Blah blah = new Blah(); blah.finalize(); } public static void main(String[] args) throws Throwable { System.out.println(\"start\"); f(); System.gc(); System.out.println(\"done\"); } The output is: start finalizing! finalizing! done Every resource out there says to never call finalize() explicitly, and pretty much never even implement the method because there are no guarantees as to if and when it will be called. You're better off just closing all of your resources manually. ","pontos":23},{"corpo":"I can enumerate the process (ie, the GetProcessById function works), and we have other code that gets the EXE name and other bits of information. I will give the test app a try. I'm also going to attempt to use WMI to get this information if I can't get the C# implementation working properly in short order (this is not critical functionality, so I can't spend days on it). ","pontos":0},{"corpo":"The solution depends on why you don't want to enumerate through the collection. If it's because enumerating the collection might be slow, then there is no solution that will be faster. You might want to consider using an ICollection instead if possible. Unless the enumeration is remarkably slow (e.g. it reads items from disk) speed shouldn't be a problem though. If it's because enumerating the collection will require more code then it's already been written for you in the form of the .Count() extension method. Just use MyEnumerable.Count(). If it's because you want to be able to enumerate the collection after you've counted then the .Count() extension method allows for this. You can even call .Count() on a collection you're in the middle of enumerating and it will carry on from where it was before the count. For example: foreach (int item in Series.Generate(5)) { Console.WriteLine(item + \"(\" + myEnumerable.Count() + \")\"); } will give the results 0 (5) 1 (5) 2 (5) 3 (5) 4 (5) If it's because the enumeration has side effects (e.g. writes to disk/console) or is dependant on variables that may change between counting and enumerating (e.g. reads from disk) [N.B. If possible, I would suggest rethinking the architecture as this can cause a lot of problems] then one possibility to consider is reading the enumeration into an intermittent storage. For example: List int seriesAsList = Series.Generate(5).ToList(); All of the above assume you can't change the type (i.e. it is returned from a library that you do not own). If possible you might want to consider changing to use an ICollection or IList (ICollection being more widely scoped than IList) which has a Count property on it. ","pontos":13},{"corpo":"I would agree with Kibbee. I wanted to jump in with SVN so I installed the daemon and had everything up and running in no time. It took me longer to get all the commands down for adding and committing files than the installation. ","pontos":0},{"corpo":"Is it an SQL Server database? If so, use instead of making the comparison (MSDN). ","pontos":1},{"corpo":"I have run several benchmarks with eAcclerator, APC, XCache, and Zend Optimizer (even though Zend is an optimizer, not a cache). Result: eAccelerator is fastest (in all tests), followed by XCache and APC. (The one in the diagram is the number of seconds to call a WordPress home page 10,000 times). Zend Optimizer made everything slower (!). ","pontos":5},{"corpo":"The preferred method is to actually use the conditional attribute to wrap your debug calls, not use the compiler directives. #ifs can get tricky and can lead to weird build problems. An example of using a conditional attribute is as follows (in C#, but works in VB.NET too): [ Conditional(\"Debug\") ] private void WriteDebug(string debugString) { // do stuff } When you compile without the DEBUG flag set, any call to WriteDebug will be removed as was assumed was happening with Debug.Write(). ","pontos":18},{"corpo":"Because I need to test the DOMElement object for the \"in-reply-to\" string in one of its attribute values. Blame Google for making their XML structure so difficult to work with. Now I think I just need the current DOMNode in the DOMNodeList and then I can get its parent?? $links = $domXPath- query('//tns:entry//tns:link'); // $links is a DOMNodeList. $link is a DomElement. foreach ($links as $link) { foreach ($link- attributes as $attrName = $attrNode) { if (ereg(\"in-reply-to\", $attrNode- nodeValue)) { $intReplyCount = $intReplyCount + 1; echo $link- attributes- getNamedItem(\"href\")- nodeValue . \"\\n\"; // STEP 1 - copy this reply node to a XmlDocument $objReplyXML- load('empty.xml'); $temp = $objReplyXML- getElementsByTagName('feed')- item(0); // Get the parent entry node of this link element $importnode = $objReplyXML- importNode($links- parent_node(), true); $temp- appendChild($importnode); } } } ","pontos":0},{"corpo":"I read the article too, and it led me to believe that when DEBUG was not defined, that the ConditionalAttribute declared on System.Debug functions would cause the compiler to leave out this code completely. I assume the same thing to be true for TRACE. That is, the System.Diagnostics.Debug functions must have ConditionalAttributes for DEBUG and for TRACE. I was wrong in that assumption. The separate Trace class has the same functions, and these define ConditionalAttribute dependent on the TRACE constant. From System.Diagnostics.Debug: _ Public Shared Sub Write ( _ message As String _ ) From System.Diagnostics.Trace: _ Public Shared Sub WriteLine ( _ message As String _ ) It seems then that my original assumption was correct, that System.Diagnostics.Debug (or system.Diagnostics.Trace) statements are actually not included in compilation as if they were included in #IF DEBUG (or #IF TRACE) regions. But I've also learned here from you guys, and verified, that the RELEASE build does not in itself take care of this. At least with Silverlight projects, which are still a little flaky, you need to get into the \"Advanced Compile Options...\" and make sure DEBUG is not defined. We jumped from .NET 1.1/VS2003 to .NET 3.5/VS2008 so I think some of this used to work differently, but perhaps it changed in 2.0/VS2005. ","pontos":1},{"corpo":"Comparison to NULL will be false every time. You want to use IS NULL instead. x = NULL -- always false x NULL -- always false x IS NULL -- these do what you want x IS NOT NULL ","pontos":2},{"corpo":"XSS (Cross Site Scripting) Attacks ","pontos":1},{"corpo":"Some basic functionals: public static class Functionals { // One-argument Y-Combinator. public static Func T, TResult Y T, TResult (Func Func T, TResult , Func T, TResult F) { return t = F(Y(F))(t); } // Two-argument Y-Combinator. public static Func T1, T2, TResult Y T1, T2, TResult (Func Func T1, T2, TResult , Func T1, T2, TResult F) { return (t1, t2) = F(Y(F))(t1, t2); } // Three-arugument Y-Combinator. public static Func T1, T2, T3, TResult Y T1, T2, T3, TResult (Func Func T1, T2, T3, TResult , Func T1, T2, T3, TResult F) { return (t1, t2, t3) = F(Y(F))(t1, t2, t3); } // Four-arugument Y-Combinator. public static Func T1, T2, T3, T4, TResult Y T1, T2, T3, T4, TResult (Func Func T1, T2, T3, T4, TResult , Func T1, T2, T3, T4, TResult F) { return (t1, t2, t3, t4) = F(Y(F))(t1, t2, t3, t4); } // Curry first argument public static Func T1, Func T2, TResult Curry T1, T2, TResult (Func T1, T2, TResult F) { return t1 = t2 = F(t1, t2); } // Curry second argument. public static Func T2, Func T1, TResult Curry2nd T1, T2, TResult (Func T1, T2, TResult F) { return t2 = t1 = F(t1, t2); } // Uncurry first argument. public static Func T1, T2, TResult Uncurry T1, T2, TResult (Func T1, Func T2, TResult F) { return (t1, t2) = F(t1)(t2); } // Uncurry second argument. public static Func T1, T2, TResult Uncurry2nd T1, T2, TResult (Func T2, Func T1, TResult F) { return (t1, t2) = F(t2)(t1); } } Don't do much good if you don't know how to use them. In order to know that, you need to know what they're for: What is currying? What is a y-combinator? ","pontos":18},{"corpo":"Assuming finalizers are similar to their .NET namesake then you only really need to call these when you have resources such as file handles that can leak. Most of the time your objects don't have these references so they don't need to be called. It's bad to try to collect the garbage because it's not really your garbage. You have told the VM to allocate some memory when you created objects, and the garbage collector is hiding information about those objects. Internally the GC is performing optimisations on the memory allocations it makes. When you manually try to collect the garbage you have no knowledge about what the GC wants to hold onto and get rid of, you are just forcing it's hand. As a result you mess up internal calculations. If you knew more about what the GC was holding internally then you might be able to make more informed decisions, but then you've missed the benefits of GC. ","pontos":1},{"corpo":"Obviously test every field for vulnerabilities: SQL - escape strings (e.g. ) XSS HTML being printed from input fields (a good sign of XSS usually) Anything else thatis not the specific purpose that field was created for Search for infinite loops (the only indirect thing (if a lot of people found it accidentally) that could kill a server really). ","pontos":2},{"corpo":"I've actually done a small test like this in python on a website I maintain and found that they are almost equivalent in speed, with the procedural approach winning by something like ten-thousandths of a second, but that the OO code was so significantly cleaner I didn't continue the exercise any longer than one iteration. So really, it doesn't matter (in my experience anyway). ","pontos":0},{"corpo":"I'm not entirely sure how your code works, but it seems like you have a small error in your code. On the line you posted in your question you have $link->parent_node(), but in the answer with the entire code snippet you have $link**s**->parent_node(). I don't think the s should be there. Also, I think you should use $link->parentNode, not $link->parent_node(). ","pontos":0},{"corpo":"The short answer: Java garbage collection is a very finely tuned tool. System.gc() is a sledge-hammer. Java's heap is divided into different generations, each of which is collected using a different strategy. If you attach a profiler to a healthy app, you'll see that it very rarely has to run the most expensive kinds of collections because most objects are caught by the faster copying collector in the young generation. Calling System.gc() directly, while technically not guaranteed to do anything, in practice will trigger an expensive, stop-the-world full heap collection. This is almost always the wrong thing to do. You think you're saving resources, but you're actually wasting them for no good reason, forcing Java to recheck all your live objects just in case. If you are having problems with GC pauses during critical moments, you're better off configuring the JVM to use the concurrent mark/sweep collector, which was designed specifically to minimise time spent paused, than trying to take a sledgehammer to the problem and just breaking it further. The Sun document you were thinking of is here: Java SE 6 HotSpot Virtual Machine Garbage Collection Tuning (Another thing you might not know: implementing a finalize() method on your object makes garbage collection slower. Firstly, it will take two GC runs to collect the object: one to run finalize() and the next to ensure that the object wasn't resurrected during finalization. Secondly, objects with finalize() methods have to be treated as special cases by the GC because they have to be collected individually, they can't just be thrown away in bulk.) ","pontos":40},{"corpo":" True. I didn't account for duplicate encodings. There are actually 252-1 NaNs for doubles and 223-1 NaNs for singles, though. :p Doh, forgot to subtract the infinities. ","pontos":0},{"corpo":"I was intrigued so I looked it up in the definition of ECMAScript 262 ed. 3 which is the basis of JavaScript 1.8. The relevant definition is found in section 11.1.4 and unfortunately is not very clear. The section explicitly states that elisions (= omissions) at the beginning or in the middle don't define an element but do contribute to the overall length. There is no explicit statements about redundant commas at the end of the initializer but by omission I conclude that the above statement implies that they do not contribute to the overall length so I conclude that MSIE is wrong. The relevant paragraph reads as follows: Array elements may be elided at the beginning, middle or end of the element list. Whenever a comma in the element list is not preceded by an Assignment Expression (i.e., a comma at the beginning or after another comma), the missing array element contributes to the length of the Array and increases the index of subsequent elements. Elided array elements are not defined. ","pontos":7},{"corpo":"You can use [System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Never)] so that it doesn't show up in Intellisence. If the consumer still want's to use it they can, but it won't be as discoverable. Keiths point about over engineering still stands though. ","pontos":8},{"corpo":"If you select only the columns you want in the linq query, and then call .ToList() on the query, it will be immedietly executed, and will only bring back the columns you are interested in. For example if you do this: var q = from p in dataContext.products select p.ProductName; var results = q.ToList(); You will get back a list of product names stored in results, and when the query executes on the server it will only bring back the ProductName column. ","pontos":0},{"corpo":"It seems to me that the Firefox behavior is correct. What is the value of the 6th value in IE (sorry I don't have it handy to test). Since there is no actual value provided, I imagine it's filling it with something like 'null' which certainly doesn't seem to be what you intended to have happen when you created the array. At the end of the day though, it doesn't really matter which is \"correct\" since the reality is that either you are targeting only one browser, in which case you can ignore what the others do, or you are targeting multiple browsers in which case your code needs to work on all of them. In this case the obvious solution is to never include the dangling comma in an array initializer. If you have problems avoiding it (e.g. for some reason you have developed a (bad, imho) habit of including it) and other problems like this, then something like JSLint might help. ","pontos":9},{"corpo":"Eh, figured out one way to do it: ExecTaskControl foo = (ExecTaskControl)LoadControl(\"tasks\\\\ExecTaskControl.ascx\"); It seems silly to have a file depedancy like that, but maybe thats how UserControls must be done. ","pontos":1},{"corpo":"The #if DEBUG pre-processor directive. It is Useful for testing and debugging (though I usually prefer to go the unit testing route). string customerName = null; #if DEBUG customerName = \"Bob\" #endif It will only execute code block if Visual Studio is set to compile in 'Debug' mode. Otherwise the code block will be ignored by the compiler (and grayed out in Visual Studio). ","pontos":25},{"corpo":"@John: The value of arrayList[5] comes out to be 'undefined'. Yes, there should never be a dangling comma in declarations. Actually, I was just going through someone else's long long javascript code which somehow was not working correctly in different browers. Turned out that the dangling comma was the culprit that has accidently been typed in! :) ","pontos":0},{"corpo":"From the Open Web Application Security Project: The OWASP Top Ten vulnerabilities (pdf) For a more painfully exhaustive list: Category:Vulnerability The top ten are: Cross-site scripting (XSS) Injection flaws (SQL injection, script injection) Malicious file execution Insecure direct object reference Cross-site request forgery (XSRF) Information leakage and improper error handling Broken authentication and session management Insecure cryptographic storage Insecure communications Failure to restrict URL access ","pontos":12},{"corpo":"You need to put your SSH public key into the ~/.ssh/authorized_keys file on the remote host. Then you'll be able to SSH to that host password-less. Alternatively you can use ssh-agent. I would recommend against storing the password in the script. ","pontos":0},{"corpo":"throw new ISaidDoNotUseException(); ","pontos":-2},{"corpo":"Yes, HTTP-Only cookies would be fine for this functionality. They will still be provided with the XmlHttpRequest's request to the server. In the case of Stack Overflow, the cookies are automatically provided as part of the XmlHttpRequest request. I don't know the implementation details of the Stack Overflow authentication provider, but that cookie data is probably automatically used to verify your identity at a lower level than the \"vote\" controller method. More generally, cookies are not required for AJAX. XmlHttpRequest support (or even iframe remoting, on older browsers) is all that is technically required. However, if you want to provide security for AJAX enabled functionality, then the same rules apply as with traditional sites. You need some method for identifying the user behind each request, and cookies are almost always the means to that end. In your example, I cannot write to your document.cookie, but I can still steal your cookie and post it to my domain using the XMLHttpRequest object. XmlHttpRequest won't make cross-domain requests (for exactly the sorts of reasons you're touching on). You could normally inject script to send the cookie to your domain using iframe remoting or JSONP, but then HTTP-Only protects the cookie again since it's inaccessible. Unless you had compromised StackOverflow.com on the server side, you wouldn't be able to steal my cookie. Edit 2: Question 2. If the purpose of Http-Only is to prevent JavaScript access to cookies, and you can still retrieve the cookies via JavaScript through the XmlHttpRequest Object, what is the point of Http-Only? Consider this scenario: I find an avenue to inject JavaScript code into the page. Jeff loads the page and my malicious JavaScript modifies his cookie to match mine. Jeff submits a stellar answer to your question. Because he submits it with my cookie data instead of his, the answer will become mine. You vote up \"my\" stellar answer. My real account gets the point. With HTTP-Only cookies, the second step would be impossible, thereby defeating my XSS attempt. Edit 4: Sorry, I meant that you could send the XMLHttpRequest to the StackOverflow domain, and then save the result of getAllResponseHeaders() to a string, regex out the cookie, and then post that to an external domain. It appears that Wikipedia and ha.ckers concur with me on this one, but I would love be re-educated... That's correct. You can still session hijack that way. It does significantly thin the herd of people who can successfully execute even that XSS hack against you though. However, if you go back to my example scenario, you can see where HTTP-Only does successfully cut off the XSS attacks which rely on modifying the client's cookies (not uncommon). It boils down to the fact that a) no single improvement will solve all vulnerabilities and b) no system will ever be completely secure. HTTP-Only is a useful tool in shoring up against XSS. Similarly, even though the cross domain restriction on XmlHttpRequest isn't 100% successful in preventing all XSS exploits, you'd still never dream of removing the restriction. ","pontos":40},{"corpo":"You can never ask too many or \"stupid\" questions. The more questions you ask, the more answers you receive. ","pontos":3},{"corpo":"The hard way You want a recursive descent parser. To get precedence you need to think recursively, for example, using your sample string, 1+11*5 to do this manually, you would have to read the , then see the plus and start a whole new recursive parse \"session\" starting with ... and make sure to parse the into its own factor, yielding a parse tree with . This all feels so painful even to attempt to explain, especially with the added powerlessness of C. See, after parsing the 11, if the * was actually a + instead, you would have to abandon the attempt at making a term and instead parse the itself as a factor. My head is already exploding. It's possible with the recursive decent strategy, but there is a better way... The easy (right) way If you use a GPL tool like Bison, you probably don't need to worry about licensing issues since the C code generated by bison is not covered by the GPL (IANAL but I'm pretty sure GPL tools don't force the GPL on generated code/binaries; for example Apple compiles code like say, Aperture with GCC and they sell it without having to GPL said code). Download Bison (or something equivalent, ANTLR, etc.). There is usually some sample code that you can just run bison on and get your desired C code that demonstrates this four function calculator: http://www.gnu.org/software/bison/manual/html_mono/bison.html#Infix-Calc Look at the generated code, and see that this is not as easy as it sounds. Also, the advantages of using a tool like Bison are 1) you learn something (especially if you read the Dragon book and learn about grammars), 2) you avoid NIH trying to reinvent the wheel. With a real parser-generator tool, you actually have a hope at scaling up later, showing other people you know that parsers are the domain of parsing tools. Update: People here have offered much sound advice. My only warning against skipping the parsing tools or just using the Shunting Yard algorithm or a hand rolled recursive decent parser is that little toy languages1 may someday turn into big actual languages with functions (sin, cos, log) and variables, conditions and for loops. Flex/Bison may very well be overkill for a small, simple interpreter, but a one off parser+evaluator may cause trouble down the line when changes need to be made or features need to be added. Your situation will vary and you will need to use your judgement; just don't punish other people for your sins [2] and build a less than adequate tool. My favorite tool for parsing The best tool in the world for the job is the Parsec library (for recursive decent parsers) which comes with the programming language Haskell. It looks a lot like BNF, or like some specialized tool or domain specific language for parsing (sample code [3]), but it is in fact just a regular library in Haskell, meaning that it compiles in the same build step as the rest of your Haskell code, and you can write arbitrary Haskell code and call that within your parser, and you can mix and match other libraries all in the same code. (Embedding a parsing language like this in a language other than Haskell results in loads of syntactic cruft, by the way. I did this in C# and it works quite well but it is not so pretty and succinct.) Notes: 1 Richard Stallman says, in Why you should not use Tcl The principal lesson of Emacs is that a language for extensions should not be a mere \"extension language\". It should be a real programming language, designed for writing and maintaining substantial programs. Because people will want to do that! [2] Yes, I am forever scarred from using that \"language\". Also note that when I submitted this entry, the preview was correct, but SO's less than adequate parser ate my close anchor tag on the first paragraph, proving that parsers are not something to be trifled with because if you use regexes and one off hacks you will probably get something subtle and small wrong. [3] Snippet of a Haskell parser using Parsec: a four function calculator extended with exponents, parentheses, whitespace for multiplication, and constants (like pi and e). aexpr = expr `chainl1` toOp expr = optChainl1 term addop (toScalar 0) term = factor `chainl1` mulop factor = sexpr `chainr1` powop sexpr = parens aexpr | scalar | ident powop = sym \"^\" = return . (B Pow) | sym \"^-\" = return . (\\x y - B Pow x (B Sub (toScalar 0) y)) toOp = sym \"- \" = return . (B To) mulop = sym \"*\" = return . (B Mul) | sym \"/\" = return . (B Div) | sym \"%\" = return . (B Mod) | return . (B Mul) addop = sym \"+\" = return . (B Add) | sym \"-\" = return . (B Sub) scalar = number = return . toScalar ident = literal = return . Lit parens p = do lparen result - p rparen return result ","pontos":49},{"corpo":"First off, Konrad is right to quote the spec, as that is what defines the language and answers your first question. To answer your other questions: Are there any other such Javascript browser quirks that I should be wary of? Oh, too many to list here! Try the QuirksMode website for a good place to find nearly everything known. How do I avoid errors such as these? The best way is to use a library that abstracts these problems away for you so that you can get down to worrying about the logic of the application. Although a bit esoteric, I prefer and recommend MochiKit. ","pontos":2},{"corpo":"for sqlite, check out the firefox extension. It offers a serviceable GUI. ","pontos":0},{"corpo":"Don't bother with finalizers. Switch to incremental garbage collection. If you want to help the garbage collector, null off references to objects you no longer need. Less path to follow= more explicitly garbage. Don't forget that (non-static) inner class instances keep references to their parent class instance. So an inner class thread keeps a lot more baggage than you might expect. In a very related vein, if you're using serialization, and you've serialized temporary objects, you're going to need to clear the serialization caches, by calling ObjectOutputStream.reset() or your process will leak memory and eventually die. Downside is that non-transient objects are going to get re-serialized. Serializing temporary result objects can be a bit more messy than you might think! Consider using soft references. If you don't know what soft references are, have a read of the javadoc for java.lang.ref.SoftReference Steer clear of Phantom references and Weak references unless you really get excitable. Finally, if you really can't tolerate the GC use Realtime Java. No, I'm not joking. The reference implementation is free to download and Peter Dibbles book from SUN is really good reading. ","pontos":3},{"corpo":"I believe this is the problem that the Microsofy Entity Framework is trying to address. Whilst not specifically designed to \"Compile (the database changes are done auto-magically)\" it does address the issue of handling changes to the domain model without a huge dependance on the underlying data model. ","pontos":1},{"corpo":"Some of the really big dogs, such as ERwin Data Modeler, will go object to DB. You need to have the big bucks to afford the product though. ","pontos":0},{"corpo":"So I tried both options on my WordPress db. I looked for the category \"Tech\" in my posts with the tags \"Perl\" AND \"Programming\". Eric's worked once I added a missing comma in the initial select statement. It returned 3 records. The problem is that the section that is looking for the \"post_tag\" is actually working as an OR option. One of my posts only had one tag not both. Also it would be good to make the SELECT DISTINCT. I tried Matt's version, but it kept returning an empty set. I may try to \"juggle\" with it. ","pontos":1},{"corpo":"I had this problem in a program I wrote a year ago -- turns out the answer is rather complicated. You'll need to use nohup as well as output redirection, as explained in the wikipedia artcle on nohup, copied here for your convenience. Nohuping backgrounded jobs is for example useful when logged in via SSH, since backgrounded jobs can cause the shell to hang on logout due to a race condition [2]. This problem can also be overcome by redirecting all three I/O streams: nohup myprogram foo.out 2 foo.err /dev/null ","pontos":137},{"corpo":"Merge is more efficient. For the simple reason that changes to the same file simultaneously tends to be common, and merge allows you to recover from that. In contrast, single checkout prevents that little bit of extra work but it does so at the cost of huge inefficiencies in scheduling. Typically it takes a short amount of time to merge two changes to the same file (e.g. minutes), whereas it takes a significant amount of time to make changes to a file (e.g. many hours or days) so that preventing access to editing a file is a huge inefficiency. Note that Perforce does not force the checkout methodology, it allows concurrent checkouts (equivalent to merge). ","pontos":6},{"corpo":"According to Steve Yegge that's the wrong question to ask. If you're gathering requirement it's already too late, your project is doomed. ","pontos":3},{"corpo":"I did so, assuming that a Security setting would be available. I didn't see any \"Security\" option when I right-clicked on the Key. =( I triple-checked just to make sure... and I just tried it on my XP machine, and it does indeed have the \"Permissions\" section... but the Windows 2000 machine doesn't. (how's that for wierd?) In my searching, I found: http://www.experts-exchange.com/Programming/Languages/.NET/ASP.NET/Q_21563044.html Which notes that RegEdit for Windows 2000 doesn't have the Security/Permissions settings... but it proposes no solution to the problem. (Whoever asked the question was using Windows XP so he was okay... but in my case, it's 2000) Is there any way to make it happen specifically in 2000? EDIT: Ahhhh... if worse come to worse, I suppose I can do the impersonation as mentioned below... though if I can't set security settings for the registry in 2000, I'm left with making that user have Administrative access (I assume?) to actually get those rights, which sadly defeats the purpose. =( ","pontos":0},{"corpo":"Just did this the other day with TCPTrace on the local machine. I mapped the remote host in the hosts file to 127.0.0.1. Ran the local web server on 8080, TcpTrace on 80 pointing to 127.0.0.1:8080. Probably your issue is trying to run both at port 80 which won't work. ","pontos":0},{"corpo":"If it's a public jar (as in, not yours) then it might be in the Maven Repository. ","pontos":0},{"corpo":"I suspect you're going to have to do the resizing manually thru the Image class and DrawImage function and respond to the resize events on the PictureBox. ","pontos":5},{"corpo":"trunk for development, and a branch (production) for the production stuff. On my local machine, I have a VirtualHost that points to the trunk branch, to test my changes. Any commit to trunk triggers a commit hook that does an svn export and sync to the online server's dev URL - so if the site is stackoverflow.com then this hook automatically updates dev.stackoverflow.com Then I use svnmerge to merge selected patches from trunk to production in my local checkouts. I have a VirtualHost again on my local machine pointing to the production branch. When I commit the merged changes to the production branch, again an SVN export hook updates the production (live) export and the site is live! ","pontos":15},{"corpo":"Have you tried the SaveAs from the Worksheet? ","pontos":0},{"corpo":"several things we use them for: integrating with the bug tracker (Trac in our case - a commit message that says 'Closes #514' automatically marks that bug as closed integrating with the build integration (buildbot in our case - a commit to a watched branch triggers a build pre-commit hook for validating the commit - we use svnchecker. It validates our Python code for PEP8 correctness sending checkin mails to a mailing list running indentation scripts ","pontos":3},{"corpo":"Excel interop is pretty painful. I dug up an old project I had, did a little fiddling, and I think this is what you're looking for. The other commenters are right, but, at least in my experience, there's a lot more to calling SaveAs() than you'd expect if you've used the same objects (without the interop wrapper) in VBA. Microsoft.Office.Interop.Excel.Workbook wbk = excelApplication.Workbooks[0]; //or some other way of obtaining this workbook reference, as Jason Z mentioned wbk.SaveAs(filename, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing, XlSaveAsAccessMode.xlNoChange, Type.Missing, Type.Missing, Type.Missing, Type.Missing, Type.Missing); wbk.Close(); excelApplication.Quit(); Gotta love all those Type.Missings. But I think they're necessary. ","pontos":8},{"corpo":"I'm not sure I understand the question here - I'm not aware of any modern source control system (other than Visual SourceSafe) that doesn't fully support merging. ","pontos":0},{"corpo":"OK, I ran some tests of my own. If you don't declare your own constructor in the subclass, trying to instantiate it will throw a fatal error, because it tries to call the superclass constructor. In the case of a DB connection, when you're presumably returning (in PHP, anyway) a mysqli instance or the resource returned by the function (or some other link to some other RDBMS), as long as you mark the instance private, there's no threat of somebody subclassing it and tampering with the link. As I alluded to before, if somebody really wants to override your behavior and make multiple connections, they could just as well do it by writing a new class. ","pontos":4},{"corpo":"Better question is how to keep your app from consuming so much memory that it requires you to reboot mongrels from time to time. www.modrails.com reduced our memory footprint significantly ","pontos":1},{"corpo":"I have all 3 installed and have had no adverse problems...knocking on wood ","pontos":2},{"corpo":"6/2002/2003/2005/2008, I believe, can all coexist. Though just this weekend I purged 'em all except 2008 as it went totally mad and stopped showing the build output. Plus my splash screen wasn't right. Now it is. ","pontos":2},{"corpo":"Setting an attribute on an object won't give a compile-time or a run-time error, it will just do nothing useful if the object doesn't access it (i.e. \"\" would also not give an error). Unless you need a specific feature of , I would look at : import sys from xml.etree.cElementTree import Element, ElementTree def make_xml(): node = Element('foo') node.text = 'bar' doc = ElementTree(node) return doc if __name__ == '__main__': make_xml().write(sys.stdout) ","pontos":8},{"corpo":"You could consider inverting the problem. That is add the control to the repeaters definition and the remove it if it is not needed. Not knowing the details of your app this might be a tremendous waste of time but it might just work out in the end. ","pontos":1},{"corpo":"Just make sure you only have RTM versions and not Beta or RC versions installed. You'll have no end of pain if you don't cleanly remove the beta or RC versions before installing the RTM versions. ","pontos":4},{"corpo":"@Daniel Thanks for the reply, I also figured out how to do it with the minidom (I'm not sure of the difference between the ElementTree vs the minidom) from xml.dom.minidom import * def make_xml(): doc = Document(); node = doc.createElement('foo') node.appendChild(doc.createTextNode('bar')) doc.appendChild(node) return doc if __name__ == '__main__': make_xml().writexml(sys.stdout) I swear I tried this before posting my question... ","pontos":7},{"corpo":"If the failover logic is in your application you could write a status screen that shows which box you're connected by writing to a var when the first connection attempt fails. I think your best bet would be a ping daemon/cron job that checks the status of each box periodically and sends an email if one doesn't respond. ","pontos":1},{"corpo":"I have seen PSPad used as a hex editor, but I usually do the same thing you do. I'm surprised there's not an \"instant answer\" for this question. It's a very common need. ","pontos":1},{"corpo":"CompileAssemblyFromDom compiles to a .cs file which is then run through the normal C# compiler. Example: using System; using System.Collections.Generic; using System.Linq; using System.Text; using Microsoft.CSharp; using System.CodeDom; using System.IO; using System.CodeDom.Compiler; using System.Reflection; namespace CodeDomQuestion { class Program { private static void Main(string[] args) { Program p = new Program(); p.dotest(\"C:\\\\fs.exe\"); } public void dotest(string outputname) { CSharpCodeProvider cscProvider = new CSharpCodeProvider(); CompilerParameters cp = new CompilerParameters(); cp.MainClass = null; cp.GenerateExecutable = true; cp.OutputAssembly = outputname; CodeNamespace ns = new CodeNamespace(\"StackOverflowd\"); CodeTypeDeclaration type = new CodeTypeDeclaration(); type.IsClass = true; type.Name = \"MainClass\"; type.TypeAttributes = TypeAttributes.Public; ns.Types.Add(type); CodeMemberMethod cmm = new CodeMemberMethod(); cmm.Attributes = MemberAttributes.Static; cmm.Name = \"Main\"; cmm.Statements.Add(new CodeSnippetExpression(\"System.Console.WriteLine('f'zxcvv)\")); type.Members.Add(cmm); CodeCompileUnit ccu = new CodeCompileUnit(); ccu.Namespaces.Add(ns); CompilerResults results = cscProvider.CompileAssemblyFromDom(cp, ccu); foreach (CompilerError err in results.Errors) Console.WriteLine(err.ErrorText + \" - \" + err.FileName + \":\" + err.Line); Console.WriteLine(); } } } which shows errors in a (now nonexistent) temp file: ) expected - c:\\Documents and Settings\\jacob\\Local Settings\\Temp\\x59n9yb-.0.cs:17 ; expected - c:\\Documents and Settings\\jacob\\Local Settings\\Temp\\x59n9yb-.0.cs:17 Invalid expression term ')' - c:\\Documents and Settings\\jacob\\Local Settings\\Tem p\\x59n9yb-.0.cs:17 So I guess the answer is \"no\" ","pontos":7},{"corpo":"I don't think it's a matter of which language is better. In the .NET world there are some inconsistencies between the libraries different languages provide. There are certain functionality that is available in VB.NET that you might like to use from C# but can't. I remember I had to use J# to use some ZIP libraries that were not available in any other language in .NET. ","pontos":1},{"corpo":"I think John is correct. \"My main concern is that instantiating and disposing one huge DataContext class all the time for individual operations that relate to specific areas of the Database would be impose an unnecessary imposition on application resources\" How do you support that statement? What is your experiment that shows that a large DataContext is a performance bottleneck? Having multiple datacontexts is a lot like having multiple databases and makes sense in similar scenarios, that is, hardly ever. If you are working with multiple datacontexts you need to keep track of which objects belong to which datacontext and you can't relate objects that are not in the same data context. That is a costly design smell for no real benefit. @Evan \"The DataContext (or Linq to Entities ObjectContext) is more of a \"unit of work\" than a connection\" That is precisely why you should not have more than one datacontext. Why would you want more that one \"unit of work\" at a time? ","pontos":1},{"corpo":"Use something like Host Monitor http://www.ks-soft.net/hostmon.eng/ to monitor the Event Log for messages related to the failover event, which can send you an alert via email/SMS. I'm curious though how you wouldn't need to know that the failover happened, because don't you have to then update the datasources in your applications to point to the new server that you failed over to? Mirroring takes place on different hosts (the primary and the mirror), unlike clustering which has multiple nodes that appear to be a single device from the outside. Also, are you using a witness server in order to automatically fail over from the primary to the mirror? This is the only way I know of to make it happen automatically, and in my experience, you get a lot of false-positives where network hiccups can fool the mirror and witness into thinking the primary is down when in fact it is not. ","pontos":1},{"corpo":"I would definitely put the graphics under version control. The diff might not be very useful from within a diff tool like diffmerge, but you can still checkout two versions of the graphic and view them side by side to see the differences. I don't see any reason why the resultant graphics shouldn't be kept in the same version control system that the coders use. However, when you're creating graphics using PSD files or PDN files you might want to create a seperate repository for those as they have a different context to the actual end jpeg or gif that is produced and deployed with the developed application. ","pontos":1},{"corpo":"Is the machine you have the code deployed on a 64-bit machine? You could also be running into a DEP issue. Edit This is a 1st gen Macbook Pro with a 1st gen Core Duo 2 Intel processor. Far from 64 bits. I mentioned 64 bit, because at low levels structs from 32 bit to 64 bit do not get properly handled. Since the machines aren't 64bit, then more than likely disabling DEP would be a good logical next step. Vista did get more secure than XP SP2. Well, I've just turned DEP globally off to no avail. Same error. Well, I also read that people were getting this error after updating a machine to Vista SP1. Do these Vista installs have SP1 on them? Turns out to be something completely different. Just for the sake of testing, I've disabled de UAC (note: I was not getting any prompt). Great, I was actually going to suggest that, but I figured you probably tried it already. ","pontos":0},{"corpo":"For more than you ever wanted to know about , read the specification of in the Single Unix Specification v3. It states Comparisons [...] shall be performed using the collating sequence of the current locale. IOW, how sorts is dependent on the locale (language) settings of the environment that the script is running under. ","pontos":1},{"corpo":"I've got 2005 and 2008 installed concurrently. 2008 is a superset of 2005, so I have no reason whatsoever to have them both, I just haven't gotten around to un-installing it yet ","pontos":0},{"corpo":"xxd is the 'standard' hex dump util and looks like it should solve your problems ","pontos":0},{"corpo":"Having seen a pile of machines recently that don't do it, I don't think that's quite true. The GMA 950 integrated ones don't do it to start with, and I don't think that the 3100/X3100 do either (at least not in hardware... the 3100 was enormously slow in a demo). Also, I don't believe that the GeForce MX5200 supported it either. Or perhaps I'm just misunderstanding what you mean when you refer to \"AA mode\". Are there a lot of cards which support modes that are virtually unnoticable? :) ","pontos":-1},{"corpo":"What Edmund said. As for not calling .add all the time, no, not idiomatically. There would be various hacks (storing it in an array and then looping) that you could do if you really wanted to, but I wouldn't recommend it. ","pontos":1},{"corpo":"I've had no problems connecting to network shares transparently as if they were local drives. The only issue you may have is what you mentioned: having the account gain access to the share. Impersonation is probably the best way to do this. You should be able to use any filestream objects to access the network share as long as it has a drive letter on the server machine. ","pontos":0},{"corpo":"I dropped that code into a file and pushed it to ff3 and I don't see what you see...the arrow is default color with gray background and black arrow. Are you styling scrollbars too? ","pontos":0},{"corpo":"I did quite a bit of googling trying to find this answer. There are plenty of people asking for it: http://developers.slashdot.org/comments.pl?sid=414610 cid=21996944 http://www.arguingwithmyself.com/archives/75-the-biggest-feature-your-editor-is-missing http://intype.info/blog/screencast-parser-in-editor/#comment-221 http://codewords.wordpress.com/2006/10/16/eclipses-achilles-heel/ just to name a few... so I don't think one exists yet, sorry :( ","pontos":4},{"corpo":"Also don't forget that both Map and Hashtable are generic in Java 5 and up (as in any other class in the Collections framework). Map String, Integer numbers = new HashMap String, Integer (); numbers.put(\"one\", 1); numbers.put(\"two\", 2); numbers.put(\"three\", 3); Integer one = numbers.get(\"one\"); Assert.assertEquals(1, one); ","pontos":7},{"corpo":"Integrated GPUs are going to be really poor performers with games FSAA or no. If you want even moderate performance, buy a separate video card. For something that's not crazy expensive go with either a nVidia Geforce 8000 series card or an ATI 3000 series card. Even as a nVidia 8800 GTS owner, I will tell you the ATIs have better support for older games. Although I personally still like FSAA, it is becoming less important with higher resolution screens. Also, more and more games are using deferred rendering which makes FSAA impossible. ","pontos":1},{"corpo":" I dropped that code into a file and pushed it to ff3 and I don't see what you see...the arrow is default color with gray background and black arrow. Are you styling scrollbars too? I've updated the post, the HTML in there is now literally all the html that is being loaded, no other CSS/JS or anything, and it still looks exactly as posted in the pic. Note I'm on vista. It may do different things on XP, I haven't checked ","pontos":0},{"corpo":"Have you made a support request to the vendor? Perhaps there's something about the MacBook Pro hardware that prevents the product from working. ","pontos":0},{"corpo":"Given that the exception is a DllNotFoundException, you might want to try checking the HardwareID.dll with Dependency Walker BEFORE installing any dev tools on the Vista install to see if there is in fact a dependency missing. ","pontos":0},{"corpo":"The unix tool is distributed as part of , and according to http://www.vmunix.com/vim/util.html#xxd, the source for xxd is ftp://ftp.uni-erlangen.de:21/pub/utilities/etc/xxd-1.10.tar.gz. It was written in C and is about 721 lines. The only licensing information given for it is this: * Distribute freely and credit me, * make money and share with me, * lose money and don't ask me. The unix tool is available from http://gd.tuwien.ac.at/softeng/Aegis/hexdump.html. It was written in C and can be compiled from source. It's quite a bit bigger than xxd, and is distributed under the GPL. ","pontos":5},{"corpo":"Have you tried reinstalling RubyGems? I had a pretty similar error message until I reuninstalled and for some reason, it installed into a different directory and then the problem went away. ","pontos":1},{"corpo":"Just finally found answer... I was missing a gem, and thrown off by bad error message from Rails... ","pontos":0},{"corpo":"A obfuscator won't help you at all if someone wants to figure out the code. The code still exists on the client machine and they can grab a copy of it and study it at their leisure. There is simply no way to hide code written in Javascript since the source code has to be handed to the browser for execution. If you want to hide your code, you have the following options: 1) Use an environment where compiled code (not source) is downloaded to the client, e.g. Flash or Silverlight. I'm not even sure that's foolproof, but it's certainly much better than Javascript. 2) Have a back end on the server side that does the work and a thin client that just makes requests to the server. ","pontos":0},{"corpo":"I'd definitely suggest PHP. I've developed browser based games (pbbgs) for about 10 years now. I've tried .Net, Perl and Java. All of them worked, but by far PHP was the best because: Speed with which you can develop (that might be due to experience) Ease/Cost of finding a host for a game site Flexibility to change/revamp on the fly (game programming seems to always have a different development cycle then normal projects) Ruby is not to bad, but the last time I tried it I rapidly ran into scaling/performance issues. I have not tried Python yet...maybe it's time to give it a shot. Just my two cents, but over the years PHP has saved me a ton of time. ","pontos":3},{"corpo":"You're always faced with the fact that any user that comes to your webpage will download some working version of your Javascript source. They will have the source code. Obfuscating it may make it very difficult to be reused by someone with the intent to steal your hard work. However, in many cases someone can even reuse the obfuscated source! Or in the worst case they can unravel it by hand and eventually comprehend it. An example of a situation like yours might be Google Maps. The Javascript source is clearly obfuscated. However, for really private/sensitive logic they push the data to the server and have the server process that information using XMLHttpRequests (AJAX). With this design you have the important parts on the server side, much more tightly controlled. ","pontos":1},{"corpo":"You are going to be fighting a losing battle if you try to obfuscate your code in the hopes of someone not stealing it. You may stop the casual browser from getting at it, but someone dedicated would almost certainly be able to overcome any measure you use. In the past I have seen people do several things: Paste a lot of whitespace at the top of the page with a message telling people that the code is unavailable, when in actuality you just need to scroll down a few pages to get at it. Running it through an encoder of some kind, this is so so useful as it can just be run through the decoder. Another method is to reduce variable names to one character and remove whitespace (this is also an efficiency thing). There are many other methods. In the end, your efforts are only likely to stop the casual browser from seeing your stuff. If someone dedicated comes along then there is not much you will be able to do. You will have to live with this. My advice would be to make a really awesome product that attracts the most people and beat off any competition by having the best product/service/community and not the most obfuscated code. ","pontos":3},{"corpo":"I vaguely remember having a similar sounding problem with the DB2 for as/400 oledb driver when trying to set up a linked server from sql 2005 to the as/400. It was a permissions issue and I eventually found that only sql server accounts (not windows) could use the linked server because (i think) then the driver was loading using the credentials of the sql instead of impersonated ones. If it works when \"run as\" admin then it gotta be permissions. ","pontos":1},{"corpo":"I assume you have seen the writeup of SQL1159 in the DB2 Reference Guide? Unfortunately for you, the reason codes stop at 6 and don't continue to 7. It does say: User response: There was a problem with your DB2 installation. If this is the first time DB2 was installed on this computer, review the install logs for any possible errors and run a repair of DB2 from the Add/Remove Programs control panel applet. The default location of the installation logs is the My Documents/DB2LOG folder of the user that performed the installation. If this does not resolve the issue please contact IBM Support and provide the reason code associated with this message along with any installation logs. So I guess try to reinstall it and if the problem continues you'll have to contact IBM. Sorry, I know that's not much help. ","pontos":1},{"corpo":"If this is for a website, which by its very nature puts viewing of its code one menu click away, is there really any reason to hide anything? If someone wants to steal your code they will most likely go through the effort of making even the most mangled code human readable. Look at commercial websites, they don't obfuscate their code, and no one goes out and steals code from the google apps. If you are really worried about code theft, I would argue for writing it in some other compiled language. (which does of course destroy the whole webapp thing...) Even then, you aren't totally safe, there are many de-compilers out there. So really, there is no way to do what you want in the face of anyone with sufficient motivation. ","pontos":0},{"corpo":"Must be a Vista problem. I have XP SP 2 and it looks normal. ","pontos":1},{"corpo":"System.IO.StreamWriter httpResponseStreamWriter = new StreamWriter(HttpContext.Current.Response.OutputStream); dataContext.Log = httpResponseStreamWriter; Stick that in your page and you'll get the SQL dumped out on the page. Obviously, I'd wrap that in a little method that you can enable/disable. ","pontos":3},{"corpo":"I'm not primarily worried about physical security, we are simply building an application not a whole system. I want to ensure votes are recorded correctly and not able to be changed or read by someone else. ","pontos":0},{"corpo":"If you have not yet garbage collected your repository (e.g. using or , but note that garbage collection can also happen automatically), then your commit is still there it's just no longer reachable through the HEAD. You can try to find your commit by looking through the output of . Newer versions of Git have something called the \"reflog\", which is a log of all changes that are made to the refs (as opposed to changes that are made to the repository contents). So, for example, every time you switch your HEAD (i.e. every time you do a to switch branches) that will be logged. And, of course, your also manipulated the HEAD, so it was also logged. You can access older states of your refs in a similar way that you can access older states of your repository, by using an sign instead of a , like . It took me a while to understand what the difference is between HEAD@{1} and HEAD~1, so here is a little explanation: git init git commit --allow-empty -mOne git commit --allow-empty -mTwo git checkout -b anotherbranch git commit --allow-empty -mThree git checkout master # This changes the HEAD, but not the repository contents git show HEAD~1 # = One git show HEAD@{1} # = Three git reflog So, means \"go to the commit before the commit that HEAD currently points at\", while means \"go to the commit that HEAD pointed at before it pointed at where it currently points at\". That will easily allow you to find your lost commit and recover it. ","pontos":17},{"corpo":"I'm going to tell you a secret. Once you understand it, you'll feel a lot better about the fact that Javascript obfuscation is only really useful for saving bandwidth when sending scripts over the wire. Your source-code is not worth stealing. I know this comes as a shock to the ego, but I can say this confidently without ever having seen a line of code you've written because outside the very few realms of development where serious magic happens, it's true of all source-code. Say, tomorrow, someone dumped a pile of DVDs on your doorstep containing the source code for Windows Vista. What would you be able to do with it? Sure, you could compile it and give away copies, but that's just one step more effort than copying the retail version. You could painstakingly find and remove the license-checking code, but that's something some bright kid has already done to the binaries. Replace the logo and graphics, pretend you wrote it yourself and market it as \"Vicrosoft Mista\"? You'll get caught. You could spend an enormous amount of time reading the code, trying to understand it and truly \"stealing the intellectual property\" that Microsoft invested in developing the product. But you'd be disappointed. You'd find the code was a long series of mundane decisions, made one after the other. Some would be smarter than you could think of. Some would leave you shaking your head wondering what kind of monkeys they're hiring over there. Most would just make you shrug and say \"yeah, that's how you do that.\" In the process you'll learn a lot about writing operating systems, but that's not going to hurt Microsoft. Replace \"Vista\" with \"Leopard\" and the above paragraphs don't change one bit. It's not Microsoft, it's software. Half the people on this site could probably develop a Stack Overflow clone, with or without looking at the source of this site. They just haven't. The source-code of Firefox and WebKit are out there for anyone to read. Now go write your own browser from scratch. See you in a few years. Software development is an investment of time. It's utter hubris to imagine that what you're doing is so special that nobody could clone it without looking at your source, or even that it would make their job that much easier without an actionable (and easily detectable) amount of cut and paste. ","pontos":120},{"corpo":"I got into this once, even tried using PSP Dashboard. It's just too hard to keep up with. Who wants to use a stop watch for all their activities? Follow Joel's advice on Painless Scheduling and Evidence Based Scheduling. +1 this question, -1 to PSP. ","pontos":5},{"corpo":"The company I work for has a large open-plan office, with pretty much everyone in the same room - developers, QA people and BA people.. It's a smallish company. So I have the same issue with people interrupting my coding with questions and requests. What we have been using for a little while is \"do not disturb\" signs on our desks, which can be flipped when \"in the zone\", and flipped back when you don't mind being disturbed (as much). They mostly work for us, when people obey the signs of course. The other thing I do is to encourage people to email me instead of phoning or face to facing - so I can respond later at my convenience (but I try to get back reasonably quickly). ","pontos":2},{"corpo":"You could spend literally thousands of dollars on the dev kit or you could be a bad person and go look at the homebrew stuff. It is technically hacking though, so I only hypothetically recommend it. ","pontos":9},{"corpo":"The FlashWindowEx function which controls the flashing takes a FLASHWINFO struct which has a uCount field to control how many times it flashes. Also, a possible value for the dwFlags field is FLASHW_STOP to cause the flashing to stop. EDIT: Forgot was a C# tagged question ... so P/Invoke goodness found here. ","pontos":4},{"corpo":"Avoid the worst CAPTCHAs of all time. Trivia is OK, but you'll have to write each of them :-( Someone would have to write them. You could do trivia questions in the same way ReCaptcha does printed words. It offers two words, one of which it knows the answer to, another which it doesn't - after enough answers on the second, it now knows the answer to that too. Ask two trivia questions: A woman needs a man like a fish needs a? Orange orange orange. Type green. Of course, this may need to be coupled with other techniques, such as timers or computed secrets. Questions would need to be rotated/retired, so to keep the supply of questions up you could ad-hoc add: Enter your obvious question: You don't even need an answer; other humans will figure that out for you. You may have to allow flagging questions as \"too hard\", like this one: \"asdf ejflf asl;jf ei;fil;asfas\". Now, to slow someone who's running a StackOverflow gaming bot, you'd rotate the questions by IP address - so the same IP address doesn't get the same question until all the questions are exhausted. This slows building a dictionary of known questions, forcing the human owner of the bots to answer all of your trivia questions. ","pontos":30},{"corpo":"Here's my solution, but even more importantly my approach to solving the problem. I approached the problem by drawing the memory cells and drawing arrows from the destination to the source. made a table showing the above drawing. labeling each row in the table with the relative byte address. This showed me the pattern: let iL be the low nybble (half byte) of a[i] let iH be the high nybble of a[i] iH = (i+1)L iL = (i+2)H This pattern holds for all bytes. Translating into C, this means: a[i] = (iH 4) OR iL a[i] = ((a[i+1] 0x0f) 4) | ((a[i+2] 0xf0) 4) We now make three more observations: since we carry out the assignments left to right, we don't need to store any values in temporary variables. we will have a special case for the tail: all 12 bits at the end will be zero. we must avoid reading undefined memory past the array. since we never read more than a[i+2], this only affects the last two bytes So, we - handle the general case by looping for N-2 bytes and performing the general calculation above - handle the next to last byte by it by setting iH = (i+1)L - handle the last byte by setting it to 0 given a with length N, we get: for (i = 0; i N - 2; ++i) { a[i] = ((a[i+1] 0x0f) 4) | ((a[i+2] 0xf0) 4); } a[N-2] = (a[N-1) 0x0f) 4; a[N-1] = 0; And there you have it... the array is shifted left by 12 bits. It could easily be generalized to shifting N bits, noting that there will be M assignment statements where M = number of bits modulo 8, I believe. The loop could be made more efficient on some machines by translating to pointers for (p = a, p2=a+N-2; p != p2; ++p) { *p = ((*(p+1) 0x0f) 4) | (((*(p+2) 0xf0) 4); } and by using the largest integer data type supported by the CPU. (I've just typed this in, so now would be a good time for somebody to review the code, especially since bit twiddling is notoriously easy to get wrong.) ","pontos":2},{"corpo":"Regex will do the trick... create a perl/python/php script to do the job for you.. I'm pretty sure windows batch file can't do regex. ","pontos":0},{"corpo":"You want a[0,1] instead of a[0]. ","pontos":7},{"corpo":"Firstly, \"ugly no-char boxes\" might not be an encoding problem, they might just be a sign you don't have a font installed that can display the glyphs in the page. Most character encoding problems happen when strings are being passed from one system to another. For webapps, this is usually between the browser and the application, between the application and the filesystem and between the application and the database. So you need to check where the mis-encoded data is coming from, what character encoding it has at the source, and what encoding it is being received as. The best way is to send through characters you know the system is having problems with, and examine them at each level of the app. What do they look like inside the app? In the database? When you get them back from the database? When they're displayed in the browser? Sorry to be so general, but the question doesn't give much more to work with. ","pontos":3},{"corpo":"I believe this is changing in Ruby 1.9 such that \"asdf\"[2] yields \"d\" rather than the character code ","pontos":6},{"corpo":"Or you can convert the integer to its character value: a[0].chr ","pontos":14},{"corpo":"Even with rep, there should still be SOME type of capcha, to prevent a malicious script attack. ","pontos":2},{"corpo":"Generally, no. The stream format for Java serialization is defined in this document, but you need access to the original class definitions (and a Java runtime to load them into) to turn the stream data back into something approaching the original objects. For example, classes may define writeObject() and readObject() methods to customise their own serialized form. (edit: lubos hasko suggests having a little java program to deserialize the objects in front of Python, but the problem is that for this to work, your \"little java program\" needs to load the same versions of all the same classes that it might deserialize. Which is tricky if you're receiving log messages from one app, and really tricky if you're multiplexing more than one log stream. Either way, it's not going to be a little program any more. edit2: I could be wrong here, I don't know what gets serialized. If it's just log4j classes you should be fine. On the other hand, it's possible to log arbitrary exceptions, and if they get put in the stream as well my point stands.) It would be much easier to customise the log4j network adapter and replace the raw serialization with some more easily-deserialized form (for example you could use XStream to turn the object into an XML representation) ","pontos":5},{"corpo":"In theory it's possible. Now how difficult in practice it might be depends on whether Java serialization format is documented or not. I guess, it's not. edit: oops, I was wrong, thanks Charles. Anyway, this is what I suggest you to do capture from log4j deserialize Java object in your own little Java program. now when you have the object again, serialize it using your own custom formatter. Tip: Maybe you don't even have to write your own custom formatter. for example, JSON (scroll down for libs) has libraries for Python and Java, so you could in theory use Java library to serialize your objects and Python equivalent library to deserialize it send output stream to your python application and deserialize it Charles wrote: the problem is that for this to work, your \"little java program\" needs to load the same versions of all the same classes that it might deserialize. Which is tricky if you're receiving log messages from one app, and really tricky if you're multiplexing more than one log stream. Either way, it's not going to be a little program any more. Can't you just simply reference Java log4j libraries in your own java process? I'm just giving general advice here that is applicable to any pair of languages (name of the question is pretty language agnostic so I just provided one of the generic solutions). Anyway, I'm not familiar with log4j and don't know whether you can \"inject\" your own serializer into it. If you can, then of course your suggestion is much better and cleaner. ","pontos":1},{"corpo":"If you decide to use macros (or are using C on a future project) you should add parenthesis around the 'b' in the macro expansion (I don't have enough points yet to edit other people's content): #define BOOL_STR(b) ((b)?\"true\":\"false\") This is a defensive programming technique that protects against hidden order-of-operations errors; i.e., how does this evaluate for all compilers? 1 == 2 ? \"true\" : \"false\" compared to (1 == 2) ? \"true\" : \"false\" ","pontos":5},{"corpo":"In my opinion it's only too automated if no one in your production support group can deploy an application manually in a pinch. Automated deployments really cut down on simple but common errors such as configuration mistakes. However, a manual deployment must always be an option. ","pontos":1},{"corpo":"This post by Omer van Kloeten seems to do what you want. Notice that the output has the line: private static Foo instance = new Foo(); ","pontos":2},{"corpo":"I think what you want is a const rather than static. I assume what you want is the effect of having a static readonly which is why you always want the value to be 5. In c# consts are treated exactly the same as a readonly static. From the c# docs: Even though constants are considered static members, a constant- declaration neither requires nor allows a static modifier. ","pontos":0},{"corpo":"Make liberal use of [SuppressMessage] attribute to begin with. At least at the beginning. Once you get the count to 0 via the attribute, you then put in a rule that new checkins may not introduce FxCop violations. Visual Studio 2008 has a nice code analysis feature that allows you to ensure that code analysis runs on every build and you can treat warnings as errors. That might slow things down a bit so I recommend setting up a continuous integration server (like CruiseControl.NET) and having it run code analysis on every checkin. Once you get it under control and aren't introducing new violations with every checkin, start to tackle whole classes of FxCop violations at a time with the goal of removing the SuppressMessageAttributes that you used. The way to keep track of which ones you really want to keep is to always add a Justification value to the ones you really want to suppress. ","pontos":12},{"corpo":"I've never heard of such a function, but it would be trivial enough to implement... def die(msg) puts msg exit end Then, if this is defined in some .rb file that you include in all your scripts, you are golden.... just because it's not built in doesn't mean you can't do it yourself ;-) ","pontos":4},{"corpo":" Very simple arithmetic is good. Blind people will be able to answer. (But as Jarod said, beware of operator precedence.) I gather someone could write a parser, but it makes the spamming more costly. Sufficiently simple, and it will be not difficult to code around it. I see two threats here: random spambots and the human spambots that might back them up; and bots created to game Stack Overflow With simple arithmetics, you might beat off threat #1, but not threat #2. ","pontos":6},{"corpo":"I have not seen any serious issues with MSTest. What, specifically, are you talking about? We are, in fact, moving away from NUnit to MSTest. I do not know our reasons for this, though. ","pontos":2},{"corpo":"There are lots of config files with mstest, making it less condusive. Another reason I chose mbunit, is the \"rollback\" feature of mbunit. This allows you to rollback all database things done in this test, so you can actually do full circuit tests and not worry about the pond being tainted after the test. Also lack of RowTest facilities in mstest. I suggest just running mbunit as a dependency inside the build process, its easy enough to just float it with your bin, and reference, no installation required. ","pontos":2},{"corpo":"Most of the memory overhead will come from the opcode cache size. Each opcode cacher has their own default(e.g. 30MB for APC) which you can change through the config file. Other than the cache size, the actual memory overhead of the cacher itself is negligible. ","pontos":5},{"corpo":"How about using the C++ language itself? bool t = true; bool f = false; std::cout std::noboolalpha t \" == \" std::boolalpha t std::endl; std::cout std::noboolalpha f \" == \" std::boolalpha f std::endl; ","pontos":73},{"corpo":"I don't know anything about groovy so in a sense I've qualified to answer this... I would want you to: Tell me why I would want to use Scripting (in general) as opposed to Java-- what does it let me do quicker (as in development time), what does it make more readable. Give tantalising examples of ways I can use chunks of scripting in my mostly Java app. You want to make this relevant to Java devs moreso than tech-junkies. With that out of the way, why Groovy? Why not Ruby, Python or whatever (which are all runnable on the JVM). Don't show me syntax that Java can already do (if statements, loops etc) or if you do make it quick. It's as boring as hell to watch someone walk through language syntax 101 for 20min. For syntax that has a comparible feature in Java maybe show them side by side quickly. For syntax that is not in Java (closures etc) you can talk to them in a bit more detail. Remember those examples from the first point. Show me one, fully working (or at least looking like it is). At the end have question time. That is crazy important, and with that comes a burden on you to be a psuedo-guru :P. I'm not sure about how the Java6 scripting support works but I'm fairly sure it can be made secure. I remember something about defining the API the script can use before it's run. If this is the case then an example you could show would be some thick-client application (e.g. a music player) where users can write their own scripts with an API you provide them in Groovy which allows them to script their app in interesting and secure ways (e.g. creating custom columns in the playlist) ","pontos":8},{"corpo":"I am now using Linq to Sql. This solves the problem entirely. However if you do not have that option (or some similar ORM tool), I don't see any reason to separate Read/Write methods. It just adds more classes and complicates data access. I have always designed it as follows: Component/Business Object: Car Data Access, containing static Read and Write methods: CarDB Example Usage: Car car = new Car(); car.Manufacturer = \"Toyota\" car.Model = \"Camry\" car.Year = 2006; car.CarID = CarDB.InsertCar(car) car.OwnerID = 2; CarDB.UpdateCar(car); This also makes sense for data access where both Reads and Write need to be performed as part of the same transaction. If you split up the classes, where would that go? ","pontos":3},{"corpo":"Well I am not Python expert so I can't comment on how to solve your problem but if you have program in .NET you may use IKVM.NET to deserialize Java objects easily. I have experimented this by creating .NET Client for Log4J log messages written to Socket appender and it worked really well. I am sorry, if this answer does not make sense here. ","pontos":1},{"corpo":"If you want to denote an actual error in your code, you could raise a exception: raise RuntimeError, 'Message goes here' This will print a stacktrace, the type of the exception being raised and the message that you provided. Depending on your users, a stacktrace might be too scary, and the actual message might get lost in the noise. On the other hand, if you die because of an actual error, a stacktrace will give you additional information for debugging. ","pontos":16},{"corpo":"Because in most cases you've got to sort your results first. For example, when you search on Google, you can view only up to 100 pages of results. They don't bother sorting by page-rank beyond 1000 websites for given keyword (or combination of keywords). Pagination is fast. Sorting is slow. ","pontos":17},{"corpo":"This is a really vague question. We'd need a concrete example to get a better idea of the problem. ","pontos":2},{"corpo":"When you say Spring Framework are you referring to Spring MVC or just the core Spring concepts (dependency injection, AOP, etc)? If it is really the concept of Spring you like then I recommend checking out Stripes. Stripes makes using Spring dependency injection really easy and offers a lot in the way of writing controllers and views. Unlike Spring MVC it is configured primarily through annotations which is something you will either love or hate. On the topic of template engines it really boils down to identifying what exactly you do not like about jsp in the first place. Personally I find Java web development is hindered more by the controller frameworks than the templating language. Stripes is the best I have tried so far, but compared to Django and Rails it still feels a little cumbersome. ","pontos":2},{"corpo":"The view state only lasts for multiple requests for the same page. Changing the query string in the URL is requesting a new page, thus clearing the view state. Is it possible to remove the reliance on the view state by adding more query string parameters? You can then build a new URL and Response.Redirect to it. Another option is to use the Action property on the form to clear the query string so at least the query string does not contradict what's displayed on the page after the user selects a different report. Form.Action = Request.Path; ","pontos":0},{"corpo":"I thought you meant pagination of the printed page - that's where I cut my teeth. I was going to enter a great monologue about collecting all the content for the page, positioning (a vast number of rules here, constrait engines are quite helpful) and justification... but apparently you were talking about the process of organizing information on webpages. For that, I'd guess database hits. Disk access is slow. Once you've got it in memory, sorting is cheap. ","pontos":1},{"corpo":"Unfortunately, git provides no way to do this. Instead, the 'git way' is to have two repositories -- client and server, and clone the one(s) you need. ","pontos":2},{"corpo":"Are you running your application locally inside of IIS or inside of the development web server? If it's the latter, then that's probably why: Cassini (the development web server) doesn't do ISAPI, so this value will be empty. ","pontos":3},{"corpo":"IDEA 8 Milestone 1 is a beta(ish) \"based on a new platform\". This may have changed the way that swing is handled. Also you are running a beta JDK. You will probably get more help/submit a bug at the Jetbrain forums unless they are on SO also. Here is the bug tracker link ","pontos":1},{"corpo":"Looks like a threading issue. Hypothesis: Maybe you have a main thread and a timer thread accessing this control. The main thread shuts down - calling Control.Dispose() to indicate that I'm done with this Control and I shall make no more calls to this. However the timer thread is still active - a context switch to that thread, where it may call methods on the same control. Now the control says I'm Disposed (already given up my resources) and I shall not work anymore. ObjectDisposed exception. How to solve this: In the timer thread, before calling methods/properties on the control, do a check with if ControlObject.IsDisposed then return; // or do whatever - but don't call control methods OR stop the timer thread BEFORE disposing the object. ","pontos":8},{"corpo":"There are ways you can work around the limitations of file logging. You can always start each log entry with a thread id of some kind, and grep out the individual thread ids. Or a different log file for each thread. I've logged to database in the past, in a separate thread at a lower priority. I must say, queryability is very valuable when you're trying to figure out what went wrong. ","pontos":1},{"corpo":" I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls. Is that right, or is there something I'm missing. You aren't missing anything; SQL Server does not support global variables, and it doesn't support data modification within UDFs. And even if you wanted to do something as kludgy as using CONTEXT_INFO (see http://weblogs.sqlteam.com/mladenp/archive/2007/04/23/60185.aspx), you can't set that from within a UDF anyway. Is there a way you can get around the \"hardcoding\" of the offset by making that a variable and looping over the iteration of it, doing the inserts within that loop? ","pontos":2},{"corpo":"Whats the value for the SqlException.ErrorCode property? Can you work with that? Seems like this guy is having timeouts, may be worth checking the code for -2146232060. I would set this up as a static const in your data code. ","pontos":1},{"corpo":"The interesting question, should you decide to log to the database, is where do you log database connection errors? If I'm logging to a database, I always have a secondary log location (file, event log, etc) in case there are communication errors. It really does make it easier to diagnose issues later on. ","pontos":6},{"corpo":"I prefer keeping all data access logic in the program code, in which the data access layer executes straight SQL queries. On the other hand, data management logic I put in the database in the form of triggers, stored procedures, custom functions and whatnot. An example of something I deem worthy of database-ifying is data generation - assume our customer has a FirstName and a LastName. Now, the user interface needs a DisplayName, which is derived from some nontrivial logic. For this generation, I create a stored procedure which is then executed by a trigger whenever the row (or other source data) is updated. There appears to be this somewhat common misunderstanding that the data access layer IS the database and everything about data and data access goes in there \"just because\". This is simply wrong but I see a lot of designs which derive from this idea. Perhaps this is a local phenomonon, though. I may just be turned off the idea of SPs after seeing so many badly designed ones. For example, one project I participated in used a set of CRUD stored procedures for every table and every possible query they encountered. In doing so they simply added another completely pointless layer. It is painful to even think about such things. ","pontos":0},{"corpo":"These days I hardly ever use stored procedures. I only use them for complicated sql queries that can't easily be done in code. One of the main reasons is because stored procedures do not work as well with OR mappers. These days I think you need a very good reason to write a business application / information system that does not use some sort of OR mapper. ","pontos":0},{"corpo":"Source for Matt's answer. I can get it to run by double-clicking a file by creating a batch file with the following in it: C:\\WINDOWS\\system32\\windowspowershell\\v1.0\\powershell.exe LocationOfPS1File ","pontos":2},{"corpo":"I still can't see the formulae in your example (just values), but that is exactly what I'm trying to do in terms of the result; obviously I can already do it \"by the side\" and sum separately - the key for me is doing it in one cell. I have looked at it again this morning - using the function for the lookup works in an array formula. But then the function does not. I have also tried using it with and without success. Finally, the function does not seem to accept a cell range as its list to choose from - the range degrades to a single value (the first cell in the range). It should also be noted that the function only accepts 30 values to choose from (according to the documentation). All very annoying. However, I do now have a working solution in one cell: using the function and explicitly listing the result cells one by one in the arguments like this: =ARRAYFORMULA(SUM(CHOOSE(MATCH(D1:D8,Lookups!$A$1:$A$3,0), Lookups!$B$1,Lookups!$B$2,Lookups!$B$3))) Obviously this doesn't extend very well but hopefully the lookup tables are by nature quite fixed. For larger lookup tables it's a pain to type all the cells individually and some people may exceed the limit of 30 cells. I would certainly welcome a more elegant solution! ","pontos":0},{"corpo":"@garethm: I believe that the function you're looking for is called tmpnam. You should definitely not use . It suffers from the race condition problem I mentioned in my answer: Between determining the name and opening it, another program may create the file or a symlink to it, which is a huge security hole. The man page specifically says not to use it, but to use or instead. ","pontos":2},{"corpo":"I suppose a good question is what language are you using? In PHP you would do: SELECT * FROM PEOPLE WHERE SURNAME='mysql_escape_string(O'Keefe)' But since you didn't specify the language I will suggest that you look into a escape string function mysql or otherwise in your language. ","pontos":0},{"corpo":"I seem to remember that I have sometimes found it useful to use RunAs when you run msvcmon (or whatever it's called this week - the remote debugging stub anyway), to force it to start as the user which you have set up to be the same on both machines. I would guess that on the machine you're running VS on, you will also need to log in as the local user rather than a domain user (or start VS with RunAs). I have never understood why this needed to be so hard, given that unmanaged debugging is so much easier, and must expose every security hole that managed debugging could. ","pontos":1},{"corpo":"You can modify the user's personal.xls file, stored in the excel startup directory (varies between Office versions). If you have lots of users though, that can be fiddly. An alternative way to get over your problem is to store the macro in a template (.xlt) file. Then when the users opens it they can't save it back over the original file, but have to specify a new filename to save it as. The disadvantage of this method is that you then get multiple copies of your original code all over the place with each saved file. If you modify the original .xlt and someone reruns the old macro in a previously-saved .xls file then things can get out of step. ","pontos":1},{"corpo":"I don't think it can be done in every browser. Someone has done it in IE6, but it does not work in FF or Opera (AFAIK). Maybe you can get it to work in all the browsers. Here's a blog post from 2005. ","pontos":0},{"corpo":"Ignoring ORM (not because I'm either for or against it) I would keep them in the same class. They are both facets of a single responsibility and separating them just makes you look in two places where I can't really think of a good reason you would want to do that. ","pontos":3},{"corpo":" we do check the IsDisposed property on the schedule component before using it in the Timer Tick event but it doesn't help. If I understand that stack trace, it's not your timer which is the problem, it's one in the control itself - it might be them who are not cleaning-up properly. Are you explicitly calling Dispose on their control? ","pontos":2},{"corpo":"If you want to increase the execution timeout for this one request you can set But you still may have the problem of the client timing out which you can't reliably solve directly from the server. To get around that you could implement a \"processing\" page (like Rob suggests) that posts back until the response is ready. Or you might want to look into AJAX to do something similar. ","pontos":13},{"corpo":"have you tried adding the following before the call : $.ajaxSetup({ scriptCharset: \"utf-8\" , contentType: \"application/json; charset=utf-8\" }); The options are explained here. contentType : When sending data to the server, use this content-type. Default is \"application/x-www-form-urlencoded\", which is fine for most cases. scriptCharset : Only for requests with 'jsonp' or 'script' dataType and GET type. Forces the request to be interpreted as a certain charset. Only needed for charset differences between the remote and local content. ","pontos":13},{"corpo":" Unable to load DLL 'HardwareID.dll': Invalid access to memory location. (Exception from HRESULT: 0x800703E6) The name of DllNotFoundException is confusing you - this isn't a problem with finding or loading the DLL file, the problem is that when the DLL is loaded, it does an illegal memory access which causes the loading process to fail. Like another poster here, I think this is a DEP problem, and that your UAC, etc, changes have finally allowed you to disable DEP for this application. ","pontos":2},{"corpo":"There are a couple under development. GitNub Gitty (404, dead project) I don't know if there are any that have hit 1.0. ","pontos":6},{"corpo":"In todays world: It's neglectible. I think memory consumption was about 50 MB bigger with eAccelerator then it was without when I did my benchmarks. If you really need the speed but do have headaches that your RAM might be not enough: grab $40 and buy another GIG of RAM for your server ;) ","pontos":0},{"corpo":"In general my rule is: \"The application should manage it's own schema.\" This means schema upgrade scripts are part of any upgrade package for the application and run automatically when the application starts. In case of errors the application fails to start and the upgrade script transaction is not committed. The downside to this is that the application has to have full modification access to the schema (this annoys DBAs). I've had great success using Hibernates SchemaUpdate feature to manage the table structures. Leaving the upgrade scripts to only handle actual data initialization and occasional removing of columns (SchemaUpdate doesn't do that). Regarding testing, since the upgrades are part of the application, testing them becomes part of the test cycle for the application. Afterthought: Taking on board some of the criticism in other posts here, note the rule says \"it's own\". It only really applies where the application owns the schema as is generally the case with software sold as a product. If your software is sharing a database with other software, use other methods. ","pontos":4},{"corpo":"In the meantime, I've tried it two tools that have some sort of integration with vim. The first is Rope, a python refactoring library that comes with a Vim (and emacs) plug-in. I tried it for a few renames, and that definitely worked as expected. It allowed me to preview the refactoring as a diff, which is nice. It is a bit text-driven, but that's alright for me, just takes longer to learn. The second is Bicycle Repair Man which I guess wins points on name. Also plugs into vim and emacs. Haven't played much with it yet, but I remember trying it a long time ago. Haven't played with both enough yet, or tried more types of refactoring, but I will do some more hacking with them. ","pontos":37},{"corpo":"Automatic generation of (M|m)akefiles makes me worry about what you're trying to do here. Do you understand what goes on under the covers when you type make? Or gmake? I'm only asking because if you don't when things break, such as new code changes not being incorporated into the build, you'll have difficulties trying to work what has happened. To start to understand make, can I suggest having a read of \"Managing Projects with GNU Make\" by Robert Mecklenberg. The early chapters cover how make is working. Getting your heard around the fact that make is backward chaining is one of the biggest things you can do. If you don't, and your system appears to work, then you'll be, to use The Pragmatic Programmers' term, \"programming by coincidence\". (-: BTW Great articles available at their site! And I'm not involved with them. YMMV. Yada-yada... ","pontos":2},{"corpo":"When is the problem likely to become a real issue? Given current growth rates, how soon do you expect signed integer overflow to happen in the MS SQL version? Be pessimistic. How long do you expect the application to live? Do you still think the factor of 2 difference is something you should worry about? (I have no idea what the answers are, but I think we should be sure that we really have a problem before searching any harder for a solution) ","pontos":1},{"corpo":"I agree with Stu, and I don't consider myself an Architect luddite :-). Kind of like a lot of MS frameworks over the years, you are tied to their particular way of thinking, which doesn't always gel with the ideas that come out of the rest of the architecture community at large. Generating stubs, in my opinion, doesn't really add that much value, and the round trip half of the equation has messed up some of my project files and made me have to re-write the things manually. ","pontos":0},{"corpo":"Go to Environment > Fonts and Colors > Display Items and change Identifier String I was hoping that their is I can be more specific with the colours - if their isn't then that's an acceptable answer - just disappointing for me. Yeah, I don't think you can do that. :) ","pontos":1},{"corpo":"There's many OS specific ways to force routing over specific interfaces. What OS are you using? XP? Vista? *nix? The simplest way is to configure your network card with a static IP and NO GATEWAY, the only gateway (ie. internet access) your laptop will find is then via the mobile. The disadvantage of this method is that you'll need to access your TFS server by IP address (or netbios name) as all DNS requests will be going out over the internet and not through your private LAN. EDIT: If you can't use the phone when the LAN is plugged in, that's because you've got it setup for DHCP and the DHCP server is advertising (incorrectly for you) that it will accept and route internet traffic. As previously mentioned, setup with a static IP and no gateway... if you insist on using DHCP you'll need to learn the ROUTE command in DOS, find the IP address of your phone (assuming it's acting as a router) set that as the default route, and remove whatever default route was assigned from the DHCP server. EDIT2: @dan - you can't use the internet from your phone directly (eg. mobile browser), or you can't make your laptop use your phone for internet when the cable is plugged in? (ie. routing issues) ... if it's the former, then your phone is probably configuring a PAN with your phone and trying to route internet back over the LAN EDIT @Jorge - IP routing is the responsibility of the network layer, not the application. Go review the OSI model ;) ","pontos":1},{"corpo":"You could do that, but if that files are binary you should always put a lock on it before editing. You won't get a conflict (which would be unresolvable). ","pontos":0},{"corpo":"Not necessarily. It depends on how often the new files are committed to the repo. If the files are edited several times before a commit, then you're precisely where you are now. The biggest benefit is if the file becomes corrupted. You can version any file; this is how Time Machine in Mac OS X Leopard works, for example, and there is an interesting article by someone who committed his entire computing environment into CVS and then just maintained working copies on his home and work machines. But \"better\" and \"easier\" are specific to your situation, and I'm not sure I completely understand your problem as things stand. ","pontos":1},{"corpo":"You can set a limit to memory consumption for APC, but that potentially limits its effectiveness. If you're just using it for silent opcode caching, then it should be fine. Once the memory allotment is full, no new files will be cached, but everything will work as expected. However, the user-space cache functions like apc_store() and apc_fetch() will fail silently and inexplicably if there is no memory available. This can be tricky to catch and debug since no error is reported and no exception is thrown. ","pontos":0},{"corpo":"I suppose it is an ovbious answer: Make a requisite for the classes stored in the collection to be cloneable. You could check that at insertion time or at retrieval time, whatever makes more sense, and throw an exception. Or if the item is not cloneable, just fail back to the return by reference option. ","pontos":1},{"corpo":"If you need really simple PDFs, then Zend or FPDF is fine. However I find them difficult and frustrating to work with. Also, because of the way the API works, there's no good way to separate content from presentation from business logic. For that reason, I use dompdf, which automatically converts HTML and CSS to PDF documents. You can lay out a template just as you would for an HTML page and use standard HTML syntax. You can even include an external CSS file. The library isn't perfect and very complex markup or css sometimes gets mangled, but I haven't found anything else that works as well. ","pontos":15},{"corpo":"You can actually configure what you want to be the default gateway globally using the \"routes\" command as described here: http://stackoverflow.com/questions/17785/default-internet-connection-on-dual-lan-workstation I admit though, on windows it'd finicky at best as sometimes that setup will just disappear :( ","pontos":1},{"corpo":"Subversion, CVS and all other source control systems are not good for Word documents and other office files (such as Excel spread sheets), since the files themselves are stored in a binary format. That means that you can never go back and annotate (or blame, or whatever you want to call it), or do diffs between documents. There are revision control systems for Word documents out there, unfortunately I do not know any good ones. We use such control systems for Excel at my work, and unfortunately they all cost money. The good thing is that they make life a lot easier, especially if you ever have to do an audit or due diligence. ","pontos":1},{"corpo":" We put the Thread.Sleep in after a couple of times when the database had gone away and we came back to 3Gb logs files full of database connection errors. I would think a better option would be to make it so that your logging system trapped duplicates, so that it could write something like, \"The previous message was repeated N times\". Assume I've written a standard note about how you should open your connection at the last possible moment and close it at the earliest opportunity, rather than spanning a potentially huge function in the way you've done it (but perhaps that is an artefact of your demonstrative code and your application is actually written properly). When you say that it's reporting the error you describe, do you mean that this handler is reporting the error? The reason it's not clear to me is that in the code snippet you say \"Something went wrong\", but you didn't say that in your description; I wouldn't want this to be something so silly as the exception is being caught somewhere else, and the code is getting stuck somewhere other than the sleep. ","pontos":3},{"corpo":"I have a tendency to stick with basic integers at first (1,2,3), moving onto rational numbers (2.1, 3.13) when things get bigger... Tried using fruit at one point, that works well for a small office. Oh, the 'banana' release? looks over in the corner \"yea... thats getting pretty old now...\" Unfortunately confusion started to set in when the development team grew, is it an Orange, or Mandarin, or Tangelo? It looks ok... what do you mean \"rotten on the inside?\" ... but in all honesty. Setup a separate repository as a master, development goes on in various repositories... for every scheduled release everything is checked in to the master repository so that you can quickly roll back when something goes wrong. (I'm assuming dev/test/production are all separate servers and dev is never allowed to touch production or the master repository....) ","pontos":2},{"corpo":"I maintain a system of web applications with various components that live in separate SVN repos. To be able to version track the system as a whole, I have another SVN repo which contains all other repos as external references. It also contains install / setup script(s) to deploy the whole thing. With that setup, the SVN revision number of the \"metarepository\" could possibly be used for versioning the complete system. In another case, I include the SVN revision via SVN keywords in a class file that serves no other purpose (to avoid the risk of keyword substitution breaking my code). The class in that file contains a string variable that is manipulated by SVN and parsed by a class method. An inconvenience with both approaches is that the revision number is not automatically updated by changes in the externals (approach 1) or the rest of the code (approach 2). ","pontos":0},{"corpo":"It's a bit hard to decypher your data the way WMD has formatted it, but you can pull of the sort of trick you need with common table expressions on SQL 2005: with LastBatches as ( select Batch, max(Id) from HistoryTable group by Batch ) select * from HistoryTable h join LastBatches b on b.Batch = h.Batch and b.Id = h.Id Or a subquery (assuming the group by in the subquery works - off the top of my head I don't recall): select * from HistoryTable h join ( select Batch, max(Id) from HistoryTable group by Batch ) b on b.Batch = h.Batch and b.Id = h.Id Edit: I was assuming you wanted the last item for every batch. If you just need it for the one batch then the other answers (doing a top 1 and ordering descending) are the way to go. ","pontos":0},{"corpo":"I just googled, but this walkthrough seems like a good reference, and it mentions the tool VSSConverter which should help you make the migration as painless as possible. I would like to recommend one thing though: Backup. Backup everything before you do this. Should anything go wrong it's better to be safe than sorry. My links aren't showing up. This is the address: http://msdn.microsoft.com/en-us/library/ms181247(VS.80).aspx ","pontos":2},{"corpo":"Thinking out of the box, would migrating to a Wiki be out of the question? Since you consider it feasible to force your users into Subversion (or something similar), a larger change seem acceptable. Another migration target could be to use some kind of structured XML document format (DocBook comes to mind). This would enable you to indeed use diffs and source control, while getting all sorts of document formats for free. ","pontos":9},{"corpo":"I tried Wireshark and Microsoft Network Monitor, but neither detected my (and the program I am trying to communicate with) transfer. If I had a day to sit and configure it I probably could get it working but I just wanted the bytes sent and, more specifically, bytes received. In the end I found HHD Software's Accurate Network Monitor software which did what I wanted it to, even if it was slight clunky. ","pontos":0},{"corpo":"I often use this little snippet I've written long time ago. It's short and easy to add anywhere when debugging etc... #include ctype.h #include stdio.h void hexdump(void *ptr, int buflen) { unsigned char *buf = (unsigned char*)ptr; int i, j; for (i=0; i buflen; i+=16) { printf(\"%06x: \", i); for (j=0; j 16; j++) if (i+j buflen) printf(\"%02x \", buf[i+j]); else printf(\" \"); printf(\" \"); for (j=0; j 16; j++) if (i+j buflen) printf(\"%c\", isprint(buf[i+j]) ? buf[i+j] : '.'); printf(\"\\n\"); } } ","pontos":26},{"corpo":"Assuming that this will work in PERL as it does in languages that claim to use PERL-compatible syntax: EDIT: But that won't match a or tag, unfortunately. This, perhaps? / \\/?(?!p |p )[^ ]+ / That should cover tags that have attributes, too. ","pontos":1},{"corpo":"Try this, it should work: / \\/?([^p](\\s.+?)?|..+?) / Explanation: it matches either a single letter except p, followed by an optional whitespace and more characters, or multiple letters (at least two). /EDIT: I've added the ability to handle attributes in tags. ","pontos":0},{"corpo":"Since HTML is not a regular language I would not expect a regular expression to do a very good job at matching it. They might be up to this task (though I'm not convinced), but I would consider looking elsewhere; I'm sure perl must have some off-the-shelf libraries for manipulating HTML. Anyway, I would think that what you want to match is /?(p.+|.*)(\\s*.*) non-greedily (I don't know the vagaries of perl's regexp syntax so I cannot help further). I am assuming that \\s means whitespace. Perhaps it doesn't. Either way, you want something that'll match attributes offset from the tag name by whitespace. But it's more difficult than that as people often put unescaped angle brackets inside scripts and comments and perhaps even quoted attribute values, which you don't want to match against. So as I say, I don't really think regexps are the right tool for the job. ","pontos":2},{"corpo":"Is it not recommended to do this with stylesheets? You can change the media type in the LINK statement in your HTML, so when the page is printed, it will revert to the different style? ","pontos":2},{"corpo":"I'd look at either Mercurial or Bazaar. I'm told Git also works on windows, but I suspect the windows port is still a second class port at best. You'll probably need to be able to run python scripts on your webserver to host either of them. ","pontos":2},{"corpo":"I use the CarbonEmacs version on the Macports progam. It installs all the dependencies with just one line: sudo port install emacs For anyone intesrested in Macports (www.macports.org) ","pontos":1},{"corpo":"There is no official way of doing what you want, because the dll interface is a C api. The compiler itself uses mangled names as a workaround, so you should use name mangling when you don't want to change too much in your code. ","pontos":2},{"corpo":"Are you required to have it run as x86? I had similar issues with web apps under Visual Studio's dev web server (which is x86), but switching over to IIS (x64) worked for me. Since I was deploying to IIS x64, I called it a day at that point. I tried tracing with Filemon and Regmon, but didn't get any denied or missing keys errors. If I were to look again, I'd check HKLM\\Software\\WOW6432Node, guessing that the installer writes to the x64 HKLM\\Software node, but not the x86 one. ","pontos":2},{"corpo":"Now I have a problem as to which answer to accept. Further thought on the problem brings me to the conclusion that I was incorrectly throwing exceptions. Duplicate user names, email addresses etc are expected issues during a sign up process and are therefore not exceptions, but simply errors. In which case I probably shouldn't be throwing exceptions, but returning error codes. Which leads me to think that irobinson's approach should be the one to take in this case, especially since the form is only a small part of the UI being displayed. I have now implemented this solution and I am returning xml containing a status and an optional message that is to be displayed. I can then use jQuery to parse it and take the appropriate action: - success: function(data){ var created = $(\"result\", data).attr(\"success\"); if (created == \"OK\"){ resetNewUserForm(); listUsers(''); } else { var errorMessage = $(\"result\", data).attr(\"message\"); $(\"#newUserErrorMessage\").text(errorMessage).show(); } enableNewUserForm(); } However travis' answer is very detailed and would be perfect during debugging or if I wanted to display an exception message to the user. I am definitely not receiving JSON back, so it is probably down to one of those attributes that travis has listed, as I don't have them in my code. (I am going to accept irobinson's answer, but upvote travis' answer. It just feels strange to be accepting an answer that doesn't have the most votes.) ","pontos":2},{"corpo":"I came up with this: (?!\\/?p(?= |\\s.* ))\\/?.*? x/ # Match open angle bracket (?! # Negative lookahead (Not matching and not consuming) \\/? # 0 or 1 / p # p (?= # Positive lookahead (Matching and not consuming) # - No attributes | # or \\s # whitespace .* # anything up to # close angle brackets - with attributes ) # close positive lookahead ) # close negative lookahead # if we have got this far then we don't match # a p tag or closing p tag # with or without attributes \\/? # optional close tag symbol (/) .*? # and anything up to # first closing tag / This will now deal with p tags with or without attributes and the closing p tags, but will match pre and similar tags, with or without attributes. It doesn't strip out attributes, but my source data does not put them in. I may change this later to do this, but this will suffice for now. ","pontos":7},{"corpo":"Dig in and find out? Stick a debugger on that bastard! I can see at least the following possibilities: the logging system hangs; the thread exited just fine but the service is still running because some other part has a logic error. And maybe, but almost certainly not, the following: Sleep() hangs. But in any case, attaching a debugger will show you whether the thread is still there and whether it really has hung. ","pontos":5},{"corpo":"Why don't you just apply the div submit styles to a submit button? I'm sure there's a javascript for this but that would be easier. ","pontos":1},{"corpo":"From the code you've posted, it's not clear that after an exception is thrown the system is definitely able to restart - e.g. if the exception comes from doStuff(), then the control flow will pass back (after the 10 minute wait) to openConnection(), without ever passing through closeConnection(). But as others have said, just attach a debugger and find where it actually is. ","pontos":0},{"corpo":"You definitely want to break up the tasks. Here is a nice example of CruiseControl.NET configuration that has different targets (tasks) for each step. It also uses a common.build file which can be shared among projects with little customization. http://code.google.com/p/dot-net-reference-app/source/browse/#svn/trunk ","pontos":3},{"corpo":"Or how about logging to a queue? That way you can switch out pollers whenever you like to log to different things. It makes things like rolling over and archiving log files very easy. It's also nice because you can add pollers that log to different things, for example: a poller that looks for error messages and posts them to your FogBugz account a poller that looks for access violations ('x tried to access /foo/y/bar.html') to a 'hacking attempts' file etc. ","pontos":2},{"corpo":"For all solutions about the back button, none of them are \"automatic\". With every single one you are going to have to do some work to persist the state of the page. So no, there isn't a way to \"trick\" the browser, but there are some great libraries out there that help you with the back button. ","pontos":0},{"corpo":"Maybe you're not getting an exact match because the browser is lower-casing the entity or something. Try using a carat (^) and lower-case \"v\" just for testing. Edited - My first theory was plain wrong. ","pontos":0},{"corpo":"Use a class to signal the current state of the span. The html could look like this h3 id=\"headerId\" span class=\"upArrow\" uArr; /span Header title /h3 Then in the javascript you do $( '.upArrow, .downArrow' ).click( function( span ) { if ( span.hasClass( 'upArrow' ) ) span.text( \" dArr;\" ); else span.text( \" uArr;\" ); span.toggleClass( 'upArrow' ); span.toggleClass( 'downArrow' ); } ); This may not be the best way, but it should work. Didnt test it tough ","pontos":1},{"corpo":"There's no true threading in JavaScript. JavaScript being the malleable language that it is, does allow you to emulate some of it. Here is an example I came across the other day. ","pontos":8},{"corpo":"I've been working on http://projecteuler.net/ ","pontos":9},{"corpo":"I also like project euler, but I would like to point out that the questions get really tricky really fast. After the first 20 questions or so, they start to be problems most people won't be able to figure out in 1/2 an hour. Another problem is that a lot of them deal with math with really large numbers, that don't fit into standard integer or even long variable types. ","pontos":0},{"corpo":"Have discovered that this only occurs when the script is run on a different drive to the one where the EXE is located. As a work around for this I have simply moved the scripts execution. Apparently the DLL relates to SSL, which isn't relevant to what I'm doing, so this is a suitable workaround. I'm guessing that the problem is caused by changes in the EXE for how it determines relative paths (unlikley as nothing (AFAICT) has changed). Or the %PATH% environmental variable has changed (more likely). Hope this helps someone in the future. ","pontos":1},{"corpo":"Unless the developers you are working with are familiar with MVC pattern I wouldn't. At a minimum I'd talk with them first before making such a big change. ","pontos":4},{"corpo":"I wouldn't recommend just making the switch on an existing project. Perhaps start a small \"demo\" project that the team can use to experiment with the technology and (if necessary) learn what they need to and demonstrate to management that it is worthwhile to make the switch. In the end, even the dev team might realize they aren't ready or it's not worth it. Whatever you do, be sure to document it. Perhaps if you use a demo project, write a postmortem for future reference. ","pontos":1},{"corpo":"You could launch a new bash process redirecting the stderr of that process: $ bash -i 2 stderr.log $ ","pontos":3},{"corpo":"If you want a pen and papper kind of exercizes I'd recommend more designing than coding. Actually coding in paper sucks and it let's you learn almost nothing. Work enviroment does matter so typing in a computer, compiling, seeing what errors you've made, using refactor here and there, just doesn't compare to what you can do on a piece of paper and so, what you can do on a piece of paper, while being an interesting mental exercize is not practical, it will not improve your coding skills so much. On the other hand you can design the architecture of a medium or even complex application by hand in a paper. In fact I usually do. Engineering tools (such as Enterprise Architect) are not good enough to replace the good all by-hand diagrams. Good projects could be, How would you design a game engine? Classes, Threads, Storage, Physics, the data structures which will hold everything and so on. How would you start a search engine? How would you design an pattern recognition system? I find that kind of problems much more rewarding that any paper coding you can do. ","pontos":4},{"corpo":"Have you tried getting a write lock on the file? If it's being written to, that should fail, and you know to leave it alone for a bit... ","pontos":1},{"corpo":"To use the least amount of space you should use a CHAR field constrained to 'Y' or 'N'. Oracle doesn't support BOOLEAN, BIT, or TINYINT data types, so CHAR's one byte is as small as you can get. ","pontos":22},{"corpo":"Doing your own BigNum library is complicated, so i'd say like jjnguy. Use whatever your language offers as libraries. In .net, reference the VisualJ dll as they contain the BigInteger and BigDecimal classes. You should however be aware of some limitations of these libraries, like the lack of a square root method, for example. ","pontos":3},{"corpo":"In the context of a programming forum, we don't usually think of the programmer also needing the application portion of the database. Normally a programmer wants to use their own development environment for the business logic and front end, and just use the store, query, retrieval, and data processing capabilities of the database. If you really want all those other things, then you're talking about a much larger and more complicated run time environment. You're not going to find anything that's 'lightweight' any more. Even MS Access itself no longer qualifies, because it's hardly light weight. It's just lucky in that a lot of users might already have it, making it appear to be light weight. This doesn't mean you won't find anything. Just that it's not likely to have the same level of maturity or distribution as Access, especially since the underlying access engine is already baked into Windows. ","pontos":5},{"corpo":"The \"Changed\" event on the FileSystemWatcher should shouldn't fire until the file is closed. See my answer to a similar question. There is a possibility that the FTP download mechanism closes the file multiple times during download as new data comes in, but I would think that is a little unlikely. ","pontos":3},{"corpo":"Unless the contents of a file can be verified for completion (it has a verifiable format or includes a checksum of the contents) only the sender can verify that a whole file has arrived. I have used a locking method for sending large files via FTP in the past. File is sent with an alternative extension and is renamed once the sender is happy it is all there. The above is obviously combined with a process which periodically tidies up old files with the temporary extension. An alternative is to create a zero length file with the same name but with an additonal .lck extension. Once the real file is fully uploaded the lck file is deleted. The receiving process obviously ignores files which have the name of a lock file. Without a system like this the receiver can never be sure that the whole file has arrived. Checking for files that haven't been changed in x minutes is prone to all sorts of problems. ","pontos":2},{"corpo":"Not directly, but I use the Agent Smith plugin for R# to do this. Unfortunately, R# isn't free. ","pontos":3},{"corpo":"It wouldn't be. Creating an index is more complex than simply scanning the column, even if the computational complexity is the same. That said - how many columns do you have? Are you sure you can't just create an index for each of them if the query time for a single find is too long? ","pontos":2},{"corpo":"I'm no DBA, but I would guess that building the index would require scanning the table anyway. Unless there are going to be multiple queries on that column, I would recommend not creating the index. Best to check the explain plans/execution times for both ways, though! ","pontos":7},{"corpo":"The database I did most of my work on used 'Y' / 'N' as booleans. With that implementation, you can pull off some tricks like: Count rows that are true: SELECT SUM(CASE WHEN BOOLEAN_FLAG = 'Y' THEN 1 ELSE 0) FROM X When grouping rows, enforce \"If one row is true, then all are true\" logic: SELECT MAX(BOOLEAN_FLAG) FROM Y Conversely, use MIN to force the grouping false if one row is false. ","pontos":4},{"corpo":"Variables in C++ can either be declared on the stack or the heap. When you declare a variable in C++, it automatically goes onto the stack, unless you explicitly use the new operator (it goes onto the heap). MyObject x = MyObject(params); // onto the stack MyObject * y = new MyObject(params); // onto the heap This makes a big difference in the way the memory is managed. When a variable is declared on the stack, it will be deallocated when it goes out of scope. A variable on the heap will not be destroyed until delete is explicitly called on the object. ","pontos":1},{"corpo":"+1 for using a file.ext.end signaler if possible, where the contents of file.ext.end is a checksum for the larger file. This isn't for security so much as it is to make sure nothing got garbled along the way. If someone can insert their own file into the large stream they can replace the checksum as well. ","pontos":0},{"corpo":"I've heard only good things about ReSharper. It's on my to-learn list. ","pontos":3},{"corpo":"For me, Ctrl+Shift+F maps to Find in Files. When I need to format code, I highlight it and hit Ctrl+K, Ctrl+F. I understand this doesn't really address automated formatting, I just wanted to clarify for those who may not know this feature even exists in VS. ","pontos":4},{"corpo":"No, you shouldn't. Feel free to try it out on a new project, but a lot of people familiar with ASP.NET webforms aren't loving it yet, due to having to muck around with raw HTML + lots of different concepts + pretty slim pickings on documentation/tutorials. ","pontos":1},{"corpo":"What you described is GORM. It is part of the Grails framework and is built to work with Hibernate (maybe JPA in the future). When I was first using Grails it seemed backwards. I was more comfortable with a Rails style workflow of making the tables and letting the framework generate scaffolding from the database schema. GORM persists your domain objects for you so you create and change the objects, it manages database create/update. This makes more sense now that I have gotten used to it. Sorry to tease you if you aren't looking for a new framework but it is on the roadmap for release 1.1 to make GORM available standalone. ","pontos":1},{"corpo":"Exactly. The code that you need to achieve this is something like that: UIApplication *app = [UIApplication sharedApplication]; [app openURL:[NSURL URLWithString: @\"http://maps.google.com/maps?q=London\"]]; since as per the documentation, UIApplication is only available in the Application Delegate unless you call sharedApplication. ","pontos":31},{"corpo":"From a security perspective, I know that it is possible to spoof a MAC, though I am not entirely sure how difficult it is or what it entails. Otherwise, if the customers don't have easy access to the hardware or the OS, you should be fairly safe doing this... probably best to put a warning sticker on saying that messing with anything will disrupt communication to the server. ","pontos":-1},{"corpo":"All versions of the .Net Framework from 2.0 onwards (i.e. 3.0 and 3.5) use exactly the same core framework files (i.e. the CLR, you'll notice there are no directories relating to 3.0 or 3.5 in the C:\\Windows\\Microsoft.Net\\Framework directory) therefore you shouldn't worry too much about any performance issues. The Core parts are referred to in Microsoft Speak as the 'Red Bits' and the rest as the 'Green Bits'. ","pontos":1},{"corpo":"Here's what I ended up with. I have never found another solution out there for this, so if you have something better, by all means, contribute. First, the long array definition in the wsdl:types area: xsd:complexType name=\"ArrayOf_xsd_long\" xsd:complexContent mixed=\"false\" xsd:restriction base=\"soapenc:Array\" xsd:attribute wsdl:arrayType=\"soapenc:long[]\" ref=\"soapenc:arrayType\" / /xsd:restriction /xsd:complexContent /xsd:complexType Next, we create a SoapExtensionAttribute that will perform the fix. It seems that the problem was that .NET wasn't following the multiref id to the element containing the double value. So, we process the array item, go find the value, and then insert it the value into the element: [AttributeUsage(AttributeTargets.Method)] public class LongArrayHelperAttribute : SoapExtensionAttribute { private int priority = 0; public override Type ExtensionType { get { return typeof (LongArrayHelper); } } public override int Priority { get { return priority; } set { priority = value; } } } public class LongArrayHelper : SoapExtension { private static ILog log = LogManager.GetLogger(typeof (LongArrayHelper)); public override object GetInitializer(LogicalMethodInfo methodInfo, SoapExtensionAttribute attribute) { return null; } public override object GetInitializer(Type serviceType) { return null; } public override void Initialize(object initializer) { } private Stream originalStream; private Stream newStream; public override void ProcessMessage(SoapMessage m) { switch (m.Stage) { case SoapMessageStage.AfterSerialize: newStream.Position = 0; //need to reset stream CopyStream(newStream, originalStream); break; case SoapMessageStage.BeforeDeserialize: XmlWriterSettings settings = new XmlWriterSettings(); settings.Indent = false; settings.NewLineOnAttributes = false; settings.NewLineHandling = NewLineHandling.None; settings.NewLineChars = \"\"; XmlWriter writer = XmlWriter.Create(newStream, settings); XmlDocument xmlDocument = new XmlDocument(); xmlDocument.Load(originalStream); List XmlElement longArrayItems = new List XmlElement (); Dictionary string, XmlElement multiRefs = new Dictionary string, XmlElement (); FindImportantNodes(xmlDocument.DocumentElement, longArrayItems, multiRefs); FixLongArrays(longArrayItems, multiRefs); xmlDocument.Save(writer); newStream.Position = 0; break; } } private static void FindImportantNodes(XmlElement element, List XmlElement longArrayItems, Dictionary string, XmlElement multiRefs) { string val = element.GetAttribute(\"soapenc:arrayType\"); if (val != null val.Contains(\":long[\")) { longArrayItems.Add(element); } if (element.Name == \"multiRef\") { multiRefs[element.GetAttribute(\"id\")] = element; } foreach (XmlNode node in element.ChildNodes) { XmlElement child = node as XmlElement; if (child != null) { FindImportantNodes(child, longArrayItems, multiRefs); } } } private static void FixLongArrays(List XmlElement longArrayItems, Dictionary string, XmlElement multiRefs) { foreach (XmlElement element in longArrayItems) { foreach (XmlNode node in element.ChildNodes) { XmlElement child = node as XmlElement; if (child != null) { string href = child.GetAttribute(\"href\"); if (href == null || href.Length == 0) { continue; } if (href.StartsWith(\"#\")) { href = href.Remove(0, 1); } XmlElement multiRef = multiRefs[href]; if (multiRef == null) { continue; } child.RemoveAttribute(\"href\"); child.InnerXml = multiRef.InnerXml; if (log.IsDebugEnabled) { log.Debug(\"Replaced multiRef id '\" + href + \"' with value: \" + multiRef.InnerXml); } } } } } public override Stream ChainStream(Stream s) { originalStream = s; newStream = new MemoryStream(); return newStream; } private static void CopyStream(Stream from, Stream to) { TextReader reader = new StreamReader(from); TextWriter writer = new StreamWriter(to); writer.WriteLine(reader.ReadToEnd()); writer.Flush(); } } Finally, we tag all methods in the Reference.cs file that will be deserializing a long array with our attribute: [SoapRpcMethod(\"\", RequestNamespace=\"http://some.service.provider\", ResponseNamespace=\"http://some.service.provider\")] [return : SoapElement(\"getFooReturn\")] [LongArrayHelper] public Foo getFoo() { object[] results = Invoke(\"getFoo\", new object[0]); return ((Foo) (results[0])); } This fix is long-specific, but it could probably be generalized to handle any primitive type having this problem. ","pontos":6},{"corpo":" The original prefix was meant to be used to spot problems in equations, but has somehow devolved into making the code slightly easier to read since you don't have to go look for the variable declaration. With todays smart editors where you can simply hover over any variable to find the full type, and not just an abbreviation for it, this type of hungarian notation has lost a lot of its meaning. I'm breaking the habit a little bit but prefixing with the type can be useful in JavaScript that doesn't have strong variable typing. ","pontos":1},{"corpo":"It may not include files that you normally wouldn't see. Or, the files may be there, but you may be unable to see them when reopening the .zip file in explorer, because they are hidden. You may go into Tools->Folder Options, go to the View tab, and select the radio button to view hidden files and folders. ","pontos":1},{"corpo":"A write lock doesn't help if the file upload failed part way through and the sender hasn't tried resending (and relocking) the file yet. ","pontos":0},{"corpo":"Stack objects are handled automatically by the compiler. When the scope is left, it is deleted. { obj a; } // a is destroyed here When you do the same with a 'newed' object you get a memory leak : { obj* b = new obj; } b is not destroyed, so we lost the ability to reclaim the memory b owns. And maybe worse, the object cannot clean itself up. In C the following is common : { FILE* pF = fopen( ... ); // ... do sth with pF fclose( pF ); } In C++ we write this : { std::fstream f( ... ); // do sth with f } // here f gets auto magically destroyed and the destructor frees the file When we forget to call fclose in the C sample the file is not closed and may not be used by other programs. (e.g. it cannot be deleted). Another example, demonstrating the object string, which can be constructed, assigned to and which is destroyed on exiting the scope. { string v( \"bob\" ); string k; v = k // v now contains \"bob\" } // v + k are destroyed here, and any memory used by v + k is freed ","pontos":12},{"corpo":"Elements can belong to more than one class, so you can do something like this: .DefaultBackColor { background-color: #123456; } .SomeOtherStyle { //other stuff here } .DefaultForeColor { color:#654321; } And then in the content portion somewhere: div class=\"DefaultBackColor SomeOtherStyle DefaultForeColor\" Your content /div The weaknesses here are that it gets pretty wordy in the body and you're unlikely to be able to get it down to listing a color only once. But you might be able to do it only two or three times and you can group those colors together, perhaps in their own sheet. Now when you want to change the color scheme they're all together and the change is pretty simple. But, yeah, my biggest complain with CSS is the inability to define your own constants. ","pontos":5},{"corpo":"I've been trying to find the original game I was thinking of - I think it was called 'bots or something like that, and ran on my Mac back in around system 6 days. I'll have to do some digging next time I'm back at my parents place. Thinking more about it over the last day or so, I suppose it's really not all that different to writing brains for bolo (http://www.lgm.com/bolo/) or bots for Quake and those sort of games. ","pontos":0},{"corpo":"It looks like the Compressed Folder shell extension ignores directories (but not files) whose names begin with a dot, unless explicitly given as a parameter (i.e. selected for the Send To command). It's hard to find out what else it excludes, as I can't even find out what the \"compressed folder\" sendto item is doing in the first place, without referring to 3rd party documentation. Edit: OK, the \"Send to compressed folder\" sendto shortcut has an extension of .ZFSendToTarget, which is handled by zipfldr.dll, which is doing all the work. @Kibbee: Mine does include hidden folders while zipping, though I do have \"show hidden files\" enabled. ","pontos":0},{"corpo":"The way I check in Windows if a file has been completely uploaded by ftp is to try to rename it. If renaming fails, the file isn't complete. Not very elegant, I admit, but it works. ","pontos":0},{"corpo":"See http://caniuse.com/#search=worker for the most up-to-date support info. The following was the state of support circa 2009. The words you want to google for are JavaScript Worker Threads Apart from from Gears there's nothing available right now, but there's plenty of talk about how to implement this so I guess watch this question as the answer will no doubt change in future. Here's the relevant documentation for Gears: WorkerPool API WHATWG has a Draft Recommendation for worker threads: Web Workers And there's also Mozillas DOM Worker Threads Update: June 2009, current state of browser support for JavaScript threads Firefox 3.5 has web workers. Some demos of web workers, if you want to see them in action: Simulated Annealing (\"Try it\" link) Space Invaders (link at end of post) MoonBat JavaScript Benchmark (first link) The Gears plugin can also be installed in Firefox. Safari 4, and the WebKit nightlies have worker threads: JavaScript Ray Tracer Chrome has Gears baked in, so it can do threads, although it requires a confirmation prompt from the user (and it uses a different API to web workers, although it will work in any browser with the Gears plugin installed): Google Gears WorkerPool Demo (not a good example as it runs too fast to test in Chrome and Firefox, although IE runs it slow enough to see it blocking interaction) IE8 and IE9 can only do threads with the Gears plugin installed ","pontos":75},{"corpo":"Send to zipped Folder does not traverse into folders without names before dot (like \".svn\"). If you had other folders that begin with dots, those would not be included either. Files without names are not excluded. Hidden attribute does not come into play. Might be a bug, might be by design. Remember that Windows explorer does not allow creating folders beginning with dot, even though the underlying system can handle them. ","pontos":4},{"corpo":"I don't think that the well-known spoofability of MAC addresses is an issue in this case. I think tweakt is just wanting to use them for initial identification. The device can read its own MAC address, and the installer can (as long as it's printed on a label) read the same number and know, \"OK - this is the box that I put at location A.\" tweakt - would these boxes be calling into the manufacturer's server, or the server of the company/person using them (or are those the same thing in this case)? ","pontos":2},{"corpo":"Please tell me what are you doing to /boot that you need more than 64MB on it? Unless you never intend to clean it, anything more is a waste of space. Kernel image + initrd + System.map won't take more than 10MB (probably less - mine weight 5MB) and you really don't need to keep more than two spares. And with the current prices of RAM - if you are needing swap, you'll be much better off buying more memory. Reserve 1GB for swap and have something monitoring it's usage (no swap at all is bad idea because the machine might lock up when it runs out of free memory). ","pontos":0},{"corpo":"As everyone else has said, it most certainly would not be faster to add an index than it would be to do a full scan of that column. However, I would suggest tracking the query pattern and find out which column(s) are searched for the most, and add indexes at least for them. You may find out that 3-4 indexes speeds up 90% of your queries. ","pontos":3},{"corpo":"I don't think there's anything magic about what you're doing here - couldn't what you're doing be described as: \"At production we burn a unique number into each of our devices which is both readable by the end user (it's on the label) and accessible to the internal processor. Our users have to enter this number into our website along with their credit-card details, and the box subsequently contacts to the website for permission to operate\" \"Coincidentally we also use this number as the MAC address for network packets as we have to uniquely assign that during production anyway, so it saved us duplicating this bit of work\" I would say the two obvious hazards are: People hack around with your device and change this address to one which someone else has already activated. Whether this is likely to happen depends on some relationship between how hard it is and how expensive whatever they get to steal is. You might want to think about how easily they can take a firmware upgrade file and get the code out of it. Someone uses a combination of firewall/router rules and a bit of custom software to generate a server which replicates the operation of your 'auth server' and grants permission to the device to proceed. You could make this harder with some combination of hashing/PKE as part of the protocol. As ever, some tedious, expensive one-off hack is largely irrelevant, what you don't want is a class-break which can be distributed over the internet to every thieving dweep. ","pontos":1},{"corpo":"The best explanation of how the garbage collector works is in Jeff Richters CLR via C# book, (Ch. 20). Reading this gives a great grounding for understanding how objects persist. One of the most common causes of rooting objects accidentally is by hooking up events outisde a class. If you hook up an external event e.g. SomeExternalClass.Changed += new EventHandler(HandleIt); and forget to unhook to it when you dispose, then SomeExternalClass has a ref to your class. As mentioned above, the SciTech memory profiler is excellent at showing you roots of objects you suspect are leaking. But there is also a very quick way to check a particular type is just use WnDBG (you can even use this in the VS.NET immediate window while attached): .loadby sos mscorwks !dumpheap -stat -type TypeName Now do something that you think will dispose the objects of that type (e.g. close a window). It's handy here to have a debug button somewhere that will run a couple of times. Then run again. If the number didn't go down, or didn't go down as much as you expect, then you have a basis for further investigation. (I got this tip from a seminar given by Ingo Rammer). ","pontos":7},{"corpo":"The MAC address is as unique as a serial number printed on a manual/sticker. Microsoft does hashing to prevent MAC address spoofing, and to allow a bit more privacy. With the only MAC approach, you can easily match a device to a customer by only being in the same subnet. The hash prevents that, by being opaque to what criteria are used and no way to reverse engineer individual parts. (see password hashing) ","pontos":0},{"corpo":"The following adds -1 years to the current date: SELECT ... From ... WHERE date DATEADD(year,-1,GETDATE()) ","pontos":78},{"corpo":"Original form (The Right Hungarian Notation :) ) where prefix means type (i.e. length, quantity) of value stored by variable is OK, but not necessary in all type of applications. The popular form (The Wrong Hungarian Notation) where prefix means type (String, int) is useless in most of modern programming languages. Especially with meaningless names like strA. I can't understand we people use meaningless names with long prefixes which gives nothing. ","pontos":0},{"corpo":"In addition to the other answers: The C++ language actually has the keyword to explicitly declare the storage class of an object. Of course, it's completely needless because this is the implied storage class for local variables and cannot be used anywhere. The opposite of is (both locally and globall). The following two declarations are equivalent: int main() { int a; auto int b; } Because the keyword is utterly useless, it will actually be recycled in the next C++ standard (C++0x) and gets a new meaning, namely, it lets the compiler infer the variable type from its initialization (like in C#): auto a = std::max(1.0, 4.0); // `a` now has type double. ","pontos":2},{"corpo":"Are you handling the textchanged event for the textbox? That would mean ASP.Net sets the textbox to cause a postback (submit the page) for anything the might cause the textbox to lose focus, including the enter key. ","pontos":0},{"corpo":"Further to @Chris Karcher's answer - you can also automatically format the whole document by hitting Ctrl+K, Ctrl+D. These formatting features work on a variety of file formats - it works wonders on ugly HTML. ","pontos":10},{"corpo":"When using a dynamically typed language, I occasionally use Apps Hungarian. For statically typed languages I don't. See my explanation in the other thread. ","pontos":1},{"corpo":"Is the fact that ASP.net MVC is only in 'Preview 5' be a cause for concern when looking into it? I know that StackOverflow was created using it, but is there a chance that Microsoft could implement significant changes to the framework before it is officially out of beta/alpha/preview release? ","pontos":0},{"corpo":"I created a sample page with a TextBox and a Button and it worked fine for me: asp:TextBox runat=\"server\" ID=\"textbox1\" TextMode=\"MultiLine\" / br / br / asp:Button runat=\"server\" ID=\"button1\" Text=\"Button 1\" onclick=\"button1_Click\" / So it most likely depends on either some other property you have set, or some other control on the form. Edit: TextChanged event is only triggered when the TextBox loses focus, so that can't be the issue. ","pontos":1},{"corpo":"Tables were designed for tabular content, not for layout. So, don't ever feel bad if you use them to display data. ","pontos":4},{"corpo":"Well, I think something is missing here. User wants to get data from the last year and not from the last 365 days. There is a huge diference. In my opinion, data from the last year is every data from 2007 (if I am in 2008 now). So the right answer would be: SELECT ... FROM ... WHERE YEAR(DATE) = YEAR(GETDATE) - 1 Then, if you want to restrict this query, you can add some other filter, but always searching in the last year SELECT ... FROM ... WHERE YEAR(DATE) = YEAR(GETDATE) - 1 AND DATE '05/05/2007' ","pontos":1},{"corpo":"Agree with Thomas -- the general rule of thumb is if it makes sense on a spreedsheet, you can use a table. Otherwise not. Just don't use tables as your layout for the page, that's the main problem people have with them. ","pontos":8},{"corpo":"As many posters have already mentioned, you should use tables to display for tabular data. Tables were introduced in HTML 3.2 here is the relevant paragraph from the spec on their usage: [tables] can be used to markup tabular material or for layout purposes... ","pontos":10},{"corpo":"I have used ASP.NET MVC (I even wrote a HTTPModule that lets you define the routes in web.config), and I still get a bitter taste in my mouth about it. It seems like a giant step backwards in organization and productivity. Maybe its not for some, but I've got webforms figured out, and they present no challenge to me as far as making them maintainable. That, and I don't endorse the current \"TEST EVERYTHING\" fad... ","pontos":12},{"corpo":"Where are you trying to access the property? If you are in onInit, the control may not be loaded yet. ","pontos":5},{"corpo":"Parameterized queries are your friend, as suggested by Matt. Command = SELECT * FROM PEOPLE WHERE SURNAME=? They will protect you from headaches involved with Strings with quotes Querying using dates SQL Injection ","pontos":1},{"corpo":"Your solution will not scale unless you add a permanent index to each column, with all of the columns that are returned in the query in the list of included columns (a covering index). These indexes will be very large, and inserts and updates to that table will be a bit slower, but you don't have much of a choice if you are allowing a user to arbitrarily select a search column. How many columns are there? How often does the data get updated? How fast do inserts and updates need to run? There are trade-offs involved, depending on the answers to those questions. Do plenty of experimentation and testing so you know for sure how things will perform. But to your original question, adding and dropping an index for the purpose of a single query is only beneficial if you do more than one select during the query (for example, the select is in a sub-query that gets run for each row returned). ","pontos":2},{"corpo":"If you created the UserControl during runtime (through ControlCollection.Add), you need to create it on postback too. Another case can be your UserControl does not match the designer.cs page ","pontos":0},{"corpo":"GUI-based command shell seems like an oxymoron to me. The key-word here is Graphical. If I want a GUI, I want a full-featured GUI. But if I want raw performance, I want a command line. ","pontos":2},{"corpo":" Ditto on the SaveAs Whenever I have to do Interop I create a separate VB.NET class library and write the logic in VB. It is just not worth the hassle doing it in C# ","pontos":0},{"corpo":"This can be quite tricky. When attempting to figure out how to map route data into a route, the system currently searches top-down until it finds something where all the required information is provided, and then stuffs everything else into query parameters. Since the required information for the route \"Content/{*pathInfo}\" is entirely satisfied always (no required data at all in this route), and it's near the top of the route list, then all your attempts to map to unnamed routes will match this pattern, and all your URLs will be based on this (\"Content?action=foo controller=bar\") Unfortunately, there's no way around this with action routes. If you use named routes (f.e., choosing Html.RouteLink instead of Html.ActionLink), then you can specify the name of the route to match. It's less convenient, but more precise. IMO, complex routes make the action-routing system basically fall over. In applications where I have something other than the default routes, I almost always end up reverting to named-route based URL generation to ensure I'm always getting the right route. ","pontos":5},{"corpo":"It usually arrives within the first hour. BUt the fact that it reads me@mycompany.com could either because you put it there to protect your privacy (in which case forget about this) or that the system didn't catch your email and they sent it to me@mycompany.com. If the email address was ok and you didn't get it, somehow it bounced or it won't arrive. I'd suggest you contact them again providing an alternate email (gmail or such) to make sure that you don't experience any problems. Last time I received a hotfix it took them 10 minutes. Good luck with that! ","pontos":1},{"corpo":"@Mark Well that's just plain weird! What's your - that could be messing thigns around. I've personally ditched it in favour of contants as it's just so temperamental (or I've never learned how to do it justice). ","pontos":0},{"corpo":"Took about a day for me when I requested one so I suspect some sort of manual/semi-automated process has to complete before you get the e-mail. Give it a day before you start bugging them ;) ","pontos":1},{"corpo":"G'day, Just wanted to clarify an answer someone gave but I don't have enough points yet. diff will work on binary files but it is only going to say something not really useful like \"toto1 and toto2 binary files differ\". cheers, Rob ","pontos":1},{"corpo":"Strictly speaking never, but it gives the garbage collector a strong hint to clean things up. As a rule: do it every time you're done with an object that you've created. ","pontos":3},{"corpo":"Setting a VB6 reference to Nothing, decreases the refecences count that VB has for that object. If and only if the count is zero, then the object will be destroyed. Don't think that just because you set to Nothing it will be \"garbage collected\" like in .NET VB6 uses a reference counter. You are encouraged to set to \"Nothing\" instanciated objects that make referece to C/C++ code and stuff like that. It's been a long time since I touched VB6, but I remember setting files and resources to nothing. In either case it won't hurt (if it was Nothing already), but that doesn't mean that the object will be destroyed. VB6 had a \"With/End With\" statement that worked \"like\" the Using() statement in C#.NET. And of course, the less global things you have, the better for you. Remember that, in either case, sometimes creating a large object is more expensive than keeping a reference alive and reusing it. ","pontos":2},{"corpo":"I had a problem similar to this a while back. I seem to think it would also prevent the app from closing, but it may be applicable here. I pulled up the old code and it looks something like: Dim y As Long For y = 0 To Forms.Count -1 Unload Forms(x) Next It may be safer to Unload the m_frm1. and not just set it to nothing. ","pontos":2},{"corpo":"The question also arises how to get the data into the BLOB. You can put the data in an INSERT statement, as the PHP example shows (although you should use mysql_real_escape_string instead of addslashes). If the file exists on the database server, you can also use MySQL's LOAD_FILE ","pontos":3},{"corpo":"@wvdschel: Don't create separate partitions for each user. Unused space on each partition is wasted. Instead create one partition for all users. Use if necessary to limit each user's space. It's much more flexible than partitioning or LVM. OTOH, one huge partition is usually a bit slower, depending on the file system. ","pontos":2},{"corpo":"I'm not aware of anyone who keeps track of this publicly on a regular basis (unlike Adobe who pushes it every chance they get). The closest that I could come was this article from last November. Based upon his site, this data could be skewed a bit, but I think we fairly similar numbers as well. ","pontos":1},{"corpo":"Did you know 1TB can easily take up to half an hour to ? Workstations usually crash and reboot more often than servers, so that can get quite annoying. Do you really need all that space? ","pontos":1},{"corpo":"Try IE7.js. Should fix your problem without having to make any modifications. Link: IE7.js ","pontos":0},{"corpo":"There is a very rough percentage of browsers with some JRE available at The Counter, though I wouldn't trust it. Sun has a few useful stats from 2007, but their stats from 2008 are much less detailed. They suggest that in 2007 \"92%...of JRE installs...are now Java SE 6\", but who knows what highly technical site they surveyed to get that number. ","pontos":1},{"corpo":"The most important pitfalls for beginning developers is to avoid confusion between C and C++. C++ should never be treated as a mere better C or C with classes because this prunes its power and can make it even dangerous (especially when using memory as in C). ","pontos":3},{"corpo":"There's also Exchange Web Services in newer versions of Exchange. If you need to use Outlook Express and talk to an Exchange server which doesn't support IMAP/POP3, you're stuck, sadly. ","pontos":1},{"corpo":"Yes you can run 2.0 with VS2008. Be sure to select that when you convert, however. When converting a project, I mistakenly left in the ASP.NET 3.5 conversion, and then all new files contained references to Linq, so it was a little bit of a pain to switch back to 2.0 when I realized the mistake. ","pontos":1},{"corpo":"Actually, VB6 implements RAII just like C++ meaning that locally declared references automatically get set to at the end of a block. Similarly, it should automatically reset member class variables after executing . However, there have been several reports that this is not done reliably. I don't remember any rigorous test but it has always been best practice to reset member variables manually. ","pontos":8},{"corpo":"The dialog you're looking for is this one in the project properties: by default, the target will be \"Any CPU\" which means it'll run as 64bit on a 64bit OS (like you're using), or 32bit on a 32bit OS - so this wont stop it from working on 32bit systems. But like you said, to use Edit Continue you will need to target x86 (so it runs as 32bit). Edit: fixed screenshot (I had the C# one, not the VB one) ","pontos":8},{"corpo":"Since you're moving from LAMP (a somewhat cool acronym) to WIMP (a less cool one), you may need to mentally affirm yourself. Otherwise, I've had very little trouble with PHP on Windows. ISAPI rewrite (http://www.isapirewrite.com/) is $99 and has worked very well for me for URL rewriting. ","pontos":0},{"corpo":"Why not go with Apache on Windows? ","pontos":0},{"corpo":"Avoid finalizers. There is no guarantee that they will be called in a timely fashion. It could take quite a long time before the Memory Management system (i.e., the garbage collector) decides to collect an object with a finalizer. Many people use finalizers to do things like close socket connections or delete temporary files. By doing so you make your application behaviour unpredictable and tied to when the JVM is going to GC your object. This can lead to \"out of memory\" scenarios, not due to the Java Heap being exhausted, but rather due to the system running out of handles for a particular resource. One other thing to keep in mind is that introducing the calls to System.gc() or such hammers may show good results in your environment, but they won't necessarily translate to other systems. Not everyone runs the same JVM, there are many, SUN, IBM J9, BEA JRockit, Harmony, OpenJDK, etc... This JVM all conform to the JCK (those that have been officially tested that is), but have a lot of freedom when it comes to making things fast. GC is one of those areas that everyone invests in heavily. Using a hammer will often times destroy that effort. ","pontos":0},{"corpo":"I have used both Subversion and Team Foundation Server extensively, and even though TFS is very tightly integrated into the IDE, I would recommend Subversion. TFS lacks a couple of features that Subversion has, that I really miss - the biggest being the ability to share code across multiple projects using the svn:externals property. TFS does not have this, and this has forced us to structure our source tree in a somewhat artifical way, so as to not have to copy GB of stuff every time we create a branch. I hear that Subversion's integration into the IDE is much better now than when I last used it. I would also mention that if you need work item tracking and other ALM features like that right in the IDE - then TFS may still be the best way to go for you- it all depends on your particular needs. ","pontos":0},{"corpo":"The average first name is about 6 letters. That leaves 43 for a last name. :) Seems like you could probably shorten it if you like. The main question is how many rows do you think you will have? I don't think varchar(50) is going to kill you until you get several million rows. ","pontos":0},{"corpo":"Well, since you only have a four element array you may just want ot unroll the recursion to save time. Passing arrays as arguments will eat up memory and leave a mess for the GC to clean up later. ","pontos":1},{"corpo":"I'm sure there's a registry entry as well but I couldn't easily locate it. There is the VS90COMNTOOLS environment variable that you could use as well. ","pontos":10},{"corpo":"I kept digging around some of the \"major\" frameworks and it seems that Django does exactly what I was talking about. Or so it seems from this screencast. Does anyone have any remark to make about this? Does it work well? ","pontos":0},{"corpo":"@Ian Nelson: I'm wondering if others see the problem there. Let's say you have split fields. That's 70 characters total, 35 for first name and 35 for last name. However, if you have one field, you neglect the space that separates first and last names, short changing you by 1 character. Sure, it's \"only\" one character, but that could make the difference between someone entering their full name and someone not. Therefore, I would change that suggestion to \"35 characters for each of Given Name and Family Name, or 71 characters for a single field to hold the Full Name\". ","pontos":1},{"corpo":"Aren't there environment settings? I have and although I'm using VS2003, I don't know if that changed for later versions. Type \"set V\" at the command line and see if you have them. ","pontos":0},{"corpo":"There is not a native way to do it, but you can achieve it with a macro. The details are described here in full: http://www.helixoft.com/blog/archives/32 You just have to add a little VB Macro to the EvironmentEvents macro section and restart VS. Note: The path will not show up when you first load VS, but will whenever you change which file you are viewing. There is probably a way to fix this, but it doesn't seem like a big deal. ","pontos":23},{"corpo":"I have worked extensively with templated control and I have not found a better solution. Why are you referencing the contentLable in the event handler? The sender is the label you can cast it to the label and have the reference to the label. Like below. //add a custom data binding contentLabel.DataBinding += (object sender, EventArgs e ) = { //do custom stuff at databind time ((Label)sender).Text = //bound content }; Then you should be able to dispose of the label reference in InstantiateIn. Please note I have not tested this. ","pontos":2},{"corpo":"As usually happens when I post questions like this, I found the problem. It turns out the Crypt::SSLeay module was not installed or at least not up to date. Of course the error messages didn't give me any clues. Updating it and all the problems go away and things are working fine now. ","pontos":1},{"corpo":"You could write a custom route that derives from the Route class GetRouteData to strip dashes, but when you call the APIs to generate a URL, you'll have to remember to include the dashes for action name and controller name. That shouldn't be too hard. ","pontos":1},{"corpo":"Are you using javascript to communicate between frames/iframes which point to different domains? This is not permitted by the JS \"same origin/domain\" security policy. Ie, if you have iframe name=\"foo\" src=\"foo.com/script.js\" iframe name=\"bar\" src=\"bar.com/script.js\" And the script on bar.com tries to access , you will get this (or similar) exceptions. Please also note that the same origin policy can also kick in if you have content from different subdomains. Here you can find a short and to the point explanation of it with examples. ","pontos":7},{"corpo":"As far as finalizers go: They are virtually useless. They aren't guaranteed to be called in a timely fashion, or indeed, at all (if the GC never runs, neither will any finalizers). This means you generally shouldn't rely on them. Finalizers are not guaranteed to be idempotent. The garbage collector takes great care to guarantee that it will never call more than once on the same object. With well-written objects, it won't matter, but with poorly written objects, calling finalize multiple times can cause problems (e.g. double release of a native resource ... crash). Every object that has a method should also provide a (or similar) method. This is the function you should be calling. e.g., . There's no reason to be calling when you have a more appropriate method that is intended to be called by you. ","pontos":3},{"corpo":"You may have come across this posting, but it appears that a flash security update changed the behaviour of the crossdomain.xml, requiring you to specify a security policy to allow arbitrary headers to be sent from a remote domain. The Adobe knowledge base article (also referenced in the original post) is here. ","pontos":2},{"corpo":"Maybe I'm not understanding the complexity of what you're asking but... shouldn't this do? SELECT groupname, SUM(value) FROM items WHERE groupname IN ('a', 'b') GROUP BY groupname And if you don't care which of a or b the item belongs to then this will do: SELECT SUM(value) FROM items WHERE groupname IN ('a', 'b') ","pontos":3},{"corpo":"If there's no requirement on preserving file type after scaling I'd recommend the following approach. using (Image src = Image.FromFile(\"main.gif\")) using (Bitmap dst = new Bitmap(100, 129)) using (Graphics g = Graphics.FromImage(dst)) { g.SmoothingMode = SmoothingMode.AntiAlias; g.InterpolationMode = InterpolationMode.HighQualityBicubic; g.DrawImage(src, 0, 0, dst.Width, dst.Height); dst.Save(\"scale.png\", ImageFormat.Png); } The result will have really nice anti aliased edges If you must export the image in gif you're in for a ride; GDI+ doesn't play well with gif. See this blog post about it for more information Edit: I forgot to dispose of the bitmaps in the example; it's been corrected ","pontos":43},{"corpo":"If your data can be laid out in a two-dimensional grid, use . If it can't, don't. Using for anything else is a hack (though frequently not one with proper alternatives, especially when it comes to compatibility with older browsers). Not using for something that clearly should be one is equally bad. and aren't for everything; in fact, being completely meaningless on a semantic level, they are to be avoided at all costs in favor of more semantic alternatives. ","pontos":3},{"corpo":"I've heard of AutoDisconnect causing similar issues (even if the device isn't idle). You may want to try disabling that on the server. ","pontos":1},{"corpo":"A reinstall of Ruby sorted this issue out. It's not what I wanted; I wanted to know why I was getting the issue, but it's all sorted out. ","pontos":1},{"corpo":"All standard ASP.NET postbacks work by calling a __doPostBack javascript method on the page. That function submits the form (ASP.NET only really likes one form per page) which includes some hidden input field in which all the viewstate and other goodness lives. On the face of it I can't see anything in SimpalModal that would screw up your page's form or any of the standard hidden inputs, unless the contents of that modal happened to come from a HTTP GET to an ASP.NET page. That would result in two ASP.NET forms being rendered into one DOM and would would almost certainly screw up the __doPostBack function. Have you considered using the ASP.NET AJAX ModalPopup control? ","pontos":4},{"corpo":"The System.Version class does not support versions with commas in it, so the solution presented by Darren Kopp is not sufficient. Here is a version that is as simple as possible (but no simpler). It uses System.Version but achieves compatibility with version numbers like \"1, 2, 3, 4\" by doing a search-replace before comparing. /// summary /// Compare versions of form \"1,2,3,4\" or \"1.2.3.4\". Throws FormatException /// in case of invalid version. /// /summary /// param name=\"strA\" the first version /param /// param name=\"strB\" the second version /param /// returns less than zero if strA is less than strB, equal to zero if /// strA equals strB, and greater than zero if strA is greater than strB /returns public static int CompareVersions(String strA, String strB) { Version vA = new Version(strA.Replace(\",\", \".\")); Version vB = new Version(strB.Replace(\",\", \".\")); return vA.CompareTo(vB); } The code has been tested with: static void Main(string[] args) { Test(\"1.0.0.0\", \"1.0.0.1\", -1); Test(\"1.0.0.1\", \"1.0.0.0\", 1); Test(\"1.0.0.0\", \"1.0.0.0\", 0); Test(\"1, 0.0.0\", \"1.0.0.0\", 0); Test(\"9, 5, 1, 44\", \"3.4.5.6\", 1); Test(\"1, 5, 1, 44\", \"3.4.5.6\", -1); Test(\"6,5,4,3\", \"6.5.4.3\", 0); try { CompareVersions(\"2, 3, 4 - 4\", \"1,2,3,4\"); Console.WriteLine(\"Exception should have been thrown\"); } catch (FormatException e) { Console.WriteLine(\"Got exception as expected.\"); } Console.ReadLine(); } private static void Test(string lhs, string rhs, int expected) { int result = CompareVersions(lhs, rhs); Console.WriteLine(\"Test(\\\"\" + lhs + \"\\\", \\\"\" + rhs + \"\\\", \" + expected + (result.Equals(expected) ? \" succeeded.\" : \" failed.\")); } ","pontos":26},{"corpo":"Kokos, Couple of things wrong there. First, doing it that way means I have to construct the Foos first, then feed their values to the mock reader which does nothing to reduce the amount of code I'm writing. Second, if the values pass through the reader, the Foos won't be the same Foos (reference equality). They might be equal, but even that's assuming too much of the Foo class that I don't dare touch at this point. ","pontos":0},{"corpo":"What is wrong with native Delphi enums? They are type safe. type TMyEnum = (Item1, Item2, Item3); if MyEnum Item1 then... Since Delphi 2005 you can have consts in a class, but Delphi 5 can not. type TMyEnum = sealed class public const Item1 = 0; const Item2 = 1; const Item3 = 2; end; ","pontos":3},{"corpo":"It's important to keep in mind that MVC and WebForms are not competing, and one is not better than the other. They are simply different tools. Most people seem to approach MVC vs WebForms as \"one must be a better hammer than the other\". That is wrong. One is a hammer, the other is a screwdriver. Both are used in the process of putting things together, but have different strengths and weaknesses. If one left you with a bad taste, you were probably trying to use a screwdriver to pound a nail. Certain problems are cumbersome with WebForms that become elegant and simple with MVC, and vice-versa. ","pontos":28},{"corpo":"My group at work is using Git, and it has been all the difference in the world. We were using SCCS and a steaming pile of csh scripts to manage quite large and complicated projects that shared code between them (attempted to, anyway). With Git, submodule support makes a lot of this stuff easy, and only a minimum of scripting is necessary. Our release engineering effort has gone way, way down because branches are easy to maintain and track. Being able to cheaply branch and merge really makes it reasonably easy to maintain a single collection of sources across several projects (contracts), whereas before, any disruption to the typical flow of things was very, very expensive. We've also found the scriptabability of Git to be a huge plus, because we can customize its behavior through hooks or through scripts that do , and it doesn't seem like a pile of kludges like before. We also sometimes have situations in which we have to maintain our version control across distributed, non-networked sites (in this case, disconnected secure labs), and Git has mechanisms for dealing with that quite smoothly (bundles, the basic clone mechanism, formatted patches, etc). Some of this is just us stepping out of the early 80s and adopting some modern version control mechanisms, but Git \"did it right\" in most areas. I'm not sure of the extent of answer you're looking for, but our experience with Git has been very, very positive. ","pontos":2},{"corpo":"@Kristopher Johnson Unfortunately ocaml doesn't have a concurrent GC, so this can't be done right now. They are working on it and Jane St Ocaml Summer Project should take a step, but it likely wont be integrated in a distribution --I wouldn't do it if I were the maintainers. I will mention that you can of course use MPI, but that is process level parallelism, obviously. ","pontos":1},{"corpo":" The answer above doesn't account for decompressors. There is no CLSID_VideoDecompressorCategory. Is the are a way to ask a filter if it is a video decompressor? Not that I know of. Most filters in this list are codecs, so contain both a encoder and decoder. The filters in the CLSID_ActiveMovieCategories are wrappers around the VfW filters installed. (Some software companies create their own categories, so there may be 'non official' categories on some machines) If you want to see all installed categories, use GraphEdit which is supplied with the DirectShow SDK. GraphEdit itself is a great tool to see what DirectShow does under the hood. So maybe that may be a source of more information about the filters (and their interactions) on your system. ","pontos":2},{"corpo":"I would prefer programmers didn't do this. I find a flashing taskbar to be very disturbing and annoying when I am in the zone doing something else. ","pontos":2},{"corpo":"Seems like my installation of Visio is the problem. I've tried on another computer here and it allow me to open 2 instances of the software. ","pontos":0},{"corpo":"Another point I forgot. The Windows Media Foundation is a toolkit for using WMV/WMA. It does not provide all things that DirectShow supports. It is really only a SDK for Windows Media. There are bindings in WMV/WMA to DirectShow, so that you can use WM* files/streams in DirectShow applications. ","pontos":1},{"corpo":"To make this less tedious, you will need to encapsulate/refactor the mapping between the DataReader and the Object you hold in the list. There is quite of few steps to encapsulate that logic out. If that is the road you want to take, I can post code for you. I am just not sure how practical it would be to post the code here on StackOverflow, but I can give it a shot to keep it concise and to the point. Otherwise, you are stuck with the tedious task of repeating each expectation on the index accessor for the reader. The encapsulation process will also get rid of the strings and make those strings more reusable through your tests. Also, I am not sure at this point how much you want to make the existing code more testable. Since this is legacy code that wasn't built with testing in mind. ","pontos":1},{"corpo":"@Matt Dillard - Did setting these to nothing fix your memory leak? VB6 doesn't have a formal garbage collector, more along the lines of what @Konrad Rudolph said. Actually calling unload on your forms seems to me to be the best way to ensure that the main form is cleaned up and that each subform cleans up their actions. I tested this with a blank project and two blank forms. Private Sub Form_Load() Dim frm As Form2 Set frm = New Form2 frm.Show Set frm = Nothing End Sub After running both forms are left visible. setting frm to nothing did well... nothing. After settign frm to nothing, the only handle open to this form is via the reference. Unload Forms(1) Am I seeing the problem correctly? Josh ","pontos":5},{"corpo":"What you probably want is a combination of a queue that contains updates for the linked server and a process that reads data from the queue and updates the remote server. The trigger will then insert a message into the queue as part of the normal transaction. This data will be read by the separate process and used to update the remote server. Logic will needed in the process handle errors (and possibly retries). The queue can be implemented with one or more tables. ","pontos":1},{"corpo":"The source code seemed to be geared for an executable, you might need to rewire stuffs a bit so it would build as a DLL instead. I don't have much experience with Visual C++ but I think it shouldn't be too hard with some research. My guess is that someone might have had made a library version already, you should try Google. Once you have tesseract-ocr code in a DLL file, you can then import the file into your C# project via Visual Studio and have it create wrapper classes and do all the marshaling stuffs for you. If you can't import then DllImport will let you call the functions in the DLL from C# code. Then you can take a look at the original executable to find clues on what functions to call to properly OCR a tiff image. ","pontos":8},{"corpo":"A PDF is what I'm after, so I'm not sure how outputting another format would help. As it turns out, the footer space just wasn't enough to fit all of this text; verified by the fact that changing the font size to 4pt would fit it all in without a problem. I spent some time attempting to rewrite the footer code using DDX as outlined here and the CFPDF tag to implement it; but even after several hours of hacking away and finally getting a valid DDX as reported by the new isDDX function, the CFPDF tag reported that it was invalid DDX for some reason. At this point I decided I had wasted enough of the client's time/money and just reformatted the footer to be 2 lines of centered text, which was good enough. ","pontos":2},{"corpo":"First, do you really want to ignore errors? If you get an error, it is likely that the data is not in sync any more. Perhaps what you want is to drop the slave database and restart the sync process when you get an error. Second, I think the error you are getting is not when you replicate an item that does not exist (what would that mean anyway?) - it looks like you are replicating an item that already exists in the slave database. I suspect the problem mainly arises from not starting at a clean data copy. It seems that the master has been copied to the slave; then replication has been turned off (or failed); and then it has started up again, but without giving the slave the chance to catch up with what it missed. If you ever have a time when the master can be closed for write access long enough to clone the database and import it into the slave, this might get the problems to go away. ","pontos":3},{"corpo":"Yes, you just run xcode builds via the command line (xcodebuild) which makes it simple to target from CC via an ant . I've been using just regular CC, not the ruby version and it works fine. Here's a barebones example: project name=\"cocoathing\" default=\"build\" target name=\"build\" exec executable=\"xcodebuild\" dir=\"CocoaThing\" failonerror=\"true\" arg line=\"-target CocoaThing -buildstyle Deployment build\" / /exec /target /project More info on xcodebuild And there does appear to be a standard git object here, but I don't use git so I can't tell you much more than that! ","pontos":9},{"corpo":"As EBGreen said, [System.Diagnostics.FileVersionInfo]::GetVersionInfo(path) will work, but remember that you can also get all the members of FileVersionInfo, for example: [System.Diagnostics.FileVersionInfo]::GetVersionInfo(path).CompanyName You should be able to use every member of FileVersionInfo documented here, which will get you basically anything you could ever want about the file. ","pontos":2},{"corpo":"@ allain Can you lower your own process' priority without being superuser? Sure. Be aware, however, that this is a one way street. You can't even get back to where you started. And even fairly small reductions in priority can have startlingly large effects on running time when there is significant load on the system. ","pontos":1},{"corpo":"You should mock the database access if you want to unit test your classes. After all, you don't want to test the database in a unit test. That would be an integration test. Abstract the calls away and then insert a mock that just returns the expected data. If your classes don't do more than executing queries, it may not even be worth testing them, though... ","pontos":5},{"corpo":"I usually try to break up my tests between testing the objects (and ORM, if any) and testing the db. I test the object-side of things by mocking the data access calls whereas I test the db side of things by testing the object interactions with the db which is, in my experience, usually fairly limited. I used to get frustrated with writing unit tests until I start mocking the data access portion so I didn't have to create a test db or generate test data on the fly. By mocking the data you can generate it all at run time and be sure that your objects work properly with known inputs. ","pontos":2},{"corpo":"Avoiding a framework altogether will leave you with lots of code and a bunch of tedious browser-testing. If you would consider a framework I'd suggest jQuery with the jqDnR plugin. I think it will solve your problem or perhaps you could combine the functionality of the jQuery draggables with the jQuery resizables ","pontos":0},{"corpo":"@Toran: What I'm testing is the programmatic mapping from data returned from the database to quote-unquote domain model. Hence I want to mock out the database connection. For the other kind of test, I'd go for all-out integration testing. @Dale: I guess you nailed it pretty well there, and I was afraid that might be the case. If you've got pointers to any articles or suchlike where someone has done the dirty job and decomposed it into more easily digestible steps, I'd appreciate it. Code samples wouldn't hurt either. I do have a clue on how to approach that problem, but before I actually dare do that, I'm going to need to get other things done, and if testing that will require tedious mocking, then that's what I'll do. ","pontos":0},{"corpo":"Why do you expect a much higher performance from the C++ application? There is no inherent slowdown added by a C# application when you are doing it right. (not too many dropped references, frequent object creation/dropping per call, etc.) The only time a C++ application really outperforms an equivalent C# application is when you can do (very) low level operations. E.g. casting raw memory pointers, inline assembler, etc. The C++ compiler may be better at creating fast code, but mostly this is wasted in most applications. If you do really have a part of your application that must be blindingly fast, try writing a C call for that hot spot. Only if most of the system behaves too slowly you should consider writing it in C/C++. But there are many pitfalls that may kill your performance in your C++ code. (TLDR: A C++ expert may create 'faster' code as an C# expert, but a mediocre C++ programmer may create slower code than mediocre C# one) ","pontos":2},{"corpo":"Options you have: Write a script that will wipe out database before you start unit tests, then populate db with predefined set of data and run the tests. You can also do that before every test it'll be slow, but less error prone. Inject the database. (Example in pseudo-Java, but applies to all OO-languages) class Database { public Result query(String query) {... real db here ...} } class MockDatabase extends Database { public Result query(String query) { return \"mock result\"; } } class ObjectThatUsesDB { public ObjectThatUsesDB(Database db) { this.database = db; } } now in production you use normal database and for all tests you just inject the mock database that you can create ad hoc. Do not use DB at all throughout most of code (that's a bad practice anyway). Create a \"database\" object that instead of returning with results will return normal objects (i.e. will return instead of a tuple ) write all your tests with ad hoc constructed real objects and write one big test that depends on a database that makes sure this conversion works OK. Of course these approaches are not mutually exclusive and you can mix and match them as you need. ","pontos":3},{"corpo":"You can use unsafe C# code and pointers in critical bottleneck points to make it run faster. Those behave much like C++ code and I believe it executes as fast. But most of the time, C# is JIT-ted to uber-fast already, I don't believe there will be much differences as with what everyone has said. But one thing you might want to consider is: Managed code (C#) string operations are rather slow compared to using pointers effectively in C++. There are more optimization tricks with C++ pointers than with CLR strings. I think I have done some benchmarks before, but can't remember where I've put them. ","pontos":3},{"corpo":"I've used singletons a bunch of times in conjunction with Spring and didn't consider it a crutch or lazy. What this pattern allowed me to do was create a single class for a bunch of configuration-type values and then share the single (non-mutable) instance of that specific configuration instance between several users of my web application. In my case, the singleton contained client configuration criteria - css file location, db connection criteria, feature sets, etc. - specific for that client. These classes were instantiated and accessed through Spring and shared by users with the same configuration (i.e. 2 users from the same company). * *I know there's a name for this type of application but it's escaping me I feel it would've been wasteful to create (then garbage collect) new instances of these \"constant\" objects for each user of the app. ","pontos":1},{"corpo":"You don't say what language you're talking about, but in something .NETish, then it's no more work to return an IList than a List or even an ArrayList, though the mere mention of that obsolete class makes me think you're not talking about .NET. ","pontos":0},{"corpo":"\"Premature optimization is the root of all evil.\" - Donald Knuth ","pontos":2},{"corpo":"I would suggest mocking out your calls to the database. Mocks are basically objects that look like the object you are trying to call a method on, in the sense that they have the same properties, methods, etc. available to caller. But instead of performing whatever action they are programmed to do when a particular method is called, it skips that altogether, and just returns a result. That result is typically defined by you ahead of time. In order to set up your objects for mocking, you probably need to use some sort of inversion of control/ dependency injection pattern, as in the following pseudo-code: class Bar { private FooDataProvider _dataProvider; public instantiate(FooDataProvider dataProvider) { _dataProvider = dataProvider; } public getAllFoos() { // instead of calling Foo.GetAll() here, we are introducing an extra layer of abstraction return _dataProvider.GetAllFoos(); } } class FooDataProvider { public Foo[] GetAllFoos() { return Foo.GetAll(); } } Now in your unit test, you create a mock of FooDataProvider, which allows you to call the method GetAllFoos without having to actually hit the database. class BarTests { public TestGetAllFoos() { // here we set up our mock FooDataProvider mockRepository = MockingFramework.new() mockFooDataProvider = mockRepository.CreateMockOfType(FooDataProvider); // create a new array of Foo objects testFooArray = new Foo[] {Foo.new(), Foo.new(), Foo.new()} // the next statement will cause testFooArray to be returned every time we call FooDAtaProvider.GetAllFoos, // instead of calling to the database and returning whatever is in there // ExpectCallTo and Returns are methods provided by our imaginary mocking framework ExpectCallTo(mockFooDataProvider.GetAllFoos).Returns(testFooArray) // now begins our actual unit test testBar = new Bar(mockFooDataProvider) baz = testBar.GetAllFoos() // baz should now equal the testFooArray object we created earlier Assert.AreEqual(3, baz.length) } } A common mocking scenario, in a nutshell. Of course you will still probably want to unit test your actual database calls too, for which you will need to hit the database. ","pontos":47},{"corpo":"If you're experienced in Java but not in Javascript/CSS, then GWT is going to be a lifesaver (unless you want to learn them, of course). CSS has so many little fiddly details. It is not uncommon to spend half a day fixing a 2 pixel misalignment that only occurs in IE6. I am not sure about how easy it would be to use ROR for the back end... It is possible, I am sure, since GWT ajax communication is just servlets. But they provide some really nice functionality for passing Java objects back and forth which you won't be able to utilize if your server isn't also using Java. ","pontos":1},{"corpo":"I don't think there are any plugins for Express versions of VS. Googling 'Jamie Cansdale' is the canonical reference for this issue. ","pontos":0},{"corpo":"Create a new Running Total Field called, for example \"RTotal\". In \"Field to summarize\" select \"Value\", in \"Type of summary\" select \"sum\", under \"Evaluate\" select \"For each record\". You can then drag this field into your report to use as the \"Total\" at the bottom of each page. You cannot use this running total field in the page header too, however, because Crystal will add the value in the first row on the page to it first (so in your example it would show 9 rather than 4 at the top of page 2). To work around this, create a formula field which subtracts the current value of the Value field from the running total (e.g. {#RTotal}-{TableName.Value}), and put this formula field in your page header. ","pontos":1},{"corpo":"Does Uri.IsWellFormedUriString work for you? ","pontos":16},{"corpo":"The VisualSVN manual says it works with all editions of Visual Studio - though I have not personally tried it. I know that none of Microsoft's Team Foundation Server stuff will work with Express. ","pontos":-1},{"corpo":"Short answer: No. The Express editions support neither the Add-Ins nor Source Control providers (SCC plug-ins). While there are ways to make this work, they are undocumented, violate the license and have caused legal trouble before ","pontos":14},{"corpo":"Yes, with --slave-skip-errors=xxx in my.cnf, where xxx is 'all' or a comma sep list of error codes. ","pontos":9},{"corpo":"See the documentation for XMLReader.setContentHandler(), it says: Applications may register a new or different handler in the middle of a parse, and the SAX parser must begin using the new handler immediately. Thus, you should be able to create a that consumes events until the first event, based on that changes the on the XML reader, and passes the first start element event to the new content handler. You just have to pass the to the in the constructor. If you need all the events to be passes to the vocabulary specific content handler, has to cache the events and then pass them, but in most cases this is not needed. On a side note, I've lately used XOM in almost all my projects to handle XML ja thus far performance hasn't been the issue. ","pontos":2},{"corpo":"Use a symbolic link: A symbolic link is a file-system object that points to another file system object. The object being pointed to is called the target. Symbolic links are transparent to users; the links appear as normal files or directories, and can be acted upon by the user or application in exactly the same manner. ","pontos":0},{"corpo":"I would suggest you start by removing the UpdatePanels at first, and make sure your control orgy is working correctly with postbacks. Once you have that working, try adding the UpdatePanels back in from the bottom up. ","pontos":2},{"corpo":"This site looks promising: http://snipplr.com/view/6889/regular-expressions-for-uri-validationparsing/ They propose following regex: /^([a-z0-9+.-]+):(?://(?:((?:[a-z0-9-._~!$ '()*+,;=:]|%[0-9A-F]{2})*)@)?((?:[a-z0-9-._~!$ '()*+,;=]|%[0-9A-F]{2})*)(?::(\\d*))?(/(?:[a-z0-9-._~!$ '()*+,;=:@/]|%[0-9A-F]{2})*)?|(/?(?:[a-z0-9-._~!$ '()*+,;=:@]|%[0-9A-F]{2})+(?:[a-z0-9-._~!$ '()*+,;=:@/]|%[0-9A-F]{2})*)?)(?:\\?((?:[a-z0-9-._~!$ '()*+,;=:/?@]|%[0-9A-F]{2})*))?(?:#((?:[a-z0-9-._~!$ '()*+,;=:/?@]|%[0-9A-F]{2})*))?$/i ","pontos":5},{"corpo":"You can use the one \"built in\", . You'll need installed though. From the documentation: The hgk Tcl script is a direct port of the gitk tool used with git. The hgk.py extension allows hgk to interact with mercurial in a git-like manner. edit @ Matthew: yeah, that's why I linked to the documentation that explains it. You need to enable it in your .hgrc (like the command), and TCL --as mentioned. ","pontos":1},{"corpo":"MD5 or SHA1 + salt. ","pontos":9},{"corpo":"If you use MD5 or SHA1 use a salt to avoid rainbow table hacks. In C# this is easy: MD5CryptoServiceProvider hasher = new MD5CryptoServiceProvider(); string addSalt = string.Concat( \"ummm salty \", password ); byte[] hash = hasher.ComputeHash( Encoding.Unicode.GetBytes( addSalt ) ); ","pontos":9},{"corpo":" @Mickey: No, it is turned off. Do I need to turn it on to find out? The trace log will show you how long each action takes. It could help you find what is taking so long. Here is a link that might help you get it setup. ","pontos":0},{"corpo":"I like to log minor stuff to a database (if it's possible without slowing things down a lot). It makes it easier to go back and condense results from the log. For fatal errors, I try to pipe them into FogBugz using ScoutSubmit ","pontos":0},{"corpo":"This is the web service to call. http://developer.yahoo.com/search/local/V2/localSearch.html This site has ok web services, but not exactly what you're asking for here. http://www.usps.com/webtools/ ","pontos":2},{"corpo":"I second the vote for MD5 or SHA with a salt. Any of the major web development languages have functions built-in for computing the hash (in PHP, for example, the mcrypt package contains the necessary functions). ","pontos":0},{"corpo":" Require SSL on the application In a custom error page for the 403 redirect the browser to the incoming URL, changing http to https along the way. Note: Keep port 80 open for this - or there won't be a server to listen for requests to redirect. ","pontos":5},{"corpo":"As mk says, SHA1 or MD5 are the standard ones, along with SHA2. What you want is more generally called a cryptographic hash function. Cryptographic hashes are designed to be one-way (given the resulting hash, you shouldn't be able to derive the original input). Also, the likelihood of two arbitrary strings having the same hash (known as a hash collision) should be low (ideally 1/number of hash values). Unfortunately, just because your passwords are hashed doesn't free you from having to try really hard to keep the hashed versions safe. Far too many people will use weak passwords that would be vulnerable to an off-line brute-force attack. Edit - several people have also already pointed out the importance of using a salt. A salt is a constant value that you mix in with the input before using the hash function. Having a unique salt prevents off-line attackers from using pre-computed tables of common passwords (rainbow tables) to brute-force your passwords even faster. ","pontos":13},{"corpo":"InputManagers are still available on Leopard, except: they need to be in the Local domain (); you cannot install them per-user any more, they need to have appropriate privileges, in 64-bit, they won't get loaded at all. The Leopard AppKit Release Notes have more specific details. ","pontos":4},{"corpo":"Hmm... I know that WebSphere is kind of hard to configure. Thats part of the reason we used ServiceMix for our ESB. Maybe its not enabled by default in WebSphere and you would have to turn it on in the config somewhere. ","pontos":0},{"corpo":"There's nothing existing (worth relying on, if anything at all), and I doubt that there would ever be anything official planned. ","pontos":-3},{"corpo":" If I understand correctly, Perforce makes all files that are not checked out read-only. This is only the default behaviour. If required, frequently changing files can be set to be read-write instead. See a full list of file modifiers here. Also, for my environment, I am using Eclipse with the Perforce Plugin. With this plugin, editing a file immediately opens the file for edit. ","pontos":1},{"corpo":"I'm all for using static functions. These just make sense especially when organized into modules ( in C#). However, the moment those functions need some kind of external (non compile-time const) data, then that function should be made an instance method and encapsulated along with its data into a class. In a nutshell: static functions ok, static data bad. ","pontos":11},{"corpo":"I used this in one of my internal tools at work. ","pontos":1},{"corpo":"Array.Copy Method I guess something like: string[] less = new string[parts.Length - (x - 2)]; Array.Copy(parts, x - 2, less, 0, less.Length); (sans the off by 1 bug that I'm sure is in there.) ","pontos":-1},{"corpo":"One specific reason static data is bad, is that C++ makes no guarantees about initialization order of static objects in different translation units. In practice this can cause problems when one object depends on another in a different translation unit. Scott Meyers discusses this in Item 26 of his book More Effective C++. ","pontos":1},{"corpo":"Honestly I think it depends on the discipline of the developers. I use Subversion for my personal work and I've used it at a few jobs. What I like about Subversion is I don't have to hunt someone down and ask them why they're working on something and if it would be OK for me to do some work. The problem comes when someone decides to start working on something and doesn't check it in for a while; this can make merging difficult as several changes get made between their check-out and check-in. I use Perforce right now and for some reason I like SVN better. Perforce definitely gives me a better indication that there's going to be merge conflicts, and even has built-in tools to help me resolve the merges. It has the same problem where if someone makes tons of changes over a long time, the merge will be more difficult. Basically both models require you to check in changes often. If you make numerous check-ins, then you reduce the likelihood that you'll require a merge. I'm guilty of keeping stuff checked out for too long way too often. Personally I feel like SVN's price tag makes up for anything it lacks compared to Perforce; I haven't found a difference between them yet. ","pontos":4},{"corpo":"I would use a minor variation in the second : where (ISNULL(feed_tbl.name, 'NONAME') ISNULL(data_tbl.name, 'NONAME')) OR (ISNULL(data_tbl.status, 'NOSTATUS') ISNULL(feed_tbl.status, 'NOSTATUS')) OR (ISNULL(data_tbl.update, '12/31/2039') ISNULL(feed_tbl.update, '12/31/2039')) For reasons I have never understood, does not equal (at least in SQL Server). ","pontos":0},{"corpo":"UNION will remove duplicates, so just UNION the two together, then search for anything with more than one entry. Given \"code\" as a primary key, you can say: edit 0: modified to include differences in the PK field itself edit 1: if you use this in real life, be sure to list the actual column names. Dont use dot-star, since the UNION operation requires result sets to have exactly matching columns. This example would break if you added / removed a column from one of the tables. select dt.* from data_tbl dt ,( select code from ( select * from feed_tbl union select * from data_tbl ) group by code having count(*) 1 ) diffs --\"diffs\" will return all differences *except* those in the primary key itself where diffs.code = dt.code union --plus the ones that are only in feed, but not in data select * from feed_tbl ft where not exists(select code from data_tbl dt where dt.code = ft.code) union --plus the ones that are only in data, but not in feed select * from data_tbl dt where not exists(select code from feed_tbl ft where ft.code = dt.code) ","pontos":2},{"corpo":"I found the answer here: http://blog.sqlauthority.com/2007/08/22/sql-server-t-sql-script-to-insert-carriage-return-and-new-line-feed-in-code/ You just concatenate the string and insert a where you want your line break. Example: DECLARE @text NVARCHAR(100) SET @text = 'This is line 1.' + CHAR(13) + 'This is line 2.' SELECT @text This prints out the following: This is line 1. This is line 2. ","pontos":101},{"corpo":"Edit: Fair point from the commenter. isn't a good choice these days; use / instead. Historical answer: Be POSIX compliant, and use tmpnam (which will give you a full filename in a temporary location). ","pontos":15},{"corpo":"Check following variables: The environment variable The value of the macro If all fails try to use the directory . You can also use function to generate a unique temporary file name. ","pontos":21},{"corpo":" but is it good or bad The first adjective that comes to mind is \"unnecessary\". C++ has free functions and namespaces, so why would you need to make them static functions in a class? The use of static methods in uninstantiable classes in C# and Java is a workaround because those languages don't have free functions (that is, functions that reside directly in the namespace, rather than as part of a class). C++ doesn't have that flaw. Just use a namespace. ","pontos":21},{"corpo":" Maybe a bonnet, lap or a tree is not a chair but they all are ISittable. Yes, but only ex post facto. They're ISittable because someone sat on them. ","pontos":1},{"corpo":"I don't think there's a built-in control that can do it in .NET. I'm poking around in the MSDN documentation for the standard Windows Button control, but it doesn't look like it's there. I did find a Code Project article with a custom implementation; this might help a little. ","pontos":1},{"corpo":"I recently came across divascheme - an alternative set of key bindings for DrScheme. This is modal, and part of the justification is to do with RSI - specifically avoiding lots of wrist twisting to hit Ctrl-Alt-Shift-something. The coder has done an informal survey of fellow coders and found that emacs users suffered from more wrist pain than vi coders. You can see him doing a short talk at LugRadio Live USA. (The video is a series of 5 minute talks and I can't remember how far through it is, sorry - if someone watches it and posts that here I'll edit this post to say when in the video it is). Note I have not used divascheme. ","pontos":1},{"corpo":"Short of any other answers, I would try attaching to the executable process in Visual Studio, setting a break point in your code and when you step into the process you don't have source to, it should ask for a source file. ","pontos":0},{"corpo":"I'm not sure I understand what sort of document you want? Leave presentation markup (width, border, font, etc) out of HTML... ","pontos":0},{"corpo":"I'm a C++ guy who only knows a little about C#, but I assume most of the concepts are the same. An alternative approach would be to move the declaration of the axle list out of the base class and into the derived classes. You can then add pure virtual functions to the base class to access the axles, which the derived classes would then implement. The problem I see with Is that 'T' is not truly generic in this case - you are expecting it to specifically be an axle derived class. ","pontos":0},{"corpo":"Yeah, my previous answer does not work because I didn't pay any attention to your code. :) The problem is that the anonymous function is a callback function - i.e. getJSON is an async operation that will return at some indeterminate point in time, so even if the scope of the variable were outside of that anonymous function (i.e. a closure), it would not have the value you would think it should: var studentId = null; j.getJSON(url, data, function(result) { studentId = result.Something; }); // studentId is still null right here, because this line // executes before the line that sets its value to result.Something Any code that you want to execute with the value of studentId set by the getJSON call needs to happen either within that callback function or after the callback executes. ","pontos":25},{"corpo":"If you're worried about forgetting to override the function, then make it abstract. ","pontos":0},{"corpo":"You have found the biggest pain point of ASP.NET. As far as sealed, private classes that hinder unit testing. This is the main reason that TDD people will use a MVC framework (ASP.NET MVC, Castle MonoRail) as it provides a clear seperation from your view templates and your controller logic. The controllers are fully testable. ","pontos":3},{"corpo":"Check out Share on Acrobat.com, there you can upload PDFs and make them embedable Flash files (sort of like YouTube for documents). Should be possible to load those into Flex. Not an ideal solution, but unfortunately you need to convert the PDF to an SWF somehow to be able to load it into a Flex application. I don't know of any good tools that do this. If someone else knows please share. If you target AIR you can load a PDF into a HTML view, but that doesn't work when running in the browser (the HTML component is only available in AIR). ","pontos":2},{"corpo":"Since I found the control in Windows itself, I was hoping to find it built-in somewhere already so I didn't have to add anything to my code-base to use it. But the split button at this link (found via the msdn suggestion) looks pretty promising. I'll try it later myself, but I don't know how well it will handle visual styles. ","pontos":0},{"corpo":"hmm, if you've serialized an object with the property then I think that it will be: var studentId; function(json) { if (json.length 0) studentId = json[0].StudentId; } But if you're just returning the itself maybe it's: var studentId; function(json) { if (json.length 0) studentId = json[0]; } Edit: Or maybe isn't even required (I've only returned generic collections in JSON). Edit #2, this works, I just tested: var studentId; jQuery.getJSON(url, data, function(json) { if (json) studentId = json; }); Edit #3, here's the actual JS I used: $.ajax({ type: \"POST\", url: pageName + \"/GetStudentTest\", contentType: \"application/json; charset=utf-8\", dataType: \"json\", data: \"{id: '\" + someId + \"'}\", success: function(json) { alert(json); } }); And in the aspx.vb: System.Web.Services.WebMethod() _ System.Web.Script.Services.ScriptMethod() _ Public Shared Function GetStudentTest(ByVal id As String) As Integer Return 42 End Function ","pontos":-1},{"corpo":"Use namespaces to make a collection of functions: namespace Console { void WriteLine(...) // ... } As for memory, functions use the same amount outside a function, as a static member function or in a namespace. That is: no memory other that the code itself. ","pontos":1},{"corpo":"distutils really isn't all that difficult once you get the hang of it. It's really just a matter of putting in some meta-information (program name, author, version, etc) and then selecting what files you want to include. For example, here's a sample distutils setup.py module from a decently complex python library: Kamaelia setup.py Note that this doesn't deal with any data files or or whatnot, so YMMV. On another note, I agree that the distutils documentation is probably some of python's worst documentation. It is extremely inclusive in some areas, but neglects some really important information in others. ","pontos":1},{"corpo":"That won't work. You might consider making a class called BadgeNumber that wraps a string in order to avoid this ambiguity. ","pontos":1},{"corpo":"I'd suggest to also monitor how often pagefaults happen. A pagefault happens when you try to access some data that have been moved from physical memory to swap file and system has to read page from disk before you can access this data. ","pontos":0},{"corpo":"You could switch to a factory style pattern. public class Person { private Person() {} public static PersonFromID(int personId) { Person p = new Person(). person.Load(personID); return p; this.Load(personId); } public static PersonFromID(string name) { Person p = new Person(). person.LoadFromName(name); return p; } ... } Or, as suggested, use custom types. You can also hack something using generics, but I wouldn't recommend it for readability. ","pontos":0},{"corpo":"This is probably not always faster but more optimistic about that you find a big prime divisor: is your number If it is prime then Calculate primes up until Go through the primes in descending order (largest first) If then Edit: In step 3 you can use the Sieve of Eratosthenes or Sieve of Atkins or whatever you like, but by itself the sieve won't find you the biggest prime factor. (Thats why I wouldn't choose SQLMenace's post as an official answer...) ","pontos":-2},{"corpo":"Sounds like you have a pretty good handle on things. I've seen a lot of people try to do a straight-line transliteration, includes and all, and it just doesn't work. You need to have a good understanding of how ASP.Net wants to work, because it's much different from Classic ASP, and it sounds like maybe you have that. For larger files, I'd try to get a higher level view first. For example, one thing I've noticed is that Classic ASP was horrible about function calls. You'd be reading through some code and find a call to a function with no clue as to where it might be implemented. As a result, Classic ASP code tended to have long functions and scripts to avoid those nasty jumps. I remember seeing a function that printed out to 40 pages! Parsing straight through that much code is no fun. ASP.Net makes it easier to follow function calls around, so you might start by breaking out your larger code blocks into several smaller functions. ","pontos":0},{"corpo":"Parallelisation aside, you don't want to be calculating sqrt(Until) on every iteration. You also can assume multiples of 2, 3 and 5 and only calculate for N%6 in {1,5} or N%30 in {1,7,11,13,17,19,23,29}. You should be able to parallelize the factoring algorithm quite easily, since the Nth stage only depends on the sqrt(n)th result, so after a while there won't be any conflicts. But that's not a good algorithm, since it requires lots of division. You should also be able to parallelize the sieve algorithms, if you have writer work packets which are guaranteed to complete before a read. Mostly the writers shouldn't conflict with the reader - at least once you've done a few entries, they should be working at least N above the reader, so you only need a synchronized read fairly occasionally (when N exceeds the last synchronized read value). You shouldn't need to synchronize the bool array across any number of writer threads, since write conflicts don't arise (at worst, more than one thread will write a true to the same place). The main issue would be to ensure that any worker being waited on to write has completed. In C++ you'd use a compare-and-set to switch to the worker which is being waited for at any point. I'm not a C# wonk so don't know how to do it that language, but the Win32 InterlockedCompareExchange function should be available. You also might try an actor based approach, since that way you can schedule the actors working with the lowest values, which may be easier to guarantee that you're reading valid parts of the the sieve without having to lock the bus on each increment of N. Either way, you have to ensure that all workers have got above entry N before you read it, and the cost of doing that is where the trade-off between parallel and serial is made. ","pontos":2},{"corpo":"I believe that generally you can just use \"this\", or just leave it off completely. The code in the inner class should be able to reference the outer class's members without any problem. The only time you should need to use the more verbose version \"Outer.this\" is if there is name conflicts. So, to expand on Frank's comment: class Outer { void foo() { new Thread() { public void run() { this.bar(); Outer.this.baz(); } public void baz() { } }.start(); } void bar() { System.out.println(\"BAR!\"); } void baz() { System.out.println(\"BAZ!\"); } } ","pontos":-1},{"corpo":"2 options spring to mind. 1 is using generics: abstract class Vehicle TAxle where TAxle : Axle { public List TAxle Axles; } The second uses shadowing - and this assumes you have properties: abstract class Vehicle { public IList Axle Axles { get; set; } } class Motorcyle : Vehicle { public new IList MotorcycleAxle Axles { get; set; } } class Car : Vehicle { public new IList CarAxle Axles { get; set; } } void Main() { Vehicle v = new Car(); // v.Axles is IList Axle Car c = (Car) v; // c.Axles is IList CarAxle // ((Vehicle)c).Axles is IList Axle The problem with shadowing is that you have a generic List. Unfortunately, you can't constrain the list to only contain CarAxle. Also, you can't cast a List Axle into List CarAxle - even though there's an inheritance chain there. You have to cast each object into a new List (though that becomes much easier with LINQ). I'd go for generics myself. ","pontos":0},{"corpo":"I like DocBook, but it doesn't really fit. It strives to be presentation-independent, the intention being that you would use XSLT to render it to a presentation format. In a word processor, the user is editing presentation along with the content. For example, the user doesn't want to mark a \"keyword\", necessarily, they want to make some text bold. A DocBook editor would be a very nice thing (I'm not sure a good one exists), but it's not really what I'm doing. ","pontos":0},{"corpo":"I have experimented a little with the BDD approach and my premature conclusion is that BDD is well suited to use case implementation, but not on the underlying details. TDD still rock on that level. BDD is also used as a communication tool. The goal is to write executable specifications which can be understood by the domain experts. ","pontos":5},{"corpo":"Don't forget refactoring support. ReSharper on .NET provides automatic refactoring and quick fixes for missing code. That means if you write a call to something that does not exist, ReSharper will ask if you want to create the missing piece. ","pontos":0},{"corpo":"You have four options that I can think of, three of which have already been named by others: Go the factory route, as suggested by several others here. One disadvantage to this is that you can't have consistent naming via overloading (or else you'd have the same problem), so it's superficially less clean. Another, larger, disadvantage is that it precludes the possibility of allocating directly on the stack. Everything will be allocated on the heap if you take this approach. Custom object wrappers. This is a good approach, and the one I would recommend if you are starting from scratch. If you have a lot of code using, e.g., badges as strings, then rewriting code may make this a non-viable option. Add an enumeration to the method, specifying how to treat the string. This works, but requires that you rewrite all the existing calls to include the new enumeration (though you can provide a default if desired to avoid some of this). Add a dummy parameter that is unused to distinguish between the two overloads. e.g. Tack a onto the method. This approach is taken by the standard library in a few places, e.g. is a dummy parameter for . The disadvantages of this approach are that it's ugly and that it doesn't scale. If you already have a large base of existing code, I'd recommend either adding the enumeration (possibly with a default value) or adding the dummy parameter. Neither is beautiful, but both are fairly simple to retrofit. If you are starting from scratch, or only have a small amount of code, I'd recommend the custom object wrappers. The factory methods would be an option if you have code which heavily uses the raw / strings, but doesn't heavily use the class. ","pontos":2},{"corpo":"Ok, I've solved my own problem. To get that \"authdata\" string, you need to configure your client to how you need to authenticate. Then navigate to c:[users directory][username]\\Local Settings\\Application Data\\plastic. Pick up the client.conf and extract the string from the SecurityConfig element in the XML. ","pontos":1},{"corpo":"As long as you have the resources (separate hard disk for the virtual machine, sufficient RAM), I don't see why you would have any problems. ","pontos":0},{"corpo":"What kind of scrpt generation are you talking about now?, generating create scripts from the objects in the database is way faster in SSMS compared to EM. But if you are running an select or something that gives you lots of rows in the grid, it is crazy slow.. like scripts generating inserts statements of all rows in an table, if you got lots of data, it is almost not doable. ","pontos":0},{"corpo":" Don't tell me -- the functions don't have any naming convention that tells you which include file has their implementation... That brings back memories (shudder)... How did you guess? ;) I hope you have weighed the upgrade you are doing against just rewriting from scratch -- as long as you are not intending to extend the app too much and you are not primarily responsible for maintaining the app, upgrading a complex workflow-based app like you are doing may be cheaper and a better choice than rewriting it from scratch. ASP.NET should give you better opportunities to improve performance and scalability, at least, than Classic ASP. From your question I imagine that it is too late in the process for that discussion anyway. This was something we talked about. Based on timing (trying to beat a competitor's site to launch) and resources (basically two developers) it made sense to not nuke the site from orbit. Things have actually gone much better than I expected. We were aware even from the planning stages that this code was going to give us the most problems. You should see the revision history of the classic ASP pages involved, it's a bloodbath. For larger files, I'd try to get a higher level view first. For example, one thing I've noticed is that Classic ASP was horrible about function calls. You'd be reading through some code and find a call to a function with no clue as to where it might be implemented. As a result, Classic ASP code tended to have long functions and scripts to avoid those nasty jumps. I remember seeing a function that printed out to 40 pages! Parsing straight through that much code is no fun. I've actually had this displeasure of working with the legacy code quite a bit so I have a decent high level understanding of the system. You're right about the function length, there are some routines (most I've refactored down into much smaller ones) that are 3-4x as long as any of the aspx pages/helper classes/ORMs on the new site. ","pontos":0},{"corpo":"JQuery has animation, but I don't know what it is like on a Mac (I don't have a mac). If things are going slow, then you are probably making the animations too complicated. Remember, JavaScript is a slow language, and DOM is not designed for animation, so try to limit yourself with respect to the number of animations at the same time. Always ask if the animation is really necessary. ","pontos":0},{"corpo":"Essentially, yes. I was not sure you could do it like that (current version does not do it like that). When using the python install script, however, there is no option (that I can find) to specify where to put directories and files (eg --prefix). I was hoping to match the current layout of python related files so as to avoid 'polluting' my machine with redundant files. ","pontos":0},{"corpo":"(Updated) You need to compile with the 1.0 compilers. These are only available with the 1.0 release of the runtime/SDK. The 2.0/3.5 compilers won't emit 1.0-compatible assemblies. Visual Studio 2008 can generate 2.0 assemblies, but 1.0 was left off. ","pontos":1},{"corpo":"Visual Studio 2008 was the first to support targeting older versions of .NET. Unfortunately, it supports only .NET 2 and up. In other words, you'll need .NET framework SDK 1 or 1.1 to do this. ","pontos":2},{"corpo":"Can you explain what you mean by targeting one framework with another framework? You can run apps which are targetted at an older framework on a newer framework, if that's what you mean. (And by the way, 3.0 and 3.5 are both actually 2.0 + Extras) ","pontos":0},{"corpo":"The most widely used IDE for Common Lisp, particularly in the free software subset of the community, is in fact SLIME, which runs on Emacs. You can use whatever CL compiler you prefer and invoke Lisp source files the way you describe, but if you do that, you won't be taking advantage of many of Lisps dynamic features that are so incredibly useful while developing your application. I suggest you take a look at this SLIME demonstration video to see what I mean, even though it might be a bit outdated at this point. If the problem is that you (think you) don't like Emacs, I seriously suggest you try to learn it. Seriously. No, really, I mean that. However, there are alternatives, such as the IDEs provided by commercial Lisp implementations such as Allegro and Lispworks (free trials available), or an Eclipse plug-in called Cusp. ","pontos":2},{"corpo":"Personally, I wouldn't worry about it until you see a problem. Messing with the default python install on a *Nix system can cause more trouble than it's worth. I can say from personal experience that you never truly understand what python has done for the nix world until you have a problem with it. You can also add a second python installation, but that also causes more problems than it's worth IMO. So I suppose the best question to start out with would be why exactly do you want to use the 64 bit version of python? ","pontos":1},{"corpo":"Why not use FormsAuth, but against ActiveDirectory instead as per the info in this thread. It's just as (in)secure as Basic Auth, but logging out is simply a matter of blanking a cookie (or rather, calling FormsAuthentication.SignOut) ","pontos":2},{"corpo":"My gut tells me that since you're already performing buffering by using the byte array, it's redundant to use the BufferedReader. ","pontos":0},{"corpo":"I don't subscribe to the religion of TDD, but I do see a lot of value in unit/etc testing, and do it a lot as I code. The point is though, nobody really knows what the code is supposed to do except the person who wrote it, and often they don't even know either. With that in mind, you're not going to get much value out of 'lackeys' writing the tests because They won't have an in-depth understanding of all the subtle corner cases They won't care about the code because they have nothing invested in it They will feel like they're being treated like idiots. Even if they ARE idiots, nobody likes to be treated like one. If you want your staff to quit, this is a good way to encourage them. ","pontos":1},{"corpo":"@Daniel The distinction between fork/exec and dynamic linking, besides being kind of artificial, doesn't carry over to interpreted languages: what about a Python/Perl/Ruby plugin, which gets loaded via import or execfile? I'm not sure that the distinction is artificial. After a dynamic load the plugin code shares an execution context with the GPLed code. After a fork/exec it does not. In anycase I would guess that ing causes the new code to run in the same execution context as the GPLed bit, and you should treat it like the dynamic link case. No? ","pontos":1},{"corpo":" he distinction between fork/exec and dynamic linking, besides being kind of artificial, I don't think its artificial at all. Basically they are just making the division based upon the level of integration. If the program has \"plugins\" which are essentially fire and forget with no API level integration, then the resulting work is unlikely to be considered a derived work. Generally speaking a plugin which is merely forked/exec'ed would fit this criteria, though there may be cases where it does not. This case especially applies if the \"plugin\" code would work independently of your code as well. If, on the other hand, the code is deeply dependent upon the GPL'ed work, such as extensively calling APIs, or tight data structure integration, then things are more likely to be considered a derived work. Ie, the \"plugin\" cannot exist on its own without the GPL product, and a product with this plugin installed is essentially a derived work of the GPLed product. So to make it a little more clear, the same principles could apply to your interpreted code. If the interpreted code relies heavily upon your APIs (or vice-versa) then it would be considered a derived work. If it is just a script that executes on its own with extremely little integration, then it may not. Does that make more sense? ","pontos":4},{"corpo":"How much info are you sharing between the Plugins and the main program? If you are doing anything more than just executing them and waiting for the results (sharing no data between the program and the plugin in the process) then you could most likely get away with them being proprietary, otherwise they would probably need to be GPL'd. ","pontos":1},{"corpo":"The short answer is because I can. The long answer, expanding on what the OP said, is to be more compatible with apache and mysql/postgresql. They are all 64bit (apache is a fat binary with ppc, ppc64 x86 and x86 and x86_64, the others just straight 64bit). Mysqldb and mod_python wont compile unless they are all running the same architecture. Yes I could run them all in 32bit (and have in the past) but this is much more work then compiling one program. EDIT: You pretty much convinced though to just let the installer do its thing and update the PATH to reflect this. ","pontos":0},{"corpo":"I saw this functionality in older versions of VS.Net (2003 I think). It may still exist in current versions, but I haven't encountered it. Seems that files with the same name, even in different directories confuse VS.Net, and it ends up setting a break point in a file with the same name. May only happen if the classes in the file both have the same name also. So much for namespaces I guess. You also may want to check your build configuration to make sure that all the projects are in fact building in debug mode. I know I've been caught a couple times when the configuration got changed somehow for the solution, and some projects weren't compiling in debug mode. ","pontos":4},{"corpo":" hg: unknown command 'view' (Maybe I need to install something - but it's not native, nonetheless). There is one \"native\" application out there, but it's not especially user-friendly. In fact, I'd go as far as saying that it's harder to use than the command line. There was some talk a year or so ago about a version of SCPlugin, which puts badges on icons in the Finder that are under SVN control, and gives you a contextual menu (very much like TortoiseSVN on windows), but that seems to have collapsed. I have been planning to create a mercurial \"clone\" of Versions (I asked them if they would consider doing a version of it for DVCS, and they said no). ","pontos":1},{"corpo":" I think you need to drop the \"~/\" and replace it with just \"/\", I believe / is the root STOP RIGHT THERE! :-) unless you want to hardcode your web app so that it can only be installed at the root of a web site. \"~/\" is the correct thing to use, but the reason that your original code didn't work as expected is that (which is used internally by ) tries to first work out if the path you are passing it is an absolute URL (e.g. \"*http://server/*foo/bar.htm\" as opposed to \"foo/bar.htm\") - but unfortunately it does this by simply looking for a colon character ':' in the URL you give it. But in this case it finds a colon in the URL you give in the query string value, which fools it - therefore your '~/' doesn't get resolved. The fix is that you should be URL-encoding the value which escapes the problematic ':' along with any other special characters. Response.Redirect(\"~/Login.aspx?ReturnPath=\" + Server.UrlEncode(Request.Url.ToString())); Additionally, I recommend that you (or anyone) never use - because it gives a human-readable, more \"friendly\" version of the URL - not a necessarily correct one (it unescapes things). Instead use Uri.AbsoluteUri - like so: Response.Redirect(\"~/Login.aspx?ReturnPath=\" + Server.UrlEncode(Request.Url.AbsoluteUri)); ","pontos":49},{"corpo":"CodeCampServer - Built with ASP.NET MVC, pretty light and small project. No cruft at all. @lomaxx - Just FYI, most of what Troy Goode wrote is now part of ASP.NET MVC as of Preview 4. ","pontos":10},{"corpo":"I haven't tried this, but wouldn't the basic framework be Open a java.net.HttpURLConnection Get an input stream using getInputStream Use the regular expression in Mike's answer to parse out the bit you want ","pontos":0},{"corpo":"This error ofter occurs because incompatibility of VMWare Tools Version and recent Kernels (You can test it using older Kernels). Sometimes you can fix some thing with patches all over the internet, but I prefer to downgrade my kernel or don't using latest distribution's version in VMWare. It can be really annoying. Another problem you may have is with your mouse pointer in X Windows, like if it was a inch to left or below than it really shows. About vmware-any-any-update117, it's a patch to VMWare running under linux, usually Workstation version. It won't have effect in Tools. ","pontos":1},{"corpo":"Other than the downtime a few weeks ago. None that I heard of. They did a good job considering the one time it was down was because of an obscure server error that cascaded throughout the cloud. They was very open about it and resolve it as soon as they found out.(it happened during a weekend, iirc) So they are pretty reliable. My advice is double check your code. And bring it up to amazon support if it is still a problem. ","pontos":4},{"corpo":"I just left this post in your other thread, though what you have above might work as well. I don't think either would be any easier than the other. The Apache packages can be accessed by just using at the top of your code. Edit: Forgot the link ;) ","pontos":2},{"corpo":"I assume you're on Vista using VS2008? In that case I think that the FOS_PICKFOLDERS option is being used when calling the Vista file dialog IFileDialog. I'm afraid that in .NET code this would involve plenty of gnarly P/Invoke interop code to get working. ","pontos":5},{"corpo":"The Brail view engine has been implemented to be used in ASP.NET MVC. The MvcContrib project implemented the code. The source code is located on Google Code. As far as the controllers, I really am not sure. I am not that familiar with Boo. I know a lot of developers use it for configuration instead of using xml for instance. My tips would be, if Boo can inherit off the Controller base class and you stick to the naming conventions, you should be alright. If you vary off the naming conventions, well you would need to implement your own IControllerFactory to instantiate the boo controllers as the requests come in. I have been following the ASP.NET MVC bits since the first CTP and through that whole time, I have not seen somebody use Boo to code with. I think you will be the first to try to accomplish this. ","pontos":1},{"corpo":"I uninstalled the previous 32bit version, reinstalled as 64bit, and now I get a completely different error. Its mentioned as requiring FP2 to fix, but since I'm using Express-C, I can't install the fixpack (IBM doesn't provide fixpacks for free DB2 products). Anyway, thanks for the help. At least I can come closer to connecting now. :) ","pontos":0},{"corpo":"I have a lot of experience with this. My application is highly iterative, and schema changes happen frequently. I do a production release roughly every 2 to 3 weeks, with 50-100 items cleared from my FogBugz list for each one. Every release we've done over the last few years has required schema changes to support new features. The key to this is to practice the changes several times in a test environment before actually making them on the live servers. I keep a deployment checklist file that is copied from a template and then heavily edited for each release with anything that is out of the ordinary. I have two scripts that I run on the database, one for schema changes, one for programmability (procedures, views, etc). The changes script is coded by hand, and the one with the procs is scripted via Powershell. The change script is run when everything is turned off (you have to pick a time that annoys the least amount of users for this), and it is run command by command, manually, just in case anything goes weird. The most common problem I have run into is adding a unique constraint that fails due to duplicate rows. When preparing for an integration testing cycle, I go through my checklist on a test server, as if that server was production. Then, in addition to that, I go get an actual copy of the production database (this is a good time to swap out your offsite backups), and I run the scripts on a restored local version (which is also good because it proves my latest backup is sound). I'm killing a lot of birds with one stone here. So that's 4 databases total: Dev: all changes must be made in the change script, never with studio. Test: Integration testing happens here Copy of production: Last minute deployment practice Production You really, really need to get it right when you do it on production. Backing out schema changes is hard. As far as hotfixes, I will only ever hotfix procedures, never schema, unless it's a very isolated change and crucial for the business. ","pontos":5},{"corpo":"I would also suggest Xml serialization as others have already mentioned. Here is a sample I threw together to demonstrate. Attributes are used to connect the names from the Xml to the actual property names and types in the data structure. Attributes also list out all the allowed types that can go into the collection. Everything in this collection must have a common base class. You said you have a common interface already -- but you may have to change that to an abstract base class because this code sample did not immediately work when was an interface. using System; using System.Collections.Generic; using System.Text; using System.Xml.Serialization; using System.IO; namespace ConsoleApplication1 { class Program { static void Main() { string xml = \" ?xml version=\\\"1.0\\\"? \" + \" config \" + \" stuff \" + \" class1 prop1=\\\"foo\\\" prop2=\\\"bar\\\" /class1 \" + \" class2 prop1=\\\"FOO\\\" prop2=\\\"BAR\\\" prop3=\\\"42\\\" /class2 \" + \" /stuff \" + \" /config \"; StringReader sr = new StringReader(xml); XmlSerializer xs = new XmlSerializer(typeof(ThingCollection)); ThingCollection tc = (ThingCollection)xs.Deserialize(sr); foreach (Thing t in tc.Things) { Console.WriteLine(t.ToString()); } } } public abstract class Thing { } [XmlType(TypeName=\"class1\")] public class SomeThing : Thing { private string pn1; private string pn2; public SomeThing() { } [XmlAttribute(\"prop1\")] public string PropertyNumber1 { get { return pn1; } set { pn1 = value; } } [XmlAttribute(\"prop2\")] public string AnotherProperty { get { return pn2; } set { pn2 = value; } } } [XmlType(TypeName=\"class2\")] public class SomeThingElse : SomeThing { private int answer; public SomeThingElse() { } [XmlAttribute(\"prop3\")] public int TheAnswer { get { return answer; } set { answer =value; } } } [XmlType(TypeName = \"config\")] public class ThingCollection { private List Thing things; public ThingCollection() { Things = new List Thing (); } [XmlArray(\"stuff\")] [XmlArrayItem(typeof(SomeThing))] [XmlArrayItem(typeof(SomeThingElse))] public List Thing Things { get { return things; } set { things = value; } } } } ","pontos":6},{"corpo":"Why can't you load the .net runtime into you process space? It is possible to host the .net runtime and call into .net using COM. ","pontos":0},{"corpo":"I'm not sure if you can figure out the exact name of the build configuration. Howerver, if you use Debug.Assert(...), that code will only be run when you compile in debug mode. Not sure it that helps you at all. ","pontos":0},{"corpo":"If you have access SSIS check out the Fuzzy grouping and Fuzzy lookup transformation. http://www.sqlteam.com/article/using-fuzzy-lookup-transformations-in-sql-server-integration-services http://msdn.microsoft.com/en-us/library/ms137786.aspx ","pontos":3},{"corpo":"More than sending bad data, I think I got an ERROR403. If I just try again it's usually ok. And I agree : I saw a lot of report about people talking about amazon being totally down, but nobody talking about a \"sometimes my access is refused\" error, so I guess there might be an error on my side. I just set up the log on amazon. Anyway thank you! I'll follow your advise and stop blaming \"the other guy\". ","pontos":0},{"corpo":"Those differences are not really important according to the XHTML standard. In other words, they are exactly the same thing. Also, if you replace double quotes with single quotes would be the same. The typical way of 'normalizing' an xml document is to pare it using some API that treats the document as its Infoset representation. Both DOM and SAX style APIs work that way. If you want to parse them by hand (or with a RegEx) you have to replicate all those things in your code and, in my opinion, that's not practical. ","pontos":2},{"corpo":"The answer is: don't use regular expressions. Seriously. Use a SGML parser, or an XML parser if you happen to know it's valid XML (probably almost never true). You will absolutely screw up and waste tons of time trying to get it right. Just use what's already available. ","pontos":12},{"corpo":"I've done a little more investigation into the Mongrel source and it turns out that Mongrel installs a signal handler to catch an standard process kill (TERM) and do a graceful shutdown, so I don't need a special procedure after all. You can see this working from the log output you get when killing a Mongrel while it's processing a request. For example: ** TERM signal received. Thu Aug 28 00:52:35 +0000 2008: Reaping 2 threads for slow workers because of 'shutdown' Waiting for 2 requests to finish, could take 60 seconds.Thu Aug 28 00:52:41 +0000 2008: Reaping 2 threads for slow workers because of 'shutdown' Waiting for 2 requests to finish, could take 60 seconds.Thu Aug 28 00:52:43 +0000 2008 (13051) Rendering layoutfalsecontent_typetext/htmlactionindex within layouts/application ","pontos":11},{"corpo":"Try this (XSLT 2.0): xsl:template match=\"/STORIES/STORY\" component xsl:if test=\"boolean(ARTICLEBODY)\" xsl:call-template name=\"insert_paras\" xsl:with-param name=\"text\" select=\"ARTICLEBODY/text()\"/ /xsl:call-template /xsl:if /component /xsl:template xsl:template name=\"insert_paras\" xsl:param name=\"text\" / xsl:variable name=\"regex\" xsl:text #10;( #10;|\\s)* /xsl:text /xsl:variable xsl:variable name=\"tokenized-text\" select=\"tokenize($text, $regex)\"/ xsl:for-each select=\"$tokenized-text\" p xsl:value-of select=\".\"/ /p /xsl:for-each /xsl:template It's generally a bad idea to use literal strings to put in XML markup, since you can't guarantee that the results are balanced. ","pontos":1},{"corpo":"The question is how to generate a temporary file name. Neither mkstemp nor tmpfile provide the caller with a name, they return a file descriptor or file handle, respectively. ","pontos":5},{"corpo":"I wouldn't do it myself, because to me it muddies what a particular method does, and the method-chaining is of limited use to me over doing it longhand. It isn't going to send me into a quivering ball of rage and psychosis, though, which is always a good thing. :') I wouldn't be concerned about performance; just ask Knuth. ","pontos":2},{"corpo":"We have moved to 2.0, but only for new development (not migrating old to new). The reason for this was there are a couple of breaking changes that are documented online and we didn't have the budget to fix it. The big ones for use were: Changed NHibernate.Expression namespace to NHibernate.Criterion section is ignored, using section (note that they have different XML formats) Edit: There's a pretty good summary of the latest changes to NHibernate 2.0 on CodeBetter ","pontos":2},{"corpo":"Circuit diagrams. Compilation (Directed Acyclic graphs) Maps. Very compact as graphs. Network flow problems. Decision trees for expert systems (sic) Fishbone diagrams for fault finding, process improvment, safety analysis. For bonus points, implement your error recovery code as objects that are the fishbone diagram. ","pontos":3},{"corpo":"@Haacked I tried to keep the pseudocode simple. foreach's take up a lot of space and braces. I clarified it. o.GetType().FullName returns Plugins.Multiply which is the expected object. Plugins.Multiply implements IPlugin. I stepped through the process in the debugger quite a few times until I gave up for the evening. Couldn't figure out why I couldn't cast it because I watched the constructor fire until I got grumpy about the whole mess. Came back to it this evening and made it work, but I still don't understand why the cast failed in the first code block. The second code block works, but it feels off to me. ","pontos":0},{"corpo":"Mike: Didn't think of that, that could work, have to remember to turn off copy-local for any libraries / projects that are common between them ","pontos":0},{"corpo":"I find this to be in poor style when used in setters. Immutable classes are usually a better fit for chaining, such as: aWithB = myObject.withA(someA).withB(someB); where is of this class: class MyClass { withA(TypeA a) { this.a.equals(a) ? this : new MyClass(this, a); } private MyClass(MyClass copy, TypeA a) { this(copy); this.a = a; } } The builder pattern is also useful, since it allows the final object to be immutable while preventing the intermediate instances you would normally have to create when using this technique. ","pontos":1},{"corpo":"If you must use regex, here is a regex to get just the content part: content\\s*=\\s*['\"].*?['\"] returns content = \"blogger\" and content='Worpress.com' respectively. I'm no regex expert, but it gets those when given your examples in regexpal. Once you get that you can get everything between the quotes however you choose, be it another regex (which is just immoral at that point) or just looping over the characters. ","pontos":0},{"corpo":"I use to be a fan of the Java (and worse C#) practice of making getters and setters (get set properties) throughout an object. This use to be what I considered object oriented, but really this leads us just to exposing the guts and implementation of the object and not really taking advantage of encapsulation. There are times you can't get away from this (OR/M comes to mind), but in general the object should be set up and then perform its function. My dream objects tend to have one or two constructors, and maybe a half dozen functions that do work. The reason for this is that once I started developing API's there is a real need to keep things simple. You really only want to add as much complexity as is required to get the job done, and getters and setters, while simple in themselves, add complexity in heaps when added in mass. What happens when I load setters i na different order? Anythign different? Are you sure? ","pontos":0},{"corpo":"I'd say stick with what works for you. Unless you are having issues with VSS, why switch? Subversion is swell, though a little sticky to begin using it. TFS is far better than VSS, though it is fairly expensive for such a small team. I have not used git so I can't really speak to it. ","pontos":1},{"corpo":"I once came across a .Net app that was ported from ASP. The .aspx pages were totally blank. To render the UI, the developers used StringBuilders in the code behind and then did a response.write. This would be the wrong way to do it! ","pontos":0},{"corpo":"I'm just guessing here because from your code it's not obvious where do you have definition of IPlugin interface but if you can't cast in your host application then you are probably having IPlugin interface in your host assembly and then at the same time in your plugin assembly. This won't work. The easiest thing is to make this work is to have IPlugin interface marked as public in your host assembly and then have your Plugin assembly reference host application assembly, so both assemblies have access to the very same interface. ","pontos":4},{"corpo":"I don't think you can remove the meta data, but you can obfuscate your code if you're looking to protect your IP. ","pontos":0},{"corpo":"Whatever you do, don't change for the sake of changing. If it's working for you and you're not having problems with it, I don't see any reason to switch. ","pontos":5},{"corpo":" I once came across a .Net app that was ported from ASP. The .aspx pages were totally blank. To render the UI, the developers used StringBuilders in the code behind and then did a response.write. This would be the wrong way to do it! I've seen it done the other way, the code behind page was blank, except for declaration of globals, then the VBScript was left in the ASPX. ","pontos":0},{"corpo":"Could depend a bit how you obtain those 2 strings. Probably the secure, fireproof way to do that is what is in URI::URL or similar libraries, where all alternatives, including malicious ones, would be considered. Maybe slower, but in some environments faster will be the speed of a bullet going to your own foot. But if you expect there something plain and not tricky could see if it starts with /, chains of ../, or any other char. The 1st would put the server name + the url, the 2nd chop paths from the base uri till getting in one of the other 2 alternatives, or just add it to the base url. ","pontos":1},{"corpo":"Don't worry about VSS corrupting you, worry about VSS corrupting your data. It does not have a good track record in that department. Back up frequently if you do not switch to a different version control system. Backups should be happening daily even with other SCMs, but it's doubly important with VSS. ","pontos":3},{"corpo":"Looks like SubVersion is the winner here. I'd do yourself a favor and use VisualSVN Server. It's free and will save you a bunch of installation headaches. ","pontos":9},{"corpo":"If you only have 2 people, and you mostly work independantly, git is going to give you a lot more flexibility, power, and be far and away the fastest to work with. It is however a pain in the backside to use. Using VSS you're obviously programming for windows - if you're doing Win32 API stuff in C then git will be a learning curve but will be quite interesting. If the depths of your knowledge however only extend to ASP and Visual Basic, just use subversion. Walk before you can run. ** I'm not trying to say if you only know VB you're dumb or anything like that, but that git can be very finicky and picky to use (if you've used the WinAPI in C you know all about picky and finicky), and you may want a more gradual introduction to SCM than git provides ","pontos":1},{"corpo":"Well, in one sense, you're lucky, 'cause Fortran doesn't have much in the way of subtle flow-of-control constructs or inheritance or the like. On the other, it's got some truly amazing gotchas, like the arithmetically-calculated branch-to-numeric-label stuff, the implicitly-typed variables which don't require declaration, the lack of true keywords. I don't know about the \"performance enhancing improvements\". I'd guess most of them are probably ineffective, as a couple of decades of compiler technology have made most hinting unnecessary. Unfortunately, you'll probably have to leave things the way they are, unless you're planning to do a massive rewrite. Anyway, the core scientific calculation code should be fairly readable. Any programming language using infix arithmetic would be good preparation for reading Fortran's arithmetic and assignment code. ","pontos":3},{"corpo":"@Alex aw that's a bummer. What if in your you had an html document that looked like: html head meta http-equiv=\"refresh\" content=\"0;url=/pdfs/somepdf.pdf\" / /head body /body /html Definitely a hack, but it might work for Firefox. Although I wonder if the load event would fire too soon in that case. ","pontos":1},{"corpo":"The biggest complaint is type erasure. In that, generics are not enforced at runtime. Here's a link to some Sun docs on the subject. Generics are implemented by type erasure: generic type information is present only at compile time, after which it is erased by the compiler. ","pontos":1},{"corpo":"You could implement your own TCP-like behaviour at the application layer. So for instance, you'd send out the UDP broadcast, but then expect a reply response from each host. If you didn't get a response within X seconds, then send another and so on until reaching some sort of threshold. If the threshold is reached (i.e. the host didn't respond at all), then report an error. To do this though, you'd need a pre-defined list of hosts to expect the responses back from. ","pontos":1},{"corpo":"You might also try: var matches = new List Record (dict.Values.Where(rec = rec.Name == \"foo\")); Basically generic collections are very difficult to cast directly, so you really have little choice but to create a new object. ","pontos":2},{"corpo":"Yes - I've got experience with that - unfortunately it was no different from your own. I've generally avoided scrolling forms and used paging wherever possible on .Net CF. If this is an option for you, I'd recommend it. I'd assume the scroll bar issue is to do with the form size being fixed to the width of the available screen (regardless of design-time settings) so the introduction of a vertical scroll bar obscures part of the (not needed) full-width form. ","pontos":0},{"corpo":"Not an expert with this stuff but it looks like the first 3 parts of the address are being masked out. Is it possible that the mobile device is being given a network mask of: 255.255.255.0 As to reach beyond the range of the first 3 parts you need the mask to be: 255.255.0.0 This may be an oversimplification or completely wrong but that's was my gut response to the question. ","pontos":0},{"corpo":" isn't evil in itself, but there are only few cases where you should use it and this isn't one of them. In XSLT you work with trees, not markup string. Here's an XSTL 1.0 solution: xsl:template match=\"/STORIES/STORY\" component xsl:if test=\"ARTICLEBODY\" xsl:call-template name=\"wrap-text\" xsl:with-param name=\"text\" select=\"ARTICLEBODY\"/ xsl:with-param name=\"delimiter\" select=\"' #10;'\"/ xsl:with-param name=\"element\" select=\"'p'\"/ /xsl:call-template /xsl:if /component /xsl:template xsl:template name=\"wrap-text\" xsl:param name=\"text\"/ xsl:param name=\"delimiter\"/ xsl:param name=\"element\"/ xsl:choose xsl:when test=\"contains($text, $delimiter)\" xsl:variable name=\"t\" select=\"substring-before($text, $delimiter)\"/ xsl:if test=\"normalize-space($t)\" xsl:element name=\"{$element}\" xsl:value-of select=\"$t\"/ /xsl:element /xsl:if xsl:call-template name=\"wrap-text\" xsl:with-param name=\"text\" select=\"substring-after($text, $delimiter)\"/ xsl:with-param name=\"delimiter\" select=\"$delimiter\"/ xsl:with-param name=\"element\" select=\"$element\"/ /xsl:call-template /xsl:when xsl:otherwise xsl:if test=\"normalize-space($text)\" xsl:element name=\"{$element}\" xsl:value-of select=\"$text\"/ /xsl:element /xsl:if /xsl:otherwise /xsl:choose /xsl:template ","pontos":5},{"corpo":"This looks like a network issue, unless there's an odd bug in .Net CF that doesn't allow you to traverse subnets in certain situations (I can find no evidence of such a thing from googling). Can you get any support from the network/IT team? Also, have you tried it from a different subnet? I.e. not the same as the XP machine (192.168.5.x) and not the same as the one that's not worked so far (192.168.10.). @Shaun Austin - that wouldn't explain why they can get at a regular web page on the XP machine from the different subnet. ","pontos":0},{"corpo":"It looks like you've got fewer items in q than you were expecting when you started iterating. Your script may be trying to access q[q.length], i.e. the element after the last element. Could it be that your successful request has been popped from the queue, and you have a race condition? Are you trying to abort a request that has already completed its life cycle? Alternatively, have you made a silly mistake as people sometimes do, and got your loop termination condition wrong? Just a few thoughts, I hope they help. ","pontos":1},{"corpo":"I occasionally get unexpected 404 errors with GETs objects that are part of a preceeding LIST but new to the bucket, and other misc. errors (eg: 403 on my access id and secret key), but nothing catastrophic. My code runs server side, so I've put in some robust error handling and logging. I think this is a wise thing to do anytime you have one server on the net communicating with another server. :P ","pontos":0},{"corpo":" Can't you just use the same control I'm Stack Overflow uses (that we're all typing into)---WMD, and just store the Markdown in the VARCHAR. That's a Web control. The input happens in Windows Forms, so that wouldn't work. ","pontos":1},{"corpo":"The problem with TypeMock is that it excuses bad design. Now, I know that it is often someone else's bad design that it's hiding, but permitting it into your development process can lead very easily to permitting your own bad designs. I think if you're going to use a mocking framework, you should use a traditional one (like Moq) and create an isolation layer around the unmockable thing, and mock the isolation layer instead. ","pontos":3},{"corpo":"I've read something similar to what you said in the past, Lars. Unfortunately, I'm somewhat restricted with what I can do with the machine in question (in other words, I can't go creating user groups willy-nilly: it's a server, not just some random PC). Thanks for the answers, Will and Lars. Unfortunately, they didn't solve my problem. Ultimate solution to this is to use WMI: using System.Management; String queryString = \"select CreationDate from Win32_Process where ProcessId='\" + ProcessId + \"'\"; SelectQuery query = new SelectQuery(queryString); ManagementScope scope = new System.Management.ManagementScope(@\"\\\\.\\root\\CIMV2\"); ManagementObjectSearcher searcher = new ManagementObjectSearcher(scope, query); ManagementObjectCollection processes = searcher.Get(); //... snip ... logic to figure out which of the processes in the collection is the right one goes here DateTime startTime = ManagementDateTimeConverter.ToDateTime(processes[0][\"CreationDate\"].ToString()); TimeSpan uptime = DateTime.Now.Subtract(startTime); Parts of this were scraped from Code Project: http://www.codeproject.com/KB/system/win32processusingwmi.aspx And \"Hey, Scripting Guy!\": http://www.microsoft.com/technet/scriptcenter/resources/qanda/jul05/hey0720.mspx ","pontos":2},{"corpo":"You have to reference the System.configuration assembly (note the lowercase) I don't know why this assembly is not added by default to new projects on Visual Studio, but I find myself having the same problem every time I start a new project. I always forget to add the reference. ","pontos":9},{"corpo":"You are missing the reference to System.Configuration. ","pontos":0},{"corpo":"WCF services can have multiple endpoints, each of which can implement a different service contract. For example, you could have a service declared as follows: [ServiceBehavior(Namespace = \"DemoService\")] public class DemoService : IDemoService, IDoNothingService Which would have configuration along these lines: service name=\"DemoService\" behaviorConfiguration=\"Debugging\" host baseAddresses add baseAddress = \"http://localhost/DemoService.svc\" / /baseAddresses /host endpoint address =\"\" binding=\"customBinding\" bindingConfiguration=\"InsecureCustom\" bindingNamespace=\"http://schemas.com/Demo\" contract=\"IDemoService\"/ endpoint address =\"\" binding=\"customBinding\" bindingConfiguration=\"InsecureCustom\" bindingNamespace=\"http://schemas.com/Demo\" contract=\"IDoNothingService\"/ /service Hope that helps, but if you were after the theoretical maximum interfaces you can have for a service I suspect it's some crazily large multiple of 2. ","pontos":16},{"corpo":" Process of .Net 1.1 uses the Performance Counters ... Process of .Net 2.0 is not depended on the Performance Counters. That's interesting to know - it certainly explains why my suggestions based on reading the 2.0 source code were completely useless! ","pontos":1},{"corpo":"Follow-up to my previous posting. Templates are one of the main reasons why C++ fails so abysmally at intellisense, regardless of the IDE used. Because of template specialization, the IDE can never be really sure if a given member exists or not. Consider: template typename T struct X { void foo() { } }; template struct X int { }; typedef int my_int_type; X my_int_type a; a.| Now, the cursor is at the indicated position and it's damn hard for the IDE to say at that point if, and what, members has. For other languages the parsing would be straightforward but for C++, quite a bit of evaluation is needed beforehand. It gets worse. What if were defined inside a class template as well? Now its type would depend on another type argument. And here, even compilers fail. template typename T struct Y { typedef T my_type; }; X Y int ::my_type b; After a bit of thinking, a programmer would conclude that this code is the same as the above: resolves to , therefore should be the same type as , right? Wrong. At the point where the compiler tries to resolve this statement, it doesn't actually know yet! Therefore, it doesn't know that this is a type. It could be something else, e.g. a member function or a field. This might give rise to ambiguities (though not in the present case), therefore the compiler fails. We have to tell it explicitly that we refer to a type name: X typename Y int ::my_type b; Now, the code compiles. To see how ambiguities arise from this situation, consider the following code: Y int ::my_type(123); This code statement is perfectly valid and tells C++ to execute the function call to . However, if is not a function but rather a type, this statement would still be valid and perform a special cast (the function-style cast) which is often a constructor invocation. The compiler can't tell which we mean so we have to disambiguate here. ","pontos":14},{"corpo":"I'd personally plump for returning the resource rather than faffing with a redirect, although I suspect that's only because my subcoscious is telling me redirects are slower. However, if you were to decide to use a redirect I'd think a 302 or 307 might be more appropiate than a 303, although the w3.org has details of the different redirect codes you could use. ","pontos":3},{"corpo":"There is no Object Model for the InfoPath designer. I believe the closest that you can get is the exposed API for the Visual Studio hosting that InfoPath supports; but I don't believe that this will give you the programatic control of the designer that you'd like. http://msdn.microsoft.com/en-us/library/aa813327.aspx#office2007infopathVSTO_InfoPathDesignerAPIIntegratingInfoPath2007VisualStudio Sorry Kevin. ","pontos":0},{"corpo":"I say this in response to a lot of questions: Don't forget that the (managed) source code to the framework is available. You can use this tool to get it all: http://www.codeplex.com/NetMassDownloader Unfortunately, in this specific case, a lot of the implementation is in native code, so you don't get to look at it... They definitely use pool threads rather than a thread-per-timer, though. The standard way to implement a big collection of timers (which is how the kernel does it internally, and I would suspect is indirectly how your big collection of Timers ends up) is to maintain the list sorted by time-until-expiry - so the system only ever has to worry about checking the next timer which is going to expire, not the whole list. Roughly, this gives O(log n) for starting a timer and O(1) for processing running timers. Edit: Just been looking in Jeff Richter's book. He says (of Threading.Timer) that it uses a single thread for all Timer objects, this thread knows when the next timer (i.e. as above) is due and calls ThreadPool.QueueUserWorkItem for the callbacks as appropriate. This has the effect that if you don't finish servicing one callback on a timer before the next is due, that your callback will reenter on another pool thread. So in summary I doubt you'll see a big problem with having lots of timers, but you might suffer thread pool exhaustion if large numbers of them are firing at the same timer and/or their callbacks are slow-running. ","pontos":26},{"corpo":"The CLR cannot directly load modules that contain no manifest. So you can't make an assembly completely private unless you also want to make it unloadable ;) You can however, as Mark noted above, use obfuscation tools to hide the parts you would like to keep truly internal. It's too bad the internal keyword doesn't exclude that metadata EDIT: it looks like this question is highly related ","pontos":1},{"corpo":"If I was faced with that problem and couldn't find anything on google I would probably try to do it my self. Some \"back-of-an-evelope\" stuff to get a feel for where it is going. But it would kinda need me to have an idea of how to do a xml parser. For non algorithmical benchmarks take a look here: http://www.xml.com/pub/a/Benchmark/exec.html http://www.devx.com/xml/Article/16922 http://xerces.apache.org/xerces2-j/faq-performance.html ","pontos":3},{"corpo":"As a former Test Commissioning manager, I would strongly argue for a test API. It does not remove the need for User Interface testing, but you will be able to add automated tests and non regression tests. If it's absolutely impossible, I would setup a test proxy, where you will be able to: Do nothing (transparent proxy). Your app should behave normally. Spy / Log data traffic. Add a filter mechanism so you don't grab everything Block specific messages. Your filter system is very useful here Corrupt specific messages (this is more difficult) If you need some sort of network testing: Limit general throughput (some libraries do this) Delay messages (same remark) Change packet order (quite difficult) ","pontos":1},{"corpo":"/EDIT: I've rewritten the whole posting. Below is a pretty complete solution to the VB highlighting problem. If SO has got nothing better, please use it. VB syntax highlighting is definitely wanted. I've also added a code example with some complex code literals that gets highlighted correctly. However, I haven't even tried to get XLinq right. Might still work, though. The keywords list is taken from the MSDN. Contextual keywords are not included. Did you know the operator? The algorithm knows literal type characters. It should also be able to handle identifier type characters but I haven't tested these. Note that the code works on HTML. As a consequence, , and are required to be read as named (!) entities, not single characters. Sorry for the long regex. var highlightVB = function(code) { var regex = /(\"(?:\"\"|[^\"])+\"c?)|('.*$)|#.+?#|( amp;[HO])?\\d+(\\.\\d*)?(e[+-]?\\d+)?U?([SILDFR%@!#]| amp;)?|\\.\\d+[FR!#]?|\\s+|\\w+| amp;| lt;| gt;|([-+*/\\\\^$@!#% ()\\[\\]{}.,:=]+)/gi; var lines = code.split(\"\\n\"); for (var i = 0; i lines.length; i++) { var line = lines[i]; var tokens; var result = \"\"; while (tokens = regex.exec(line)) { var tok = getToken(tokens); switch (tok.charAt(0)) { case '\"': if (tok.charAt(tok.length - 1) == \"c\") result += span(\"char\", tok); else result += span(\"string\", tok); break; case \"'\": result += span(\"comment\", tok); break; case '#': result += span(\"date\", tok); break; default: var c1 = tok.charAt(0); if (isDigit(c1) || tok.length 1 c1 == '.' isDigit(tok.charAt(1)) || tok.length 5 (tok.indexOf(\" amp;\") == 0 tok.charAt(5) == 'H' || tok.charAt(5) == 'O') ) result += span(\"number\", tok); else if (isKeyword(tok)) result += span(\"keyword\", tok); else result += tok; break; } } lines[i] = result; } return lines.join(\"\\n\"); } var keywords = [ \"addhandler\", \"addressof\", \"alias\", \"and\", \"andalso\", \"as\", \"boolean\", \"byref\", \"byte\", \"byval\", \"call\", \"case\", \"catch\", \"cbool\", \"cbyte\", \"cchar\", \"cdate\", \"cdec\", \"cdbl\", \"char\", \"cint\", \"class\", \"clng\", \"cobj\", \"const\", \"continue\", \"csbyte\", \"cshort\", \"csng\", \"cstr\", \"ctype\", \"cuint\", \"culng\", \"cushort\", \"date\", \"decimal\", \"declare\", \"default\", \"delegate\", \"dim\", \"directcast\", \"do\", \"double\", \"each\", \"else\", \"elseif\", \"end\", \"endif\", \"enum\", \"erase\", \"error\", \"event\", \"exit\", \"false\", \"finally\", \"for\", \"friend\", \"function\", \"get\", \"gettype\", \"getxmlnamespace\", \"global\", \"gosub\", \"goto\", \"handles\", \"if\", \"if\", \"implements\", \"imports\", \"in\", \"inherits\", \"integer\", \"interface\", \"is\", \"isnot\", \"let\", \"lib\", \"like\", \"long\", \"loop\", \"me\", \"mod\", \"module\", \"mustinherit\", \"mustoverride\", \"mybase\", \"myclass\", \"namespace\", \"narrowing\", \"new\", \"next\", \"not\", \"nothing\", \"notinheritable\", \"notoverridable\", \"object\", \"of\", \"on\", \"operator\", \"option\", \"optional\", \"or\", \"orelse\", \"overloads\", \"overridable\", \"overrides\", \"paramarray\", \"partial\", \"private\", \"property\", \"protected\", \"public\", \"raiseevent\", \"readonly\", \"redim\", \"rem\", \"removehandler\", \"resume\", \"return\", \"sbyte\", \"select\", \"set\", \"shadows\", \"shared\", \"short\", \"single\", \"static\", \"step\", \"stop\", \"string\", \"structure\", \"sub\", \"synclock\", \"then\", \"throw\", \"to\", \"true\", \"try\", \"trycast\", \"typeof\", \"variant\", \"wend\", \"uinteger\", \"ulong\", \"ushort\", \"using\", \"when\", \"while\", \"widening\", \"with\", \"withevents\", \"writeonly\", \"xor\", \"#const\", \"#else\", \"#elseif\", \"#end\", \"#if\" ] var isKeyword = function(token) { return keywords.indexOf(token.toLowerCase()) != -1; } var isDigit = function(c) { return c = '0' c = '9'; } var getToken = function(tokens) { for (var i = 0; i tokens.length; i++) if (tokens[i] != undefined) return tokens[i]; return null; } var span = function(class, text) { return \" span class=\\\"\" + class + \"\\\" \" + text + \" /span \"; } Code for testing: Protected Sub Page_Load(ByVal sender As Object, ByVal e As EventArgs) Handles Me.Load 'set page title' Page.Title = \"Something\" Dim r As String = \"Say \"\"Hello\"\"\" Dim i As Integer = 1234 Dim d As Double = 1.23 Dim s As Single = .123F Dim l As Long = 123L Dim ul As ULong = 123UL Dim c As Char = \"x\"c Dim h As Integer = amp;H0 Dim t As Date = #5/31/1993 1:15:30 PM# Dim f As Single = 1.32e-5F End Sub ","pontos":7},{"corpo":"Being relatively new to python I'm not sure what the most common idiom is, but the simplest thing I can think of is just using a module instead of a class. What would have been instance methods on your class become just functions in the module and any data just becomes variables in the module instead of members of the class. I suspect this is the pythonic approach to solving the type of problem that people use singletons for. If you really want a singleton class, there's a reasonable implementation described on the first hit on google for \"python singleton\", specifically: class Singleton: __single = None def __init__( self ): if Singleton.__single: raise Singleton.__single Singleton.__single = self That seems to do the trick. ","pontos":0},{"corpo":"Here is an example from Peter Norvig's Python IAQ How do I do the Singleton Pattern in Python? (You should use search feature of your browser to find this question, there is no direct link, sorry) Also Bruce Eckel has another example in his book Thinking in Python (again there is no direct link to the code) ","pontos":3},{"corpo":"If a big team of programmers really want to get at your source code and that had the time, money and effort, then they would be successful. Obfuscation, therefore, should stop people who don't have the time, money or effort to get your source, passers by you might call them. ","pontos":6},{"corpo":" We use citrix for home-office, and people really like it. Now, they would like the same kind of environment at work, a nice page where every important application/document/folder is nicely arranged and classified in an orderly fashion I haven't used citrix very many times, but what's it got to do with executing local applications? I don't see how \"People like citrix\" and \"browser executing local applications\" relate at all? If the people are accessing your citrix server from home, and want the same experience in the office, then buy a cheap PC, and run the exact same citrix software they run on their home computers. Put this computer in the corner and tell them to go use it. They'll be overjoyed. Isn't it madness to allow such 'dangerous' ActiveX controls, even in the 'local intranet' zone ? People will use the same browser to surf the web, can I fully trust IE ? Put it this way. IE has built in support for AX controls. It uses it's security mechanisms to prevent them from running unless in a trusted site. By default no sites are trusted at all. If you use IE at all then you're putting yourself at the mercy of these security mechanisms. Whether or not you tell it to trust the local intranet is beside the point, and isn't going to affect the operation of any other zones. The good old security holes that require you to reboot your computer every few weeks when MS issues a patch will continue to exist and cause problems, regardless of whether you allow activex in your local intranet. Isn't there a risk that Microsoft would just disable those controls in future updates / versions ? Since XP-SP2, microsoft have been making it increasingly difficult to use ActiveX controls. I don't know how many scary looking warning messages and \"This might destroy your computer\" dialogs you have to click through these days to get them to run, but it's quite a few. This will only get worse over time. ","pontos":3},{"corpo":"While not related to .net, I would consider obfuscation in Javascript, and possibly other interpeted languages. Javascript benefits well from obfuscation because it reduces the bandwith needed, and the tokens the parser has to read. But obfuscating compiled bytecode doesn't really seem that usefull to me. I mean what would you try and achieve? I can only see obfuscation beeing slightly usefull in license checking code to avoid it beeing circumvented too easily. ","pontos":2},{"corpo":"You asked for engineering reasons, so this is not strictly speaking an answer to the question. But I think it's a valid clarification. As you say, obfuscation is intended to address a social problem. And social (or business) problems, unlike technical ones, rarely have a complete solution. There are only degrees of success in addressing or minimising the problem. In this case, obfuscation will raise the barriers to someone decompiling and stealing your code. It will discourage casual attacks and, through inertia, may make your intellectual property less likely to be stolen. To make a tiresome analogy, an immobiliser doesn't prevent your car being stolen, but it will make it less likely. Of course there is a cost, in maintainability, (possibly) in performance and most importantly in making it harder for users to accurately submit bug reports. As GateKiller said, obfuscation won't prevent a determined team from decompiling, but (and it depends what your product is) how determined a team is likely to be attacking you? So, this is not a technical solution to a social problem, it's a technical decision which adds one influence to a complex social structure. ","pontos":13},{"corpo":"Example 1 dissociates the $query variable from the MySQL result. The MySQL result still exists in memory, and will continue to exist and waste memory until garbage collection occurs. Example 2 frees the MySQL result immediately, releasing the used resources. However, since PHP pages are generally short-lived with small result-sets, the memory saved is trivial. You will not notice a slowdown unless you leave a ton of results in memory over a long period of time on pages that run for a long time. Brian, PHP can garbage collect the MySQL result, it just doesn't happen immediately. The result lives in PHP's memory pool, not in the MySQL server's. (the locality of memory when using unbuffered queries is slightly different, but they're so rarely used in PHP as to not be worth mentioning) ","pontos":3},{"corpo":" Consolidate them. Create a timer service and ask that for the timers. It will only need to keep 1 active timer (for the next due call)... For this to be an improvement over just creating lots of Threading.Timer objects, you have to assume that it isn't exactly what Threading.Timer is already doing internally. I'd be interested to know how you came to that conclusion (I haven't disassembled the native bits of the framework, so you could well be right). ","pontos":5},{"corpo":"Use encryption to protect information on the way. Use obfuscation to protect information while your program still has it. ","pontos":1},{"corpo":"Why haven't anyone talked about turbogears, web.py and pylons? ","pontos":2},{"corpo":"Yep, use table and index partitioning with filegroups. You don't even have to change the select statements, only if you want to get the last bit of speed out of the result. Another option can be the workload balancing with two servers and two way replication between them. ","pontos":1},{"corpo":"I'll add my voice to the noise and take a stab at making things clear: C# Generics allow you to declare something like this. List Person foo = new List Person (); and then the compiler will prevent you from putting things that aren't into the list. Behind the scenes the C# compiler is just putting into the .NET dll file, but at runtime the JIT compiler goes and builds a new set of code, as if you had written a special list class just for containing people - something like . The benefit of this is that it makes it really fast. There's no casting or any other stuff, and because the dll contains the information that this is a List of , other code that looks at it later on using reflection can tell that it contains objects (so you get intellisense and so on). The downside of this is that old C# 1.0 and 1.1 code (before they added generics) doesn't understand these new , so you have to manually convert things back to plain old to interoperate with them. This is not that big of a problem, because C# 2.0 binary code is not backwards compatible. The only time this will ever happen is if you're upgrading some old C# 1.0/1.1 code to C# 2.0 Java Generics allow you to declare something like this. ArrayList Person foo = new ArrayList Person (); On the surface it looks the same, and it sort-of is. The compiler will also prevent you from putting things that aren't into the list. The difference is what happens behind the scenes. Unlike C#, Java does not go and build a special - it just uses the plain old which has always been in Java. When you get things out of the array, the usual casting-dance still has to be done. The compiler is saving you the key-presses, but the speed hit/casting is still incurred just like it always was. When people mention \"Type Erasure\" this is what they're talking about. The compiler inserts the casts for you, and then 'erases' the fact that it's meant to be a list of not just The benefit of this approach is that old code which doesn't understand generics doesn't have to care. It's still dealing with the same old as it always has. This is more important in the java world because they wanted to support compiling code using Java 5 with generics, and having it run on old 1.4 or previous JVM's, which microsoft deliberately decided not to bother with. The downside is the speed hit I mentioned previously, and also because there is no pseudo-class or anything like that going into the .class files, code that looks at it later on (with reflection, or if you pull it out of another collection where it's been converted into or so on) can't tell in any way that it's meant to be a list containing only and not just any other array list. C++ Templates allow you to declare something like this std::list Person * foo = new std::list Person (); It looks like C# and Java generics, and it will do what you think it should do, but behind the scenes different things are happening. It has the most in common with C# generics in that it builds special rather than just throwing the type information away like java does, but it's a whole different kettle of fish. Both C# and Java produce output which is designed for virtual machines. If you write some code which has a class in it, in both cases some information about a class will go into the .dll or .class file, and the JVM/CLR will do stuff with this. C++ produces raw x86 binary code. Everything is not an object, and there's no underlying virtual machine which needs to know about a class. There's no boxing or unboxing, and functions don't have to belong to classes, or indeed anything. Because of this, the C++ compiler places no restrictions on what you can do with templates - basically any code you could write manually, you can get templates to write for you. The most obvious example is adding things: In C# and Java, the generics system needs to know what methods are available for a class, and it needs to pass this down to the virtual machine. The only way to tell it this is by either hard-coding the actual class in, or using interfaces. For example: string addNames T ( T first, T second ) { return first.Name() + second.Name(); } That code won't compile in C# or Java, because it doesn't know that the type actually provides a method called Name(). You have to tell it - in C# like this: interface IHasName{ string Name(); }; string addNames T ( T first, T second ) where T : IHasName { .... } And then you have to make sure the things you pass to addNames implement the IHasName interface and so on. The java syntax is different (), but it suffers from the same problems. The 'classic' case for this problem is trying to write a function which does this string addNames T ( T first, T second ) { return first + second; } You can't actually write this code because there are no ways to declare an interface with the method in it. You fail. C++ suffers from none of these problems. The compiler doesn't care about passing types down to any VM's - if both your objects have a .Name() function, it will compile. If they don't, it won't. Simple. So, there you have it :-) ","pontos":365},{"corpo":"The technical answer is that the Grammar of the PHP language only allows subscript notation on the end of variable expressions and not expressions in general, which is how it works in most other languages. I've always viewed it as a deficiency in the language, because it is possible to have a grammar that resolves subscripts against any expression unambiguously. It could be the case, however, that they're using an inflexible parser generator or they simply don't want to break some sort of backwards compatibility. Here are a couple more examples of invalid subscripts on valid expressions: $x = array(1,2,3); print ($x)[1]; //illegal, on a parenthetical expression, not a variable exp. function ret($foo) { return $foo; } echo ret($x)[1]; // illegal, on a call expression, not a variable exp. ","pontos":36},{"corpo":"If I understand this correctly... We had a object that could use different hardware options. To facilitate this we used a abstract interface of Device. Device had a bunch of functions that would be fired on certain events. The use would be the same but the various implementations of the Device would either have a fully-fleshed out functions or just return immediately. To make life even easier, the functions were void and threw exceptions on when something went wrong. ","pontos":0},{"corpo":"You can configure eclipse to show warnings for things that lack javadoc, or have javadoc that does not have all the information, or has wrong information. It can also insert templates for you to fill out. Not quite the tool you asked for, but probably better because you won't end up with empty skeletons on methods that you missed. You can achieve this by investigating and editing the preference page beyond the path Window > Preferences > Java > Compiler > Javadoc for your workspace. The screenshot of that preference page is below: For further information about the items in this screen please follow the link below: Java Compiler Javadoc Preferences Help ","pontos":4},{"corpo":"Have a look at ScriptManager.RegisterStartupScript The idea is that you register a script to run on start up (I believe once the page has loaded). Your script should call a function that causes a post back through your UpdatePanel ","pontos":2},{"corpo":"Yes private assemblies DO NOT require reset of the IIS. So you should just to xcopy new version to the application's Bin directory and refresh the page (e.g. by VS post build event as I did). But there are some trade offs. You should decrease trust level in application web.config file: system.web ... trust level=\"WSS_Medium\" originUrl=\"\" / ... /system.web By the way. I do not suggest to deploy like this. It's just workaround for comfort write-test-debug cycle length. ","pontos":4},{"corpo":"I use APC, and can attest that it can dramatically reduce the CPU and I/O load on an app server if you maintain a high cache-hit rate. It not only saves you from having to compile, it can save you from having to read the php files from disk at all. (i.e. the bytecodes are served directly from main memory, so it's super fast) It lowers the speed to render a single page, and increases the requests per second your server can handle. If you use RedHat or CentOS, installing APC is super simple: yum install php-devel httpd-devel php-pear pecl install apc echo \"extension=apc.so\" /etc/php.d/apc.ini # if you're using SELinux: chcon \"system_u:object_r:textrel_shlib_t\" /usr/lib/php/modules/apc.so /etc/init.d/httpd restart You asked about downsides. The only downside is that it requires some memory. The default on APC is 30MB, but it can be adjusted, and the cost of a little bit of memory more than pays for itself with the increased speed and response rate. ","pontos":1},{"corpo":"Pat, I think the functionality you are looking for only exists in IE. MSDN. But this is not an official JS thing nor is it implemented in other browsers so I don't recommend using it. ","pontos":-2},{"corpo":"For completeness's sake: it's of course completely possible to write an own implementation of a multimethod pointer table for your objects and calculate the method addresses manually at run time. There's a paper by Stroustrup on the topic of implementing multimethods (albeit in the compiler). I wouldn't really advise anyone to do this. Getting the implementation to perform well is quite complicated and the syntax for using it will probably be very awkward and error-prone. If everything else fails, this might still be the way to go, though. ","pontos":0},{"corpo":"Is it a large system with many programmers? If so it might be worth checking that nowhere in the code is the logger having its config changed programatically. In log4j, this can be done using the or classes. Also via the and . Just one rogue line of code could set up a new Logger to stdout using the PatternLayout shown in your example. BasicConfigurator.configure(); ","pontos":1},{"corpo":"Without Powershell you can do it like this: C:\\ set DOOMED=c:\\windows C:\\ cd %DOOMED% C:\\WINDOWS ","pontos":0},{"corpo":"Yes, [A-Za-z] will be much faster than setting the , largely because of Unicode strings. But it's also much more limiting -- [A-Za-z] does not match accented international characters, it's literally the A-Za-z ASCII set and nothing more. I don't know if you saw Tim Bray's answer to my message, but it's a good one: One of the trickiest issues in internationalized search is upper and lower case. This notion of case is limited to languages written in the Latin, Greek, and Cyrillic character sets. English-speakers naturally expect search to be case-insensitive if only because theyre lazy: if Nadia Jones wants to look herself up on Google shell probably just type in nadia jones and expect the system to take care of it. So its fairly common for search systems to normalize words by converting them all to lower- or upper-case, both for indexing and queries. The trouble is that the mapping between cases is not always as straightforward as it is in English. For example, the German lower-case character  becomes SS when upper-cased, and good old capital I when down-cased in Turkish becomes the dotless  (yes, they have i, its upper-case version is ). I have read (but not verified first-hand) that the rules for upcasing accented characters such  are different in France and Qubec. One of the results of all this is that software such as java.String.toLowerCase() tends to run astonishingly slow as it tries to work around all these corner-cases. http://www.tbray.org/ongoing/When/200x/2003/10/11/SearchI18n ","pontos":10},{"corpo":"I use soapUI, and it's generally pretty good. Be aware that it seems to leak memory, and eventually it will no longer save your project, so save regularly! This is about the only hassle I have with it (other than the general ugliness that almost every Java application has!), and I can't live without it. ","pontos":6},{"corpo":"That's right, events are an implementation of the observer pattern. I have read discussions , though, of people who still write their own, to give them either more flexibility, or maybe just to avoid the event-raising syntax. ","pontos":4},{"corpo":"People here seem to mistake Protected class inheritance and Protected methods. FWIW, I've never seen anyone use protected class inheritance, and if I remember correctly I think Stroustrup even considered the \"protected\" level to be a mistake in c++. There's precious little you cannot do if you remove that protection level and only rely on public and private. ","pontos":14},{"corpo":"What's at: at MyDeliveryExtension.MailDelivery.SendMail(SubscriptionData data, Stream reportStream, String reportName, String smptServerHostname, Int32 smtpServerPort) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MailDelivery.cs:line 48 at MyDeliveryExtension.MyDelivery.Deliver(Notification notification) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MyDelivery.cs:line 153 Also you seem to be disposing the report stream, but that should be done by whatever opened that stream, not your method (it won't be obvious that attaching a stream disposes it). You're losing part of your stack trace due to how you re-throw exceptions. Don't throw the ex variable, just throw is enough. Try this tweak: public static List string SendMail(SubscriptionData data, Stream reportStream, string reportName, string smptServerHostname, int smtpServerPort) { List string failedRecipients = new List string (); MailMessage emailMessage = new MailMessage(data.ReplyTo, data.To) { Priority = data.Priority, Subject = data.Subject, IsBodyHtml = false, Body = data.Comment }; if (reportStream != null) emailMessage.Attachments.Add(new Attachment(reportStream, reportName)); try { SmtpClient smtp = new SmtpClient(smptServerHostname, smtpServerPort); // Send the MailMessage smtp.Send(emailMessage); } catch (SmtpFailedRecipientsException ex) { // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List failedRecipients.Add(ex.FailedRecipient); //are you missing a loop here? only one failed address will ever be returned } catch (SmtpFailedRecipientException ex) { // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List failedRecipients.Add(ex.FailedRecipient); } // Return the List of failed recipient e-mail addresses, so the client can maintain its list. return failedRecipients; } ","pontos":0},{"corpo":"Hey guys, just as a little helper, you can express a case-insensitive a-z range easily doing this: [A-z] If you want to include numbers in that, I believe you can even either begin or end with the lowest or highest number (depending on whether it's beginning or ending). ","pontos":2},{"corpo":"Java contains some sort of preprocessor of its own. It's called APT. It processes and generates code. At the moment I'm not sure how this should work (I haven't tried it). But it seems to be used for these kind of things. ","pontos":0},{"corpo":"I did a test where I listened for key up events on the stage and noticed that (on my Mac) I could capture control-c, control-v, etc. just fine, but anything involving command (the  key) wasn't captured until I released the command key, and then ctrlKey was false (even though the docs says that ctrlKey should be true for the command key on the Mac), and the charCode was 0. Pretty useless, in short. ","pontos":1},{"corpo":"To directly answer your question: I don't know. But here is another solution to your problem: In my mind, there are two statements that collide with each other here: \"debug statements\" and \"production code\". What is the purpose of debug statements? Help to get rid of bugs while (unit) testing. If a piece of software is properly tested and works according to the requirements, debug statements are nothing else but OBSOLETE. I strongly disagree with leaving any debug statements in production code. I bet nobody bothers testing side-effects of debug code in production code. The code probably does what it's supposed to do, but does it do more than that? Do all your #defines work correctly and really take ALL of the debug code out? Who analyzes 100000 lines of pre-processed code to see if all the debug stuff is gone? Unless we have a different definition of production code, you should consider taking out the debug statements after the code is tested and be done with it. ","pontos":-2},{"corpo":"Agree with Neall, bit confusing the question. If you want the output listed in the question, the sql is as simple as: select page.content, page-tag.tag-id from page, page-tag where page.id = page-tag.pag-id and page-tag.tag-id in (1, 3, 8) order by page-tag.tag-id desc But if you want the tagcount, Daren answered your question ","pontos":0},{"corpo":"Powershell is nice, but it's an extra thing you have to install. Not standard in almost any windows installation. So, if it's just for your own use, then powershell should be fine. If you need the scripts to run on the computers of the general population, for instance, as part of a piece of software you are producing, it may not be the best option. If you are ok with an extra thing you have to install, you might want to check out cygwin. This allows you to have a full Linux bash command line and all the associated tools at your disposal. If you need something included in a default windows install. There's the windows command line (cmd.exe). Which has some functionality, but is very deficient compared to what's available in Linux. The other, probably worse problem, is that there isn't much out there in the way of documentation. You might also be interested in VB Script (flame away). VB Script should work on almost any recent standard windows install, and is a lot more functional than the command line. ","pontos":0},{"corpo":"I have cygwin installed, so I can run bash shell scripts for my automatization needs. Besides, when I need stuff running moreless natively on Windows, I use a combination of batch + jscript (runs on cmdline if you have Visual Studio.Net installed, just call \"cscript XXX.js\"). ","pontos":0},{"corpo":"I suppose you can do something like: SELECT * FROM Table ORDER BY NumericalColumn DESC LIMIT 1 OFFSET 1 or SELECT * FROM Table ORDER BY NumericalColumn DESC LIMIT (1, 1) depending on your database server. Hint: SQL Server doesn't do LIMIT. ","pontos":8},{"corpo":"Two recommendations. First: for real logging, use a modern logging package like log4j or java's own built in logging. Don't worry about performance so much, the logging level check is on the order of nanoseconds. (it's an integer comparison). And if you have more than a single log statement, guard the whole block: (log4j, for example:) if (logger.isDebugEnabled()) { // perform expensive operations // build string to log logger.debug(\"....\"); } This gives you the added ability control logging at runtime. Having to restart and run a debug build can be very inconvenient. Second: You may find assertions are more what you need. An assertion is a statement which evaluates to a boolean result, with an optional message: assert (sky.state != FALLING) : \"The sky is falling!\"; Whenever the assertion results in a false, the assertion fails and an AssertionError is thrown containing your message (this is an unchecked exception, intended to exit the application). The neat thing is, these are treated special by the JVM and can toggled at runtime down to the class level, using a VM parameter (no recompile needed). If not enabled, there is zero overhead. ","pontos":17},{"corpo":"I think the canonical answer is: \"Don't\". What you should probably do instead is unravel the thing in your view code, so it's just a matter of iterating over (in|de)dents in the template. I think I'd do it by appending indents and dedents to a list while recursing through the tree and then sending that \"travelogue\" list to the template. (the template would then insert and from that list, creating the recursive structure with \"understanding\" it.) I'm also pretty sure recursively including template files is really a wrong way to do it... ","pontos":20},{"corpo":"Scripting is a blast. Personally I like to write some evil little batch files. You can find a command line program to do just about anything. I prefer Batch files mostly because they are portable from one machine to another with at most a zip with a few unix tools (SSED, GREP, GAWK). there is a commandline REG.Exe that can even do Registry changes and reads. You can parse output from commands with a \"FOR /f\" loop. PowerShell does have more... err.. Power (2nd post I wrote that in, but I can't help it.) If you want to look at windows automation check out AutoHotKey. What are you trying to automate? That may help us narrow down what would be helpfull. Josh EDIT: for the record I typed that at the same time as @jameso If someone at work hadn't asked me a question, I may have posted before him. I did get a bit of a shiver at the similarity of the post though.... ","pontos":0},{"corpo":"true and false operators are really weird. More comprehensive example can be found here. Edit: There is related SO question Whats the false operator in C# good for? ","pontos":24},{"corpo":"Visual Studio doesn't make it obvious which assembly reference you need to add. One way to find out would be to look up ConfigurationManager in the MSDN Library. At the top of the \"about ConfigurationManager class\" page it tells you which assembly and DLL the class is in. ","pontos":0},{"corpo":"Now that there's Unicode, it's generally counter-productive to use named character entities. I would recommend using the Unicode character for a non-breaking space instead of an entity, just for that reason. Alternatively, you could use the entity ;, instead of the named entity. Using named entities makes your XML dependent on an inline or external DTD. ","pontos":5},{"corpo":"If you have only simple HTML pages as you said, it can be opened with Word. Otherwise there are some libraries which can do this, but I don't have experience with them. My last idea is that if you are using ASP.NET, try to add to the header and you can save it as a Word document (it won't be a real Word doc, only an HTML renamed to doc to be able to open). ","pontos":11},{"corpo":"C-style cast syntax, do not error check. C++-style cast syntax, does some checking. When using static_cast, even if it doesn't do checking, at least you know you should be carefull here. ","pontos":1},{"corpo":"The way I do it is the following: class test { protected $x=''; protected $y=''; function set_y ($y) { print \"specific function set_y\\n\"; $this- y = $y; } function __call($function , $args) { print \"generic function $function\\n\"; list ($name , $var ) = split ('_' , $function ); if ($name == 'get' isset($this- $var)) { return $this- $var; } if ($name == 'set' isset($this- $var)) { $this- $var= $args[0]; return; } trigger_error (\"Fatal error: Call to undefined method test::$function()\"); } } $p = new test(); $p- set_x(20); $p- set_y(30); print $p- get_x(); print $p- get_y(); $p- set_z(40); Which will output (line breaks added for clarity) generic function set_x specific function set_y generic function get_x 20 generic function get_y 30 generic function set_z Notice: Fatal error: Call to undefined method set_z() in [...] on line 16 ","pontos":3},{"corpo":"According to Stroustrup: The \"new-style casts\" were introduced to give programmers a chance to state their intentions more clearly and for the compiler to catch more errors. So really, its for safety as it does extra compile-time checking. ","pontos":5},{"corpo":"Microsoft is walking a fine line. On one hand, they regularly send ActiveX killbits with Windows Update to remove/disable applications that have been misbehaving. On the other hand, the latest version of Sharepoint 2007 (can't speak for earlier versions) allows for Office documents to be opened by clicking a link in the browser, and edited in the local application. When the edit is finished, the changes are transmitted back to the server and the webpage (generally) is refreshed. This is only an IE thing, as Firefox will throw up an error message. I can see the logic behind it, though. Until Microsoft gets all of their apps 'in the cloud', there are cases that need to bridge the gap between the old client-side apps and a more web-centric business environment. While there is likely a non-web workaround, more and more information workers have come to expect that a large portion of their work will be done in a browser. Anything that makes the integration with the desktop easier is not going to be opposed by anyone except the sysadmins. ","pontos":2},{"corpo":"C-style cast is the worst way to go. It's harder to see, ungreppable, conflates different actions that should not be conflated, and can't do everything that C++-style casts can do. They really should have removed C-style casts from the language. ","pontos":1},{"corpo":"Yes that's right the variables have to be manually declared but i find that better since I fear a typo in the setter $props2- setFristName('Mark'); will auto-generate a new property (FristName instead of FirstName) which will make debugging harder. ","pontos":1},{"corpo":"A clarification about the . This statement is the result of being inheritance unfriendly. The JLS (Java language specification) specifies that if then must also return . If you omit that statement inheriting classes that override (and change its behavior) will break this specification. Consider the following example of what happens when the statement is omitted: class A { int field1; A(int field1) { this.field1 = field1; } public boolean equals(Object other) { return (other != null other instanceof A ((A) other).field1 == field1); } } class B extends A { int field2; B(int field1, int field2) { super(field1); this.field2 = field2; } public boolean equals(Object other) { return (other != null other instanceof B ((B)other).field2 == field2 super.equals(other)); } } Doing Also, result give out true, as it should. This looks all very good, but look what happens if we try to use both classes: A a = new A(1); B b = new B(1,1); a.equals(b) == true; b.equals(a) == false; Obviously, this is wrong. If you want to ensure the symmetric condition. a=b if b=a and the Liskov substitution principle call not only in the case of instance, but check after for instance: if (other instanceof B ) return (other != null ((B)other).field2 == field2 super.equals(other)); if (other instanceof A) return super.equals(other); else return false; Which will output: a.equals(b) == true; b.equals(a) == true; Where, if is not a reference of , then it might be a be a reference of class (because you extend it), in this case you call too. ","pontos":48},{"corpo":"It's best practice never to use C-style casts for two main reasons: as already mentioned, no checking is performed here. The programmer simply cannot know which of the various casts is used which weakens strong typing the new casts are intentionally visually striking. Since casts often reveal a weakness in the code, it's argued that making casts visible in the code is a good thing. this is especially true if searching for casts with an automated tool. Finding C-style casts reliably is nearly impossible. As palm3D noted: I find C++-style cast syntax too verbose. This is intentional, for the reasons given above. The constructor syntax (official name: function-style cast) is semantically the same as the C-style cast and should be avoided as well (except for variable initializations on declaration), for the same reasons. It is debatable whether this should be true even for types that define custom constructors but in Effective C++, Meyers argues that even in those cases you should refrain from using them. To illustrate: void f(auto_ptr int x); f(static_cast auto_ptr int (new int(5))); // GOOD f(auto_ptr int (new int(5)); // BAD The here will actually call the constructor. ","pontos":39},{"corpo":"Definitely C++-style. The extra typing will help prevent you from casting when you shouldn't :-) ","pontos":1},{"corpo":"In T-Sql there are two ways: --filter out the max select max( col ) from [table] where col ( select max( col ) from [table] ) --sort top two then bottom one select top 1 col from ( select top 2 col from [table] order by col) topTwo order by col desc In Microsoft SQL the first way is twice as fast as the second, even if the column in question is clustered. This is because the sort operation is relatively slow compared to the table or index scan that the aggregation uses. Alternatively, in Microsoft SQL 2005 and above you can use the function: select col from ( select ROW_NUMBER() over (order by col asc) as 'rowNum', col from [table] ) withRowNum where rowNum = 2 ","pontos":19},{"corpo":"You do not mention which language you would like the solution in so here is some pseudo code. Loop through each character If the previous character was an alphabet letter Make the character lower case Otherwise Make the character upper case End loop ","pontos":0},{"corpo":"I believe this should do the trick: $srcImage = imagecreatefrompng($uploadTempFile); imagealphablending($srcImage, false); imagesavealpha($srcImage, true); edit: Someone in the PHP docs claims should be true, not false. YMMV. ","pontos":6},{"corpo":"You could try cloning using the innerHTML method, or a mix: var newItem = $(item).cloneNode(false); newItem.innerHTML = $(item).innerHTML; Also: I think cloneNode doesn't clone events, registered with addEventListener. But IE's attachEvent events are cloned. But I might be wrong. ","pontos":0},{"corpo":"Sorry to be prickly, but I'm not a noob: I know you can't install SQL Server on Linux. Do you guys have customers running Netware trying to connect to a SQL Server? That is what I am dealing with. We have customers, mostly school systems, that use Netware as the \"network OS\" with many Windows workstations running the Netware client. Our app uses SQL Server which is usually installed on a Windows 2003 server, but the server is always a second class citizen on the network. Users often must use the IP address rather than machine name to connect the SQL Server. @Will: Do your Novell customers have trouble accessing SQL Server on the Windows server? Can you install the Netware client on the Windows server to enable file sharing? ","pontos":1},{"corpo":"RegexBuddy is a weapon of choice ","pontos":6},{"corpo":"I'm definitely aware that there are syntactic differences, though I'm certainly not fluent enough yet to automatically use them, making the code look much more similar currently ;-). And I had a feeling your answer would be the case, but can always hope for a shortcut _ . ","pontos":0},{"corpo":"I generally prefer not doing either, since it's just slowing things down. NullPointerExceptions are thrown later on anyway, which will quickly lead the user to discovering they're passing null to the method. I used to check, but 40% of my code ended up being checking code, at which point I decided it was just not worth the nice assertion messages. Edit: 4 down votes this quick? I'm just saying what I think of the matter, and I think I make a fairly valid point, although it differs from popular opinion around here. My answer is as valid as any of yours. ","pontos":1},{"corpo":"May be not exactly responding to your general question, but if you used (N)Hibernate then you can automatically generate the database schema from your hbm mapping files. Its not done directly from your code as you seem to be wanting but Hibernate Schema generation seems to work well for us ","pontos":0},{"corpo":"In our JBoss Seam in Action presentation at the Javapolis conference last year, my colleague and I said that 'Seam is the next Struts'. This needed some explanation, which I later wrote-up as Seam is the new Struts. Needless to say, we like Seam. One indication of Seam's popularity is the level of traffic on the Seam Users Forum. ","pontos":14},{"corpo":" It doesn't really go into how you would enforce this restriction? You enforce it by throwing an ArgumentExcexception if they pass in null. if (p1 == null || p2 == null) { throw new ArgumentExcexception(\"Invalid argument for xProjection\"); } ","pontos":2},{"corpo":"I agree or disagree with wvdschel's post, it depends on what he's specifically saying. In this case, sure, this method will crash on null so the explicit check here is probably not needed. However, if the method simply stores the passed data, and there is some other method that you call later that will deal with it, discovering bad input as early as possible is the key to fixing bugs faster. At that later point, there could be a myriad of ways that bad data happened to be given to your class. It's sort of trying to figure out how the rats came into your house after the fact, trying to find the hole somewhere. ","pontos":1},{"corpo":"I'm not sure what you are asking. Are you looking for software to allow NetWare applications to talk to a SQL Server running on Windows? The wording of your original question implied that you want SQL Server to run on the NetWare machine. The question of why SQL Server doesn't support NetWare is best asked of Microsoft, but AFAIK SQL Server doesn't support any non-Windows OS. As someone else said, SQL Server originally came from Sybase's SQL Server (now called Adaptive Server Enterprise), which supported NetWare at one time but dropped it a long time ago. Sybase's other RDBMS, SQL Anywhere, dropped NetWare as of version 11, but versions 9 and 10 are still supported on NW. ","pontos":2},{"corpo":"Even if you didn't want to actually edit in VS, you could create the project there and edit the files in another editor. ","pontos":3},{"corpo":"As noted by MDCore, SnippetsEmu is a popular Vim script that does just that and more. If you need only expending (without moving back the caret), you can use the standard command. :ab[breviate] [ expr ] {lhs} {rhs} add abbreviation for {lhs} to {rhs}. If {lhs} already existed it is replaced with the new {rhs}. {rhs} may contain spaces. See |:map- expr | for the optional expr argument. ","pontos":4},{"corpo":"Your problem is your directory service, whether it's Microsoft's Active Directory or Novell's Directory Services (I think it's called). Sounds to me like your DNS is broken if your clients can't resolve names to IP address. ","pontos":4},{"corpo":"If it's just HTML, all you need to do is change the extension to .doc and word will open it as if it's a word document. However, if there are images to include or javascript to run it can get a little more complicated. ","pontos":1},{"corpo":"Is there any class in STL that takes a string... I dont think so (couldnt find any in my quick search). So it's probably some design decision, that no class in STL should be dependent on any other STL class (that is not directly needed for functionality). ","pontos":1},{"corpo":"@Brian My problem with this is that adding \"more logic later\" requires that you add blanket logic that applies to all properties accessed with the getter/setter or that you use if or switch statements to evaluate which property you're accessing so that you can apply specific logic. That's not quite true. Take my first example: class PropTest extends PropertyHandler { public function __construct() { parent::__construct(); } } $props = new PropTest(); $props- setFirstName(\"Mark\"); echo $props- getFirstName(); Let's say that I need to add some logic for validating FirstNames. All I have to do is add a setFirstName method to my subclass and that method is automatically used instead. class PropTest extends PropertyHandler { public function __construct() { parent::__construct(); } public function setFirstName($name) { if($name == 'Mark') { echo \"I love you, Mark!\"; } } } I'm just not satisfied with the limitations that PHP has when it comes to implicit accessor methods. I agree completely. I like the Python way of handling this (my implementation is just a clumsy rip-off of it). ","pontos":2},{"corpo":"It turns out this is a bug with Firefox + ASP.NET where the generated javascript for the defaultButton stuff doesn't work in Firefox. I had to put a replacement for the WebForm_FireDefatultButton function as described here: function WebForm_FireDefaultButton(event, target) { var element = event.target || event.srcElement; if (event.keyCode == 13 !(element element.tagName.toLowerCase() == \"textarea\")) { var defaultButton; if (__nonMSDOMBrowser) { defaultButton = document.getElementById(target); } else { defaultButton = document.all[target]; } if (defaultButton typeof defaultButton.click != \"undefined\") { defaultButton.click(); event.cancelBubble = true; if (event.stopPropagation) { event.stopPropagation(); } return false; } } return true; } ","pontos":3},{"corpo":"My understanding is that this is how HTML works. If you do a and post the form, then the form will post foo?param1=value1 ... paramn=valuen. It has nothing to do with MVC. Besides, what part of REST does that URL violate? It's not a \"pretty\" URL, but by strict definition of REST, it can be RESTful. REST doesn't specify that query parameters have to be in an URL segment. And in this case, those are query parameters. ","pontos":3},{"corpo":"There are several places where the C++ standard committee did not really optimize the interaction between facilities in the standard library. and its use in the library is one of these. One other example is . Many containers have a swap member function, but no overload of std::swap is supplied. The same goes for . I hope all these small things will be fixed in the upcoming standard. ","pontos":14},{"corpo":"Not really - the only thing you could realistically do is offer advice on the site; maybe, before their first time signing in, you could show them a form with information indicating that it is not recommended that they allow the browser to store the password. Then the user will immediately follow the advice, write down the password on a post-it note and tape it to their monitor. ","pontos":7},{"corpo":"I'd say that it is very important to consider how much load you are causing. For instance, if your crawler requests every object of a single site, more or less at once, it might cause load problems for that particular site. In other words, make sure your crawler is not too aggressive. ","pontos":2},{"corpo":" Is there a way for a site to tell the browser not to offer to remember passwords? The website tells the browser that it is a password by using . So if you must do this from a website perspective then you would have to change that. (Obviously I don't recommend this). The best solution would be to have the user configure their browser so it won't remember passwords. ","pontos":0},{"corpo":"I'll add to the vote of Reggy for the Mac, gonna try out some of the other ones that Joseph suggested and upvote that post tomorrow when my limit gets reset. ","pontos":1},{"corpo":"I'm not a tester but in my opinion it is vital to document the \"UI route\" that the test must take to avoid any confusion. I have worked on countless defects that I could not reproduce simply because I was not accessing the function from the same UI path as the tester was. e.g. Right Click menu vs Toolbar or functions that can be carried out from various dialogs, etc. etc. ","pontos":1},{"corpo":"I believe that this has been thought about and was done to avoid the dependency; i.e. #include fstream should not force one to #include string . To be honest, this seems like quite an inconsequential issue. A better question would be, why is std::string's interface so large? ","pontos":0},{"corpo":"Markus raised a great point. I decided to look up the attribute and got the following: The only downside to using this attribute is that it is not standard (it works in IE and Mozilla browsers), and would cause XHTML validation to fail. I think this is a case where it's reasonable to break validation however. (source) So I would have to say that although it doesn't work 100% across the board it is handled in the major browsers so its a great solution. ","pontos":2},{"corpo":"You can prevent the browser from matching the forms up by randomizing the name used for the password field on each show. Then the browser sees a password for the same the url, but can't be sure it's the same password. Maybe it's controlling something else. Update: note that this should be in addition to using autocomplete or other tactics, not a replacement for them, for the reasons indicated by others. Also note that this will only prevent the browser from auto-completing the password. It won't prevent it from storing the password in whatever level of arbitrary the security the browser chooses to use. ","pontos":16},{"corpo":"My first question would be - why isn't your QA department writing the test plans? Typically, software developers provide QA with a functional spec of how the software is supposed to work and then QA creates test plans based on that. With that said, I would suggest being very specific with the steps since you are detailing how things are supposed to work. It is then the job of the tester to make sure that your specific steps get the desired results and it is also their job to deviate from the plan and try to break things. If there are multiple ways to achieve a goal, you need to describe each path to get there. ","pontos":5},{"corpo":"There is a good searchable catalog of regular expressions at the Regular Expression Library. There is at least one regular expression for UK phone numbers in this catalog. ","pontos":-7},{"corpo":"After fooling around with the tunctionallity that gets the reportStream, I was able to fix the mail sending problem. The error wasn't in the SendMail method, but somewehere else. The exception was thrown in the context, of SendMail though. Buggered! ","pontos":0},{"corpo":"I found a thread with a bunch of Perl guys arguing the toss on this question over at http://www.perlmonks.org/?node_id=336331. I hope this isn't too much of a non-answer to the question, but I would say you have a bit of a problem in that it would be a very open-ended algorithm which could have a lot of 'misses' as well as hits. For example, say you inputted:- camelCase(\"hithisisatest\"); The output could be:- \"hiThisIsATest\" Or:- \"hitHisIsATest\" There's no way the algorithm would know which to prefer. You could add some extra code to specify that you'd prefer more common words, but again misses would occur (Peter Norvig wrote a very small spelling corrector over at http://norvig.com/spell-correct.html which might help algorithm-wise, I wrote a C# implementation if C#'s your language). I'd agree with Mark and say you'd be better off having an algorithm that takes a delimited input, i.e. this_is_a_test and converts that. That'd be simple to implement, i.e. in pseudocode:- SetPhraseCase(phrase, CamelOrPascal): if no delimiters if camelCase return lowerFirstLetter(phrase) else return capitaliseFirstLetter(phrase) words = splitOnDelimiter(phrase) if camelCase ret = lowerFirstLetter(first word) else ret = capitaliseFirstLetter(first word) for i in 2 to len(words): ret += capitaliseFirstLetter(words[i]) return ret capitaliseFirstLetter(word): if len(word) = 1 return upper(word) return upper(word[0]) + word[1..len(word)] lowerFirstLetter(word): if len(word) = 1 return lower(word) return lower(word[0]) + word[1..len(word)] You could also replace my capitaliseFirstLetter() function with a proper case algorithm if you so wished. A C# implementation of the above described algorithm is as follows (complete console program with test harness):- using System; class Program { static void Main(string[] args) { var caseAlgorithm = new CaseAlgorithm('_'); while (true) { string input = Console.ReadLine(); if (string.IsNullOrEmpty(input)) return; Console.WriteLine(\"Input '{0}' in camel case: '{1}', pascal case: '{2}'\", input, caseAlgorithm.SetPhraseCase(input, CaseAlgorithm.CaseMode.CamelCase), caseAlgorithm.SetPhraseCase(input, CaseAlgorithm.CaseMode.PascalCase)); } } } public class CaseAlgorithm { public enum CaseMode { PascalCase, CamelCase } private char delimiterChar; public CaseAlgorithm(char inDelimiterChar) { delimiterChar = inDelimiterChar; } public string SetPhraseCase(string phrase, CaseMode caseMode) { // You might want to do some sanity checks here like making sure // there's no invalid characters, etc. if (string.IsNullOrEmpty(phrase)) return phrase; // .Split() will simply return a string[] of size 1 if no delimiter present so // no need to explicitly check this. var words = phrase.Split(delimiterChar); // Set first word accordingly. string ret = setWordCase(words[0], caseMode); // If there are other words, set them all to pascal case. if (words.Length 1) { for (int i = 1; i words.Length; ++i) ret += setWordCase(words[i], CaseMode.PascalCase); } return ret; } private string setWordCase(string word, CaseMode caseMode) { switch (caseMode) { case CaseMode.CamelCase: return lowerFirstLetter(word); case CaseMode.PascalCase: return capitaliseFirstLetter(word); default: throw new NotImplementedException( string.Format(\"Case mode '{0}' is not recognised.\", caseMode.ToString())); } } private string lowerFirstLetter(string word) { return char.ToLower(word[0]) + word.Substring(1); } private string capitaliseFirstLetter(string word) { return char.ToUpper(word[0]) + word.Substring(1); } } ","pontos":3},{"corpo":" It is inconsequential, that is true. What do you mean by std::string's interface being large? What does large mean, in this context - lots of method calls? I'm not being facetious, I am actually interested. It has more methods than it really needs, and its behaviour of using integral offsets rather than iterators is a bit iffy (as it's contrary to the way the rest of the library works). The real issue I think is that the C++ library has three parts; it has the old C library, it has the STL, and it has strings-and-iostreams. Though some efforts were made to bridge the different parts (e.g. the addition of overloads to the C library, because C++ supports overloading; the addition of iterators to basic_string; the addition of the iostream iterator adaptors), there are a lot of inconsistencies when you look at the detail. For example, basic_string includes methods that are unnecessary duplicates of standard algorithms; the various find methods, could probably be safely removed. Another example: locales use raw pointers instead of iterators. ","pontos":2},{"corpo":"My colleague just found a reference to that method right after I posted (in reference to css) at http://www.stefanhayden.com/blog/2006/04/03/css-caching-hack/. Good to see that others are using it and it seems to work. I assume at this point that there isn't a better way than find-replace to increment these \"version numbers\" in all of the script tags? ","pontos":1},{"corpo":"If you use Packer, just go far the 'shrink variables' option and gzip the resulting code. The base62 option is only for if your server cannot send gzipped files. Packer with 'shrink vars' achieves better compression the YUI, but can introduce bugs if you've skipped a semicolon somewhere. base62 is basically a poor man's gzip, which is why gzipping base62-ed code gives you bigger files than gzipping shrink-var-ed code. ","pontos":4},{"corpo":"Another possibility is to put the if statement within your logging function, you get less code this way, but at the expense of some extra function calls. I'm also not a big fan of completely removing the debug code. Once you're in production, you'll probably need access to debug messages if something goes wrong. If you remove all of your code level debugging, than this isn't a possibility. ","pontos":1},{"corpo":"Edit: I tested with http://code.google.com, not http://www.google.com/codesearch - odd that they don't return the same results. Google code search doesn't work either - searching for something like \"cs[i]\" brings back hits for \"csi\". I really doubt there's any general-purpose searching tool that takes programming syntax into consideration - it's just much too specialized. There may be search products/appliances out there, but they're likely to be pointed at private codebases, not intended for public search. ","pontos":-1},{"corpo":"Can you generate some random data once (I mean exactly once, not once per test run), then use it in all tests thereafter? I can definitely see the value in creating random data to test those cases that you haven't thought of, but you're right, having unit tests that can randomly pass or fail is a bad thing. ","pontos":3},{"corpo":" if it's a random value and the test fails, we need to a) fix the object and b) force ourselves to test for that value every time, so we know it works, but since it's random we don't know what the value was If your test case does not accurately record what it is testing, perhaps you need to recode the test case. I always want to have logs that I can refer back to for test cases so that I know exactly what caused it to fail whether using static or random data. ","pontos":1},{"corpo":"Unfortunately, it seems workarounds are in order. I've found that searching for csharp or c sharp seems to be necessary. I've also used \"Ansi C\" or \"c99\" to search on C instead of C++. I know google code search seems to suffer the same issues, although it does have a regex engine. ","pontos":2},{"corpo":"Unfortunately I don't think this is possible. The exception you are raising in your web service code is being encoded into a Soap Fault, which then being passed as a string back to your client code. What you are seeing in the SoapException message is simply the text from the Soap fault, which is not being converted back to an exception, but merely stored as text. If you want to return useful information in error conditions then I recommend returning a custom class from your web service which can have an \"Error\" property which contains your information. [WebMethod] public ResponseClass HelloWorld() { ResponseClass c = new ResponseClass(); try { throw new Exception(\"Exception Text\"); // The following would be returned on a success c.WasError = false; c.ReturnValue = \"Hello World\"; } catch(Exception e) { c.WasError = true; c.ErrorMessage = e.Message; return c; } } ","pontos":4},{"corpo":"In this case, I would do as you are doing (use a byte array for buffering and not one of the stream buffers). There are exceptions, though. One place you see buffers (output this time) is in the servlet API. Data isn't written to the underlying stream until flush() is called, allowing you to buffer output but then dump the buffer if an error occurs and write an error page instead. You might buffer input if you needed to reset the stream for rereading using mark(int) and reset(). For example, maybe you'd inspect the file header before deciding on which content handler to pass the stream to. Unrelated, but I think you should rewrite your stream handling. This pattern works best to avoid resource leaks: InputStream stream = new FileInputStream(\"in\"); try { //no operations between open stream and try block //work } finally { //do nothing but close this one stream in the finally stream.close(); } If you are opening multiple streams, nest try/finally blocks. Another thing your code is doing is making the assumption that the returned content is encoded in your VM's default character set (though that might be adequate, depending on the use case). ","pontos":4},{"corpo":"On krugle, a search for \"cs[i]\" in quotes seems to work... as it does also in google codesearch... ","pontos":4},{"corpo":"The biggest one is making sure you don't put pointers into 32-bit storage locations. But there's no proper 'language-agnostic' answer to this question, really. You couldn't even get a particularly firm answer if you restricted yourself to something like standard 'C' or 'C++' - the size of data storage, pointers, etc, is all terribly implementation dependant. ","pontos":0},{"corpo":"It honestly depends on the language, because managed languages like C# and Java or Scripting languages like JavaScript, Python, or PHP are locked in to their current methodology and to get started and to do anything beyond the advanced stuff there is not much to worry about. But my guess is that you are asking about languages like C++, C, and other lower level languages. The biggest thing you have to worry about is the size of things, because in the 32-bit world you are limited to the power of 2^32 however in the 64-bit world things get bigger 2^64. With 64-bit you have a larger space for memory and storage in RAM, and you can compute larger numbers. However if you know you are compiling for both 32 and 64, you need to make sure to limit your expectations of the system to the 32-bit world and limitations of buffers and numbers. ","pontos":0},{"corpo":"According to Kalen Delaney... The NOLOCK hint has nothing to do with the index options. The hint tells SQL Server not to request locks when doing SELECT operations, so there will be no conflict with data that is already locked. The index options just tell SQL Server that this level of locking is allowed, when locking is going to occur. For example, if ALLOW_ROW_LOCKS was off, the only possible locks would be page or table locks. The index options don't force locks to be held, they just control the possible size of the locks. In answer to the question in your subject, the NOLOCK hint and the READUNCOMMITTED hint are equivalent. ","pontos":1},{"corpo":"OK, so the key difference between this and kristof's answer is that you only want a count of 1 to show against page 1, because it has been tagged only with one tag from the set (even though two separate users both tagged it). I would suggest this: SELECT page.ID, page.content, count(*) AS uniquetags FROM ( SELECT DISTINCT page.content, page.ID, page-tag.tag-id FROM page INNER JOIN page-tag ON page.ID=page-tag.page-ID WHERE page-tag.tag-id IN (1, 3, 8) ) GROUP BY page.ID I don't have a SQL Server installation to check this, so apologies if there's a syntax mistake. But semantically I think this is what you need. This may not give the output in descending order of number of tags, but try adding: ORDER BY uniquetags DESC at the end. My uncertainty is whether you can use ORDER BY outside of grouping in SQL Server. If not, then you may need to nest the whole thing in another SELECT. ","pontos":1},{"corpo":"In most cases the only thing you have to do is just compile your code for both platforms. (And that's assuming that you're using a compiled language; if it's not, then you probably don't need to worry about anything.) The only thing I can think of that might cause problems is assuming the size of data types, which is something you probably shouldn't be doing anyway. And of course anything written in assembly is going to cause problems. ","pontos":0},{"corpo":"I've added a shortcut to my Control-Shift-C key combination to bring up my Visual Studio 2008 Console. This alone has saved me countless seconds when needing to register a dll or do any other command. I imagine if you leverage this with another command tool and you may have some massive productivity increases. ","pontos":0},{"corpo":"Not 100% sure what you mean here, but I will say that after doing ASP.NET for the last 6 years, my web pages are now mostly driven by JavaScript once the basic page rendering is done by the server. I use JSON for everything (have been for about 3 years now) and use MochiKit for my client-side needs. By the way, JavaScript is OO, but since it uses prototypical inheritance, people don't give it credit in that way. I would also argue that it is functional as well, it all depends on how you write it. If you are really interested in functional programming styles, check out MochiKit - you may like it; it leans quite a bit towards the functional programming side of JavaScript. ","pontos":0},{"corpo":"I use svn:// for personal projects because I often work on multiple machines on the same network and I want to store everything in the repository on my desktop machine. ","pontos":0},{"corpo":"None that I know if. It should prove to a be at least a little bit faster. ","pontos":0},{"corpo":"If you did 1 check-in and you just want to undo it, that has a changeset # associated with it. Do a history on the folder in question to see the bad changeset. Open it up to see the details (all files changed, etc). I believe that you can restore or undo a changeset from that screen, but my Visual Studio just crashed when I tried to do this. /sigh -- I definitely share your pain. Where do I downmod TFS on this site? ","pontos":1},{"corpo":"I just upgraded our team to TFS 2008, from TFS 2005. The hardest part was upgrading SharePoint 2.0 to 3.0, so I would make sure to do that first, if you have not already installed TFS 2008. We had a couple of other difficulties, but they were all either related to the SharePoint upgrade, or to the fact that we were using an aftermarket Policy package - Scrum for TeamSystem. We are on SQL Server 2005, so I cannot address SQL Server 2008. As for splitting the layers, we did not do this either, as we are running on Windows Server 2003 and everything ran under the host OS. ","pontos":1},{"corpo":"Please be sure to include a URL in your user-agent string that explains who/what/why your robot is crawling. ","pontos":2},{"corpo":"Clicking on the line number in the left hand margin should create a break point for you (a red circle should appear). All loaded scripts should be available from the firebug menu - click where it says the name of the current file should show a drop down with all files listed. ","pontos":2},{"corpo":"I have many different machines I work with so it's easier for me to use svn:// for the paths. In addition to that, I find that the svn path is almost always shorter than my file paths, so it's less to type. ","pontos":0},{"corpo":"I've used it. My company had an very NFS-intensive infrastructure at one point (less so now) and many Perl sysadmin tools dating back to the mid 90s. We wrapped lockfile in a perl module so that we could do consistent locking across NFS mounts. For that matter, our home directories were NFS mounted and we used procmail to deliver mail into them using the same style of locking and never had any problems with it (procmail delivering mail via NFS from server-a and mail being read via firect file access or UW-imap from a bunch of other servers). ","pontos":2},{"corpo":"The default build publisher in CC.NET does not provide a way to do this. You have a few options: Create your own build publisher with the desired functionality Create a custom NAnt/MSBuild task Use a scripting technology (RoboCopy, batch file, etc.) to create a script file and run an \"Executable\" task for CC.NET, or an \"exec\" task for NAnt/MSBuild ","pontos":0},{"corpo":"To me, \"padding\" just sounds more inner than \"margin\". Perhaps thinking about the printed page would help? Margins are areas on the far outside - generally, you cannot even print to the edge - they are unmarkable. Within those margins, the content could be padded to provide an extra barrier between the content and the margin? Once you work in CSS enough, it'll become second nature to remember this. ","pontos":3},{"corpo":"There is no single interface or base class that they all inherit (that is not also inherited by other classes) so the simple answer is no. I do wonder why this is an issue though. What are you wanting to do inside your IntegerFunction class that can only be done to integers? ","pontos":0},{"corpo":"There's no constraint for this. It's a real issue for anyone wanting to use generics for numeric calculations. I'd go further and say we need static bool GenericFunction T (T value) where T : operators( +, -, /, * ) Or even static bool GenericFunction T (T value) where T : Add, Subtract Unfortunately you only have interfaces, base classes and the keywords (must be value-type), (must be reference type) and (must have default constructor) You could wrap the number in something else (similar to ) like here on codeproject. You could apply the restriction at runtime (by reflecting for the operators or checking for types) but that does lose the advantage of having the generic in the first place. ","pontos":40},{"corpo":"LINQ will bloat the procedure cache If an application is using LINQ to SQL and the queries involve the use of strings that can be highly variable in length, the SQL Server procedure cache will become bloated with one version of the query for every possible string length. For example, consider the following very simple queries created against the Person.AddressTypes table in the AdventureWorks2008 database: var p = from n in x.AddressTypes where n.Name == \"Billing\" select n; var p = from n in x.AddressTypes where n.Name == \"Main Office\" select n; If both of these queries are run, we will see two entries in the SQL Server procedure cache: One bound with an NVARCHAR(7), and the other with an NVARCHAR(11). Now imagine if there were hundreds or thousands of different input strings, all with different lengths. The procedure cache would become unnecessarily filled with all sorts of different plans for the exact same query. More here: https://connect.microsoft.com/VisualStudio/feedback/ViewFeedback.aspx?FeedbackID=363290 ","pontos":22},{"corpo":"Probably the closest you can do is static bool IntegerFunction T (T value) where T: struct Not sure if you could do the following static bool IntegerFunction T (T value) where T: struct, IComparable , IFormattable, IConvertible, IComparable T , IEquatable T For something so specific, why not just have overloads for each type, the list is so short and it would possibly have less memory footprint. ","pontos":5},{"corpo":"When working with CSS finally drives you mad the padded cell that they will put you in has the padding on the inside of the walls. ","pontos":114},{"corpo":"I've just learnt it over time - the box model is fairly simple but the main reason people find it hard is because doesn't visibly break the model. Really, if you give a margin and a background you should see it surrounded by a white strip. However this isn't the case - 's padding is the same as margin. This establishes a few incorrect things about the box model. I usually think about it like this: margin = spacing around the box; border = the edge of the box; padding = space inside the box. ","pontos":2},{"corpo":" What are you wanting to do inside your IntegerFunction class that can only be done to integers? More to the point, Why do you need a generic method for if you just just allows integers? ","pontos":0},{"corpo":"I've gotten this error in a circumstance completely unrelated to what the error message describes. What I did was load a LINQ object via one DataContext, and then tried to SubmitChanges() for the object via a different DataContext - gave this exact same error. What I had to do was call DataContext.Table.Attach(myOldObject), and then call SubmitChanges(), worked like a charm. Worth a look, especially if you're of the opinion that there really shouldn't be any conflicts at all. ","pontos":4},{"corpo":"Here's a way to see where the conflicts are (this is an MSDN example, so you'll need to heavily customize): try { db.SubmitChanges(ConflictMode.ContinueOnConflict); } catch (ChangeConflictException e) { Console.WriteLine(\"Optimistic concurrency error.\"); Console.WriteLine(e.Message); Console.ReadLine(); foreach (ObjectChangeConflict occ in db.ChangeConflicts) { MetaTable metatable = db.Mapping.GetTable(occ.Object.GetType()); Customer entityInConflict = (Customer)occ.Object; Console.WriteLine(\"Table name: {0}\", metatable.TableName); Console.Write(\"Customer ID: \"); Console.WriteLine(entityInConflict.CustomerID); foreach (MemberChangeConflict mcc in occ.MemberConflicts) { object currVal = mcc.CurrentValue; object origVal = mcc.OriginalValue; object databaseVal = mcc.DatabaseValue; MemberInfo mi = mcc.Member; Console.WriteLine(\"Member: {0}\", mi.Name); Console.WriteLine(\"current value: {0}\", currVal); Console.WriteLine(\"original value: {0}\", origVal); Console.WriteLine(\"database value: {0}\", databaseVal); } } } To make it ignore the problem and commit anyway: db.SubmitChanges(ConflictMode.ContinueOnConflict); ","pontos":21},{"corpo":"Place in your external script file on the line you want to break on. ","pontos":28},{"corpo":"Unfortunately you are only able to specify struct in the where clause in this instance. It does seem strange you can't specify Int16, Int32, etc. specifically but I'm sure there's some deep implementation reason underlying the decision to not permit value types in a where clause. I guess the only solution is to do a runtime check which unfortunately prevents the problem being picked up at compile time. That'd go something like:- static bool IntegerFunction T (T value) where T : struct { if (typeof(T) != typeof(Int16) typeof(T) != typeof(Int32) typeof(T) != typeof(Int64) typeof(T) != typeof(UInt16) typeof(T) != typeof(UInt32) typeof(T) != typeof(UInt64)) { throw new ArgumentException( string.Format(\"Type '{0}' is not valid.\", typeof(T).ToString())); } // Rest of code... } Which is a little bit ugly I know, but at least provides the required constraints. I'd also look into possible performance implications for this implementation, perhaps there's a faster way out there. ","pontos":11},{"corpo":"Here's where I'd start: Get Process Explorer and show %Time in JIT, %Time in GC, CPU Cycles Delta, CPU Time, CPU %, and Threads. You'll also want kernel and user time, and a couple of representative stack traces but I think you have to hit Properties to get snapshots. Compare before and after shots. A couple of thoughts on possibilities: excessive GC (% Time in GC going up. Also, Perfmon GC and CPU counters would correspond) excessive threads and associated context switches (# of threads going up) polling (stack traces are consistently caught in a single function) excessive kernel time (kernel times are high - Task Manager shows large kernel time numbers when CPU is high) exceptions (PE .NET tab Exceptions thrown is high and getting higher. There's also a Perfmon counter) virus/rootkit (OK, this is a last ditch scenario - but it is possible to construct a rootkit that hides from TaskManager. I'd suspect that you could then allocate your inevitable CPU usage to another process if you were cunning enough. Besides, if you've ruled out all of the above, I'm out of ideas right now) ","pontos":2},{"corpo":"I use SuperDuper! and backup my Virtual Machine to another external drive (i have two). All the code is on a SVN server. I have a clean VM in case mine fails. But in either case it takes me a couple of hours to install WinXP+Vstudio. i don't use anything else in that box. ","pontos":0},{"corpo":"I think you are misunderstanding generics. If the operation you are trying to perform is only good for specific data types then you are not doing something \"generic\". Also, since you are only wanting to allow the function to work on int data types then you shouldn't need a separate function for each specific size. Simply taking a parameter in the largest specific type will allow the program to automatically upcast the smaller data types to it. (i.e. passing an Int16 will auto-convert to Int64 when calling). If you are performing different operations based on the actual size of int being passed into the function then I would think you should seriously reconsider even trying to do what you are doing. If you have to fool the language you should think a bit more about what you are trying to accomplish rather than how to do what you want. Failing all else, a parameter of type Object could be used and then you will have to check the type of the parameter and take appropriate action or throw an exception. ","pontos":-4},{"corpo":"Step 2 to 3 (i.e. Gmail to Hotmail) would normally happen through SMTP (or ESMTP - extended SMTP). Hotmail doesn't send anything to a client via POP3. It's important to understand some of the nuances here. The client contacts Hotmail via POP3 and requests its mail. (i.e. the client initiates the discussion). ","pontos":1},{"corpo":"OK, I found the problem, I also had to restart the NIS service on the server to get it to refresh everything () ","pontos":1},{"corpo":"These work very well for me: http://unxutils.sourceforge.net/. Cygwin is not so good on Vista or 64 bit, so I stopped using it a while back. ","pontos":5},{"corpo":"It's frowned upon for normal exits. If \"not everything is going according to plan\", then System.exit is fine. Update: I should add that I assume your '1' has meaning that is documented somewhere. ","pontos":1},{"corpo":"I don't have access to the server itself, so I can't check that. I can only chmod files and folder from my FTP client. I think my hosting provider needs to grant write permission to the network service account on the App_Data folder. ","pontos":0},{"corpo":"I assume that this server is behind a router? You should be able to block connections to the server on the router and still leave it open to accepting connection. Or you could restrict the that can connect to the server to the development machines on the network. ","pontos":1},{"corpo":"It can be dangerous / problematic in web servlet environments also. Throwing an Exception is generally considered the other alternative. ","pontos":1},{"corpo":"Why vote down this question? It's obviously meant to be tongue in cheek is it worth the voter and the receiver losing rep over? Can't you people leave anything at zero and mark up the answers you want to see float rather than mark down the funny one liners? In answer to the question I've used Cygwin in the past but always found it clunky and wanting. I don't think it's the tools problem but mine but I have book marked Eric's suggestion of unxutils for when my new windows machine arrives tomorrow. ","pontos":0},{"corpo":"Short answer: Yes ","pontos":3},{"corpo":"The MouseDoubleClick event of the TabControl seems to respond just fine to double-clicking. The only additional step I would do is set a short timer after the TabIndexChanged event to track that a new tab has been selected and ignore any double-clicks that happen outside the timer. This will prevent double-clicking on the selected tab. ","pontos":3},{"corpo":"Yes, it just can't come from the site that has the app_offline.htm file. The image would have to be hosted elsewhere. ","pontos":13},{"corpo":"Throwing exceptions is the best way to send information about a certain error up and out of the app. A number doesn't tell you as much as: Exception at thread 'main': FileNotFoundException \"The file 'foo' doesn't exist\" (or something close to that) ","pontos":1},{"corpo":"I don't think a complete system restore would be a good plan. Two reasons that quickly come to mind: Wasted disk space Unintended consequences from a rollback ","pontos":-1},{"corpo":"You will run the risk of having incorrect data if you do not use UTC to transmit dates... If you change time zones on the device... you're dates will be even further off. You may want to use UTC and then calculate time in each timezone. ","pontos":0},{"corpo":"We've had similar problems before, unfortunately I don't remember the exact solution. If your using a \"Web Site\" project (no project file) then start by checking that both your page and your control both set the ClassName property in the first line of your aspx/ascx file and that you specify the full name of the class including the namespace. Example: @Control Language=\"VB\" AutoEventWireup=\"false\" ClassName=\"YourProjectName.YourUserControl\" Inherits=\"YourProjectName.YourUserControl\" CodeFile=\"YourUserControl.ascx.vb\" %> Many times not setting all of these will still work but you will get odd compiler errors and behavior in VS. If you using a Web Site Application project try deleting the designer file manually and then right click on your project and choose \"Convert from Web Application.\" This will should recreate the designer file for you. My only other suggestion would be to recreate the page and/or the user control from scratch. ","pontos":8},{"corpo":"You might also be interested to know why the GMail to HotMail link uses SMTP, just like your Thunderbird client. In other words, since your client can send email via SMTP, and it can use DNS to get the the MX record for hotmail.com, why doesn't it just send it there directly, skipping gmail.com altogether? There are a couple of reasons, some historical and some for security. In the original question, it was assumed that your Thunderbird client logs in with a user name and password. This is often not the case. SMTP doesn't actually require a login to send a mail. And SMTP has no way to tell who's really sending the mail. Thus, spam was born! There are, unfortunately, still many SMTP servers out there that allow anyone and everyone to connect and send mail, trusting blindly that the sender is who they claim to be. These servers are called \"open relays\" and are routinely black-listed by smarter administrators of other mail servers, because of the spam they churn out. Responsible SMTP server admins set up their server to accept mail for delivery only in special cases 1) the mail is coming from \"its own\" network, or 2) the mail is being sent to \"its own\" network, or 3) the user presents credentials that identifies him as a trusted sender. Case #1 is probably what happens when you send mail from work; your machine is on the trusted network, so you can send mail to anyone. A lot of corporate mail servers still don't require authentication, so you can impersonate anyone in your office. Fun! Case #2 is when someone sends you mail. And case #3 is probably what happens with your GMail example. You're not coming from a trusted network, your just out on the Internet with the spammers. But by using a password, you can prove to GMail that you are who you say you are. The historical aspect is that in the old days, the link between gmail and hotmail was likely to be intermittent. By queuing your mail up at a local server, you could wash your hands of it, knowing that when a link was established, the local server could transfer your messages to the remote server, which would hold the message until the recipient's agent picked it up. ","pontos":4},{"corpo":"No, it's not Taboo - in fact, I'd encourage it. The OS manages how much hard drive takes, and I'd put money down on Microsoft spending more money time testing System Restore than you the money time you're putting into testing your setup application. ","pontos":2},{"corpo":"I'm pretty certain that it cannot be done. Pretty much anything else than PDF works, even Flash. (Tested on Safari, Firefox 3, IE 7) Too bad. ","pontos":26},{"corpo":"There probably is a list, this is why we use CSS Resets however. Eric Meyer's Reset Yahoo's Reset ","pontos":10},{"corpo":"For some reason, MouseDoubleClick, as suggested by Jason Z is only firing when clicking on the tabs and clicking on the tab panel does not do anything, so that's exactly what I was looking for. ","pontos":1},{"corpo":" In fact, IIRC, that's actually part of the 'official' spec for parsers. Official does not need to be quoted :) fatal error [Definition:] An error which a conforming XML processor must detect and report to the application. After encountering a fatal error, the processor may continue processing the data to search for further errors and may report such errors to the application. In order to support correction of errors, the processor may make unprocessed data from the document (with intermingled character data and markup) available to the application. Once a fatal error is detected, however, the processor must not continue normal processing (i.e., it must not continue to pass character data and information about the document's logical structure to the application in the normal way). You could use xmllint with the recover option. ","pontos":1},{"corpo":"I use Cygwin, but I have used the Berkley Utilities in the past. They worked well enough, if you are used to DOS and you just want the commands. There are some alternatives listed at TinyApps. Maybe you could also consider running a command line version of Linux in a virtual machine? Colinux is also an option, but it's immature. ","pontos":2},{"corpo":"We use the free version of ISAPI_Rewrite. It uses similar syntax to mod_rewrite, so if you're familiar with that you may have an easier time getting started. There used to be a (syntax-compatible) port of mod_rewrite for IIS, but I can't find it now. ","pontos":0},{"corpo":"A simple test shows Eclipse is correct: public class Test { public static final void main(String[] args) throws Exception { String s = \"This is the original string.\"; /* This is commented out. s = \"This is the end of a comment: */ \"; */ System.out.println(s); } } This fails to compile with: Test.java:5: unclosed string literal s = \"This is the end of a comment: */ \"; ","pontos":0},{"corpo":"@jmein Actually the problem is that the Validator client script's don't work when placed inside of an updatePanel (UpdatePanels refresh using .innerHTML, which adds the script nodes as text nodes, not script nodes, so the browser does not run them). The fix was a patch released by microsoft that fixes this issue. I found it with the help of Google. http://blogs.msdn.com/mattgi/archive/2007/01/23/asp-net-ajax-validators.aspx ","pontos":2},{"corpo":"I would encapsulate the list of allowed IDs as data not code. Then it's source can be changed easily later on. List int allowedIDs = ...; public bool IsAllowed(int userID) { return allowedIDs.Contains(userID); } If using .NET 3.5, you can use instead of thanks to extension methods. (This function shouldn't be static. See this posting: using too much static bad or good ?.) ","pontos":2},{"corpo":" However, if you are using unmanaged resources in those threads, you may end up in a lot of trouble. That would rather depend how you were using them - if these unmanaged resources were properly wrapped then they'd be dealt with by their wrapper finalization regardless of the mechanism used to kill threads which had referenced them. And unmanaged resources are freed up by the OS when an app exits anyway. There is a general feeling that (Windows) applications spend much too much time trying to clean-up on app shutdown - often involving paging-in huge amounts of memory just so that it can be discarded again (or paging-in code which runs around freeing unmangaged objects which the OS would deal with anyway). ","pontos":10},{"corpo":"I don't think the biggest problem is just someone stealing your bandwidth, but what they do with it. It's one thing if someone uses my wireless network to browse the Internet. It's another thing if they use it for torrenting (I find that slows down the network) or any illegal activities (kiddy porn? not on my network you don't). ","pontos":4},{"corpo":"Bruce Schneier is famous for running an open wireless network at home (see here). He does it for two reasons: To be neighborly (you'd let your neighbor borrow a cup of sugar, wouldn't you? Why not a few megabits?) To keep away from the false sense of security that a firewall gives you. In other words, it forces him to make sure his hosts are secure. Personally, I would never run an open wireless network for one reason: accountability. If someone does something illegal on my network, I don't want to be held accountable. ","pontos":12},{"corpo":"Yes you are, your wireless router also doubles as a firewall preventing harmful data from the Internet, by letting one of your virus-infected neighbors in on your wlan you're essentially letting him bypass that. Now, this shouldn't be a problem in an ideal world since you'd have a well-configured system with a firewall but that's certainly not always the case. What about when you have your less security minded friends over? Not to mention the legal hassle you could get yourself into if one of your neighbors or someone sitting with a laptop in a car close enough starts browsing kiddieporn. ","pontos":2},{"corpo":"In Eclipse you can highlight the part of the source code you want to comment out and use the Ctrl+/ to single-line comment every line in the highlighted section - puts a \"//\" at the beginning of the lines. Or if you really want to block-comment the selection use the Ctrl+Shift+/ combination. It will detect the block comments in your selection. However undoing this is harder than single-line comments. ","pontos":2},{"corpo":"If you are talking about the ReportViewer control, it is available. However you need Windows XP, Windows Vista or Windows Server 2003 to install it. It is also written that .NET 3.5 is required, but I'm not sure about this one. I managed to install it with .NET 2.0 on an XP. ","pontos":1},{"corpo":"For most people, the wireless access point is a router that is acting as a hardware firewall to external traffic. If someone's not on your wireless network, the only way they'll get to a service running on your machine is if the router is configured to forward requests. Once a device is behind the router, you're relying on your computer's firewall for security. From a \"paranoid\" layered security standpoint, I'd consider an open wireless network in this scenario to be a reduction in security. I've met a lot of people that leave their networks open on purpose, because they feel it's a kind of community service. I don't subscribe to that theory, but I can understand the logic. They don't see it as their neighbor stealing bandwidth because they feel like they aren't using that bandwidth anyway. ","pontos":1},{"corpo":"I feel it all has to due with population density. My parents own a big plot of land nearest neighbor is .5 mile away. To me it doesn't make sense to lock a wireless router down. But if I lived in a apartment complex that thing will be locked down and not broadcasting it's ID. Now at my house I just don't broadcast my ID and keep it open. The signal doesn't travel further then my property line so I am not to worried about people hijacking it. ","pontos":2},{"corpo":"I would actually disagree with Thomas in the sense that I think bandwidth is the biggest problem, as it's unlikely there are many dodgy people in your area who just so happen to connect to your network to misbehave. It's more likely I think that you'll have chancers, or even users who don't fully understand wireless, connecting and slowing down your connection. I've experienced horribly laggy connections due to bandwidth stealing, a lot of the problem is with ADSL - it just can't handle big upstream traffic; if a user is using torrents and not restricting the upstream bandwidth it can basically stall everything. ","pontos":2},{"corpo":"@kronoz: I guess it depends on where you live. Only two houses are within reach of my wireless network, excluding my own. So I doubt that small number of people can affect my bandwidth. But if you live in a major metro area, and many people are able to see and get on the network, yeah, it might become a problem. ","pontos":0},{"corpo":" Is it \"taboo\" to programatically create system restore points? No. That's why the API is there; so that you can have pseudo-atomic updates of the system. ","pontos":3},{"corpo":"I suspect you are running the original release (RTM) of .NET 2.0. Until early 2007 validator controls were not compatible with UpdatePanels. This was resolved with the SP1 of the .NET Framework. The source of the problem is that UpdatePanel can detect markup changes in your page, but it has no way to track scripts correctly. Validators rely heavily on scripts. During a partial postback, the scripts are either blown away, not updated, or not run when they are meant to. In early betas, MS had the UpdatePanel try to guess what scripts needed to be re-rendered or run. It didn't work very well, and they had to take it out. To get around the immediate problem, Microsoft released a patched version of the validator classes in a new DLL called Validators.DLL, and gave instructions on how to tell ASP.NET to use those classes instead of the real ones. If you Google for that DLL name, you should find more information. See also This blog post. This was a stop-gag measure and you should not use it avoid it if possible. The real solution to the problem came shortly after, in .NET 2.0 SP1. Microsoft introduced a new mechanism to register scripts in SP1, and changed the real validator classes to use that mechanism instead of the older one. Let me give you some details on the changes: Traditionally, you were supposed to register scripts via Page methods such as Page.RegisterStartupScript() and Page.RegisterClientScriptBlock(). The problem is that these methods were not designed for extensibility and UpdatePanel had no way to monitor those calls. In SP1 there is a new property object on the page called Page.ClientScripts. This object has methods to register scripts that are equivalent (and in some ways better) to the original ones. Also, UpdatePanel can monitor these calls, so that it rerenders or calls the methods when appropriate. The older RegisterStartupScript(), etc. methods have been deprecated. They still work, but not inside an UpdatePanel. There is no reason (other than politics, I suppose) to not update your installations to .NET 2.0 SP1. Service Packs carry important fixes. Good luck. ","pontos":20},{"corpo":"I can't answer the main question, but do keep in mind that Windows, by default, is always sharing the roots of your drives. Try: \\\\yourmachine\\c$ (And then try not to freak out.) ","pontos":0},{"corpo":" Personally, I would never run an open wireless network for one reason: accountability. If someone does something illegal on my network, I don't want to be held accountable. The flip side of this is deniability. If the government or RIAA come knocking on your door about something done from your IP address you can always point to your insecure wireless connection and blame someone else. ","pontos":1},{"corpo":"I agree with the \"throw an Exception\" crowd. One reason is that calling System.exit makes your code difficult to use if you want other code to be able to use it. For example, if you find out that your class would be useful from a web app, or some kind of message consuming app, it would be nice to allow those containers the opportunity to deal with the failure somehow. A container may want to retry the operation, decide to log and ignore the problem, send an email to an administrator, etc. An exception to this would be your main() method; this could trap the Exception, and call System.exit() with some value that can be recognized by the calling process or shell script. ","pontos":5},{"corpo":"It is so easy to lock a wireless router down now, that I think a better question is why not lock it down? The only reason I can think of is if you had a yard large enough so that your neighbors can't get a signal and you frequently have visitors bringing devices into your home (since setting them up can be a chore). Note that I'm saying both of those things would need to be true for me to leave one open. ","pontos":0},{"corpo":" Personally, I would never run an open wireless network for one reason: accountability. If someone does something illegal on my network, I don't want to be held accountable. The flip side of this is deniability. If the government or RIAA come knocking on your door about something done from your IP address you can always point to your insecure wireless connection and blame someone else. I would argue that anyone who is running a network is responsible for the actions of all people who use it. If you aren't controlling use, then you are failing as a network administrator. But then again, I'm not a lawyer, so... ","pontos":0},{"corpo":"If this is a home network with no wifi or secured wifi, it's probably not an issue. Your isp will almost certainly prevent anyone from trying anything via the larger web. If you have open wifi, then there's a little more cause for concern. If it's properly secured so that some authentication is required, you're probably okay. I mean, a determined hacker could probably break in, but you're not likely to find a determined hacker in wi-fi range. But the risk (if small) is there. You will want to make sure the administrative shares (the \\\\yourmachine\\c$ or \\\\yourmachine\\admin$ mentioned earlier) are disabled if you have open wifi. No sense making it too easy. ","pontos":1},{"corpo":"Using regions (or otherwise folding code) should have nothing to do with code smells (or hiding them) or any other idea of hiding code you don't want people to \"easily\" see. Regions and code folding is really all about providing a way to easily group sections of code that can be collapsed/folded/hidden to minimize the amount of extraneous \"noise\" around what you are currently working on. If you set things up correctly (meaning actually name your regions something useful, like the name of the method contained) then you can collapse everything except for the function you are currently editing and still maintain some level of context without having to actually see the other code lines. There probably should be some best practice type guidelines around these ideas, but I use regions extensively to provide a standard structure to my code files (I group events, class-wide fields, private properties/methods, public properties/methods). Each method or property also has a region, where the region name is the method/property name. If I have a bunch of overloaded methods, the region name is the full signature and then that entire group is wrapped in a region that is just the function name. ","pontos":0},{"corpo":" @Jonathan Holland: What is wrong with using Validators.dll? Since they replace the original classes, you are quietly bypassing any bug and security fixes, enhancements, etc. that Microsoft might release in the future (or might have already released). Unless you look carefully at the web.config, you might never notice that you are skipping patches. Of course, you have to evaluate each situation. If you are absolutely stuck using .NET 2.0 RTM, then Validators.dll is better than nothing. ","pontos":3},{"corpo":"Easy: Burn the haystack! Afterward, only the needle will remain. Also, you could try magnets. A harder question: How do you find one particular needle in a pool of needles? Answer: thread each one and attach the other end of each strand of thread to a sorted index (i.e. pointers) ","pontos":2},{"corpo":"To the people concerned about \"boxing\" in jsight's answer: there is none. is used here, and no unboxing to is ever performed. Whether you use or depends on how you want to handle possible nulls. Do you want to throw an exception (probably), or have \"null\" Strings in your list (maybe). If the former, do you want to throw a or some other type? Also, one small flaw in jsight's response: is an interface, you can't use the new operator on it. I would probably use a in this case, especially since we know up front how long the list is likely to be. ","pontos":3},{"corpo":"It could be a combination of cookies, and ip address logging. Edit: I have just checked my bank and cleared the cookies. Now I have to re-enter all of my info. ","pontos":1},{"corpo":"Unfortunately, there's no way to disconnect one object from the entity manager in the current JPA implementation, AFAIR. EntityManager.clear() will disconnect all the JPA objects, so that might not be an appropriate solution in all the cases, if you have other objects you do plan to keep connected. So your best bet would be to clone the objects and pass the clones to the code that changes the objects. Since primitive and immutable object fields are taken care of by the default cloning mechanism in a proper way, you won't have to write a lot of plumbing code (apart from deep cloning any aggregated structures you might have). ","pontos":15},{"corpo":"I think it depends on the bank. My bank does use a cookie since I loose it when I wipe cookies. ","pontos":1},{"corpo":"It is possible for flash files to store a small amount of data on your computer. It's also possible that the bank uses that approach to \"remember\" your computer, but it's risky to rely on users having (and not having disabled) flash. ","pontos":1},{"corpo":"My bank's site makes me re-authenticate every time a new version of Firefox is out, so there's definitely a user-agent string component in some. ","pontos":1},{"corpo":"EDIT: Sorry, I've misinterpreted your post. If you're looking for a regex, then here is one: content = Regex.Replace(content, \"'([^']*)\\n([^']*)'\", \"'\\1TOKEN\\2'\"); There might be edge cases and that two problems but I think it should be ok most of the time. What the Regex does is that it first finds any pair of single quotes that has \\n between it and replace that \\n with TOKEN preserving any text in-between. But still, I'd go state machine like what @bryansh explained below. ","pontos":0},{"corpo":"What if you got the whole file into a variable then split that based on non-quoted newlines? ","pontos":1},{"corpo":"This doesn't strictly answer your question, but you can avoid the problem by configuring Emacs to use a specific directory to keep the backup files in. There are different implementations for Emacs or XEmacs. In GNU Emacs (defvar user-temporary-file-directory (concat temporary-file-directory user-login-name \"/\")) (make-directory user-temporary-file-directory t) (setq backup-by-copying t) (setq backup-directory-alist `((\".\" . ,user-temporary-file-directory) (,tramp-file-name-regexp nil))) (setq auto-save-list-file-prefix (concat user-temporary-file-directory \".auto-saves-\")) (setq auto-save-file-name-transforms `((\".*\" ,user-temporary-file-directory t))) In XEmacs (require 'auto-save) (require 'backup-dir) (defvar user-temporary-file-directory (concat (temp-directory) \"/\" (user-login-name))) (make-directory user-temporary-file-directory t) (setq backup-by-copying t) (setq auto-save-directory user-temporary-file-directory) (setq auto-save-list-file-prefix (concat user-temporary-file-directory \".auto-saves-\")) (setq bkup-backup-directory-info `((t ,user-temporary-file-directory full-path))) You can also remove them all with a simple find command find . -name *~ -delete Note that the asterisk and tilde are in double quotes to stop the shell expanding them. By the way, these aren't strictly temporary files. They are a backup of the previous version of the file, so you can manually \"undo\" your last edit at any time in the future. ","pontos":4},{"corpo":"For desktop apps, get the colors from the OS. I, personally, want all of my apps to look and feel the same as my OS. For web apps, I'm not really sure. ","pontos":18},{"corpo":"What should happen in the case of overflow? If you want it to just get to the bottom of the window, use absolute positioning: div { position:absolute; top:300px; bottom:0px; left:30px; right:30px; } This will put the div 30 px in from each side, 300 px from the top of the screen, and flush with the bottom. Add an \"overflow:auto;\" to handle cases where the content is larger than the div. Edit: @Whoever marked this down, an explanation would be nice... Is something wrong with the answer? ","pontos":8},{"corpo":"You can create a small sunction/script to it, like: #!/bin/bash olddir=\"/tmp/old\" newdir=\"/tmp/new\" pushd $newdir for files in $(find . -name \\*.c) do diff $olddir/$file $newdir/$file done popd This is only one way to script this. The simple way. But I think you got the idea. Other suggestion is configuring in emacs a backup dir, so your backup files go always to the same place, outside your work dir! ","pontos":0},{"corpo":"I'd recommend running your uploaded files through antivirus software such as ClamAV. I don't know about scrubbing files to remove viruses, but this will at least allow you to detect and delete infected files before you view them. ","pontos":4},{"corpo":"OK, I found the issue, and it was from a part of the code unrelated to the part of the code I was asking about. The data was being passed as a string, I was converting it to a byte array (this was a test rig so I was trying to simulate the byte array that I get in the main app), then converting that to a MemoryStream, then making an Image from that. What I failed to realize was that the string was Base64 encoded. Calling caused it to turn into a byte array which wouldn't kill the method. So basically it boiled down to a stupid mistake on my part. But hey, the code above is still useful and this page will probably serve as a Google result as to how to avoid this mistake to someone else. Also, I found an easy way to construct a Multi-Page TIFF from my byte arrays here. ","pontos":2},{"corpo":"If you pick a \"theme\" color for your app, you can use Kuler to help flesh out the palette. Related post: Web 2.0 Color Combinations I know I've seen more, but can't find them :) ","pontos":0},{"corpo":"I tend to use alot of grays, along with black and white, keep things simple and avoid any kind of annoying, bright colors. Seems to me like that's what the SO guys did. ","pontos":0},{"corpo":"Since this isn't a true CSV file, does it have any sort of schema? From your example, it looks like you have: int, int, int, int, string , bool, bool, int With that making up your record / object. Assuming that your data is well formed (I don't know enough about your source to know how valid this assumption is); you could: Read your line. Use a state machine to parse your data. If your line ends, and you're parsing a string, read the next line..and keep parsing. I'd avoid using a regex if possible. ","pontos":3},{"corpo":"With a antivirus software like clamAv, does it scan the internals of a byte file like pdf? I ask because the place I previously worked had really strict requirements of not sending Exes through email, and our way of bypassing it was to change the extension to .pdf. The email scanner ignored it, because it new it was supposed to be a byte (non-text) file. ","pontos":0},{"corpo":"No, public inheritance only. ","pontos":1},{"corpo":"Probably using the event, and either from it or use on the Event object. Note that is non standard, don't rely on it for production sites, because it will not be there forever. ","pontos":10},{"corpo":"This isn't a full answer for you, but on the left join piece you can use the DefaultIfEmpty operator like so: var collection = from u in db.Universe join history in db.History on u.id = history.id into temp from h in temp.DefaultIfEmpty() where h.dateCol DateTime.Now.Date.AddDays(-1) select u.id, u.name, h.dateCol ?? '1900-01-01' I haven't had the need to do any groupby commands yet, so I left that out as to not send you down the wrong path. Two other quick things to note. I have been unable to actually join on two parameters although as above there are ways to get around it. Also, the ?? operator works really well in place of the isnull in SQL. ","pontos":0},{"corpo":" @17 of 26 I used to have a solution like this - I found that it ran into weird issues with ie 6.0 sometimes being off by a few pixels, which really made the layout look odd. Yeah, in my solution I just wound up shrinking the height by an arbitrary number of pixels for IE. I could not find any other way to dynamically size a div though. A lot of my layout uses tables since they handle dynamically sized content automatically. Cross-browser web design just plain sucks :P. ","pontos":0},{"corpo":"We use WZC on XP and Native WiFi on Vista, but here's the code which we use on Vista, FWIW. Profile creation: // open a handle to the service if ((dwError = WlanOpenHandle( WLAN_API_VERSION, NULL, // reserved dwServiceVersion, hClient )) != ERROR_SUCCESS) { hClient = NULL; } return dwError; dwError=WlanSetProfile(hClient, guid, 0, profile, NULL, TRUE, NULL, reason_code); Make a connection: WLAN_CONNECTION_PARAMETERS conn; conn.wlanConnectionMode=wlan_connection_mode_profile; conn.strProfile=name; conn.pDot11Ssid=NULL; conn.pDesiredBssidList=NULL; conn.dot11BssType=dot11_BSS_type_independent; conn.dwFlags=NULL; dwError = WlanConnect(hClient, guid, conn, NULL); Check for connection: BOOL ret=FALSE; DWORD dwError; DWORD size; void *p=NULL; WLAN_INTERFACE_STATE *ps; dwError = WlanQueryInterface(hClient, guid, wlan_intf_opcode_interface_state, NULL, size, p, NULL); ps=(WLAN_INTERFACE_STATE *)p; if(dwError!=0) ret=FALSE; else if(*ps==wlan_interface_state_connected) ret=TRUE; if(p!=NULL) WlanFreeMemory(p); return ret; To keep connected to the network, just spawn a thread then keep checking for a connection, then re-connecting if need be. EDIT: Man this markup stuff is lame. Takes me like 3 edits to get the farking thing right. ","pontos":1},{"corpo":"No it doesn't. What would the benefit be of allowing this type of restriction? ","pontos":-1},{"corpo":"Actually, pre-build and post-build events seem to be solely a place to add batch-file type commands. This would not help me to set up standard build directories for our projects, unfortunately. And having these events create batch files seems like a very 1980's approach for a modern language like C#, IMO. After digging some more, and experimenting, I have found that you can add an Import directive into your .csproj file. When you do this, the IDE pops up a warning dialog that there is an unsafe entry point in your project - but you can ignore this, and you can make it not appear at all by editing a registry entry, evidently. So this would give me a way to get the variables containing the directory paths I need into the .csproj file. Now to get the Output Path to refer to it - unfortunately when you add a string like \"$(MySpecialPath)/Debug\" to the Output Path field, and save the project, the $ and () chars are converted to hex, and your file get's put in a Debug directory under a directory named \"$(MySpecialPath)\". Arrgghh. If you edit the .csproj file in a text editor, you can set this correctly however, and it seems to work as long as the Import tag appears before the PropertyGroup containing the Output Path. So I think the solution for me will be to create a standard OurTeam.targets MsBuild file in a standard location, add an installer for changing the registry so it doesn't flag warnings, and then create custom project templates that Import this file, and also set the Output Path to use the properties defined in the OurTeam.targets file. Sadly, this is more work and a less elegant solution than the property sheet inheritance mechanism in C++. ","pontos":0},{"corpo":"I fiddled around with the ScriptManager suggestions - which I reckon I would have eventually got working but it seems to me that the Timer idea is easier to implement and not really(!) that much of a hack?! Here's how I got my panel updated after the initial page render was complete... default.aspx %@ Page Language=\"C#\" AutoEventWireup=\"true\" CodeBehind=\"Default.aspx.cs\" Inherits=\"AJAXPostLoadCall._Default\" % !DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\" html xmlns=\"http://www.w3.org/1999/xhtml\" head runat=\"server\" title Untitled Page /title /head body form id=\"form1\" runat=\"server\" h2 And now for a magic trick... /h2 asp:ScriptManager ID=\"ScriptManager1\" runat=\"server\" EnablePartialRendering=\"True\" /asp:ScriptManager div asp:UpdatePanel ID=\"UpdatePanel1\" runat=\"server\" ContentTemplate asp:Timer ID=\"Timer1\" runat=\"server\" Interval=\"2000\" ontick=\"Timer1_Tick\" / asp:Label ID=\"Label1\" runat=\"server\" Something magic is about to happen... /asp:Label /ContentTemplate /asp:UpdatePanel /div /form /body /html and the code behind default.aspx.cs reads using System; using System.Collections; using System.Configuration; using System.Data; using System.Linq; using System.Web; using System.Web.Security; using System.Web.UI; using System.Web.UI.HtmlControls; using System.Web.UI.WebControls; using System.Web.UI.WebControls.WebParts; using System.Xml.Linq; namespace AJAXPostLoadCall { public partial class _Default : System.Web.UI.Page { protected void Page_Load(object sender, EventArgs e) { } public void DoMagic() { Label1.Text = \"Abracadabra\"; } protected void Timer1_Tick(object sender, EventArgs e) { // Do the magic, then disable the timer DoMagic(); Timer1.Enabled = false; } } } So, the page loads up and the Timer (contained within the UpdatePanel) fires 2 secs after the page has loaded up (I think - I'm not sure when the Timer actually starts?). The label text is rewritten and then the Timer is disabled to stop any more updates. Simple enough - but can you purists out there tell me if this is a Horrible Hack? ","pontos":6},{"corpo":"Unless I've misunderstood your question I don't think you need to roll your own, the TextInfo class can do it for you. using System.Globalization; CultureInfo.InvariantCulture.TextInfo.ToTitleCase(\"GeOrGE bUrdEll\") Will return \"George Burdell. And you can use your own culture if there's some special rules involved. Update: Michael (in a comment to this answer) pointed out that this will not work if the input is all caps since the method will assume that it is an acronym. The naive workaround for this is to .ToLower() the text before submitting it to ToTitleCase. ","pontos":15},{"corpo":"@bdukes: Keep in mind that you aren't truly hiding the member. E.g.: class Base { public void F() {} } class Derived: Base { new private void F() {} } Base o = new Derived(); o.F(); // works EDIT: But this accomplishes the same as private inheritance in C++, which is what the questioner wanted :) ","pontos":3},{"corpo":"No easy way comes to mind without parsing syscomments to see what it's querying from where. If you can edit the SP to select XML, you can append XML_INFO to the query to get the schema back. ","pontos":0},{"corpo":"I use svnsync, which sets up a remote server as a mirror/slave. We had a server go down two weeks ago, and I was able to switch the slave into primary position quite easily (only had to reset the UUID on the slave repository to the original). Another benefit is that the sync can be run by a middle-man, rather than as a task on either server. I've had a client to two VPNs sync a repository between them. ","pontos":17},{"corpo":"The statement executes one or the other of the controlled statements (both in your example). No matter what you use for , that snippet will either print \"Hello\", or \"World\", but never both. Edit: Okay, so it's a trick question and you can put whatever you like in the condition (including a call to an entire other function that does anything you want). But that's hardly interesting. I can't believe I got downmodded for giving a correct answer. ","pontos":5},{"corpo":"#define CONDITION (0) if (0) {} else or some such. If you see such a question on an interview, run away as fast as you can! The team that asks such questions is bound to be unhealthy. Edit - I forgot to clarify - this relies on \"else\" being matched with closest open \"if\", and on the fact that it's written as \"if CONDITION\" rather than if (CONDITION) - parenthesis would make the puzzle unsolvable. ","pontos":6},{"corpo":" Faster/Slower? It will probably be a little faster. However, you run a greater risk of running into deadlocks, losing uncommitted changes should something catastrophic happen (cleaning lady unplugs the server), FUD, Fire, Brimstone, etc. Why would it help? Obviously fewer commit operations, which in turn means fewer disk writes, etc. DBA's and straight answers? If it was easy, you won't need one. ","pontos":0},{"corpo":"Actually, you can override the paint event. And the idea is that you offload long-running operations to a separate thread. That's no different from any other event-driven framework, really. Anything that relies on a handling a Paint event is going to be susceptible to that. Also, there's no system that lets you determine when the paint event is raised. That kind of event is generally raised by the window manager layer, which is outside of the application (or even the framework). You can handle the event yourself and just do no work some of the time, but I wouldn't recommend it. ","pontos":0},{"corpo":" Greg wrote: No matter what you use for condition, that snippet will either print \"Hello\", or \"World\", but never both. Well, this isn't true, but why you would want it to print both, I can't find a use case for. It's defeating the point of having an if statement. The likely \"real\" solution is to not use an if at all. Silly interview questions... :) ","pontos":0},{"corpo":" a bit slow and you can't control the paint event so during processor intensive operations the UI might leave the user staring at a half rendered screen. It's generally a bad idea to do expensive tasks on the UI thread. To keep your UI responsive, these tasks should be performed by a worker thread ","pontos":0},{"corpo":"How about this? public static class Extensions { public static bool In T (this T testValue, params T[] values) { return values.Contains(testValue); } } Usage: Personnel userId = Personnel.JohnDoe; if (userId.In(Personnel.JohnDoe, Personnel.JaneDoe)) { // Do something } I can't claim credit for this, but I also can't remember where I saw it. So, credit to you, anonymous Internet stranger. ","pontos":13},{"corpo":"Agree with Adam. Querying the Sharepoint Database is a big no-no, as Microsoft does not guarantee that the Schema is in any way stable. Only access the database if there is really no other way. As for Sharepoint, usually the Lists.asmx Web Service is what you want to look at first. http://www.c-sharpcorner.com/UploadFile/mahesh/WSSInNet01302007093018AM/WSSInNet.aspx http://geekswithblogs.net/mcassell/archive/2007/08/22/Accessing-Sharepoint-Data-through-Web-Services.aspx ","pontos":3},{"corpo":"Well, think of this from the point of view of the app designer. If you wrote an application, do you want users to be able to inject things into your application (more importantly, would you want to incur the support/revenue headache of clueless users doing this and then blaming you)? Each application's drag and drop infrastructure is written specifically for the application, not to allow you to drop anything you want onto it (potentially causing crashes and all sorts of other nasty behaviour when you drag something onto an app that simply can't handle it). Stuff like this is hard to do for a reason. It is possible to do, but it's a lot of work: you need to acquire the window handle of the thing you want to drop something onto, and then replace that window's message handler with your own. That's fraught with danger, of course, since you either have to replicate all of the existing functionality of that window yourself, or risk the app not working correctly. ","pontos":0},{"corpo":"A commit results in Oracle writing stuff to the disk - i.e. in the redo log file so that whatever the transaction being commited has done can be recoverable in the event of a power failure, etc. Writing in file is slower than writing in memory so a commit will be slower if performed for many operations in a row rather then for a set of coalesced updates. In Oracle 10g there's an asynchronous commit that makes it much faster but less reliable: http://articles.techrepublic.com.com/5100-10878_11-6158695.html PS I know for sure that, in a scenario I've seen in a certain application, changing the number of coalesced updates from 5K to 50K makes it faster by an order of magnitude (10 times faster). ","pontos":3},{"corpo":"I seem to recall either Adobe Dreamweaver or Adobe Golive having a feature to find both orphaned styles and images; can't remember which now. Possibly both, but the features were well-hidden. ","pontos":2},{"corpo":"I looked into more affordable ways to do back in the VS 2003 days, but couldn't find anything. My guess is that you still need VS to do it. @MartinHN You CAN NOT use version older than 2005 or less then Pro for Windows Mobile 5/6 device development. ","pontos":1},{"corpo":"If you're willing to do in-memory diddling while the application is loaded, you could probably finagle that. But if you're looking for an easy way to just inject code you want into another window's message pump, you're not going to find it. The skills required to accomplish something like this are formidable (unless someone has wrapped all of this up in an application/library that I'm unaware of, but I doubt it). It's like clipboard hooking, writ-large: it's frowned upon, there are tons of gotchas, and you're extremely likely to introduce significant instability into your system if you don't really know what you're doing. ","pontos":0},{"corpo":"Probably not. Look into cryptography and Windows' built-in information-hiding mechanisms (DPAPI and storing the keys in an ACL-restricted registry key, for example). That's as good as you're going to get for security you need to keep on the same system as your application. If you are looking for a way to stop someone physically sitting at the machine from getting your information, forget it. If someone is determined, and has unrestricted access to a computer that is not under your control, there is no way to be 100% certain that the data is protected under all circumstances. Someone who is determined will get at it if they want to. ","pontos":8},{"corpo":"I wouldn't think so, as obfuscating (as I understand it at least) will simply mess around with the method names to make it hard (but not impossible) to understand the code. This won't change the data of the actual key (which I'm guessing you have stored in a constant somewhere). If you just want to make it somewhat harder to see, you could run a simple cipher on the plaintext (like ROT-13 or something) so that it's at least not stored in the clear in the code itself. But that's certainly not going to stop any determined hacker from accessing your key. A stronger encryption method won't help because you'd still need to store the key for THAT in the code, and there's nothing protecting that. The only really secure thing I can think of is to keep the key outside of the application somehow, and then restrict access to the key. For instance, you could keep the key in a separate file and then protected the file with an OS-level user-based restriction; that would probably work. You could do the same with a database connection (again, relying on the user-based access restriction to keep non-authorized users out of the database). I've toyed with the idea of doing this for my apps but I've never implemented it. ","pontos":0},{"corpo":"Hm thats really too bad. I suppose there are sometimes reasons why apps don't exist yet. Basically what I'm trying to do is simplify the process of sending image links to people using various apps (mainly web browser text forms, but also anytime I'm editing in a terminal window) by hooking the process of pasting an image in a text context, uploading the image in the background, and pasting a url to where the image was uploaded all with a single action. Edit: I suppose the easier solution to this is to just create a new keyboard combo that is hooked by my app before it gets to any other app. There's no reason in particular that I need to tie it to copy/paste functionality. ","pontos":0},{"corpo":"The page you link to http://msdn.microsoft.com/en-us/library/6x6y6z4d.aspx says what they were for, which was a way of handling nullable bools before nullable value types were introduced. I'd guess nowadays they're good for the same sort of stuff as ArrayList - i.e. absolutely nothing. ","pontos":14},{"corpo":"Reducing the frequency of commits will certainly speed things up, however as you are reading and writing to this table frequently there is the potential for locks. Only you can determine the likelihood of the same data being updated at the same time. If the chance of this is low, commit every 50 rows and monitor the situation. Trial and error I'm afraid :-) ","pontos":1},{"corpo":"Are you using subselects in your queries? From my experience, a SELECT statement with subselects that runs fine on SQL Server 2000 can crawl on SQL Server 2005 (it can be like 10x slower!). Make an experiment - re-write one query to eliminate the subselects and see how its performance changes. ","pontos":1},{"corpo":"It appears from the MSDN article you linked to it was provided to allow for nullable boolean types prior to the Nullable (i.e. int?, bool?, etc.) type being introducted into the language in C#2. Thus you would store an internal value indicating whether the value is true or false or null, i.e. in your example >0 for true, 0 for false and ==0 for null, and then you'd get SQL-style null semantics. You would also have to implement a .IsNull method or property in order that nullity could be checked explicitly. Comparing to SQL, imagine a table Table with 3 rows with value Foo set to true, 3 rows with value Foo set to false and 3 rows with value Foo set to null. SELECT COUNT(*) FROM Table WHERE Foo = TRUE OR Foo = FALSE 6 In order to count all rows you'd have to do the following:- SELECT COUNT(*) FROM Table WHERE Foo = TRUE OR Foo = FALSE OR Foo IS NULL 9 This 'IS NULL' syntax would have equivilent code in your class as .IsNull(). LINQ makes the comparison to C# even clearer:- int totalCount = (from s in MyTypeEnumerable where s || !s select s).Count(); Imagining that MyTypeEnumberable has exactly the same contents of the database, i.e. 3 values equal to true, 3 values equal to false and 3 values equal to null. In this case totalCount would evaluate to 6 in this case. However, if we re-wrote the code as:- int totalCount = (from s in MyTypeEnumerable where s || !s || s.IsNull() select s).Count(); Then totalCount would evaluate to 9. The DBNull example given in the linked MSDN article on the false operator demonstrates a class in the BCL which has this exact behaviour. In effect the conclusion is you shouldn't use this unless you're completely sure you want this type of behaviour, it's better to just use the far simpler nullable syntax!! Update: I just noticed you need to manually override the logic operators !, || and to make this work properly. I believe the false operator feeds into these logical operators, i.e. indicating truth, falsity or 'otherwise'. As noted in another comment !x won't work off the bat; you have to overload !. Weirdness! ","pontos":3},{"corpo":"One key piece of advice I can give is that most LiveCDs use a compressed filesystem called squashfs to cram as much data on the CD as possible. Since you don't need compression, you could run the mksquashfs step (present in most tutorials) with -noDataCompression and -noFragmentCompression to save on decompression time. You may even be able to drop the squashfs approach entirely, but this would require some restructuring. This may actually be slower depending on your CD-ROM read speed vs. CPU speed, but it's worth looking into. This Ubuntu tutorial was effective enough for me to build a LiveCD based on 8.04. It may be useful for getting the feel of how a LiveCD is composed, but I would probably not recommend using an Ubuntu LiveCD. If at all possible, find a minimal LiveCD and build up with only minimal stripping out, rather than stripping down a huge LiveCD like Ubuntu. There are some situations in which the smaller distros are using smaller/faster alternatives rather than just leaving something out. If you want to get seriously hardcore, you could look at Linux From Scratch, and include only what you want, but that's probably more time than you want to spend. ","pontos":2},{"corpo":"@CodeSlave your your questions is answered by @stevechol , if i remove ALL the incremental commits there will be locks. I guess if nothing better comes along I'll follow his advice pick a random number , monitor the load and adjust accordingly. While applying @diciu twaks. PS: the transaction on top of transaction is just accidental, I get the files used for updates by FTP and instead of deleting them immediately I set a cron job to deletes them a week later (if no one using the application has complained) that means if something goes wrong I have a week to catch the errors. ","pontos":0},{"corpo":"Our form spam has been drastically cut after implementing the honeypot captcha method as mentioned previously. I believe we haven't received any since implementing it. ","pontos":1},{"corpo":"Have you tried to hide it through the itemdatabound event onload or do you need it to hide after it loads? ","pontos":0},{"corpo":"I honestly have never seen this message and I work with Visual Studio for at least 8 hours a day. Is this reproducible on other machines? If so is there anything weird or abnormal in your code that could cause this to crash? ","pontos":0},{"corpo":"I agree on log file debugging to narrow it down. I've used \"Entering FunctionName\" \"Leaving FunctionName\" until I can find what method it enters before the crash. Then I add more log messages re-compile and re-release. ","pontos":0},{"corpo":"I think Jeff Atwood talked about this in the Herding Code podcast, when he was questioned about the exact same thing. Listen to it towards the last 15-20 minutes or so. I think in SO, the datacontext is created in the Controller class. Not sure about a lot of details here. But that's what it looked like. ","pontos":0},{"corpo":"Lists are arrays underneath, so the performance hit of adding an item, unless it is at the end, will be very costly. Otherwise they will be basically as fast as an array. ","pontos":2},{"corpo":"@jmein - you've described how to create a modal popup (which is exactly what jqModal does) however you've missed that the content of the modal window is served from another domain. The two domains involved belong to two separate companies so can't be combined in the way you describe. ","pontos":0},{"corpo":"The LinkedList object would take less time to add to and remove from because of the nature of linked lists. When you add an element it does not have to resize an array like a normal list does. Other than that improvement I would suspect that the LinkedList would perform about the same as a normal List. See this on Wikipedia: Linked Lists vs. Arrays ","pontos":2},{"corpo":"I am having trouble understanding your requirements. But Ill state - in my own words as it were - what I understand the situation to be: You have abstract Parameter class, which is subclassed eventually to some concrete classes (eg: ParameterLimitedInt). You have a seperate GUI system which will be passed these parameters in a generic fashion, but the catch is that it needs to present the GUI component specific to the concrete type of the parameter class. The restrictions are that you dont want to do RTTID, and dont want to write code to handle every possible type of concrete parameter. You are open to using the visitor pattern. With those being your requirements, here is how I would handle such a situation: I would implement the visitor pattern where the accept() returns a boolean value. The base Parameter class would implement a virtual accept() function and return false. Concrete implementations of the Parameter class would then contain accept() functions which will call the visitor's visit(). They would return true. The visitor class would make use of a templated visit() function so you would only override for the concrete Parameter types you care to support: class Visitor { public: template class T void visit( const T param ) const { assert( false \"this parameter type not specialised in the visitor\" ); } void visit( const ParameterLimitedInt ) const; // specialised implementations... } Thus if accept() returns false, you know the concrete type for the Parameter has not implemented the visitor pattern yet (in case there is additional logic you would prefer to handle on a case by case basis). If the assert() in the visitor pattern triggers, its because its not visiting a Parameter type which you've implemented a specialisation for. One downside to all of this is that unsupported visits are only caught at runtime. ","pontos":0},{"corpo":"For session cookies it doesn't seem to be supported in Tomcat yet. See the bug report Need to add support for HTTPOnly session cookie parameter. A somewhat involved work-around for now can be found here, which basically boils down to manually patching Tomcat. Can't really find an easy way to do it at this moment at this point I'm affraid. To summarize the work-around, it involves downloading the 5.5 source, and then change the source in the following places: org.apache.catalina.connector.Request.java //this is what needs to be changed //response.addCookieInternal(cookie); //this is whats new response.addCookieInternal(cookie, true); } org.apache.catalina.connectorResponse.addCookieInternal public void addCookieInternal(final Cookie cookie) { addCookieInternal(cookie, false); } public void addCookieInternal(final Cookie cookie, boolean HTTPOnly) { if (isCommitted()) return; final StringBuffer sb = new StringBuffer(); //web application code can receive a IllegalArgumentException //from the appendCookieValue invokation if (SecurityUtil.isPackageProtectionEnabled()) { AccessController.doPrivileged(new PrivilegedAction() { public Object run(){ ServerCookie.appendCookieValue (sb, cookie.getVersion(), cookie.getName(), cookie.getValue(), cookie.getPath(), cookie.getDomain(), cookie.getComment(), cookie.getMaxAge(), cookie.getSecure()); return null; } }); } else { ServerCookie.appendCookieValue (sb, cookie.getVersion(), cookie.getName(), cookie.getValue(), cookie.getPath(), cookie.getDomain(), cookie.getComment(), cookie.getMaxAge(), cookie.getSecure()); } //of course, we really need to modify ServerCookie //but this is the general idea if (HTTPOnly) { sb.append(\"; HttpOnly\"); } //if we reached here, no exception, cookie is valid // the header name is Set-Cookie for both \"old\" and v.1 ( RFC2109 ) // RFC2965 is not supported by browsers and the Servlet spec // asks for 2109. addHeader(\"Set-Cookie\", sb.toString()); cookies.add(cookie); } ","pontos":7},{"corpo":"The .Net List doesn't use a linked list. It is an array, it starts with 4 positions by default and I think it doubles in size as you add things. So performance can vary a bit depending on how you use it. If your using VS 2008 run the profiler before you get too far down this rat hole. When we started actually looking at where we were losing time it didn't take long for use to figure out that debating the finer points of linked lists just really didn't matter. ","pontos":0},{"corpo":"\"and also is there a way of getting LINQ to ignore the issue and simply commit the data regardless?\" You can set the 'Update Check' property on your entity to 'Never' to stop that field being used for optimistic concurrency checking. You can also use: db.SubmitChanges(ConflictMode.ContinueOnConflict) ","pontos":-1},{"corpo":"Perhaps a better way is to use a graphical tool? Or write a script to do the update that redirects the output to a file and does a \"cat svnupdate.log | grep \"^C \"\" at the end to show you any conflicts? With the graphical tools that I use (TortoiseSVN and Netbeans), they make a nasty noise at the end and present you with a merge selection dialog for dealing with them. I don't know of an equivalent with as much power for the command line tools. ","pontos":1},{"corpo":" s = p.stderr.readline() I suspect it's the above line. When you invoke a command directly through ssh, you don't get your full pty (assuming Linux), and thus no stderr to read from. When you log in interactively, stdin, stdout, and stderr are set up for you, and so your script works. ","pontos":3},{"corpo":"What's your goal? Who's your audience? What browser is your intended audience using (beware when mixing Firefox and Silverlight)? ","pontos":0},{"corpo":"There's another nice trick you can use to significantly improve the look of a rendered HTML diff. Although this doesn't fully solve the initial problem, it will make a significant difference in the appearance of your rendered HTML diffs. Side-by-side rendered HTML will make it very difficult for your diff to line up vertically. Vertical alignment is crucial for comparing side-by-side diffs. In order to improve the vertical alignment of a side-by-side diff, you can insert invisible HTML elements in each version of the diff at \"checkpoints\" where the diff should be vertically aligned. Then you can use a bit of client-side JavaScript to add vertical spacing around checkpoint until the sides line up vertically. Explained in a little more detail: If you want to use this technique, run your diff algorithm and insert a bunch of s or tiny s wherever your side-by-side versions should match up, according to the diff. Then run JavaScript that finds each checkpoint (and its side-by-side neighbor) and adds vertical spacing to the checkpoint that is higher-up (shallower) on the page. Now your rendered HTML diff will be vertically aligned up to that checkpoint, and you can continue repairing vertical alignment down the rest of your side-by-side page. ","pontos":13},{"corpo":"Unfortunately, I don't have an answer, but I do have three pointers to projects that you could look at. The first is the Lively Kernel by Dan Ingalls (yes, the Dan Ingalls) at Sun Labs. It is an implementation of a Smalltalk Virtual World in JavaScript on top of SVG. More precisely, it is an implementation of the Morphic GUI framework from Squeak Smalltalk in JavaScript using SVG and a port of (parts of) Squeak Smalltalk in JavaScript. Or, if you're not a Smalltalker and the above doesn't make sense to you: it's an Operating System, written in JavaScript with the JavaScript interpreter as the CPU, SVG as the graphics card and the browser as the computer. This is about as extreme as it gets, when it comes to JavaScript and SVG. And it only fully works in Safari 3 and partly in Firefox 3, although there is an experimental port to Internet Explorer as well. The second project is John Resig's Processing.js port of the Processing visualization language to JavaScript. It uses the element instead of SVG precisely because of the problems that you mentioned. This one however, only works in Firefox 3. The third one is Real-Time 3D in JavaScript by Useless Pickles. It uses only JavaScript, DOM and CSS and no SVG or or Flash or whatever. And it is portable to almost any browser, including Internet Explorer 7 and up. Doing 2D should be even easier than this. Between those three projects you should be able to find some inspiration and also to find some people who tried to push the envelope with JavaScript and SVG or JavaScript and Graphics and can tell you what works and what doesn't. Conclusion: doing cross-browser SVG or cross-browser is nigh impossible, but with a little bit of craziness, cross-browser graphics without SVG or is possible. ","pontos":7},{"corpo":"My cdrecord method did support dvd burning, I just looked over the code, and boy did I forget how much time and effort I put into that class. cdrecord has no problem burning just about any type of media you throw at it, but since it is a stand alone application, I had to do a lot of parsing to get useful information. I can dig up the flags and different calls I used if you are interested, but unfortunately I cannot share the source as it was developed for a commercial project. While looking over the code I was also reminded that I switched form cdrecord (cdrtools) to wodim (cdrkit). wodim is a branch of cdrecord made a few years ago by the debian team because cdrecord dropped the GPL license. Like I said before this was released as part of a commercial application, our interpretation of the GPL was that you can call external binaries from your program without a problem as long as your program can run without the external binaries (if cdrecord wasn't found we popped up a dialog informing the user that burning capabilities were not available) and we also had to host the source for cdrkit and cygwin and include a copy of the GPL with our distributed program. So basically we would not make \"derivative works\", we would compile the cdrkit code exactly as it was, and then use the produced binaries. As far as StarBurn SDK, I demoed it, but I didn't use it for a shipped product so I can't really give a recommendation or say much more than it does work ","pontos":1},{"corpo":"@jsight: TortoiseSVN is great, but I primarily develop in a *NIX environment, without X. So I'm usually using (restricted to) the command line. In re your script suggestion, that's what I'm working on now - which is why I'm annoyed that I can't just check $?. Right now I'm skipping the \"output to a file\" and using a pipe, but otherwise exactly what you describe. ","pontos":1},{"corpo":"I've done similar things, but I got around it by cloning too. The difference is that I had the cache do the cloning. When you put an object into the cache, the cache will clone the object first and store the cloned version (so you can mutate the original object without poisoning the cache). When you get an object from the cache, the cache returns a clone of the object instead of the stored object (again so that the caller can mutate the object without effecting the cached/canonical object). I think that this is perfectly acceptable as long as the data you're storing/duping is small. ","pontos":1},{"corpo":"How can your guy run the test again when it has failed to see if he has fixed it? I.e. he loses repeatability of tests. While I think there is probably some value in flinging a load of random data at tests, as mentioned in other replies it falls more under the heading of load testing than anything else. It is pretty much a \"testing-by-hope\" practice. I think that, in reality, your guy is simply not thinkng about what he is trying to test, and making up for that lack of thought by hoping randomness will eventually trap some mysterious error. So the argument I would use with him is that he is being lazy. Or, to put it another way, if he doesn't take the time to understand what he is trying to test it probably shows he doesn't really understand the code he is writing. ","pontos":0},{"corpo":"I like to repackage exceptions between the \"tiers\" of my application, so for example a DB-specific exception is repackaged inside of another exception which is meaningful in the context of my application (of course, I leave the original exception as a member so I don't clobber the stack trace). That said, I think that a non-unique user name is not an \"exceptional\" enough situation to warrant a throw. I'd use a boolean return argument instead. Without knowing much about your architecture, it's hard for me to say anything more specific or applicable. ","pontos":3},{"corpo":"Online backup is cheap and easy. Why would you not? ","pontos":0},{"corpo":"My co-worker has had 3 blue-screens on his machine since installing it. Not totally convinced this is what did it, but it's the only thing he's changed today. I'm uninstalling it for now (and so is he). ","pontos":0},{"corpo":"Ints are immutable and you can't modify them in place, so you should go with option #2 (because option #1 is impossible without some trickery). ","pontos":0},{"corpo":"Slightly off-topic, but one feature of findbugs that I think is very useful is to be able to annotate the parameters of methods to describe which parameters should not be passed a null value. Using static analysis of your code, findbugs can then point out locations where the method is called with a potentially null value. This has two advantages: The annotation describes your intention for how the method should be called, aiding documentation FindBugs can point to potential problem callers of the method, allowing you to track down potential bugs. Only useful when you have access to the code that calls your methods ... but that is usually the case. ","pontos":0},{"corpo":"I'd warn again doing a double for loop to pull out each datacell's data, and writing out individually to an excel cell. Instead, use a 2D object array, and loop through your datagrid saving all your data there. You'll then be able to set an excel range equal to that 2D object array. This will be several orders of magnitude faster than writing excel cell by cell. Some reports that I've been working on that used to take two hours simply to export have been cut down to under a minute. ","pontos":1},{"corpo":"This kind of session tracking is very likely to be done using a combination of a cookie with a unique id identifying your current session, and the website pairing that id with the last IP address you used to connect to their server. That way, if the IP changes, but you still have the cookie, you're identified and logged in, and if the cookie is absent but you have the same IP address as the one save on the server, then they set your cookie to the id paired with that IP. Really, it's that second possibility that is tricky to get right. If the cookie is missing, and you only have your IP address to show for identification, it's quite unsafe to log someone in just based of that. So servers probably store additional info about you, LSO seem like a good choice, geo IP too, but User Agent, not so much because they don't really say anything about you, every body using the same version of the same browser as you has the same. As an aside, it has been mentioned above that it could work with MAC adresses. I strongly disagree! Your MAC address never reaches your bank's server, as they are only used to identify sides of an Ethernet connection, and to connect to your bank you make a bunch of Ethernet connections: from your computer to your home router, or your ISP, then from there to the first internet router you go through, then to the second, etc... and each time a new connection is made, each machine on each side provide their very own MAC addresses. So your MAC address can only be known to the machines directly connected to you through a switch or hub, because anything else that routes your packets will replace your MAC with their own. Only the IP address stays the same all the way. If MAC addresses did go all the way, it would be a privacy nightmare, as all MAC addresses are unique to a single device, hence to a single person. This is a slightly simplified explanation because it's not the point of the question, but it seemed useful to clear what looked like a misunderstanding. ","pontos":5},{"corpo":"I find that long mocking procedure to be too much friction. The best way we have found - using ASP.NET MVC on a real project - is to abstract the HttpContext to an IWebContext interface that simply passes through. Then you can mock the IWebContext with no pain. Here is an example ","pontos":1},{"corpo":"I don't think this is a concern. Yes, the mythical \"somebody\" can replace the implementation of MD5 with something insecure. But in order to do that, the mythical somebody must actually be able to get his code into the Ruby process. And if he can do that, then he presumably could also inject his code into a Java process and e.g. rewrite the bytecode for the MD5 operation. Or just intercept the keypresses and not actually bother with fiddling with the cryptography code at all. One of the typical concerns is: I'm writing this awesome library, which is supposed to be used like so: require 'awesome' # Do something awesome. But what if someone uses it like so: require 'evil_cracker_lib_from_russian_pr0n_site' # Overrides crypto functions and sends all data to mafia require 'awesome' # Now everything is insecure because awesome lib uses # cracker lib instead of builtin And the simple solution is: don't do that! Educate your users that they shouldn't run untrusted code they downloaded from obscure sources in their security critical applications. And if they do, they probably deserve it. To come back to your Java example: it's true that in Java you can make your crypto code and and what not. However, someone can still replace your crypto implementation! In fact, someone actually did: many open-source Java implementations use OpenSSL to implement their cryptographic routines. And, as you probably know, Debian shipped with a broken, insecure version of OpenSSL for years. So, all Java programs running on Debian for the past couple of years actually did run with insecure crypto! ","pontos":9},{"corpo":"This is sort of a silly question, but I prefer Rhino Mocks as it represents a more complete understanding of mocks vs. stubs. Look deep into TypeMock before committing to the price. Also, there is no recommended mocking framework for ASP.NET MVC. Finally - I'd suggest you stick to one mocking framework in your project (and even in your team) - the differences, while not huge, can lead to confusion that is unwarranted on such a \"polishing-the-rock\" decision. By that I mean the decision should not be a long one, just pick what works and get on with creating value. ","pontos":2},{"corpo":"Whoa there! There's a potentially serious problem with this code, because it ignores the character encoding specified in the (which is UTF-8 by default). When you call the platform default encoding is used to encode Unicode characters to bytes. So, the parser may think it's getting UTF-8 data when in fact it's getting EBCDIC or something not pretty! Instead, use the parse method that takes an InputSource, which can be constructed with a Reader, like this: import java.io.StringReader; import org.xml.sax.InputSource;  return builder.parse(new InputSource(new StringReader(xml))); It may not seem like a big deal, but ignorance of character encoding issues leads to insidious code rot akin to y2k. ","pontos":107},{"corpo":"It's just a cost of doing business. Yes, caching to a database is slower than caching on your webserver. But you've got to store that state information in a centralized location, otherwise one webserver isn't going to know what users are logged into another. Assumption: You're trying to prevent multiple concurrent log-ins by a single user. ","pontos":5},{"corpo":"Something we found out recently: with MySQL running on Win32, you can only use up to 2GB per process. On Win64, the memory is not managed as well and a single MySQL instance will run your memory into the ground. Ours used up all 16GB we have. So regarding how much memory 1 64-bit process can use: the answer is however much the OS allows. ","pontos":0},{"corpo":"You should be able to create your database from scratch into a known state. Why would you be adding bogus data? ","pontos":-1},{"corpo":"This is a Windows Server machine. As for which edition (Datacenter, Enterprise, etc)... Whatever it takes to give my little .Net Process as much memory as it can. ","pontos":0},{"corpo":" Java provides lots of other tools for defensive programming Initially I thought you were talking about normal defensive programming, wherein the idea is to defend the program (or your subset of it, or your single function) from invalid data input. That's a great thing, and I encourage everyone to go read that article. However it seems you are actually talking about \"defending your code from other programmers.\" In my opinion, this is a completely pointless goal, as no matter what you do, a malicious programmer can always run your program under a debugger, or use dll injection or any number of other techniques. If you are merely seeking to protect your code from incompetent co-workers, this is ridiculous. Educate your co-workers, or get better co-workers. At any rate, if such things are of great concern to you, ruby is not the programming language for you. Monkeypatching is in there by design, and to disallow it goes against the whole point of the feature. ","pontos":4},{"corpo":"It depends on how the authentication is done. If you store the last successful login datetime (whatever the backend), so maybe you can change the schema to store a flag \"logged_in\" and that won't involve an extra performance cost. (ok, it's not clean at all) ","pontos":0},{"corpo":"Version numbers embedded in the database are helpful. You have two choices, embedding values into a table (allows versioning multiple items) that can be queried, or having an explictly named object (such as a table or somesuch) you can test for. When you release to production, do you have a rollback plan in the event of unexpected catastrophe? If you do, is it the application of a schema rollback script? Use your rollback script to rollback the database to a previous code version. ","pontos":3},{"corpo":"You can wrap the ShellExecute between ImpersonateLoggedOnUser / RevertToSelf links: ImpersonateLoggedOnUser: http://msdn.microsoft.com/en-us/library/aa378612(VS.85).aspx RevertToSelf: http://msdn.microsoft.com/en-us/library/aa379317.aspx sorry, cannot hyperlink URLs with \"()\" ","pontos":0},{"corpo":"The fact that the L2S designer doesn't support syncing with the database structure is a huge limitation in my mind. However, there is an add-in available that provides some re-sync capabilities: http://www.huagati.com/dbmltools/ Unfortunately, it's no longer free. ","pontos":9},{"corpo":"if you're not going to be using mylyn just uncheck that dependency. I'm not really familiar with Aptana, but in eclipse you can expand whats being installed and uncheck anything you don't need. ","pontos":1},{"corpo":"You can use Reflector to search for uses of the Switch class and its subclasss (BooleanSwitch, TraceSwitch, etc). The various switches are hardcoded by name, so AFAIK there's no master list somewhere. ","pontos":1},{"corpo":"@aku then you should throw System.ArgumentNullException I don't see how throwing a .net framework exception is going to help him :) Otherwise, in a Java way, assuming the null comes from a programming error (ie. should never go outside the testing phase), then leave the system throw it, or if there are side-effects reaching that point, check for null at the beginning and throw either IllegalArgumentException or NullPointerException. If the null could come from an actual exceptional case but you don't want to use a checked exception for that, then you definitely want to go the IllegalArgumentException route at the beginning of the method. ","pontos":0},{"corpo":" Crono wrote: Are Environment variables defined via \"set\" not meant for the current session only? Can I persist them? They are set for the current process, and by default inherited by any process that it creates. They are not persisted to the registry. Their scope can be limited in cmd scripts with \"setlocal\" (and \"endlocal\"). ","pontos":1},{"corpo":"As you suspected, Remote.Disable stops the app from attaching debug info to remote requests. It's defined inside the .NET framework methods that make the SOAP request. The basic situation is that these switches can be defined anywhere in code, you just need to create a new System.Diagnostics.BooleanSwitch with the name given and the config file can control them. This particular one is defined in System.ComponentModel.CompModSwitches.DisableRemoteDebugging: public static BooleanSwitch DisableRemoteDebugging { get { if (disableRemoteDebugging == null) { disableRemoteDebugging = new BooleanSwitch(\"Remote.Disable\", \"Disable remote debugging for web methods.\"); } return disableRemoteDebugging; } } In your case it's probably being called from System.Web.Services.Protocols.RemoteDebugger.IsClientCallOutEnabled(), which is being called by System.Web.Services.Protocols.WebClientProtocol.NotifyClientCallOut which is in turn being called by the Invoke method of System.Web.Services.Protocols.SoapHttpClientProtocol Unfortunately, to my knowledge, short of decompiling the framework seaching for new BooleanSwitch or any of the other inheritors of the System.Diagnostics.Switch class, there's no easy way to know what switches are defined. It seems to be a case of searching msdn/google/stack overflow for the specific case In this case I just used Reflector searched for the Remote.Disable string ","pontos":2},{"corpo":"If your game has a replay system built in, you can submit replays to the server and have the server calculate the score from the replay. This method isn't perfect, you can still cheat by slowing down the game (if it is action-based), or by writing a bot. ","pontos":5},{"corpo":"For a generic implementation of Vistor, I'd suggest the Loki Visitor, part of the Loki library. ","pontos":6},{"corpo":"A database operation at login and logout won't cause a performance problem. If you are using a caching proxy, that will cause a problem: a user will log out, but won't be able to log back in until the logout reaches the cache Your biggest potential problem might be: if the app/box crashes without a chance for the user to log out, the user's state in the database will remain \"logged in\". ","pontos":2},{"corpo":"Why use a at all? From your description a dictionary will work just as well, if not better. The only reason for using a would be if you wanted to list out the contents of the container in key order. It certainly doesn't sound like you want to do that, in which case go for the hash table. insertion and search, no worries about deletion, what could be better? ","pontos":3},{"corpo":"I don't see any code here to register to the mouse listeners. You have to call addMouseListener(this) and addMouseMotionListener(this) on the DisplayArea. ","pontos":3},{"corpo":"Who reads books these days? I have the 1st edition, I forgot to read it. Go to the iPhone Developer Center. Read examples. In case you didn't read any of that, click the pretty picture. ","pontos":3},{"corpo":"It looks like you are doomed. See this document. TL/DR: A data conversion error always causes the whole batch to be aborted - your sql script will not continue to execute no matter what you do. Transactions won't help. You can't check @@ERROR because execution will already have aborted. I would first reexamine why you need a staging database full of varchar(255) columns - can whatever fills that database do the conversion? If not, I guess you'll need to write a program/script to select from the varchar columns, convert, and insert into the prod db. ","pontos":1},{"corpo":"I've seen similar behaviour when setting certain properties of controls in the constructor of the form itself. They seem to revert back to their design-time defaults. I notice you're already overriding the OnLoad method. Have you tried setting AutoSize = false there? Or are you mainly concerned with providing a default value of false? ","pontos":3},{"corpo":"There are already a lot of good answers on what the differences are, so let me give a slightly different perspective and add the why. As was already explained, the main difference is type erasure, i.e. the fact that the Java compiler erases the generic types and they don't end up in the generated bytecode. However, the question is: why would anyone do that? It doesn't make sense! Or does it? Well, what's the alternative? If you don't implement generics in the language, where do you implement them? And the answer is: in the Virtual Machine. Which breaks backwards compatibility. Type erasure, on the other hand, allows you to mix generic clients with non-generic libraries. In other words: code that was compiled on Java 5 can still be deployed to Java 1.4. Microsoft, however, decided to break backwards compatibility for generics. That's why .NET Generics are \"better\" than Java Generics. Of course, Sun aren't idiots or cowards. The reason why they \"chickened out\", was that Java was significantly older and more widespread than .NET when they introduced generics. (They were introduced roughly at the same time in both worlds.) Breaking backwards compatibility would have been a huge pain. Put yet another way: in Java, Generics are a part of the Language (which means they apply only to Java, not to other languages), in .NET they are part of the Virtual Machine (which means they apply to all languages, not just C# and Visual Basic.NET). Compare this with .NET features like LINQ, lambda expressions, local variable type inference, anonymous types and expression trees: these are all language features. That's why there are subtle differences between VB.NET and C#: if those features were part of the VM, they would be the same in all languages. But the CLR hasn't changed: it's still the same in .NET 3.5 SP1 as it was in .NET 2.0. You can compile a C# program that uses LINQ with the .NET 3.5 compiler and still run it on .NET 2.0, provided that you don't use any .NET 3.5 libraries. That would not work with generics and .NET 1.1, but it would work with Java and Java 1.4. ","pontos":18},{"corpo":"You have: TAD = Telephone Answering Device (pretty sure) AUX_IN = analog aux input CD_IN = analog audio input from your CD-ROM drive (oh so ancient) CD_SPDIF = digital, but still ancient So none of those are really what you're looking for. It's possible that they don't actually offer connections for front-mounted headphones and microphone, or it's possible that the magical white connector is what you want. ","pontos":1},{"corpo":"you can use SMO to connect to SQL Server versions 7, 2000, and 2005, but SMO does not support databases set to compatibility levels 60, 65, and 70. for SQL Server 7.0 the compatibility level is 70 Obviously this is conflicting information...I assume if your compatibility level of your DB is 70 you can not connect. To check run: EXEC sp_dbcmptlevel 'databasename' Looking through this link, it seems you might be able to change the compatibility level by running this: EXEC sp_dbcmptlevel 'databasename', 80 Obviously make a back up before changing anything. ","pontos":2},{"corpo":"the million dollar question! first off, don't worry too much about performance now. you will be amazed at how quickly an optimized xml parser will rip through your xml. more importantly, what is your design for the future: as the XML evolves, how will you maintain loose coupling and interoperability? more concretely, you can make the content model of an element more complex but it's harder to extend an attribute. ","pontos":4},{"corpo":"If all else fails, you could just grab (quite literally) the \"legs\" of the jacks on the card. ","pontos":0},{"corpo":"I Found the manual linked on Amazon. The pin descriptions are on there, and Brad had them right. It doesn't look like it has a front panel audio connector, but I didn't look for very long. ","pontos":1},{"corpo":"I know I find OOP useful pretty much solely on a syntactical sugar basis (encapsulation, operator overloading, typechecking). As to the benefits of OOP... I don't know. I don't think it's worse than procedural stuff. On the lighter side, my OOP lecturer said that OOP is important because otherwise the \"code would have too many loops\". Yeah. Sometimes it's depressing that I pay $500 per paper. :( ","pontos":1},{"corpo":"OK, to answer my own question, I was missing Adorners (never came back in any of the searches I did, so it doesn't seem that they're as widely known as they perhaps should be). They seem rather more complex than the WndProc overrides, unfortunately, but I think it should be possible to manhandle them into doing what I want. ","pontos":3},{"corpo":"SqlCommandBuilder.DeriveParameters(command) This statement does what I need it to. Here is a full code sample for the way I solved this problem. Public Sub GetLogEntriesForApplication(ByVal settings As FilterSettings, Optional ByVal RowGovernor As Integer = -1) Dim command As New SqlCommand(\"GetApplicationActions\", New SqlConnection(m_environment.LoggingDatabaseConnectionString)) Dim adapter As New SqlDataAdapter(command) Using command.Connection With command .Connection.Open() .CommandType = CommandType.StoredProcedure SqlCommandBuilder.DeriveParameters(command) With .Parameters If settings.FilterOnLoggingLevel Then If .Contains(\"@loggingLevel\") Then .Item(\"@loggingLevel\").Value = settings.LoggingLevel End If End If If settings.FilterOnApplicationID Then If .Contains(\"@applicationID\") Then .Item(\"@applicationID\").Value = settings.ApplicationID End If End If If settings.FilterOnCreatedDate Then If .Contains(\"@startDate\") Then .Item(\"@startDate\").Value = settings.CreatedDate.Ticks End If End If If settings.FilterOnEndDate Then If .Contains(\"@endDate\") Then .Item(\"@endDate\").Value = settings.EndDate.Ticks End If End If If settings.FilterOnSuccess Then If .Contains(\"@success\") Then .Item(\"@success\").Value = settings.Success End If End If If settings.FilterOnProcess Then If settings.Process -1 Then If .Contains(\"@process\") Then .Item(\"@process\").Value = settings.Process End If End If End If If RowGovernor -1 Then If .Contains(\"@topRows\") Then .Item(\"@topRows\").Value = RowGovernor End If End If End With End With adapter.TableMappings.Clear() adapter.TableMappings.Add(\"Table\", \"ApplicationActions\") adapter.TableMappings.Add(\"Table1\", \"Milestones\") LogEntries.Clear() Milestones.Clear() adapter.Fill(m_logEntryData) End Using End Sub ","pontos":2},{"corpo":".Net Memory Profiler is exactly what you need. It's not free but there's a trial version. Actually I used the trial to find leaks on our last project. One notable feature is: Easily identify memory leaks by collecting and comparing snapshots of .NET memory I think this is what your looking for. ","pontos":3},{"corpo":"I'm not sure. You could always create a new file and copy the latest revision into that, wiping out prior revision history. ","pontos":-3},{"corpo":"Maybe you should change your production password to avoid the svn problem altogether. ","pontos":2},{"corpo":"link to subversion FAQ entry on this ","pontos":11},{"corpo":"It isn't pretty: How do I completely remove a file from the repository's history? ","pontos":7},{"corpo":"In earlier versions of Sql, you could use either an extended stored proc or xp_cmdshell to shell out and call a webservice. Not that either of these sound like a decent architecture - but sometimes you have to do crazy shit. ","pontos":3},{"corpo":"A word of caution - don't attempt to match dotted files (like .htaccess) with .* - this inconveniently also matches .., and would result in copying all the files on the path to the root directory. I did this once (with rm, no less!) and I had to rebuild the server because I'd messed with /var. @jwmittag: I just did a test on Ubuntu and .* matches when I use cp. Here's an example: root@krash:/# mkdir a root@krash:/# mkdir b root@krash:/# mkdir a/c root@krash:/# touch a/d root@krash:/# touch a/c/e root@krash:/# cp -r a/c/.* b cp: will not create hard link `b/c' to directory `b/.' root@krash:/# ls b d e If .* did not match .., then d shouldn't be in b. ","pontos":3},{"corpo":"Some background info: the wildcard does not match so-called \"dot-files\" (i.e. files whose name begins with a dot). Some shells allow you to set an option, so that it will match dot-files, however, doing that is asking for a lot of pain: now will also match (the current directory) and (the parent directory), which is usually not what is intended and can be quite surprising! ( deleting the parent directory is probably not the best way to start a day ...) ","pontos":4},{"corpo":"That seemed to work. So what I did was: Copy the file to another folder. Do a TortoiseSVN delete from the current folder followed by a commit. Copy the file back in to the folder. Add the file using TortoiseSVN and commit again. I can't seem to find any revision history now - however, it could just be that I'm not looking in the right place. So a modified question would now be, how can I find the revision history of the file that was deleted and then resubmitted to SVN? (BTW I apologize for not asking the question more accurately earlier as I never mentioned that one of the options was to obliterate all revision history as it hadn't occurred to me.) ","pontos":0},{"corpo":"Why don't you just do CreateProcessAsUser specifying the process you want to run? You may also be able to use SHCreateProcessAsUserW. ","pontos":0},{"corpo":"Download PSKill. Write a batch file that calls it for each process you want dead, passing in the name of the process for each. ","pontos":5},{"corpo":"taskkill /f /im \"devenv.exe\" this will forcibly kill the pid with the exe name \"devenv.exe\" equivalent to -9 on the nix'y kill command ","pontos":80},{"corpo":" I can't seem to find any revision history now - however, it could just be that I'm not looking in the right place. You can see it by looking at the folder history, which will give you the revision where the file was still there, and thus you'll be able to recover the confidential file. So it's a bad solution. ","pontos":3},{"corpo":"Well, this doesn't answer the question and is more of an opinion, but... I think that the best scraping strategy (and consequently, to eliminate this problem) is not to analyze an HTML line by line, which is unnatural to HTML, but to analyze it by its natural delimiter: > pairs. There will be two types of course: Tag elements that are immediately closed, e.g., br /> Tag elements that need a separate closing tag, e.g., p > text /p > You can immediately see the advantage of using this strategy in the case of paragraph(p) tags: It will be easier to parse mutiline paragraphs instead of having to track where the closing tag is. ","pontos":1},{"corpo":"I would have said you can't - you have created a new file and thus revision tree in the eyes of SVN. It may be possible to recover the old tree independently (not sure if you managed an actual delete or just SVN Delete) but there is no link between the old revision tree and the new one. ","pontos":1},{"corpo":"Use a source control system  Subversion, Perforce, Git, Mercurial, Bazaar, etc.  so you're never editing code on a shared server. Instead you should be editing a local work area and committing changes to a repository located on the network. Also, convince your company to adapt their policy such that company code is allowed on personal machines if it's on an encrypted volume. Encrypted disk images that you can use for this are trivial to create using Disk Utility, and can use strong cryptography. You can get even more security by not storing your encryption passphrase in your keychain, and instead typing it every time you mount the encrypted volume; this means that even if your local user account is compromised, as long as you don't have the volume mounted, nobody else will be able to mount it. I did this all the time when I was consulting and none of my clients  some of whom had similar rules about company code  ever had a problem with it once I explained how things worked. (I think some of them even started using encrypted disk images even within their offices.) ","pontos":9},{"corpo":"Its a bug in the rendering engine. I run into it all the time. One potential way to solve it is to hide and show the div whenever you change the content (that in turn changes the height): var divCol = document.getElementById('column'); divCol.style.display = 'none'; divCol.style.display = 'block'; Hopefully this happens fast enough that it isn't noticeable :) ","pontos":3},{"corpo":"Ultimately I want my data stored in some reasonable format. If that data started as XML and I want to retrieve it/them using XQuery, without the XML layer, I have to write a lot of code to do the XQuery by myself, and perhaps even worse to know my XML well enough to be able to have a reasonable storage system for it. Conversely, so long as the performance of the system allows, I can forget about that part of the back end, and just worry about my XML document and up (i.e. to the user) level and leave the rest as a black box. It gives me the B-DB storage goodness, but I get to use it from a document-centric perspective. ","pontos":6},{"corpo":"I think the subtle use of uint vs. int will cause confusing with developers unless it was written into developer guidelines for the company. If the length, for example, can't be less than zero then it should be expressed clearly in the business logic so future developers can read the code and know the true intent. Just my 2 cents. ","pontos":2},{"corpo":"For the specific example of Runtime.exec there is a method on the SecurityManager class checkExec(String cmd) that will throw an exception that can be caught to determine if the necessary command can be executed. For more information see the javadoc for Runtime.exec and SecurityManager.checkExec. The more general case requires creating a Permission object representing the task being checked and running SecurityManager's checkPermission method. ","pontos":0},{"corpo":"@Ben Collins I think you're right about stderr being an issue. I am pretty sure it's blocking on the readline() call. In the end, I gave up and decided to use the pxssh module from pexpect to automate my interaction with an ssh session. @Misha M Unfortunately, the semi-colon trick doesn't work here: it blocks on executing my program. ","pontos":0},{"corpo":"What makes you think that it is not possible to remove a revision from Subversion? The solution given to your other question () does exactly that (see the parameters and )! And when the revision is gone, there's obviously no way to get at the revision history, because it was never there in the first place. ","pontos":3},{"corpo":"Why don't you read in a line, and set it to a string, then check the string for tag openings and closings, If a tag spans more then one line add the next line to the string and move the part before the opening brace to your processed string. Then just parse through the entire file doing this. Its not beautiful but it should work. ","pontos":0},{"corpo":"Short answer: you can Long answer: Unfortunately (for you but perhaps not for most folks) , the revision history for a deleted file is still there - it's just a little harder to get at. Here's an example: $ touch one $ svn add one $ svn ci -m \"Added file one\" $ date one $ svn ci -m \"Updated file one\" $ date one $ svn ci -m \"Updated file one again\" $ svn log file:///repos/one ------------------------------------------------------------------------ r3 | andrewr | 2008-08-29 12:27:10 +1000 (Fri, 29 Aug 2008) | 1 line Updated file one again ------------------------------------------------------------------------ r2 | andrewr | 2008-08-29 12:26:50 +1000 (Fri, 29 Aug 2008) | 1 line Updated file one ------------------------------------------------------------------------ r1 | andrewr | 2008-08-29 12:25:07 +1000 (Fri, 29 Aug 2008) | 1 line Added file one ------------------------------------------------------------------------ $ svn delete one $ svn ci -m \"Deleted file one\" $ svn up $ touch one $ svn add one $ svn ci -m \"Adding file one back in\" $ svn log file:///repos/one ------------------------------------------------------------------------ r5 | andrewr | 2008-08-29 12:29:13 +1000 (Fri, 29 Aug 2008) | 1 line add one back ------------------------------------------------------------------------ It looks like it works (the old history is gone), but if you request the file at older revisions you get the history of the deleted file. $ svn log -r 3:1 file:///repos/one ------------------------------------------------------------------------ r3 | andrewr | 2008-08-29 12:27:10 +1000 (Fri, 29 Aug 2008) | 1 line Updated file one again ------------------------------------------------------------------------ r2 | andrewr | 2008-08-29 12:26:50 +1000 (Fri, 29 Aug 2008) | 1 line Updated file one ------------------------------------------------------------------------ r1 | andrewr | 2008-08-29 12:25:07 +1000 (Fri, 29 Aug 2008) | 1 line Added file one ------------------------------------------------------------------------ ","pontos":2},{"corpo":"Sure you can, but this is a terrible idea. As web-service calls may take arbitrary amounts of time, and randomly fail, depending on how many games of counterstrike are being played on your network at the time, you can't tell how long this is going to take. At the bare minimum you're looking at probably half a second by the time it builds the XML, sends the HTTP request to the remote server, which then has to parse the XML and send a response back. Whichever application did the query which caused the web-service to fire is going to have to wait for it to finish. Unless this is something that only happens in the background like a daily scheduled task, your app's performance is going to bomb The web service-invoking code runs inside SQL server, and uses up it's resources. As it's going to take a long time to wait for the HTTP request, you'll end up using up a lot of resources, which will again hurt the performance of your server. ","pontos":19},{"corpo":"Enabling anti-aliasing should solve the display problem. ","pontos":0},{"corpo":"Short answer: you can do no trick. CIFS is really geared towards LAN with a reasonably calm trafic, so you have zero chance to not suffer intermittent lag accessing a share through a VPN. The editor at some point needs to access the file in blocking IO, because it makes no real sense to do otherwise. You could switch editor and use Emacs + TRAMP which is geared to work on remote files. ","pontos":0},{"corpo":" Does CSS have a way? No Does PHP? No - To do that you'd have to get the font metrics for each character, and apply them to all your letters in your string. While you could do this by using a drawing/rendering library like ImageMagick on the server, it wouldn't really work because different browser on different OS's render fonts differently. Even if it did work, you wouldn't want to do it, because it would also take forever to render. Your server would be able to push 1 page per second (if that) instead of several thousand. If you can live without the trailing ..., then you can nicely fake it using tags and css , like this: .line_of_text { height:1.3em; line-height:1.3em; overflow:hidden; } div class=\"line_of_text\" Some long text which will arbitrarily be cut off at whatever word fits best /div ","pontos":2},{"corpo":"\"Educate your co-workers, or get better co-workers\" works great for a small software startup, and it works great for the big guns like Google and Amazon. It's ridiculous to think that every lowly developer contracted in for some small medical charts application in a doctor's office in a minor city. I'm not saying we should build for the lowest common denominator, but we have to be realistic that there are lots of mediocre programmers out there who will pull in any library that gets the job done, paying no attention to security. How could they pay attention to security? Maybe the took an algorithms and data structures class. Maybe they took a compilers class. They almost certainly didn't take an encryption protocols class. They definitely haven't all read Schneier or any of the others out there who practically have to beg and plead with even very good programmers to consider security when building software. I'm not worried about this: require 'evil_cracker_lib_from_russian_pr0n_site' require 'awesome' I'm worried about requiring and , and requiring , and ... eventually two of these conflict in some obscure way that undoes an important security aspect. One important security principle is \"defense in depth\" -- adding these extra layers of security help you from accidentally shooting yourself in the foot. They can't completely prevent it; nothing can. But they help. ","pontos":1},{"corpo":"The link you posted uses mjt, a javascript framework designed for Freebase. The Query they use. mjt.freebase.MqlRead([{ limit: 100, id:qid, /* allow fuzzy matches in the value for more results... */ /* 'q:name': {'value~=': qname, value:null, lang: '/lang/'+qlang}, */ 'q:name': {value: qname, lang: '/lang/'+qlang}, type: '/common/topic', name: [{ value:null, lang:{ id:null, name:{ value:null, lang:'/lang/en', optional:true }, 'q:name':{ value:null, lang:'/lang/'+qlang, optional:true } } }], article: [{id:null, limit:1}], image: [{id:null, limit:1, optional:true}], creator: null, timestamp:null }]) Where: qlang - is your desired language to translate too. qname - is is the location to query. To get the link you want, you'll need the API, and you can convert the above query to a link that will return a JSON object containing the translated string. ","pontos":4},{"corpo":"I'm assuming as a developer, you have some degree of administrative control over your machine. If so, from the command line, run msconfig.exe. You can remove many processes from even starting, thereby eliminating the need to kill them with the above mentioned solutions. ","pontos":5},{"corpo":"Yeah I did a double-take when I heard them say that too. The ribbon control, along with a DatePicker and DataGrid, are being developed out of band over here on CodePlex. I'm not sure why Carl and Scott were suggesting that it was part of the SP1 release. Vincent Sibal posts about DataGrid (which is available already in some form) on his blog. ","pontos":4},{"corpo":"Well my website came with cPanel, which has a nice file manager and code editor. It has syntax highlighting and line numbering. It runs too slow on my computer to really use but I've got a pretty slow computer. :P So to get to the code editor, I'd go to cPanel at http://mysite.com:2082, click File Manager, then select a file and click Code Editor. Edit: I tried using it, and it can highlight PHP and HTML (at the same time), and it also has a \"code completion\" feature... I'm not sure if that's what it's called, but when you write an opening bracket or quote, it writes the closing one after the cursor. The only problems are that the highlighting isn't perfect (it treats escaped quotes as actual quotes) and more importantly, it's not free. ","pontos":2},{"corpo":" VIM script Aqua Data studio $ I use this one all the time. ","pontos":1},{"corpo":"Using regular recursion, each recursive call pushes another entry onto the call stack. When the recursion is completed, the app then has to pop each entry off all the way back down. With tail recursion, the compiler is able to collapse the stack down to one entry, so you save stack space...A large recursive query can actually cause a stack overflow. Basically Tail recursions are able to be optimized into iteration. ","pontos":26},{"corpo":"Tail recursion refers to the recursive call being last in the last logic instruction in the recursive algorithm. Typically in recursion you have a base-case which is what stops the recursive calls and begins popping the call stack. To use a classic example, though more C-ish than Lisp, the factorial function illustrates tail recursion. The recursive call occurs after checking the base-case condition. factorial(x, fac) { if (x == 1) return fac; else return factorial(x-1, x*fac); } Note, the initial call to factorial must be factorial(n, 1) where n is the number for which the factorial is to be calculated. ","pontos":8},{"corpo":"Instead of explaining it with words, here's an example. This is a Scheme version of the factorial function: (define (factorial x) (if (= x 0) 1 (* x (factorial (- x 1))))) Here is a version of factorial that is tail-recursive: (define factorial (letrec ((fact (lambda (x accum) (if (= x 0) accum (fact (- x 1) (* accum x)))))) (lambda (x) (fact x 1)))) You will notice in the first version that the recursive call to fact is fed into the multiplication expression, and therefore the state has to be saved on the stack when making the recursive call. In the tail-recursive version there is no other S-expression waiting for the value of the recursive call, and since there is no further work to do, the state doesn't have to be saved on the stack. As a rule, Scheme tail-recursive functions use constant stack space. ","pontos":43},{"corpo":"did you try... ?? I'm not sure if it should be in the table of the textarea... experiment a bit ","pontos":0},{"corpo":"The RoleProvider sets a cookie to cache role information in a cookie. When the cookie resets during an asynch post back from AJAX, you will get this error. The solution is to either set the cookieTimeout in the roleManager section of your web.config to a very large number of minutes, or set the cacheRolesInCookie=false. This was a known bug in AJAX 1.0 Extensions. I'm not sure if it was fixed in future releases, and I should have mentioned that I was using AJAX 1.0 extensions in VS2008 targeting the 2.0 framework. Happy programming! ","pontos":2},{"corpo":"you can add a text object to the report. And while editing the text of the text object, drag the field you want to show from the object explorer into the text box. Then hit space, then drag the second field in to the same text box. Your two fields will always be one space a part. You could, of course, add more spaces or any other text you want. ","pontos":5},{"corpo":"Apply the width to the , not the . EDIT: @Emmett - the width could just as easily be applied via CSS. td { width: 300px; } produces the desired result. Or, if you're using jQuery, you could add the width through script: $('textarea[width=100%]').parent('td').css('width', '300px'); Point being, there's more than one way to apply a width to a table cell, if development constraints prevent you from applying it directly. ","pontos":4},{"corpo":"@Peter Meyer, Jim Robert I tried different overflow values, to no avail. Experimenting with different values for the wrap attribute and the word-wrap style also wasn't fruitful. EDIT: @dansays, seanb Due to some awkward application-specific constraints, the width can only be applied to the table. @travis Setting style=\"word-break:break-all;\" sort of worked! It still wraps differently in IE7 and FF. I'll accept this answer if nothing better comes up. ","pontos":2},{"corpo":"best thing I could find to make it work, a little hacky: wrap textarea with [div style=\"width:300px;overflow:auto;\"] might want to play around with the overflow value ","pontos":0},{"corpo":"I've created and used my own generic view classes, defining so an instance of the class is callable. I really like it; while Django's generic views allow some customization through keyword arguments, OO generic views (if their behavior is split into a number of separate methods) can have much more fine-grained customization via subclassing, which lets me repeat myself a lot less. (I get tired of rewriting the same create/update view logic anytime I need to tweak something Django's generic views don't quite allow). I've posted some code at djangosnippets.org. The only real downside I see is the proliferation of internal method calls, which may impact performance somewhat. I don't think this is much of a concern; it's rare that Python code execution would be your performance bottleneck in a web app. UPDATE: Django's own generic views are now class-based. UPDATE: FWIW, I've changed my opinion on class-based views since this answer was written. After having used them extensively on a couple of projects, I feel they tend to lead to code that is satisfyingly DRY to write, but very hard to read and maintain later, because functionality is spread across so many different places, and subclasses are so dependent on every implementation detail of the superclasses and mixins. I now feel that TemplateResponse and view decorators is a better answer for decomposing view code. ","pontos":34},{"corpo":" SQL Compact Edition running on the Silverlight CLR I thought the point of silverlight was to provide a small, embedded runtime in the browser. Adding every kitchen sink (like SQL or any kind of ORM library, or parity with WPF) is just going to cause what happened with .net 3.5. Nobody will develop for it because they don't want to burden their end users with a 200 megabyte download My Top Feature Requests for silverlight would be: The smallest download size possible. Last time I looked I think it was at 4.6 meg? This is too big. One click installation with no disruption. Don't make me navigate off to other sites, reboot my browser*, or DARE reboot my computer. Backwards compatibility. I've been to several silverlight sites now which don't work because they require 1.0 and I have 2.0 beta something, but I can't install 1.0 because 2.0 stops it. This is stupid. yeah I realise it might not be possible within the confines of firefox etc, but still. This is the end goal. ","pontos":1},{"corpo":"There is a good description of the 3.5 web.config available here: http://www.4guysfromrolla.com/articles/121207-1.aspx The assemblies and config sections are important because they tell the runtime to use the new 3.5 dlls instead of the 2.0 dlls The codedom section tells the compiler to use 3.5. If you're not using ASP.Net Ajax you can probably skip the rest. I've never tested that though. ","pontos":9},{"corpo":"You can get the address that connects to your ServerSocket using http://java.sun.com/javase/6/docs/api/java/net/NetworkInterface.html#getInetAddresses() However if your client is connecting via a NAT, then you will get the address of the router and NOT the Ethernet address. If it is on your local network (via a hub/switch, no router with NAT) the it wil work as intended. ","pontos":3},{"corpo":"Thats an interesting idea. One could use something like this: http://code.google.com/p/syntaxhighlighter/ to the syntax highlighting then it's just a matter of code completion for things like functions. That much is relatively simple, it gets harder when you get into things like per file (or even included file) variables (for the code completion). And now that you have me thinking... It's to bad that I don't know javascript better. If anyone wants to get together and maybe build this idea into a viable project I'm definitely game. ","pontos":1},{"corpo":"I think it's seconds. The NHibernate API closely mirrors Hibernate Core for Java, where the Criteria.setTimeout(int) method uses seconds as the units (see also Statement.setQueryTimeout(int)). Also, after looking at some NHibernate source, it appears that it's using that value to set the timeout for the underlying ADO.NET query, which uses seconds. ","pontos":7},{"corpo":"A little bit of poking around suggests that it could be seconds: Assuming that ICriteria is the same as the Criteria interface in Hibernate core, then the JavaDoc for org.hibernate.Criteria provides a hint - the \"see also\" link to java.sql.Statement.setQueryTimeout(). The latter refers to its timeout parameter as seconds. Assuming that the NHibernate implementation follows the implied contract of that method, then that should be fine. However, for peace of mind's sake, I went and looked for some NHibernate specific stuff. There are various references to CommandTimeout; for example, here, related to NHibernate. Sure enough, the documentation for CommandTimeout states that it's seconds. I almost didn't post the above, because I don't know the answer outright, and can't find any concrete documentation - but since there is so little on the issue, I figured it couldn't hurt to present these findings. ","pontos":17},{"corpo":"Two main reasons. In short, consider carefully; there could be a good reason for it, but if there is be VERY explicit in your comments because it can be brittle and, as you say yourself, people aren't generally used to seeing code like this. Bitwise xor != Logical xor (except for 0 and 1) Firstly, if you are operating on values other than and (or and , as integers), the operator can introduce behavior not equivalent to a logical xor. For example: int one = 1; int two = 2; // bitwise xor if (one ^ two) { // executes because expression = 3 and any non-zero integer evaluates to true } // logical xor; more correctly would be coded as // if (bool(one) != bool(two)) // but spelled out to be explicit in the context of the problem if ((one !two) || (!one two)) { // does not execute b/c expression = ((true false) || (false true)) // which evaluates to false } Credit to user @Patrick for expressing this first. Order of operations Second, , , and , as bitwise operators, do not short-circuit. In addition, multiple bitwise operators chained together in a single statement -- even with explicit parentheses -- can be reordered by optimizing compilers, because all 3 operations are normally commutative. This is important if the order of the operations matters. In other words bool result = true; result = result a() b(); // will not call a() if result false, will not call b() if result or a() false will not always give the same result (or end state) as bool result = true; result = (a() b()); // a() and b() both will be called, but not necessarily in that order in an // optimizing compiler This is especially important because you may not control methods and , or somebody else may come along and change them later not understanding the dependency, and cause a nasty (and often release-build only) bug. ","pontos":13},{"corpo":"Harpreet: the inserts into that would be linear since you have to move items for an insert. Doesn't that depend on the implementation of the collection? If it acts like a linked-list, inserts would be O(1), while if it were implemented like an array it would be linear, as you stated. ","pontos":0},{"corpo":"I will point out that in C# you can turn on to check for arithmetic overflow / underflow, which isn't a bad idea anyways. If performance matters in a critical section, you can still use to avoid this. For internal code (ie code that won't be referenced in any interop manor with other languages) I vote for using unsigned when the situation warrants it, such as variables as mentioned earlier. This - along with checked arithmetic - provides one more net for developers, catching subtle bugs earlier. Another point in the signed vs unsigned debate is that some programmers use values such as -1 to indicate errors, when they wouldn't otherwise have meaning. I subscribe to the view that each variable should have only one purpose, but if you - or colleagues you code with - like to indicate errors in this way, leaving variables signed gives you the flexibility to add error states later. ","pontos":2},{"corpo":"I use ILMerge for almost all of my different applications. I have it integrated right into the release build process so what I end up with is one exe per application with no extra dll's. You can't ILMerge any C++ assemblies that have native code. You also can't ILMerge any assemblies that contain XAML for WPF (at least I haven't had any success with that). It complains at runtime that the resources cannot be located. I did write a wrapper executable for ILMerge where I pass in the startup exe name for the project I want to merge, and an output exe name, and then it reflects the dependent assemblies and calls ILMerge with the appropriate command line parameters. It is much easier now when I add new assemblies to the project, I don't have to remember to update the build script. ","pontos":28},{"corpo":"Try WinSQL lite at http://www.indus-soft.com/SynametricsWebApp/WinSQL.jsp. It is absolutely free and does not expire. It is only one file and does not come with any bulky DLLs. If you don't like it, simply delete the file from your hard drive. An introduction about how to use it against an informix database can be found in this article. ","pontos":5},{"corpo":"Have you tried adding the to your VirtualHost configuration? ","pontos":3},{"corpo":"Xerces has a feature you can set on to try and continue after a fatal error: True: Attempt to continue parsing after a fatal error. False: Stops parse on first fatal error. Default: false Note: The behavior of the parser when this feature is set to true is undetermined! Therefore use this feature with extreme caution because the parser may get stuck in an infinite loop or worse. ","pontos":1},{"corpo":"In theory, something like could work (that syntax fails though). Even if that did work, it would still be sort of ghetto to be calling an eval through a select onchange. Another solution would be to somehow get Rails to inject the onsubmit code into the onchange field of the select tag, but I'm not sure if there's a way to do that. ActionView has link_to_remote, but there's no obvious helper to generate the same code in the onchange field. ","pontos":-1},{"corpo":"Your two points are good. The primary reason to avoid it is casting, though. Casting makes them incredibly annoying to use. I tried using unisigned variables once but I had to sprinkle casts absolutely everywhere because the framework methods all use signed integers. Therefore, whenever you call a framework method, you have to cast. ","pontos":0},{"corpo":"@littlegeek: Toad is not available for Informix. Additionally, the OP seems to want a single program that can query several different brands of DBMS, and you have to buy a different version of Toad for every DBMS you want to use it with. ","pontos":0},{"corpo":"Python threads are good for concurrent I/O programming. Threads are swapped out of the CPU as soon as they block waiting for input from file, network, etc. This allows other Python threads to use the CPU while others wait. This would allow you to write a multi-threaded web server or web crawler, for example. However, Python threads are serialized by the GIL when they enter interpreter core. This means that if two threads are crunching numbers, only one can run at any given moment. It also means that you can't take advantage of multi-core or multi-processor architectures. There are solutions like running multiple Python interpreters concurrently, using a C based threading library. This is not for the faint of heart and the benefits might not be worth the trouble. Let's hope for an all Python solution in a future release. ","pontos":36},{"corpo":"Two gotchas that I wish I hadn't learned the hard way: (1) A lot of output (such as printf) is buffered by default. If you're debugging crashing code, and you're using buffered debug statements, the last output you see may not really be the last print statement encountered in the code. The solution is to flush the buffer after each debug print (or turn off the buffering altogether). (2) Be careful with initializations - (a) avoid class instances as globals / statics; and (b) try to initialize all your member variables to some safe value in a ctor, even if it's a trivial value such as NULL for pointers. Reasoning: the ordering of global object initialization is not guaranteed (globals includes static variables), so you may end up with code that seems to fail nondeterministically since it depends on object X being initialized before object Y. If you don't explicitly initialize a primitive-type variable, such as a member bool or enum of a class, you'll end up with different values in surprising situations -- again, the behavior can seem very nondeterministic. ","pontos":6},{"corpo":"Given your background in .NET but limited Asp .net experience... I assume you are more of a service/client guy. Which will mean your javascript is probably just as limited... If this is the case, I'd go with Silverlight. It will ease you into WPF, which you may be likely to use in the future. But more importantly working with Silverlight 2.0 feels more like building a sandboxed desktop application. More than a web application. You will be more at home with Silverlight if your prior experience is with client apps. If you want to break into building web sites/applications go with ASP .NET MVC. Either way knowledge of the typical ASP .NET controls will not go far, since they are for WebForms. ","pontos":0},{"corpo":"RegQueryValueEx This gives the value if it exists, and returns an error code ERROR_FILE_NOT_FOUND if the key doesn't exist. (I can't tell if my link is working or not, but if you just google for \"RegQueryValueEx\" the first hit is the msdn documentation.) ","pontos":4},{"corpo":"The nsIIOService.newURI(...) method is what you're looking for. It throws NS_ERROR_MALFORMED_URI if the URI string is invalid. Example: try { var ioServ = Components.classes[\"@mozilla.org/network/io-service;1\"] .getService(Components.interfaces.nsIIOService); var uriObj = ioServ.newURI(uriString, uriCharset, baseURI); } catch (e) { // catch the error here } ","pontos":3},{"corpo":"flex and bison are the new lex and yacc though. The syntax for BNF is often derided for being a bit obtuse. Some have moved to ANTLR and Ragel for this reason. If you're not doing much translation, you may one to pull a one-off using multiline regexes with Perl or Ruby. Writing a compatible BNF grammar for an existing language is not a task to be taken lightly. On the other hand, it is entirely possible to leverage any given language's .l and .y files if they are available as open source. Then, you could construct new code from an existing parse tree. ","pontos":1},{"corpo":"I'm not at all sure, but it seems to me that is not doing what you think it is. That counts the number of children of the current node, not the size of the current node list. Could you print it out to check that it's 8 or 9 instead of 12? Use to get the context size. ","pontos":0},{"corpo":"When you do , the current node is the element being processed. You want either or (preferable), or just calculate the midpoint to a variable for better performance and clearer code: xsl:variable name=\"nodes\" select=\"node\"/ xsl:variable name=\"mid\" select=\"count($nodes) div 2\"/ xsl:for-each select=\"$nodes[position() lt;= $mid]\" li foo /li /xsl:for-each xsl:for-each select=\"$nodes[$mid lt; position()]\" li bar /li /xsl:for-each ","pontos":7},{"corpo":"There is one tiny problem with OpenID. Seamlessly logging in with OpenID requires automatic (unverified) redirection between domains. That makes the OpenID server a 3rd party. This can cause cookies for the OpenID server to be rejected if you turn off 3rd party cookies and your browser strictly follows the Unverifiable Transactions rule in 3.3.6 of RFC2965. An example of this is Opera. If you turn off 3rd party cookies (by setting the global to \"Accept only cookies from the site I visit\"), you can't log in with OpenID because the server script you submit to automatically (without your interaction to approve it) redirects you to the OpenID server and the OpenID server does the same to get you back. But, you get lucky in Firefox, IE and Safari with their corresponding blocking of 3rd party cookies because they violate RFC2965 in multiple situations. Having to use OpenID in this case does a disservice to more compliant clients. As a workaround, in Opera, besides accepting all cookeis, you can goto tools - preferences - advanced - Network and turn off Automatic Redirection. Then, you'll be able to verify and click each link you're redirected to and the cookies won't be rejected because the transactions are verified. It should also work if you keep Automatic Redirection on and both servers generate a page with a link for you to click on so you can verify the transaction. But, there can't be any automatic redirects anywhere. Logging in with just a username and password where you're only dealing with first party cookies would be much better in this case. OpenID is still cool though and I guess Opera just needs an option to allow unverifiable transactions between SO and your OpenID server so that you can use \"Accept only cookies from the site I visit\" here. ","pontos":3},{"corpo":"If you dont like the idea of an Array (this is not slating Konrad's answer - you may have differing param types) you can pass complex objects (i.e. objects that you made yourself).. The downside is that you cannot then test using the ASMX page, but would need to do it all in code (which isn't really a bad thing, especially if you are used to it). ","pontos":0},{"corpo":"I think throwing an exception is what you should do when something goes wrong. This way, if your application is not running as a stand-alone app the caller can react to it and has some information about what went wrong. It is also easier for debugging purposes because you as well get a better idea about what went wrong when you see a stack trace. One important thing to note is that when the exception reaches the top level and therefore causes the VM to quit the VM returns a return code of 1, therefore outside applications that use the return code see that something went wrong. The only case where I think System.exit() makes sense is when your app is meant to be called by applications which are not Java and therefore have to use return codes to see if your app worked or not and you want those applications to have a chance to react differently on different things going wrong, i.e. you need different return codes. ","pontos":1},{"corpo":"Using the Maven Dependency Plugin: mvn dependency:tree ","pontos":20},{"corpo":"You could try using the function which will give you the size of the current context: xsl:for-each select=\"./node [position() lt;= last() div 2]\" li foo /li /xsl:for-each xsl:for-each select=\"./node [last() div 2 lt; position()]\" li bar /li /xsl:for-each ","pontos":2},{"corpo":"In my experience, there are two major points to this: 1) The most important thing is to be consistent. I don't think either of the two methods is necessarily easier to read, as long as you stick to it. I only get confused when both methods are used in a project (or even worse on the same page) because then I have to start searching for the calls and don't immediately know where to look. 2) The second kind, i.e. Event.observe() has advantages when the same or a very similar action is taken on multiple events because this becomes obvious when all those calls are in the same place. Also, as Konrad pointed out, in some cases this can be handled with a single call. ","pontos":3},{"corpo":"A good weekly update to the Ruby on Rails world: Rails Envy. The thestacktrace is good general programming podcast, which covers every thing from git to Scala. ","pontos":7},{"corpo":"To add to @David Crow, here's a dependency:tree example from the Maven site: mvn dependency:tree -Dincludes=velocity:velocity might output [INFO] [dependency:tree] [INFO] org.apache.maven.plugins:maven-dependency-plugin:maven-plugin:2.0-alpha-5-SNAPSHOT [INFO] \\- org.apache.maven.doxia:doxia-site-renderer:jar:1.0-alpha-8:compile [INFO] \\- org.codehaus.plexus:plexus-velocity:jar:1.1.3:compile [INFO] \\- velocity:velocity:jar:1.4:compile ","pontos":66},{"corpo":"In standard XML you embed quotes in attribute values using , or . See the page on Wikipedia for a list of XML entity references. I don't know if this will solve your problem, but seeing as it is an XML parser error it should. ","pontos":1},{"corpo":"I guess I should have specified the compiler - we're using gcc for Linux, and MSVC 6 (yeah I know, it's old, but it works (mostly) for us) for WIn32. For that reasons, gcov won't work for our Win32 builds, and Bullseye won't work for our Linux builds. Then again maybe I only need coverage in one OS... ","pontos":0},{"corpo":"If you are currently 'editing' the current form then it will not allow the action. Editing a record can sometimes be triggered by simply clicking inside a field, or other simple actions you wouldn't normally consider 'editing'. This is usually avoided in Access by using the RunCommand method to undo any edits before deleting the record: DoCmd.RunCommand acCmdUndo ","pontos":1},{"corpo":"Continuations can be used in \"real-life\" examples whenever the program flow is not linear, or not even pre-determined. A familiar situation is web applications. ","pontos":3},{"corpo":"While I hate to give an answer I'm not 100% certain of, the lack of responses so far makes me think a potentially correct answer might be okay in this case. As far as I'm aware there isn't the kind of session token mechanism you're looking for out-of-the-box with WCF which means you're going to have to do some heavy lifting to get things working in the way you want. I should make it clear there is a session mechanism in WCF but it's focused on guaranteeing message orders and is not the ideal tool for creating an authentication session. I just finished working on a project where we implemented our own session mechanism to handle all manner of legacy SOAP stacks, but I believe the recommended way to implement authenticated sessions is to use a Secure Token Service (STS) like Pablo Cibraro's. If you want more details please shout, but I suspect Pablo's blog will have more than enough info for you to steam ahead. ","pontos":1},{"corpo":"Teifion, if you use classes as a mere replacement for arrays, you are nowhere near OOP. The essence of OOP is that objects have knowledge and responsibility, can actually do things and cooperate with other classes. Your objects have knowledge only and can't do anything else than idly exist, however they seem to be good candidates for persistence providers (objects that know how to store/retrieve themselves into/from database). Don't worry about performance, too. Objects in PHP are fast and lightweight and performance in general is much overrated. It's cheaper to save your time as a programmer using the right approach than to save microseconds in your program with some obscure, hard to debug and fix piece of code. ","pontos":0},{"corpo":"Hejlsberg has described the reasons for not implementing the feature in an interview with Bruce Eckel. I have to admit, though, that I don't know how he thinks his proposed workaround will work. His proposal is to defer arithmetic operations to some other generic class (read the interview!). How does this help? IMHO, not much. ","pontos":72},{"corpo":"My guess would be that the build.cmd is waiting for some sort of user-interaction/reply. If you log the output of the command with the \"> logfile.txt\" operator at the end, it might help you find the problem. ","pontos":0},{"corpo":"The overflow property is the way to go. In particular, if you want the extra text to be ignored, you can use \"overflow:hidden\" as a css property on the text. In general, when a browser has an unbreakable object, such as a long string without spaces, it can have a conflict between various size constraints - those of the string (long) vs its container (short). If you see different behavior in different browsers, they are just resolving this conflict differently. By the way, there is a nice trick available for long strings - the wbr tag. If your browser sees longstringlongstring, then it will try to fit it in the container as a single, unbroken string -- but if it can't fit, it will break that string in half at the wbr. It's basically a break point with a implicit request to not break there, if possible (sort of like a hyphen in printed texts). By the way, it's a little buggy in some versions of Safari and Opera - check out this quirksmode page for more. ","pontos":0},{"corpo":"Your question is a little vague. I assume that the text files contain structured data, not just random lines of text. If you are parsing the files yourself then .NET has a library function to read all the lines from a text file into an array of strings (File.ReadAllLines). If you know your files are small enough to hold in memory, then you can use this method and iterate over the array using a regular expression to validate extract the fields. Excel files are a different ball game. .XLS files are binary, not text, so you would need to use a 3rd party library to access them. .XLSX files from Excel 2007 contain compressed XML data, so once again you would need to decompress the XML then use an XML parser to get at the data. I would not recommend writing your own XML parser, unless you feel the need for the intellectual exercise. ","pontos":1},{"corpo":" While being able to do so is helpful (especially in the early stages of a new project), many (most?) databases will quickly become far too large for that to be possible. Also, if you have any BLOBs then you're going to have problems generating SQL scripts for your entire database. Backups and compression can help you there. Sorry - there's no excuse not to be able to get a a good set of data to develop against. Even if it's just a sub-set. ","pontos":0},{"corpo":"I use 4 different machines and have got this situation on all of them. I understand what is causing the problem - it is that the VS hosting process isn't terminating after the first debug session ends, which means that the next time that you try to compile the exe the hosting process is locking the exe and preventing compilation. Another solution therefore is to use Task Manager to kill the VS hosting process and compile and debug as normal but thats even more of a hassle! I can't think that its anything in my code that would be causing this - its probably a VS issue itself isn't it? ","pontos":0},{"corpo":"Just use a cookie. ","pontos":1},{"corpo":"Copernic Desktop Search sometimes locks files so that they can't be written. Closing the program resolves the problem. Perhaps the same problem occurs with other search engines too. ","pontos":1},{"corpo":"Set CancelButtonStyle.CssClass to something like \"hiddenItem\" and set the CSS to \"display:none\". Otherwise you can convert the control to a template and simply delete away the cancel-button manually. When you click the control in Design-mode in Visual Studio, you get a little arrow with options and one of them is \"Convert to Template\". ","pontos":7},{"corpo":"Some time ago, I was searching for a text editor for my new Mac. Since this was some months ago, some points might have been corrected in the meantime. I feel that Aquamacs is by far the best OSX-Emacs. However, it feels a bit too Mac-like in some areas. For example, it rather uses several windows instead of several buffers and the coloring schemes are not \"normal\" Emacs-style. If you look for a more basic set, Carbon Emacs might do it as well, though you might want to add some additional packages to add PHP support or AucTeX. Emacs.app feels broken in my oppinion. It not even opens files using drag and drop. ","pontos":1},{"corpo":"We frequently encounter this error from our last project. The solution is to reinstall the libraries since we're using the trial version. This occurs when the libraries expire. ","pontos":2},{"corpo":"Is there any more information in the error message? When I had problems with LC.exe in the past, most times it was because the licensed component was upgraded (the version number increased), but the licx file still contained the old version. In this case, you can try to update the version in the licx file manually, or change it to to just work for further updates. You can also try to re-generate the licx file by deleting it and re-inserting the licensed windows forms controls into your form. ","pontos":1},{"corpo":"Not yet, because the OS is still unmanaged. If MS finally do what their labs have been talking about for years and produce a fully managed OS then it will. That OS won't be backwards compatible though. They would have to produce managed versions of Office, IE, etc first. They will have to produce a virtual machine to run unmanaged apps. The pain would be something similar to the move from Mac OS9 to OSX. ","pontos":10},{"corpo":"I haven't checked Simple Test for a while, last time it had an eclipse plugin, which is a major factor for me, but it hasn't been updated for a long time. Sebastian Bergmann is still very actively working on PHPUnit, but it still lacks a good plugin for eclipse - but it is included for the new Zend Studio. ","pontos":0},{"corpo":"COM was the last major technology that MS actually dogfooded. MS are continuing to build new APIs that depend on COM; for example, Vista's new Media Foundation (a kind of successor to DirectShow, which was also COM-based) is a COM API. So is Direct3D10 (and I would assume D3D11). I don't think it's going to disappear any time soon, and for a lot of Windows programming tasks it's not at all redundant. ","pontos":4},{"corpo":"From the way that you are asking, I assume that you consider either choice sufficient. Given that, I suggest that you go with Markdown, even though RST is more powerful. I feel Markdown succeeds where other markup languages fail because the author didn't try to create a new language, but rather codify what people were doing already (specifically in emails). From Markdown's home page: While Markdowns syntax has been influenced by several existing text-to-HTML filters, the single biggest source of inspiration for Markdowns syntax is the format of plain text email. To examplify why I think RST fails, I think both double colons and double back-quotes are obscure and hard to get right. ","pontos":91},{"corpo":"Well to start with on entering room B each prisoner has the probability of 50/100 (or 1/2) to get his number. With no strategy this gives the prisoners (1/2)/100 (or 0.005 chance of survivial). Are the prisoners allowed to re-order the boxes? ","pontos":0},{"corpo":"I tried most of the suggestions, and none of them worked. I didn't get a chance to try /resetuserdata. Finally I reinstalled the plugin and uninstalled it again, and the windows went away. ","pontos":1},{"corpo":"Slow compile time is most often caused by having large numbers of embedded resources ([Embed] or @Embed). Option 2 on this article might help you: [http://www.rogue-development.com/blog2/2007/11/slow-flex-builder-compile-and-refresh-solution-modules/] ","pontos":4},{"corpo":"Is it possible that the serverSocket is being closed from another thread? That will cause this exception. ","pontos":25},{"corpo":"I would agree that if possible, native front-ends are the way to go. I've not used wxWidgets recently, and I've heard it's come a long way, but back when it was wxWindows, we built an app with it that was spec'd to be built in X/Motif. When we finished the effort and delivered it, the customer said it did not look enough like X/Motif, and we had to re-work the entire UI at our expense... Joel Spolsky wrote a good article on this, but I can't remember the title. What he did say, IIRC, was the problem with Java and some other cross-platform UI was that \"your dog barks at my app\" - it's the little inconsistencies that annoy folks. ","pontos":2},{"corpo":"I find a low tech solution to this type of problem is always the best way to go. first we make some assumptions about the situation The prisoners are not all programmers or mathematicians They don't want to die The guards are well armed So with a 0.005% chance that they will see tomorrow, there is a very simple and low tech solution to this problem. RIOT its all about losses v potential gain, the chances are the prisoners far out number the guards, and using each other as human shields, as they are all dead men anyway if they don't, they can increase the chances they will over power a guard, once they have his weapon there chance goes up, helping them over power more guards to get more fire power to further increase there survival rate. once the guards realise what's happening, they will probably run for the hills and lock down the prison, this will give the media a heads up and then its a human rights issue. ","pontos":3},{"corpo":"Maybe I'm not reading it right, but the question seems to be badly constructed or missing information. If he finds the number that was assigned to him in one of these 50 boxes, the prisoner gets to walk into a room C and all boxes are closed again before the next one walks into room B from room A. Otherwise, all prisoners (in rooms A, B and C) gets killed. Does the last sentence there mean that all prisoners are killed the first time a prisoner fails to find their number? If not, what happens to prisoners that don't find their number? If no communication is possible, and whenever a prisoner enters room B it is always in an identical state then there is no possibility for a strategy. The prisoners could could say before they leave room A which number box they are going to open. But without subsequent prisoners knowing whether they were successful or not (assuming failure for one isn't failure for all) when the next prisoner enters room B they still have the same odds of picking their number as the previous prisoner (always 1:100). If failure for one is failure for all, then by knowing which box the previous prisoners opened, and by dint of the fact that they haven't all been killed, each successive prisoner could reduce the odds of picking the wrong box by one box. i.e. 1:100 for the first prisoner, 1:99 for the second, down to 1:1 for the last. ","pontos":0},{"corpo":"This is simple. I started getting this problems a few revisions ago. Basically, just remove the \"core=True\" parameter in the ImageField in the models, and then follow the instructions here to convert to what the newforms admin uses. ","pontos":2},{"corpo":"If you want to store numeric and string values in the same column, I am not sure you can avoid doing a lot of casts and converts when using that column as a query filter. ","pontos":0},{"corpo":"two columns. Table: (ValueLable as char(x), Value as numerica(p,s)) ","pontos":0},{"corpo":"These answers were helpful and they did let me add a limited form of fixed positioning to IE6, however none of these fix the bug that breaks my layout in IE6 if I specify both a top and a bottom css property for my sidebars (which is the behavior I need). Since top and bottom can't be specified, I used top and height. The height property turned out to be very necessary. I used javascript to recalculate the height when the page loads and for any resize. Below is the code I added to my test case to get it to work. This could be much cleaner with jQuery. !--[if lt IE 7] style body div.ie6-autoheight { height: 455px; } body div.ie6-autowidth { right: ; width: 530px; } /style script src=\"http://ie7-js.googlecode.com/svn/version/2.0(beta3)/IE7.js\" type=\"text/javascript\" /script script type=\"text/javascript\" function fixLayout() { if (document.documentElement.offsetWidth) { var w = document.documentElement.offsetWidth - 450; var h = document.documentElement.offsetHeight - 175; var l = document.getElementById('left-sidebar'); var r = document.getElementById('right-sidebar'); var c = document.getElementById('content'); c.style.width = w; c.style.height = h; l.style.height = h; r.style.height = h; } } window.onresize = fixLayout; fixLayout(); /script ![endif]-- ","pontos":0},{"corpo":"Did you try on your ? Something like this: !DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\" html head style type=\"text/css\" ul li { float: left; margin-left: 2em; } /style /head body ul li test /li li test2 /li /ul /body /html I only tested Firefox 3.0.1, works there. The is set because else your bullet overlaps the previous item. addition: Be wary that when you float the items you remove them from the normal flow, which in turn causes the to have no height. If you want to add a border or something, you'll get weird results. One way to fix that is to add the following to your styles: ul { overflow: auto; background: #f0f; } ","pontos":1},{"corpo":"I have found that sometimes I get a NoClassDefFound error when code is compiled with an incompatible version of the class found at runtime. The specific instance I recall is with the apache axis library. There were actually 2 versions on my runtime classpath and it was picking up the out of date and incompatible version and not the correct one, causing a NoClassDefFound error. This was in a command line app where I was using a command similar to this. set classpath=%classpath%;axis.jar I was able to get it to pick up the proper version by using: set classpath=axis.jar;%classpath%; ","pontos":16},{"corpo":"I believe it can also happen if you don't run your java program with the correct syntax. For instance, you have to call your class from the root bin folder with the full package name (ie. my.package.myClass). I'd be more specific if I could but I'm not much of a java guy. I just remember messing this up a few times. ","pontos":2},{"corpo":"Efficient way would be finding how much (pessimistically) bytes you will need per character with Encoding.GetMaxByteCount(1); then dividing your string size by the result, then converting that much characters with public virtual int Encoding.GetBytes ( string s, int charIndex, int charCount, byte[] bytes, int byteIndex ) If you want to use less memory use Encoding.GetByteCount(string); but that is a much slower method. ","pontos":1},{"corpo":"The Encoding class in .NET has a method called which can take in a string or char[]. If you pass in 1 character, it will tell you how many bytes are needed for that 1 character in whichever encoding you are using. The method is faster, but it does a worst case calculation which could return a higher number than is actually needed. ","pontos":1},{"corpo":"You need to think of the XHTML as a hierarchy of elements and treat it as such. This is basically the way XML is meant to be treated. Then just go through the hierarchy recursively, adding the number of words together as you go. When you hit your limit throw everything else away. I work mainly in PHP, and I would use the DOMDocument class in PHP to help me do this, you need to find something like that in your chosen language. To make things clearer, here is the hierarchy for your sample: - p - Proin tristique dapibus neque. Nam eget purus sit amet leo tincidunt accumsan. - p - Proin semper, orci at mattis blandit, augue justo blandit nulla. - span - Quisque ante congue justo - , ultrices aliquet, mattis eget, hendrerit, - em - justo - . You hit the 25 word limit inside the span element, so you remove all remaining text within the span and add the ellipsis. All other child elements (both text and tags) can be discarded, and all subsequent elements can be discarded. This should always leave you with valid markup as far as I can see, because you are treating it as a hierarchy and not just plain text, all closing tags that are required will still be there. Of course if the XHTML you are dealing with is invalid to begin with, don't expect the output to be valid. Sorry for the poor hierarchy example, couldn't work out how to nest lists. ","pontos":1},{"corpo":"Cookey, your code doesn't do what you apparent think it does. Pre-allocating the byte buffer in your case is pure waste because it will not be used. Rather, your assignment drops the allocated memory and resets the reference to point to another buffer because returns a new array. ","pontos":1},{"corpo":"If the column has a unique index: no, it's no faster a non-unique index: maybe, because it will prevent sending any additional rows beyond the first matched, if any exist no index: sometimes if 1 or more rows match the query, yes, because the full table scan will be halted after the first row is matched. if no rows match the query, no, because it will need to complete a full table scan ","pontos":25},{"corpo":"If \"name\" is unique in the table, then there may still be a (very very minimal) gain in performance by putting the limit constraint on your query. If name is the primary key, there will likely be none. ","pontos":0},{"corpo":"Here's what I did: link rel=\"Stylesheet\" type=\"text/css\" href=\"Stylesheet.css\" id=\"style\" runat=\"server\" visible=\"false\" / It fools Visual Studio into thinking you've added a stylesheet to the page but it doesn't get rendered. Here's an even more concise way to do this with multiple references; % if (false) { % link rel=\"Stylesheet\" type=\"text/css\" href=\"Stylesheet.css\" / script type=\"text/javascript\" src=\"js/jquery-1.2.6.js\" / % } % As seen in this blog post from Phil Haack. ","pontos":59},{"corpo":"To answer your questions in order: 1) yes, if there is no index on name. The query will end as soon as it finds the first record. take off the limit and it has to do a full table scan every time. 2) no. primary/unique keys are guaranteed to be unique. The query should stop running as soon as it finds the row. ","pontos":2},{"corpo":"By default it does it based on the reference to the object, but that means that it's the exact same object, so both would return the same hash. But a hash should be based on the value, like in the case of the string class. \"a\" and \"b\" would have a different hash, but \"a\" and \"a\" would return the same hash. ","pontos":0},{"corpo":"A bit of extra info that I've gained by painful experience: although NSNotificationCenter uses zeroing weak references when running under garbage collection, KVO does not. Thus, you can get away with not removing an NSNotificationCenter observer when using GC (when using retain/release, you still need to remove your observer), but you must still remove your KVO observers, as Chris describes. ","pontos":5},{"corpo":"A lock occurs when multiple processes try to access the same resource at the same time. One process loses out and must wait for the other to finish. A deadlock occurs when the waiting process is still holding on to another resource that the first needs before it can finish. So, an example: Resource A and resource B are used by process X and process Y X starts to use A. X and Y try to start using B Y 'wins' and gets B first now Y needs to use A A is locked by X, which is waiting for Y The best way to avoid deadlocks is to avoid having processes cross over in this way. Reduce the need to lock anything as much as you can. In databases avoid making lots of changes to different tables in a single transaction, avoid triggers and switch to optimistic/dirty/nolock reads as much as possible. ","pontos":56},{"corpo":"There is a great chapter in the Secure Programming for Linux HOWTO that describes what they are, and how to avoid them. ","pontos":10},{"corpo":"Deadlock occurs when two threads aquire locks which prevent either of them from progressing. The best way to avoid them is with careful development. Many embedded systems protect against them by using a watchdog timer (a timer which resets the system whenever if it hangs for a certain period of time). ","pontos":0},{"corpo":"I sometimes use Emacs with Steve Yegge's js2-mode, evaluating code with Rhino John Resig's env.js to load jQuery or Prototype in my standalone scripts. This allows me to explore javascript, jQuery, and Prototype outside of a browser. Example: var window; load(\"Library/env.js\"); window.location = 'index.html'; // Load the page 'index.html' print($('aForm').id); // Play with the Dom in a standalone script! ","pontos":3},{"corpo":"A semaphore is a way to lock a resource so that it is guaranteed that while a piece of code is executed, only this piece of code has access to that resource. This keeps two threads from concurrently accesing a resource, which can cause problems. ","pontos":0},{"corpo":"A race condition is a kind of bug, that happens only with certain temporal conditions. Example: Imagine you have two threads, A and B. In Thread A: if( object.a != 0 ) object.avg = total / object.a In Thread B: object.a = 0 If thread A is preempted just after having check that object.a is not null, B will do , and when thread A will gain the processor, it will do a \"divide by zero\". This bug only happen when thread A is preempted just after the if statement, it's very rare, but it can happen. ","pontos":18},{"corpo":"I would remove this line. alert(\"Your browser does not support AJAX!\") Shouting at the user in a language he probably doesn't understand is worse than failure. :-) ","pontos":6},{"corpo":" Rules 1 3 are contradictory to me. To a certain extent, they are. The reason is simple: if an object is stored in a hash table and, by changing its value, you change its hash then the hash table has lost the value and you can't find it again by querying the hash table. It is important that while objects are stored in a hash table, they retain their hash value. To realize this it is often simplest to make hashable objects immutable, thus evading the whole problem. It is however sufficient to make only those fields immutable that determine the hash value. Consider the following example: struct Person { public readonly string FirstName; public readonly string Name; public readonly DateTime Birthday; public int ShoeSize; } People rarely change their birthday and most people never change their name (except when marrying). However, their shoe size may grow arbitrarily, or even shrink. It is therefore reasonable to identify people using their birthday and name but not their shoe size. The hash value should reflect this: public int GetHashCode() { return FirstName.GetHashCode() ^ Name.GetHashCode() ^ Birthday.GetHashCode(); } ","pontos":22},{"corpo":"A deadlock happens when a thread is waiting for something that never occurs. Typically, it happens when a thread is waiting on a mutex or semaphore that was never released by the previous owner. It also frequently happens when you have a situation involving two threads and two locks like this: Thread 1 Thread 2 Lock1- Lock(); Lock2- Lock(); WaitForLock2(); WaitForLock1(); -- Oops! You generally detect them because things that you expect to happen never do, or the application hangs entirely. ","pontos":2},{"corpo":"A race condition occurs when two or more threads can access shared data and they try to change it at the same time. Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data. Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e. both threads are \"racing\" to access/change the data. Problems often occur when one thread does a \"check-then-act\" (e.g. \"check\" if the value is X, then \"act\" to do something that depends on the value being X) and another thread does something to the value in between the \"check\" and the \"act\". E.g: if (x == 5) // The \"Check\" { y = x * 2; // The \"Act\" // If another thread changed x in between \"if (x == 5)\" and \"y = x * 2\" above, // y will not be equal to 10. } The point being, y could be 10, or it could be anything, depending on whether another thread changed x in between the check and act. You have no real way of knowing. In order to prevent race conditions from occurring, you would typically put a lock around the shared data to ensure only one thread can access the data at a time. This would mean something like this: // Obtain lock for x if (x == 5) { y = x * 2; // Now, nothing can change x until the lock is released. // Therefore y = 10 } // release lock for x ","pontos":377},{"corpo":"Mutual Exclusion. Here's the Wikipedia entry on it: http://en.wikipedia.org/wiki/Mutual_exclusion The point of a mutex is to synchronize two threads. When you have two threads attempting to access a single resource, the general pattern is to have the first block of code attempting access to set the mutex before entering the code. When the second code block attempts access, it sees the mutex is set and waits until the first block of code is complete (and un-sets the mutex), then continues. Specific details of how this is accomplished obviously varies greatly by programming language. ","pontos":34},{"corpo":"When I am having a big heated discussion at work, I use a rubber chicken which I keep in my desk for just such occassions. The person holding the chicken is the only person who is allowed to talk. If you don't hold the chicken you cannot speak. You can only indicate that you want the chicken and wait until you get it before you speak. Once you have finished speaking, you can hand the chicken back to the moderator who will hand it to the next person to speak. This ensures that people do not speak over each other, and also have their own space to talk. Replace Chicken with Mutex and person with thread and you basically have the concept of a mutex. Of course, there is no such thing as a rubber mutex. Only rubber chicken. My cats once had a rubber mouse, but they ate it. Of course, before you use the rubber chicken, you need to ask yourself whether you actually need 5 people in one room and it would not just be easier with one person in the room on their own doing all the work. Actually, this is just extending the analogy, but you get the idea. ","pontos":548},{"corpo":"@Craig: A semaphore is a way to lock a resource so that it is guaranteed that while a piece of code is executed, only this piece of code has access to that resource. This keeps two threads from concurrently accesing a resource, which can cause problems. This is not restricted to only one thread. A semaphore can be configured to allow a fixed number of threads to access a resource. ","pontos":10},{"corpo":"The only thing that's wrong with this code (at least to me) is that you're not using a loop to process all elements. Other than that, why not to it like that? And with loop, I mean grabbing the container element via a JQuery and iterating over all child elements  basically a one-liner. ","pontos":0},{"corpo":"Rules 1 3 aren't really a contradiction. For a reference type the hash code is derived from a reference to the object - change an object's property and the reference is the same. For value types the hash code is derived from the value, change a property of a value type and you get a completely new instance of the value type. ","pontos":4},{"corpo":"Race conditions occur in multi-threaded applications or multi-process systems. A race condition, at its most basic, is anything that makes the assumption that two things not in the same thread or process will happen in a particular order, without taking steps to ensure that they do. This happens commonly when two threads are passing messages by setting and checking member variables of a class both can access. There's almost always a race condition when one thread calls sleep to give another thread time to finish a task (unless that sleep is in a loop, with some checking mechanism). Tools for preventing race conditions are dependent on the language and OS, but some comon ones are mutexes, critical sections, and signals. Mutexes are good when you want to make sure you're the only one doing something. Signals are good when you want to make sure someone else has finished doing something. Minimizing shared resources can also help prevent unexpected behaviors Detecting race conditions can be difficult, but there are a couple signs. Code which relies heavily on sleeps is prone to race conditions, so first check for calls to sleep in the affected code. Adding particularly long sleeps can also be used for debugging to try and force a particular order of events. This can be useful for reproducing the behavior, seeing if you can make it disappear by changing the timing of things, and for testing solutions put in place. The sleeps should be removed after debugging. The signature sign that one has a race condition though, is if there's an issue that only occurs intermittently on some machines. Common bugs would be crashes and deadlocks. With logging, you should be able to find the affected area and work back from there. ","pontos":13},{"corpo":"The private methods are called by a public method, so the inputs to your public methods should also test private methods that are called by those public methods. When a public method fails, then that could be a failure in the private method. ","pontos":30},{"corpo":"Deadlocks will only occur when you have two or more locks that can be aquired at the same time and they are grabbed in different order. Ways to avoid having deadlocks are: avoid having locks (if possible), avoid having more than one lock always take the locks in the same order. ","pontos":15},{"corpo":"I'd say that the main rule of thumb is not to roll your own. Try to use something that has been thoroughly tested, e.g., SHA-1 or something along those lines. ","pontos":2},{"corpo":"Here's the jQuery version: script type=\"text/javascript\" src=\"http://jqueryjs.googlecode.com/files/jquery-1.2.6.min.js\" /script script type=\"text/javascript\" $(function () { $(\"#switches li\").mouseover(function () { var $this = $(this); $(\"#slides div\").hide(); $(\"#slide\" + $this.attr(\"id\").replace(/switch/, \"\")).show(); $(\"#switches li\").css(\"font-weight\", \"normal\"); $this.css(\"font-weight\", \"bold\"); }); }); /script ul id=\"switches\" li id=\"switch1\" style=\"font-weight:bold;\" First slide /li li id=\"switch2\" Second slide /li li id=\"switch3\" Third slide /li li id=\"switch4\" Fourth slide /li /ul div id=\"slides\" div id=\"slide1\" Well well. /div div id=\"slide2\" style=\"display:none;\" Oh no! /div div id=\"slide3\" style=\"display:none;\" You again? /div div id=\"slide4\" style=\"display:none;\" I'm gone! /div /div ","pontos":4},{"corpo":"A sort-of-canonical definition is \"when two threads access the same location in memory at the same time, and at least one of the accesses is a write.\" In the situation the \"reader\" thread may get the old value or the new value, depending on which thread \"wins the race.\" This is not always a bug in fact, some really hairy low-level algorithms do this on purpose but it should generally be avoided. @Steve Gury give's a good example of when it might be a problem. ","pontos":22},{"corpo":"Have you seen this: http://www.itefix.no/i2/taxonomy/term/39 I have used cwrsync without any problem (and with the much of the usual cygwin misery), but I haven't had any need for unicode filenames, so I've not seen that problem. I don't really know why there isn't a native Win32 port, but I did look at the source a while back because I implemented a similar delta-copy system in C#. As one would expect from the world of brilliant *nix hackers, the source is largely single-character variable names and a total absence of comments, which isn't terrible helpful and might be rather off-putting to would-be porters. ","pontos":0},{"corpo":"I tend not to test private methods. There lies madness. Personally, I believe you should only test your publicly exposed interfaces (and that includes protected and internal methods). ","pontos":1},{"corpo":"I'd use reflection, since I don't like the idea of changing the access to a package on the declared method just for the sake of testing. However, I usually just test the public methods which should also ensure the the private methods are working correctly. you can't use reflection to get private methods from outside the owner class, the private modifier affects reflection also This is not true. You most certainly can, as mentioned in Cem Catikkas's answer. ","pontos":1},{"corpo":"You could always try doing a . This will only reset the limit for your current shell and the number you specify must not exceed the hard limit Each operating system has a different hard limit setup in a configuration file. For instance, the hard open file limit on Solaris can be set on boot from /etc/system. set rlim_fd_max = 166384 set rlim_fd_cur = 8192 On OS X, this same data must be set in /etc/sysctl.conf. kern.maxfilesperproc=166384 kern.maxfiles=8192 Under Linux, these settings are often in /etc/limits.conf. There are two kinds of limits: soft limits are simply the currently enforced limits hard limits mark the maximum value which cannot be exceeded by setting a soft limit Soft limits could be set by any user while hard limits are changeable only by root. Limits are a property of a process. They are inherited when a child process is created so system-wide limits should be set during the system initialization in init scripts and user limits should be set during user login for example by using pam_limits. There are often defaults set when the machine boots. So, even though you may reset your ulimit in an individual shell, you may find that it resets back to the previous value on reboot. You may want to grep your boot scripts for the existence ulimit commands if you want to change the default. ","pontos":83},{"corpo":" html head script type=\"text/javascript\" src=\"jquery.js\" /script script type=\"text/javascript\" $(document).ready( function(){ $( '#switches li' ).mouseover( function(){ $( \"#slides div\" ).hide(); $( '#switches li' ).css( 'font-weight', 'normal' ); $( this ).css( 'font-weight', 'bold' ); $( '#slide' + $( this ).attr( 'id' ).replace( 'switch', '' ) ).show(); } ); } ); /script /head body ul id=\"switches\" li id=\"switch1\" style=\"font-weight:bold;\" First slide /li li id=\"switch2\" Second slide /li li id=\"switch3\" Third slide /li li id=\"switch4\" Fourth slide /li /ul div id=\"slides\" div id=\"slide1\" Well well. /div div id=\"slide2\" style=\"display:none;\" Oh no! /div div id=\"slide3\" style=\"display:none;\" You again? /div div id=\"slide4\" style=\"display:none;\" I'm gone! /div /div /body /html ","pontos":1},{"corpo":"There's no such thing as a good hash function for universal hashes (ed. yes, I know there's such a thing as universal hashing but that's not what I meant). Depending on the context different criteria determine the quality of a hash. Two people already mentioned SHA. This is a cryptographic hash and it isn't at all good for hash tables which you probably mean. Hash tables have very different requirements. But still, finding a good hash function universally is hard because different data types expose different information that can be hashed. As a rule of thumb it is good to consider all information a type holds equally. This is not always easy or even possible. For reasons of statistics (and hence collision), it is also important to generate a good spread over the problem space, i.e. all possible objects. This means that when hashing numbers between 100 and 1050 it's no good to let the most significant digit play a big part in the hash because for ~ 90% of the objects, this digit will be 0. It's far more important to let the last three digits determine the hash. Similarly, when hashing strings it's important to consider all characters  except when it's known in advance that the first three characters of all strings will be the same; considering these then is a waste. This is actually one of the cases where I advise to read what Knuth has to say in The Art of Computer Programming, vol. 3. Another good read is Julienne Walker's The Art of Hashing. ","pontos":38},{"corpo":"This CSS snippet should remove the vertical scrollbar: body { overflow-x: hidden; overflow-y: hidden; } I'm not sure yet about having it take up as much vertical space as it needs, but I'll see if I can't figure it out. ","pontos":0},{"corpo":"It's kind of a hack, but sometimes I use an AtomicInteger, which is mutable, to do things like this. I've also seen cases where an int[] of size 1 is passed in. ","pontos":2},{"corpo":"split up work in 8 hour tasks per developer, start with the daily status meeting what did you do yesterday, what will you be doing today, what is blocking/stopping you from accomplishing your task for today ","pontos":5},{"corpo":"A good hash function has the following properties: Given a hash of a message it is computationally infeasible for an attacker to find another message such that their hashes are identical. Given a pair of message, m' and m, it is computationally infeasible to find two such that that h(m) = h(m') The two cases are not the same. In the first case, there is a pre-existing hash that you're trying to find a collision for. In the second case, you're trying to find any two messages that collide. The second task is significantly easier due to the birthday \"paradox.\" Where performance is not that great an issue, you should always use a secure hash function. There are very clever attacks that can be performed by forcing collisions in a hash. If you use something strong from the outset, you'll secure yourself against these. Don't use MD5 or SHA-1 in new designs. Most cryptographers, me included, would consider them broken. The principle source of weakness in both of these designs is that the second property, which I outlined above, does not hold for these constructions. If an attacker can generate two messages, m and m', that both hash to the same value they can use these messages against you. SHA-1 and MD5 also suffer from message extension attacks, which can fatally weaken your application if you're not careful. A more modern hash such as Whirpool is a better choice. It does not suffer from these message extension attacks and uses the same mathematics as AES uses to prove security against a variety of attacks. Hope that helps! ","pontos":2},{"corpo":"That's why you have to avoid: catch (Exception ex) { throw ex; } As that basically cloaks your exception in a new one. If you use: catch (Exception ex) { throw; //note: no ex } It keeps the original exception and stack trace. ","pontos":0},{"corpo":"This should set the IFRAME height to its content's height: script type=\"text/javascript\" the_height = document.getElementById('the_iframe').contentWindow.document.body.scrollHeight; document.getElementById('the_iframe').height = the_height; /script You may want to add to your IFRAME to turn off the scrollbars. edit: Oops, forgot to declare . ","pontos":9},{"corpo":"As far as I've seen, there isn't a significant performance difference between the two. I'm reasonably certain that in most cases it will be 'compiled' down to the same code. If you're not sure, try writing a test application that does each method a million times or so, all the while timing how long it takes. That's the only way to be certain (although it may vary on different architecture.) ","pontos":0},{"corpo":"Check out article from Cocoa is My Girlfriend. The gist of it, is that there is no performance penalty of using one over the other. However, the notation does make it more difficult to see what is happening with your variables and what your variables are. ","pontos":4},{"corpo":"Right click > TortoiseSVN > Settings > System Sounds.. Scroll down to the bottom. ","pontos":3},{"corpo":"$(document).ready(function() { switches = $('#switches li'); slides = $('#slides div'); switches.each(function(idx) { $(this).data('slide', slides.eq(idx)); }).hover( function() { switches.removeClass('active'); slides.removeClass('active'); $(this).addClass('active'); $(this).data('slide').addClass('active'); }); }); Rather than displaying all slides when JS is off (which would likely break the page layout) I would place inside the switch LIs real A links to server-side code which returns the page with the \"active\" class pre-set on the proper switch/slide. And here's the HTML: html head title test /title script type=\"text/javascript\" src=\"jquery.js\" /script script type=\"text/javascript\" src=\"switch.js\" /script style type=\"text/css\" #switches .active { font-weight: bold; } #slides div { display: none; } #slides div.active { display: block; } /style /head body ul id=\"switches\" li class=\"active\" First slide /li li Second slide /li li Third slide /li li Fourth slide /li /ul div id=\"slides\" div class=\"active\" Well well. /div div Oh no! /div div You again? /div div I'm gone! /div /div /body /html ","pontos":16},{"corpo":"You could iterate over the entire Workbook using vba (i've included the code from @PabloG and @euro-micelli ): Sub iterateOverWorkbook() For Each i In ThisWorkbook.Worksheets Set rRng = i.UsedRange For Each j In rRng If (Not IsEmpty(j)) Then If (j.HasFormula) Then If InStr(oCell.Formula, \"INDIRECT\") Then j.Value = Replace(j.Formula, \"INDIRECT(D4)\", \"INDIRECT(C4)\") End If End If End If Next j Next i End Sub This example substitues every occurrence of \"indirect(D4)\" with \"indirect(C4)\". You can easily swap the replace-function with something more sophisticated, if you have more complicated indirect-functions. Performance is not that bad, even for bigger Workbooks. ","pontos":4},{"corpo":"Here's how I would do it. I'd obtain a list of common English words with usage frequency and some grammatical information (like is it a noun or a verb?). I think you can look around the intertubes for some copy. Firefox is open-source and it has a spellchecker... so it must be obtainable somehow. Then I'd run a filter on it so obscure words are removed and that words which are too long are excluded. Then my generation algorithm would pick 2 words from the list and concatenate them and add a random 3 digits number. I can also randomize word selection pattern between verb/nouns like eatCake778 pickBasket524 rideFlyer113 etc.. the case needn't be camel casing, you can randomize that as well. You can also randomize the placement of the number and the verb/noun. And since that's a lot of randomizing, Jeff's The Danger of Navet is a must-read. Also make sure to study dictionary attacks well in advance. And after I'd implemented it, I'd run a test to make sure that my algorithms should never collide. If the collision rate was high, then I'd play with the parameters (amount of nouns used, amount of verbs used, length of random number, total number of words, different kinds of casings etc.) ","pontos":7},{"corpo":"DesignMode is a private property (from what I can tell). The answer is to provide a public property that exposes the DesignMode prop. Then you can cascasde back up the chain of user controls until you run into a non-user control or a control that is in design mode. Something like this.... public bool RealDesignMode() { if (Parent is MyBaseUserControl) { return (DesignMode ? true : (MyBaseUserControl) Parent.RealDesignMode; } return DesignMode; } Where all your UserControls inherit from MyBaseUserControl. Alternatively you could implement an interface that exposes the \"RealDeisgnMode\". Please note this code is not live code, just off the cuff musings. :) ","pontos":1},{"corpo":"This is probably going to be difficult to resolve unless you post either the error message from the log file or the list of steps that you took so far. I have JRun 3.1 configured on my machine so maybe I can duplicate your issue if you give us more information. ","pontos":1},{"corpo":"Edit: My apologies, I missed that the question was about Web forms - for which the below does not work. Must learn to read the question fully! Go to menu View Click on Design Tasks Select Controls in the 'Design Tasks' Task pane Click on the 'add or remove custom controls' button to install your custom control Click on the Add button and select ActiveX Control Select the Windows Media Player control Select the necessary properties for databinding and finish the wizard. After you have added the control, you can drag and drop the control on your screen. Right-Click on the control and select the 'Windows Media Player properties' Fill in the URL to automatically embed the file to play. ","pontos":0},{"corpo":"In short, what you are doing is right, you want to move the common code into a class library (DLL) and then reference that in any projects that require its logic. Where you are going wrong is that you are not maintaining it. If you need to make little \"tweaks\" subclass your existing code and extend it, dont change it.. If there are major changes needed, then re-think the design. ","pontos":8},{"corpo":"I don't use Visual Studio or .NET, but it think this problem is common enough amongst ALL programmers so I guess I'll take a crack at it. We've run into problems just like this when we try to extract common code into a separate library. It might be OK at first, but eventually 1 client is going to need some new functionality and require a change to the library. Invariably this leads to problems with some of the other clients, creating a huge mess. Unless you've got a good way to version your library file, this is a tough problem to solve. In the end, you might be better off just copying-and-pasting the source files into your new project. Yes, this violates the DRY (Don't Repeat Yourself) principle, but you avoid a lot of problems related to the dependencies a common library creates. ","pontos":0},{"corpo":"Not 100% sure example what you are asking, but personally, and I use MochiKit, I create JavaScript \"classes\" (or widgets, if you prefer) for every significant client-side UI structure. These know, of course, how to populate themselves with data. I don't know what more there is to say - writing UI code for the browser in JavaScript is no different than writing UI code for other types of apps, as far as I am concerned. Build classes and instantiate them as needed, populate them with data, have them throw events, etc. etc. Am I up in the night on this? :) EDIT: In other words, yes - do what you are doing, for the most part. I see too many novice JavaScript hackers write a bunch of poorly-cohesive functions that don't appear to be a part of anything specific other than they are all in a single file. Hope that makes sense. ","pontos":1},{"corpo":"I think the problem is that when the Grid is drawn, it draws each row from top to bottom, and within each row the items left to right. So the row-spanned mx:TextArea item is drawn first extending down into the area of the 2 next rows, which get drawn after and on top. The quickest way around I can see would be to draw the row borders on the mx:GridItem s instead, skipping the left and right edges based on the item's placement in the row. Something like this: ?xml version=\"1.0\" encoding=\"utf-8\"? mx:Application xmlns:mx=\"http://www.adobe.com/2006/mxml\" layout=\"absolute\" mx:Style Grid { background-color: white; horizontal-gap: 0; } GridItem { padding-top: 5; padding-left: 5; padding-right: 5; padding-bottom: 5; background-color: #efefef; border-style: solid; border-thickness: 1; border-color: black; } .left { border-sides: top, bottom, left; } .right { border-sides: top, bottom, right; } .center { border-sides: top, bottom; } /mx:Style mx:Grid mx:GridRow mx:GridItem styleName=\"left\" mx:Label text=\"Label\"/ /mx:GridItem mx:GridItem styleName=\"center\" mx:ComboBox/ /mx:GridItem mx:GridItem styleName=\"center\" mx:Label text=\"Label\"/ /mx:GridItem mx:GridItem styleName=\"right\" mx:ComboBox/ /mx:GridItem /mx:GridRow mx:GridRow mx:GridItem styleName=\"left\" mx:Label text=\"Label\"/ /mx:GridItem mx:GridItem styleName=\"center\" mx:TextInput/ /mx:GridItem mx:GridItem colSpan=\"2\" rowSpan=\"3\" mx:VBox width=\"100%\" height=\"100%\" mx:Label text=\"Label\"/ mx:TextArea width=\"100%\" height=\"100%\"/ /mx:VBox /mx:GridItem /mx:GridRow mx:GridRow mx:GridItem styleName=\"left\" mx:Label text=\"Label\"/ /mx:GridItem mx:GridItem styleName=\"center\" mx:TextInput/ /mx:GridItem /mx:GridRow mx:GridRow mx:GridItem styleName=\"left\" mx:Label text=\"Label\"/ /mx:GridItem mx:GridItem styleName=\"center\" mx:TextInput/ /mx:GridItem /mx:GridRow /mx:Grid /mx:Application ","pontos":1},{"corpo":"If the OP is asking about idomatic sorting expressions, then not all languages have a natural expression built in. For c I'd go to and use . Something on the lines of : /* non-functional mess deleted */ to sort the arguments into lexical order. Unfortunately this idiom is rather hard to parse for those not used the ways of c. Suitably chastened by the downvote, I actually read the linked article. Mea culpa. In anycase the original code did not work, except in the single case I tested. Damn. Plain vanilla c does not have this function, nor is it in any of the usual libraries. The code below sorts the command line arguments in the natural way as linked. Caveat emptor as it is only lightly tested. #include stdio.h #include stdlib.h #include string.h #include ctype.h int naturalstrcmp(const char **s1, const char **s2); int main(int argc, char **argv){ /* Sort the command line arguments in place */ qsort( argv[1],argc-1,sizeof(char*), (int(*)(const void *, const void *))naturalstrcmp); while(--argc){ printf(\"%s\\n\",(++argv)[0]); }; } int naturalstrcmp(const char **s1p, const char **s2p){ if ((NULL == s1p) || (NULL == *s1p)) { if ((NULL == s2p) || (NULL == *s2p)) return 0; return 1; }; if ((NULL == s2p) || (NULL == *s2p)) return -1; const char *s1=*s1p; const char *s2=*s2p; do { if (isdigit(s1[0]) isdigit(s2[0])){ /* Compare numbers as numbers */ int c1 = strspn(s1,\"0123456789\"); /* Could be more efficient here... */ int c2 = strspn(s2,\"0123456789\"); if (c1 c2) { return 1; } else if (c1 c2) { return -1; }; /* the digit strings have equal length, so compare digit by digit */ while (c1--) { if (s1[0] s2[0]){ return 1; } else if (s1[0] s2[0]){ return -1; }; s1++; s2++; }; } else if (s1[0] s2[0]){ return 1; } else if (s1[0] s2[0]){ return -1; }; s1++; s2++; } while ( (s1!='\\0') || (s2!='\\0') ); return 0; } This approach is pretty brute force, but it is simple and can probably be duplicated in any imperative language. ","pontos":3},{"corpo":"What exactly are you having problems with? I assume you've been able to hook the pins of the encoder to your PIC as per the technical specifications linked on the Farnell page you gave, so is the problem with reading the data? Do you not get any data from the encoder? Do you not know how to interpret the data you're getting back? ","pontos":0},{"corpo":"I think cmd.exe hangs if the parameters are incorrect. If the batch executes correctly then I would just shell execute it like this instead. ProcessStartInfo psi = new ProcessStartInfo(); Process p = new Process(); psi.WindowStyle = ProcessWindowStyle.Hidden; psi.WorkingDirectory = @\"c:\\build\"; psi.FileName = @\"C:\\build\\build.cmd\"; psi.UseShellExecute = true; psi.UserName = \"builder\"; psi.Password = password; p.StartInfo = psi; p.Start(); Also it could be that cmd.exe just can't find build.cmd so why not give the full path to the file? ","pontos":0},{"corpo":"This is specific to a C# project, but I ignore these files/directories: I have no problems running the code in the depot on other machines after I ignore all of these files. The easiest way to find out what you need to keep is to make a copy of the folder and start deleting things you think aren't necessary. Keep trying to build, and as long as you can build successfully keep on deleting. If you delete too much, copy it from the source folder. In the end you'll have a nice directory full of the only files that have to be committed. ","pontos":36},{"corpo":".NET 3.5 SP1 tries to use the action=\"\" attribute (.NET 3.5 RTM did not). So, when you deploy, your code is attempting to set the HtmlForm.Action property and failing, as the System.Web.dll on the deploy target is RTM and does not have a setter on the property. ","pontos":6},{"corpo":"I would say the answer to all those questions is NO, altough my experience with MS-SQL goes as far as SQL2000. Might be a different story in SQL2005 ","pontos":3},{"corpo":"No to the first 3 because the index will hold the data and no the last once also ","pontos":1},{"corpo":"For the fourth bullet: No you can't specify where you want to add the column. Here is the syntax for ALTER TABLE: http://doc.ddart.net/mssql/sql70/aa-az_5.htm In MySQL they offer an ALTER TABLE ADD ... AFTER ... but this doesn't appear in T-SQL. If you want to reorder the columns you'll have to rebuild the table. Edit: For your last last bullet point, you'll have to DROP the table and recreate it to reorder the columns. Some graphical tools that manipulate SQL databases will do this for you and make it look like you're reordering columns, so you might want to look into that. ","pontos":3},{"corpo":"I don't like this hack but it seems to do the job both in Firefox and IE6: span.right { vertical-align:top; display:inline-block; text-align:right; height:80px; width:50%; *width:100%; background-color:red; } Note the which seems to satisfy IE6's requirement and is ignored by Firefox. ","pontos":1},{"corpo":"One possibility I can think of is to store the count in a member variable of the class. This of course assumes that the public method is only called by a single thread. Another option is to refactor the public method to call a private helper method. The private method takes the list as a parameter and returns the count. For example: public List Thing doIt(String aString) { List Thing list = new ArrayList Thing (); int count = doItHelper(aString, list, 0); // ... return list; } private int doItHelper(String aString, List Thing list, int count) { // ... // do something that updates count count = doItHelper(aString, list, count); // ... return count; } This assumes that you can do the error handling in the public method, since the variable isn't actually passed back to the caller. If you need to do that, you could of course throw an exception: public List Thing doIt(String aString) throws SomeCustomException { List Thing list = new ArrayList Thing (); int count = doItHelper(aString, list, 0); // ... if (someErrorOccurred) { throw new SomeCustomException(\"Error occurred at chracter index \" + count, count); } return list; } It's difficult to know whether that will help without knowing more about how your algorithm actually works. ","pontos":0},{"corpo":"Change the error message. ","pontos":1},{"corpo":"Doesn't using multiple open-id providers sort of undermine the point of open id? ","pontos":0},{"corpo":"do you have ChildrenAsTriggers=\"false\" on the UpdatePanel? Are there any javascript errors on the page? ","pontos":2},{"corpo":"This is a long shot, but perhaps the svn you're executing isn't the real svn - is there an alias, function, shell script, or other command that's being hit? If there's an svn wrapper, maybe it's not so good about passing arguments along. which svn type -a svn ","pontos":1},{"corpo":"At the end of the object's constructor you could serialize the object to a base 64 string just like the cookie stores it, and store this in a member variable. When you want to check if the cookie needs recreating, re - serialize the object and compare this new base 64 string against the one stored in a member variable. If it has changed, reset the cookie with the new value. Watch out for the gotcha - don't include the member variable storing the base 64 serialization in the serialization itself. I presume your language uses something like a sleep() function (is how PHP does it) to serialize itself, so just make sure the member is not included in that function. This will always work because you are comparing the exact value you'd be saving in the cookie, and wouldn't need to override GetHashCode() which sounds like it could have nasty consequences. All that said I'd probably just drop the test and always reset the cookie, can't be that much overhead in it when compared to doing the change check, and far less likelyhood of bugs. ","pontos":1},{"corpo":"First, I'd create a simple DependencyObject class to hold your collection: class YourCollectionType : DependencyObject { [PROPERTY DEPENDENCY OF ObservableCollection YourType NAMED: BoundList] } Then, on your ValidationRule-derived class, create a property: YourCollectionType ListToCheck { get; set; } Then, in the XAML, do this: Binding.ValidationRules YourValidationRule YourValidationRule.ListToCheck YourCollectionType BoundList=\"{Binding Path=TheCollectionYouWantToCheck}\" / /YourValidationRule.ListToCheck /YourValidationRule /Binding.ValidationRules Then in your validation, look at ListToCheck's BoundList property's collection for the item that you're validating against. If it's in there, obviously return a false validation result. If it's not, return true. ","pontos":2},{"corpo":"@Martin That works for local forms that open in InfoPath. Nathan was asking about web-enabled forms. ActiveX controls are disabled for web forms, as evidenced by the informational label at the bottom of the design controls when the form compatability has been set to the web. Now, I will admit that I know nothing about the HTML tags to play audio in a browser, but I have something else that might work. I had an InfoPath form that I needed to dynamically load an image into for a web-enabled form. Similar to the ActiveX issue, the Picture control was also disabled. What I did was put some managed code behind the form and execute the following when the form loaded. public void FormEvents_Loading(object sender, LoadingEventArgs e) { string imgPath = \"http://yoursite/yourimage.jpeg\"; XPathNodeIterator xpni = MainDataSource.CreateNavigator().SelectSingleNode(\"/my:FormName/my:RichTextControlName\", NamespaceManager).SelectChildren(XPathNodeType.All); xpni.Current.InnerXml = \" img xmlns=\\\"http://www.w3.org/1999/xhtml\\\" src=\\\"\" + filePath + \"\\\" width=\\\"200px\\\" height=\\\"55px\\\" / \"; } I don't see why you couldn't take the same approach and load audio rather than an image. ","pontos":1},{"corpo":"I like to sanitize it as early as possible, which means the sanitizing happens when the user tries to enter in invalid data. If there's a TextBox for their age, and they type in anything other that a number, I don't let the keypress for the letter go through. Then, whatever is reading the data (often a server) I do a sanity check when I read in the data, just to make sure that nothing slips in due to a more determined user (such as hand-editing files, or even modifying packets!) Edit: Overall, sanitize early and sanitize any time you've lost sight of the data for even a second (e.g. File Save -> File Open) ","pontos":11},{"corpo":"User input should always be treated as malicious before making it down into lower layers of your application. Always handle sanitizing input as soon as possible and should not for any reason be stored in your database before checking for malicious intent. ","pontos":0},{"corpo":"Clean the data before you store it. Generally you shouldn't be preforming ANY SQL actions without first cleaning up input. You don't want to subject yourself to a SQL injection attack. I sort of follow these basic rules. Only do modifying SQL actions, such as, INSERT, UPDATE, DELETE through POST. Never GET. Escape everything. If you are expecting user input to be something make sure you check that it is that something. For example, you are requesting an number, then make sure it is a number. Use validations. Use filters. Clean up unwanted characters. ","pontos":1},{"corpo":"Assume all users are malicious. Sanitize all input as soon as possible. Full stop. ","pontos":0},{"corpo":"As far as I can see Changing the error message has no way of changing the message of a specific error. Plus the manual makes it look like like this is a function belonging to Zend_Form, but I get method not found when using it on an instance of Zend_Form. And example of the useage would be really great. ","pontos":0},{"corpo":"I sanitize my data right before I do any processing on it. I may need to take the First and Last name fields and concatenate them into a third field that gets inserted to the database. I'm going to sanitize the input before I even do the concatenation so I don't get any kind of processing or insertion errors. The sooner the better. Even using Javascript on the front end (in a web setup) is ideal because that will occur without any data going to the server to begin with. The scary part is that you might even want to start sanitizing data coming out of your database as well. The recent surge of ASPRox SQL Injection attacks that have been going around are doubly lethal because it will infect all database tables in a given database. If your database is hosted somewhere where there are multiple accounts being hosted in the same database, your data becomes corrupted because of somebody else's mistake, but now you've joined the ranks of hosting malware to your visitors due to no initial fault of your own. Sure this makes for a whole lot of work up front, but if the data is critical, then it is a worthy investment. ","pontos":1},{"corpo":"If you end up using flock, here's some code to do it: use Fcntl ':flock'; # Import LOCK_* constants # We will use this file path in error messages and function calls. # Don't type it out more than once in your code. Use a variable. my $file = '/path/to/some/file'; # Open the file for appending. Note the file path is quoted # in the error message. This helps debug situations where you # have a stray space at the start or end of the path. open(my $fh, ' ', $file) or die \"Could not open '$file' - $!\"; # Get exclusive lock (will block until it does) flock($fh, LOCK_EX) or die \"Could not lock '$file' - $!\"; # Do something with the file here... # Do NOT use flock() to unlock the file if you wrote to the # file in the \"do something\" section above. This could create # a race condition. The close() call below will unlock the # file for you, but only after writing any buffered data. # In a world of buffered i/o, some or all of your data may not # be written until close() completes. Always, always, ALWAYS # check the return value of close() if you wrote to the file! close($fh) or die \"Could not write '$file' - $!\"; Some useful links: PerlMonks file locking tutorial (somewhat old) documentation In response to your added question, I'd say either place the lock on the file or create a file that you call 'lock' whenever the file is locked and delete it when it is no longer locked (and then make sure your programs obey those semantics). ","pontos":21},{"corpo":"Pretty much every language does a short circuit evaluation. Meaning the second condition is only evaluated if it's aboslutely necessary to. For this to work, most languages use the double pipe, ||, not the single one, |. See http://en.wikipedia.org/wiki/Short-circuit_evaluation ","pontos":3},{"corpo":"In response to some of the answers so far: @Blair Conrad: # $ which svn # /usr/bin/svn # $ type -a svn # svn is /usr/bin/svn # $ file /usr/bin/svn # /usr/bin/svn: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), for GNU/Linux 2.6.9, stripped Doesn't seem like anything too funky is going on. @crashmstr: There are some crazy symbols in my password that would need escaping without the quotes. Also, using \"--non-interactive --no-auth-cache\" still gives me the prompt (I'm really confused about why \"--non-interactive\" doesn't work). @Daniel: I'm sure the password is correct. And it asks for the password for whatever user I'm logged in as, not the one specified by --username: # $ svn update --username user2 # user1@domain.com's password: @Joril: My config file is using the defaults (everything is commented out). @Thomas: # $ svn info # Path: . # URL: svn+ssh://user1@domain.com/path/to/repo # Repository Root: svn+ssh://user1@domain.com/path/to/repo # Repository UUID: 8397572a-6293-4696-b0bc-7f7839384894 # Revision: 40 # Node Kind: directory # Schedule: normal # Last Changed Author: user1 # Last Changed Rev: 40 # Last Changed Date: 2008-08-28 15:45:26 -0400 (Thu, 28 Aug 2008) It is an svn+ssh repository, but I didn't think that that mattered since in this case I'm just running the svn commands locally (on the same machine as the actual repository). Is it making an ssh connection to itself? If so, can I check it out locally using svn:// so that I can use the \"--username\" and \"--password\" options? ","pontos":1},{"corpo":"For C, C++, C#, Java and other .NET languages boolean expressions are optimised so that as soon as enough is known nothing else is evaluated. An old trick for doing obfuscated code was to use this to create if statements, such as: a || b(); if \"a\" is true, \"b()\" would never be evaluated, so we can rewrite it into: if(!a) b(); and similarly: a b(); would become if(a) b(); Please note that this is only valid for the || and operator. The two operators | and is bitwise or, and and, respectively, and are therefore not \"optimised\". EDIT: As mentioned by others, trying to optimise code using short circuit logic is very rarely well spent time. First go for clarity, both because it is easier to read and understand. Also, if you try to be too clever a simple reordering of the terms could lead to wildly different behaviour without any apparent reason. Second, go for optimisation, but only after timing and profiling. Way too many developer do premature optimisation without profiling. Most of the time it's completely useless. ","pontos":9},{"corpo":"If all prisoners are killed when someone fails to find their number then you either save 100 or 0. There is no way to save 30 people. ","pontos":0},{"corpo":"I've seen a lot of these types of questions lately--optimization to the nth degree. I think it makes sense in certain circumstances: Computing condition 2 is not a constant time operation You are asking strictly for educational purposes--you want to know how the language works, not to save 3us. In other cases, worrying about the \"fastest\" way to iterate or check a conditional is silly. Instead of writing tests which require millions of trials to see any recordable (but insignificant) difference, focus on clarity. When someone else (could be you!) picks up this code in a month or a year, what's going to be most important is clarity. In this case, your first example is shorter, clearer and doesn't require you to repeat yourself. ","pontos":2},{"corpo":"According to this article PHP does short circuit evaluation, which means that if the first condition is met the second is not even evaluated. It's quite easy to test also (from the article): ?php /* ch06ex07  shows no output because of short circuit evaluation */ if (true || $intVal = 5) // short circuits after true { echo $intVal; // will be empty because the assignment never took place } ? ","pontos":2},{"corpo":"This puzzle is explained at http://www.math.princeton.edu/~wwong/blog/blog200608191813.shtml and that person does a much better job of explaining the problem. The \"all prisoners are killed\" statement is wrong. The \"you can save 30+ on average\" is also wrong, the article says that 30% of the time you can save 100% of the prisoners. If I had more karma, I would vote down this question. ","pontos":5},{"corpo":"One of the common linking errors I've run into is when a function is used differently from how it's defined. If you see such an error you should make sure that every function you use is properly declared in some .h file. You should also make sure that all the relevant source files are compiled into the same lib file. An error I've run into is when I have two sets of files compiled into two separate libraries, and I cross-call between libraries. Is there a failure you have in mind? ","pontos":2},{"corpo":"Early is good, definitely before you try to parse it. Anything you're going to output later, or especially pass to other components (i.e., shell, SQL, etc) must be sanitized. But don't go overboard - for instance, passwords are hashed before you store them (right?). Hash functions can accept arbitrary binary data. And you'll never print out a password (right?). So don't parse passwords - and don't sanitize them. Also, make sure that you're doing the sanitizing from a trusted process - JavaScript/anything client-side is worse than useless security/integrity-wise. (It might provide a better user experience to fail early, though - just do it both places.) ","pontos":3},{"corpo":"on *nix, there's a tool called valgrind that I use for dealing with memory issues, like memory leaks and memory corruption. ","pontos":1},{"corpo":"We currently have one branch for ongoing maintenance, one branch for \"new initiatives\" which just means \"stuff that will come out sometime in the future; we're not sure when.\" We have also occasionally had two maintenance branches going on: one to provide fixes for what is currently in production and one that is still in QA. The main advantage we've seen is the ability to react to user requests and emergencies more rapidly. We can do the fix on the branch that is in production and release it without releasing anything extra that may have already been checked in. The main disadvantage is that we end up doing a lot of merging between branches, which increases the chance that something will get missed or merged incorrectly. So far, that hasn't been a problem, but it is definitely something to keep in mind. Before we instituted this policy, we generally did all development in the trunk and only branched when we released code. We then did fixes against that branch as needed. It was simpler, but not as flexible. ","pontos":2},{"corpo":"The C-runtime libraries are often the biggest culprit. Making sure all your projects have the same settings wrt single vs multi-threading and static vs dll. The MSDN documentation is good for pointing out which lib a particular Win32 API call requires if it comes up as missing. Other than that it usually comes down to turning on the verbose flag and wading through the output looking for clues. ","pontos":2},{"corpo":"The is a bitwise operator in PHP. It does not mean , exactly. You'll want to use the double-pipe. And yes, as mentioned, PHP does short-circuit evaluation. In similar fashion, if the first condition of an clause evaluates to false, PHP does not evaluate the rest of the clause, either. ","pontos":0},{"corpo":"Post office box number. It's a piece of information that allows you to access something else. (And if you do arithmetic on post office box numbers, you may have a problem, because the letter goes in the wrong box. And if somebody moves to another state -- with no forwarding address -- then you have a dangling pointer. On the other hand -- if the post office forwards the mail, then you have a pointer to a pointer.) ","pontos":0},{"corpo":" Problems - no way to get the number of strings automatically (that i know of). There is a bog-standard way of doing this, which lots of people (including MS) define macros like arraysize() for: #define arraysize(ar) (sizeof(ar) / sizeof(ar[0])) ","pontos":16},{"corpo":"The philosophy that we follow at work is to keep the trunk in a state where you can push at any time without drastic harm to the site. This is not to say that the trunk will always be in a perfect state. There will of course be bugs in it. But the point is to never, ever leave it broken drastically. If you have a feature to add, branch. A design change, branch. There have been so many times where I thought, \"oh I can just do this in the trunk it isn't going to take that long\", and then 5 hours later when I can't figure out the bug that is breaking things I really wished that I had branched. When you keep the trunk clean you allow the opportunity to quickly apply and push out bug fixes. You don't have to worry about the broken code you have that you conveniently branched off. ","pontos":1},{"corpo":"Okay... so no-one's tried Astra, or people just avoid Flash questions. After a lot of guess work it turns out I needed to cast the series to a PieSeries and then work with those member functions, as the ISeries was useless on it's own. myPieChart.dataTipFunction = function (item:Object, index:int, series:ISeries):String { var oPieSeries:PieSeries = series as PieSeries; return oPieSeries.itemToCategory(item,index) + \"\\n$\" + oPieSeries.itemToData(item) + \"\\n\" + Number(oPieSeries.itemToPercentage(item)).toFixed(2) + \"%\"; }; ","pontos":2},{"corpo":"DISCLAIMER: I am not a C++ programmer, however I know C really well. I adapated these calls from some C code I have. Also markdown put these strange as my underscores. You should just be able to write an abstraction class around the C sockets with something like this: class my_sock { private int sock; private int socket_type; private socklen_t sock_len; private struct sockaddr_in server_addr; public char *server_ip; public unsigned short server_port; }; Then have methods for opening, closing, and sending packets down the socket. For example, the open call might look something like this: int my_socket_connect() { int return_code = 0; if ( this- socket_type != CLIENT_SOCK ) { cout \"This is a not a client socket!\\n\"; return -1; } return_code = connect( this- local_sock, (struct sockaddr *) this- server_addr, sizeof(this- server_addr)); if( return_code 0 ) { cout \"Connect() failure! %s\\n\", strerror(errno); return return_code; } return return_code; } ","pontos":2},{"corpo":"We use a script like the following. Gzip is from the cygwin project. I'm sure you could modify the syntax to use a zip tool instead. The \"skip\" argument is the number of files to not archive off -- we keep 11 days in the 'current' directory. @echo off setlocal For /f \"skip=11 delims=/\" %%a in ('Dir D:\\logs\\W3SVC1\\*.log /B /O:-N /T:C')do move \"D:\\logs\\W3SVC1\\%%a\" \"D:\\logs\\W3SVC1\\old\\%%a\" d: cd \"\\logs\\W3SVC1\\old\" gzip -n *.log Endlocal exit ","pontos":2},{"corpo":" The default value of the argument must be a constant expression. It can't be a variable or a function call. If you need this functionality however: function foo($foo, $bar = false) { if(!$bar) { $bar = $foo; } } Assuming isn't expected to be a boolean of course. ","pontos":16},{"corpo":"Access can be a bitch. Ive been in the position where i had to go around and tell 20-50 people to close access so I could go to \"design mode\" to change the design of the forms and maybe a column. No fun at all. (Old access, and it might just be a bad setup) ","pontos":2},{"corpo":"I'm not sure I understand your question. What exactly are you trying to count? If I understand correctly you're trying to find the Most Significant non-zero byte. You're probably better off using a loop like this: int i; int write_zeros = 0; for (i = 3; i =0 ; --i) { t = (n (8 * i)) 0xff; if (t || write_zeros) { write_zeros = 1; printf (\"byte %d : 0x%02x\\n\", 4-i, t); byte_stream[bytes++] = t; } } ","pontos":0},{"corpo":"I don't think so. There is a way to create a read-only List and read only Collection, but I don't think there's a built in read only Dictionary. System.ServiceModel has a ReadOnlyDictinoary implementation, but its internal. Probably wouldn't be too hard to copy it though, using Reflector, or to simply create your own from scratch. It basically wraps an Dictionary and throws when a mutator is called. ","pontos":3},{"corpo":"URL encoding. I think it's in PHP. ","pontos":0},{"corpo":"You can use rawurlencode() to convert a string according to the RFC 1738 spec. This function replaces all non-alphanumeric characters by their associated code. The difference with urlencode() is that spaces are encoded as plus signs. You'll probably want to use the last one. This technique is called Percent or URL encoding. See Wikipedia for more details. ","pontos":3},{"corpo":"To answer B: Comparison of JavaScript frameworks EDIT: Although everyone and their mom is apparently riding the jQuery bandwagon (I use MochiKit), there are many libraries which provide the same functionality - the problem set which most libraries solve (async client-server communication, DOM manipulation, etc.) is the same, and there are few that don't have what you will need to get the job done. The important thing to determine for yourself is whether or not a library will fit your particular style and sensibilities. Wide-spread ignorance about how JavaScript, the language, actually works, coupled with the negative press resulting thereby, coupled with the now-immense popularity of jQuery leads most people down that road. Thankfully, it isn't a bad road to be on as there are a lot of travellers to keep you company when the abstractions leak and you need help. You probably can't go wrong choosing jQuery. ","pontos":10},{"corpo":"GACUTIL doesn't register DLLs -- not in the \"COM\" sense. Unlike in COM, GACUTIL copies the file to an opaque directory under %SYSTEMROOT%\\assembly and that's where they run from. It wouldn't make sense to ask GACUTIL \"register a folder\" (not that you can do that with RegSvr32 either). You can use a batch FOR command such as: FOR %a IN (C:\\MyFolderWithAssemblies\\*.dll) DO GACUTIL /i %a If you place that in a batch file, you must replace %a with %%a ","pontos":22},{"corpo":"rawurlencode will encode \"exotic\" characters in a URL. ","pontos":0},{"corpo":"As far as I know, there is not. But may be you can copy some code (and learn alot) from these articles: Immutability in C# Part One: Kinds of Immutability Immutability in C# Part Two: A Simple Immutable Stack Immutability in C# Part Three: A Covariant Immutable Stack Immutability in C# Part Four: An Immutable Queue Immutability in C# Part Six: A Simple Binary Tree Immutability in C# Part Seven: More on Binary Trees Immutability in C# Part Eight: Even More On Binary Trees Immutability in C# Part Nine: Academic? Plus my AVL tree implementation Immutability in C# Part 10: A double-ended queue Immutability in C# Part Eleven: A working double-ended queue ","pontos":24},{"corpo":"Stackoverflow uses jquery I think, and I hear that jquery is all the rage ","pontos":3},{"corpo":"I really don't think that file-based databases can scale past half a dozen users. The last time I had an Access database (admittedly this was quite a while ago) I had to work really hard to get it to work for 8-9 people. It is really much easier to install Ubuntu on an old junk computer with PostgreSQL or MySQL. That's what I had to do even when I kept my Access front-end. ","pontos":6},{"corpo":"Here is the script you would put into a batch file to register all of the files in the current directory with Gacutil. You don't need to put it in a batch file (you can just copy/paste it to a Command Prompt) to do it. FOR %1 IN (*) DO Gacutil /i %1 Edit: Bah, sorry I was late. I didn't see the previous post when I posted mine. ","pontos":8},{"corpo":"I usually go for this, a public getter that returns System.Collections.ObjectModel.ReadOnlyCollection: public ReadOnlyCollection SomeClass Collection { get { return new ReadOnlyCollection SomeClass (myList); } } And public methods on the object to modify the collection. Clear(); Add(SomeClass class); If the class is supposed to be a repository for other people to mess with then I just expose the private variable as per method #1 as it saves writing your own API, but I tend to shy away from that in production code. ","pontos":3},{"corpo":"We are starting to use jQuery where I work. I'm not big on JavaScript, but everyone else likes it a lot. I don't know if that helps at all... ","pontos":2},{"corpo":"The urlencode() function will convert spaces into plus signs (+), so it won't work. The rawurlencode does the trick. Thanks. Be sure to convert each part of the path separately, otherwise path/file will be converted into path%2Ffile. (which was what I missed) ","pontos":1},{"corpo":"Here is the method I've used in the past with good success: /trunk - bleeding edge. Next major release of the code. May or may not work at any given time. /branches/1.0, 1.1, etc. Stable maintenance branches of the code. Used to fix bugs, stabilize new releases. If a maintenance branch, it should compile (if applicable) and be ready for QA/shipping at any given time. If a stabilization branch, it should compile and be feature complete. No new features should be added, no refactoring, and no code cleanups. You can add a pre- prefix to indicate stabilization branches vs maintenance branches. /branches/cool_feature. Used for highly experimental or destructive work that may or may not make it into trunk (or a maintenance branch). No guarantees about code compiling, working, or otherwise behaving sanely. Should last the minimum time as possible before merging into the mainline branch. /tags/1.0.1, 1.0.2, 1.1.3a, etc. Used for tagging a packaged shipped release. Never EVER changes. Make as many tags as you want, but they're immutable. ","pontos":53},{"corpo":"If you have lastupdate columns you can check for the writes, there is really no easy way to check for reads. You could run profiler, save the trace to a table and check in there What I usually do is rename the table by prefixing it with an underscrore, when people start to scream I just rename it back ","pontos":0},{"corpo":"I looked into it by checking out my file associations. It seems that a .reg file is just called as the first parameter to the executable on Windows. So you can just say . What I'm not sure of is how to get rid of the dialog box that pops up that asks for your confirmation. ","pontos":2},{"corpo":"If by not used, you mean your application has no more references to the tables in question and you are using dynamic sql, you could do a search for the table names in your app, if they don't exist blow them away. I've also outputted all sprocs, functions, etc. to a text file and done a search for the table names. If not found, or found in procedures that will need to be deleted too, blow them away. ","pontos":0},{"corpo":"Perl has a taint option which considers all user input \"tainted\" until it's been checked with a regular expression. Tainted data can be used and passed around, but it taints any data that it comes in contact with until untainted. For instance, if user input is appended to another string, the new string is also tainted. Basically, any expression that contains tainted values will output a tainted result. Tainted data can be thrown around at will (tainting data as it goes), but as soon as it is used by a command that has effect on the outside world, the perl script fails. So if I use tainted data to create a file, construct a shell command, change working directory, etc, Perl will fail with a security error. I'm not aware of another language that has something like \"taint\", but using it has been very eye opening. It's amazing how quickly tainted data gets spread around if you don't untaint it right away. Things that natural and normal for a programmer, like setting a variable based on user data or opening a file, seem dangerous and risky with tainting turned on. So the best strategy for getting things done is to untaint as soon as you get some data from the outside. And I suspect that's the best way in other languages as well: validate user data right away so that bugs and security holes can't propagate too far. Also, it ought to be easier to audit code for security holes if the potential holes are in one place. And you can never predict which data will be used for what purpose later. ","pontos":2},{"corpo":"Use the Win32 API function ShellExecute() or ShellExecuteEx(). If the comment is 'open' it should merge the .reg file. I haven't tested it, but it should work. ","pontos":1},{"corpo":"\"Out of the box\" there is not a way to do this. You can create one by deriving your own Dictionary class and implementing the restrictions you need. ","pontos":1},{"corpo":"Just delete them and see if any user complains about it ;) ","pontos":0},{"corpo":"I hear you, I've followed the Pylons mailing list for a while looking for something similar. There have been some attempts in the past (see AdminPylon and Restin) but none have really kept up with SQLAlchemy's rapidly developing orm api. Since DBSprockets is likely to be incorporated into TurboGears it will likely be maintained. I'd bite the bullet and go with that. ","pontos":4},{"corpo":"I wish I knew more about your specific situation, but as general piece of advice, you might look into C++/CLI for issues involving unmanaged/managed interoperability: C++: The Most Powerful Language for .NET Framework Programming I know from experience that I can \"lift\" unmanaged code into a C++/CLI project where I can use it from any C#/.NET/managed code, but it sounds like you want to do the opposite: lift managed code into a C++/CLI project, and then link that with some unmanaged code and expose that as a traditional unmanaged DLL (or installer binary). I'm not sure if this is possible in C++/CLI. ","pontos":0},{"corpo":"Out of pure curiosity, what's your reasoning for never wanting to load the file if it's been changed? Why not just keep all of the configuration information compiled in the executable? Why bother with an external file at all? Edit I just read your edit about this being a credit card info program. That poses a very interesting challenge. I would think, for that level of security, some sort of pretty major encryption would be necessary but I don't know anything about handling that sort of thing in such a way that the cryptographic secrets can't just be extracted from the executable. Is authenticating against some sort of online source a possibility? ","pontos":1},{"corpo":"Looks like the docs are wrong (and have continued to be wrong for the last 3+ years!). I found this snippet with Reflector in Microsoft.SqlServer.Management.Common.ConnectionManager, Microsoft.SqlServer.ConnectionInfo protected void CheckServerVersion(ServerVersion version) { if ((version.Major = 7 || (version.Major 9)) { throw new ConnectionFailureException( StringConnectionInfo.ConnectToInvalidVersion(version.ToString()) ); } } So, it looks like only SQL 2000 and SQL 2005 are supported. Presumably, SQL 2008 (version 10) has updated SMO assemblies. Bummer - guess it's back to SQL-DMO for this project. ","pontos":1},{"corpo":"yeah, thought of both of those.... but then how do you remove the entries? I don't think regedit command line provides that functionality. I think I'm going to go with the approach of just adding the keys via the usual registry API's, then remove them the same way. Unless some better way comes along. ","pontos":1},{"corpo":"Since the JavaScriptSerializer class is technically being deprecated, I believe DataContractJsonSerializer is the preferable way to go if you're using 3.0+. ","pontos":4},{"corpo":"The most important thing is to always be consistent in when you escape. Accidental double sanitizing is lame and not sanitizing is dangerous. For SQL, just make sure your database access library supports bind variables which automatically escapes values. Anyone who manually concatenates user input onto SQL strings should know better. For HTML, I prefer to escape at the last possible moment. If you destroy user input, you can never get it back, and if they make a mistake they can edit and fix later. If you destroy their original input, it's gone forever. ","pontos":3},{"corpo":" Without her input, I started the Scrum practices (daily scrums, burndown charts and other things I've found that worked for me and my previous teams (ala H. Kniberg's cool wall chart). During out daily stand up she slinks by and ignores us as if we actually weren't standing right outside her door (we are actually). It's pretty amazing. I've never seen such resistance. Question... how do I get her onboard? Peer pressure is not working. Yikes! Who would ever want to work in such an oppressive environment? If you're lucky, she's sending around her resume and you'll be able to hire someone who is on board with your development process. Assuming you want to hang on to her, I'd turn down (or off) the rhetoric and work on being a friend and co-worker first. If the project is a year late, she can't be feeling good about herself and it sounds like you aren't afraid to trumpet your success. That can be intimidating. I know nothing about Scrum, however. I'm just imagining what it would be like to walk around in your co-worker's shoes. ","pontos":12},{"corpo":"It looks like you can't embed tags in a richtext field. I'm getting nothing when I do it. But thanks anyway Jason. Any other ideas? ","pontos":1},{"corpo":"First, we have check-in (smoke) tests that must run before code can be checked in. It's done automatically by running a job that runs the tests and then makes the check-in to source control upon successful test completion. Second, cruise control kicks off build and regression tests. The product is built then several sets of integration tests are run. The number of tests vary by where we are in the release cycle. More testing is added late in the cycle during ramp down. Cruise control takes all submissions within a certain time window (12 minutes) so your changes may be built and tested with a small number of others. Third, there's an automated nightly build and tests that are quite extensive. We have load or milestone points every 2 or 3 weeks. At a load point, all automated tests are run plus manual testing is done. Performance testing is also done for each milestone. Performance tests can be kicked off on request but the hardware available is limited so people have to queue up for performance tests. Usually people rely on the load performance tests unless they are making changes specifically to improve performance. Finally, stress tests are also done for each load. These tests are focussed on making sure the product has no memory leaks or anything else that prevents 24/7 running of the product as opposed to performance. All of this is done with ant, cruise control, and Python scripts. ","pontos":3},{"corpo":"It is possible to remove registry keys using a .reg file, although I'm not sure how well it's documented. Here's how: REGEDIT4 [-HKEY_CURRENT_USER\\Software\\ otherpath ] The in front of the key name tells that you want to remove the key. To run this silently, type: regedit /s \"myfile.reg\" ","pontos":8},{"corpo":"In native code, if the corruption always occurs in the same place in memory, you can use a data breakpoint to break the debugger when that memory is changed. Unfortunately, you cannot set a data breakpoint in the managed C++ environment, presumably because the GC could move the object in memory. Not sure if this helps, but hopefully it leads you off in the right direction. ","pontos":1},{"corpo":"The only way to change the instance name is to re-install - uninstall and install as default instance. ","pontos":2},{"corpo":"Are null and an empty string equivalent? If they are, I would include logic in my application (or maybe a trigger if the app is \"out-of-the-box\"?) to force the field to be either null or '', but not the other. If you went with '', then you could set the column to NOT NULL as well. Just a data-cleanliness thing. ","pontos":0},{"corpo":"This is usually caused when using a build system like Apache Ant that only compiles java files when the java file is newer than the class file. If a method signature changes and classes were using the old version things may not be compiled correctly. The usual fix is to do a full rebuild (usually \"ant clean\" then \"ant\"). Sometimes this can also be caused when compiling against one version of a library but running against a different version. ","pontos":4},{"corpo":"Are you testing in Firefox or IE? We have a similar issue where the entire page refreshes in Firefox (but not IE). To get around it we use a hidden asp:button with the useSubmitBehavior=\"false\" set. asp:Button ID=\"btnRefresh\" runat=\"server\" OnClick=\"btnRefresh_Click\" Style=\"display: none\" UseSubmitBehavior=\"false\" / ","pontos":1},{"corpo":"It means that the task is re-entrant - items declared within the task are dynamically allocated rather than shared between different invocations of the task. You see - some of us do Verilog... (ugh) ","pontos":8},{"corpo":"s/[^:]\\bBoolean\\b[^\"]/bool/g Edit: Rats, beaten again. +1 for beating me, good sir. ","pontos":1},{"corpo":"Seems like the best you could do is to iterate through the list, for every item add it to a list of \"seen\" items or else remove it from the \"seen\" if it's already there, and at the end your list of \"seen\" items will include the singular element. This is O(n) in regards to time and n in regards to space (in the worst case, it will be much better if the list is sorted). The fact that they're integers doesn't really factor in, since there's nothing special you can do with adding them up... is there? Question I don't understand why the selected answer is \"best\" by any standard. O(N*lgN) > O(N), and it changes the list (or else creates a copy of it, which is still more expensive in space and time). Am I missing something? ","pontos":0},{"corpo":"Without any more information it is difficult to pinpoint the problem, but the root cause is that you most likely have compiled a class against a different version of the class that is missing a method, than the one you are using when running it. Look at the stack trace ... If the exception appears when calling a method on an object in a library, you are most likely using separate versions of the library when compiling and running. Make sure you have the right version both places. If the exception appears when calling a method on objects instantiated by classes you made, then your build process seems to be faulty. Make sure the class files that you are actually running are updated when you compile. ","pontos":51},{"corpo":"I'm surprised that someone who has used Subversion in the past would even have a want/need for TFS source control. My experience with TFS (2005) has been pretty horrible. I've read all kinds of whitepapers guidance as to how to properly structure your source for various development needs. Our simple situation, where we have a trunk with mainline development, and integration branch where we integrate changes deploy from, and a releases branch to keep track of past releases is very common and straightforward, but we are continually running into problems. My main issues with TFS: Merging is a PAIN in comparison to subversion. There are unfixed bugs. I ran into one about renaming/merging that has been known for 2 years and a fix will never be released for 2005. We ended up moving our branch to a \"broken\" folder and we ignore it now. Putting read-only locks on your files is friction. Who says I need to edit batch files and build scripts inside of TFS so that it will \"check it out\" for me? Subversion knows which files changed. There are no readonly locks there. Speed. TFS is dog-slow over a WAN, and it's really only usable if I VPN into my work computer, which makes my dev experience really slow overall. Lack of good command-line and explorer integration. IDE integration is really nice for the day-to-day Get-Latest, adding files, and checking in, but when you need to do things across many projects, it's nice to have good tools at your disposal. And before someone jumps down my throat claiming tf.exe works well... it's not really a cmd line tool. For example, checking in code shouldn't pop up a modal dialog. ...the list goes on. I think even with all of the integration, there are free alternatives that are far superior. ","pontos":46},{"corpo":"I would leave the onClick and set it as the trigger for the updatePanel. That's odd that it works in FF and not IE. That is opposite from the behavior we experience. ","pontos":0},{"corpo":"It's not so black and white... it really depends on a lot of factors (the more important being \"what does the person paying you want you to do\") Where I work we re-wrote a development framework, and on the other hand, we keep modifying some old systems that cannot be migrated (because of the client's technology and time restrictions). In this case, we try to mantain the coding style and sometimes you have to implement a lot of workarounds because of the way it was built ","pontos":0},{"corpo":"Refactor unless it is very bad indeed. Joel has a lot to say on this... At the very least, rewrite the code with the old code in front of you and don't just start over from scratch. The old code may be terrible, but it is the way it is for a reason and if you ignore it you'll end up seeing the same bugs that were probably fixed years ago in the old code. ","pontos":1},{"corpo":"See Joel Spolsky's essay Things You Should Never Do. In summary, when you rewrite you lose all the lessons you learned to make your current code work the way it needs to work. See also: Big Ball of Mud ","pontos":4},{"corpo":"Just clean up the code a little bit every time you work with it. If there isn't one already, setup a unit testing framework. All new code should get tests written. Any old code you fix as a result of bugs, try to slide in tests too. As the cleanups progress, you'll be able to sweep more and more of the nasty code into encapsulated bins. Then you can pick those off one by one in the future. A tool like javadoc or doxygen, if not already in use, can also help improve code documentation and comprehensibility. The arguments against a complete rewrite a pretty strong. Those tons of \"little bugs\" and behaviors that were coded in over the time frame of the original project will sneak right back in again. ","pontos":9},{"corpo":"Just a small comment. Never ever go to the database direct. If there is no way to do it via published and supported API's, then there is no way to do it. End of story. This applies even to when you are \"just reading data\", as this can still cause significant issues. ","pontos":1},{"corpo":"Some folks in our company do that with their external dependencies, and they get occasional build errors, usually because a library or header can't be retrieved. When they rebuild again it all works. Of course the speed and traffic-level of your network would have a major effect on this. ","pontos":1},{"corpo":"One reason for rewriting at one of my previous jobs was an inability to find developers with enough experience to work on the original code base. The decision was made to first clean up the underlying database structure, then rewrite in something that would make it easier to find full-time employees and/or contractors. I haven't heard yet how it worked out :) I think people have a tendency to go for rewrites because it seems more fun on the surface. We get to rebuild from scratch! We'll do it right this time! etc. ","pontos":2},{"corpo":"Essentially this is the same issue as people had with WebForms and trying to compile their UserControl ASCX files into a DLL. I found this http://www.codeproject.com/KB/aspnet/ASP2UserControlLibrary.aspx that might work for you too. ","pontos":14},{"corpo":"It is rare for a re-write of anything complex to succeed. It's tempting, but a low percentage strategy. Get legacy code under unit tests and refactor it, and/or completely replace small portions of it incrementally when opportune. ","pontos":2},{"corpo":"bittorrent? There have been a few web-based versions already (bitlet, w3btorrent), and Azureus was built using java, so it's definitely possible. Edit: @TonyB is it limited to port 80? ","pontos":6},{"corpo":"Please don't use ActiveX... I am so sick of sites that are only viewable in IE. My actual preference, as a user, in these situations is to download a lightweight .exe file that downloads the file for you. ","pontos":4},{"corpo":"@travis Unfortunately It has to be over HTTP inside the users browser. I'll update the question to be more clear about that. ","pontos":0},{"corpo":"It really depends on how bad it is. If it's a small system, and you fully understand it, then a rewrite is not crazy. On the other hand, if it's a giant legacy monster with ten million lines of undocumented mystery code, then you're really going to have a hard time with a full rewrite. Points to consider: If it looks good to the user, they won't care what kind of spaghetti mess it is for you. On the other hand, if it's bad for them too, then it's easier to get agreement (and patience). If you do rewrite, try to do it one part at a time. A messy, disorganized codebase may make this difficult (i.e, replacing just one part requires a rewrite of large icebergs of dependency code), but if possible, this makes it a lot easier to gradually do the rewrite and get feedback from users along the way. I would really hesitate to take on a giant rewrite project for a large system without being able to release the new edition one part at a time. ","pontos":8},{"corpo":"Can you split the files into pieces and then rejoin them after the download? ","pontos":2},{"corpo":"More likely you'd put an Access database in App_Data. If you're using a MSSQL MDF file, you'll definitely still need either MSSQL or MSSQL-Express. Your question is confusing, however. You seem to interchanging data access, ORM and the actual database. You can use SubSonic with MySQL, but you cannot use LINQ to SQL with non-MS databases or MS Access. ","pontos":1},{"corpo":"It appears that I was misunderstanding how mdf files are accessed through .net. There is no MS SQL Server available on the server, so it looks like I'm screwed. ","pontos":0},{"corpo":" Doesn't using multiple open-id providers sort of undermine the point of open id? No. Say you are using a Yahoo OpenID, but you decide to move to Google instead. Multiple OpenIDs per account allows you to associate your account with the Google OpenID, then deauthorize the Yahoo OpenID. ","pontos":2},{"corpo":"git checkout -- foo That will reset to HEAD. You can also: git checkout HEAD^ foo for one revision back, etc. ","pontos":149},{"corpo":"@jjnguy I'm looking for a java applet or ActiveX component that will do that for me. These are non-technical users so we really just want to have them click download and the full file ends up in the specified location ","pontos":0},{"corpo":"@levand: My actual preference, as a user, in these situations is to download a lightweight .exe file that downloads the file for you. That's a dealbreaker for many, many sites. Users either are or should be extremely reluctant to download .exe files from websites and run them willy-nilly. Even if they're not always that cautious, incautious behaviour is not something we should encourage as responsible developers. If you're working on something along the lines of a company intranet, a .exe is potentially an okay solution, but for the public web? No way. @TonyB: What is the best way to do this without using FTP. I'm sorry, but I have to ask why the requirement. Your question reads to me along the lines of \"what's the best way to cook a steak without any meat or heat source?\" FTP was designed for this sort of thing. ","pontos":7},{"corpo":"I've had the best luck with Bazaar, followed by Mercurial. Never could get Git to work correctly. A quick search shows that Git still requires clunky emulation layers like Cygwin/MSYS, and I can't find any integration tools like TortoiseBzr for Git. With Mercurial in Windows, I had several minor issues (insensitive paths, symlinks, ). They were usually fixed eventually, but I felt that the same quality of testing was not applied to running on Windows as for the other platforms. Bazaar also had better documentation for integrating with native applications like Visual C. ","pontos":3},{"corpo":"The | operator performs a bitwise OR of its two operands (meaning both sides must evaluate to false for it to return false) while the || operator will only evaluate the second operator if it needs to. http://msdn.microsoft.com/en-us/library/kxszd0kx(VS.71).aspx http://msdn.microsoft.com/en-us/library/6373h346(VS.71).aspx ","pontos":-1},{"corpo":"|| (two pipes) is usually a logical or while | (one pipe) is a binary or. Off the top of my head, I can't think of any time the difference would be a big gotcha (other than when you're assigning the result to something else). However I sure someone else will have a situation where it matters. Edit: Wow, six other answers in the time it took me to write this. ","pontos":-1},{"corpo":"There isn't a tag for that. You would need to use javascript to show the text. Some people already suggested using JS to dynamically set CSS visible. You could also dynamically generate the text with or dynamically creating the nodes, but the CSS hack is probably the most straightforward to read. ","pontos":0},{"corpo":"The problem is, the process didn't just die, it died unexpectedly. Sounds like there's a bug in your SSH client that Vista is pointing out. ","pontos":1},{"corpo":"Amusingly, 'git checkout foo' will not work if the working copy is in a directory named foo; however, both 'git checkout HEAD foo' and 'git checkout ./foo' will: $ pwd /Users/aaron/Documents/work/foo $ git checkout foo D foo Already on \"foo\" $ git checkout ./foo $ git checkout HEAD foo ","pontos":30},{"corpo":"Did you accidentally omit a semicolon on a previous line? If the previous line is an , you might have to look elsewhere for the missing semicolon. Edit: If the rest of your code is valid C++, then there probably isn't enough information to determine what the problem is. Perhaps you could post your code to a pastebin so we can see the whole thing. Ideally, in the process of making it smaller to post, it will suddenly start working and you'll then have discovered the problem! ","pontos":1},{"corpo":"I like stored procs, dont know how many times I was able to make a change to an application using a stored procedure which didn't produce any downtime to the application. Big fan of Transact SQL, tuning large queries have proven to be very useful for me. Haven't wrote any inline SQL in about 6 years! ","pontos":9},{"corpo":" is not just for 3rd-party sources. In fact, directories are not versioned by CVS, so they are not a subject to branch policies. As long as you import empty directories, it is fine. ","pontos":2},{"corpo":"Did you write your own FormsAuth attribute for the action? If so, in the OnActionExecuting method, you get passed the FilterExecutingContext. You can use this to pass back the 401 code. public class FormsAuth : ActionFilterAttribute { public override void OnActionExecuting(FilterExecutingContext filterContext) { filterContext.HttpContext.Response.StatusCode = 401; filterContext.Cancel = true; } } This should work. I am not sure if you wrote the FormsAuth attribute or if you got it from somewhere else. ","pontos":0},{"corpo":" You can use Will Dean's suggestion [] to replace the magic number 3 here with arraysize(str_array) -- although I remember there being some special case in which that particular version of arraysize might do Something Bad (sorry I can't remember the details immediately). But it very often works correctly. The case where it doesn't work is when the \"array\" is really just a pointer, not an actual array. Also, because of the way arrays are passed to functions (converted to a pointer to the first element), it doesn't work across function calls even if the signature looks like an array is really . ","pontos":3},{"corpo":"Watch out with that quote-matching lookahead assertion. That'll only match if Boolean is the last part of a string, but not in the middle of the string. You'll need to match an even number of quote marks preceding the match if you want to be sure you're not in a string (assuming no multi-line strings and no escaped embedded quote marks). ","pontos":2},{"corpo":"I rather like this new (?) behavior because the XML document doesn't have any mention of Bar in it, so the deserializer should not even be attempting to set it. ","pontos":0},{"corpo":"Big fan of the UPSERT, really cuts down on the code to manage. Here is another way I do it: One of the input parameters is ID, if the ID is NULL or 0, you know it's an INSERT, otherwise it's an update. Assumes the application knows if there is an ID, so wont work in all situations, but will cut the executes in half if you do. ","pontos":3},{"corpo":"I would suggest: A script to quickly restore the latest backup of a database, in case it gets corrupted What kind of backups are you doing? Full backups each day, or incremental every hour, etc? Some scripts to create new users and grant them basic access. However, the number one suggestion is to limit as much as possible the power other users have, this will greatly reduce the chance of stuff getting badly messed up. Servers that have everyone as an sa tend to get screwed up quicker than servers that are locked down. ","pontos":3},{"corpo":"I know this is going to be heresy for a cygwin user, but you could just use PuTTY instead. ","pontos":0},{"corpo":"As far as I know this is not possible. You might be able to do it if you use uncompressed wave files already encoded in DTS or something and put a surround receiver in between. This will however stop you from doing anything with the sound before outputting it, not even changing the volume. And I guess that's not an option? I think going with an external application for sound would be your best choice, maybe you can do something using Director. ","pontos":0},{"corpo":"The question is ill-posed in the standard ZFC (Zermelo-Fraenkel + axiom of Choice) set theory because the object thus defined is not a set. Since (again, assuming standard ZFC) your class {x : x\\not\\in x} is not a set, the answer becomes no, it's not an element of itself (even as a class) since only sets can be elements of classes or sets. By the way, as soon as you agree to the axiom of foundation, no set can be an element of itself. Of course the nice thing about math is you can choose whichever axioms you want :) but believing in paradoxes is just weird. ","pontos":2},{"corpo":"Since your application is small, there is essentially no appreciable cost increase to using nvarchar over varchar, and you save yourself potential headaches down the road if you have a need to store unicode data. ","pontos":10},{"corpo":"I still don't understand (probably because of my poor English). You could try: ROW_NUMBER() OVER (ORDER BY dbo.human_sort(field_name) ASC) But it won't work for millions of records. That why I suggested to use trigger which fills separate column with human value. Moreover: built-in T-SQL functions are really slow and Microsoft suggest to use .NET functions instead. human value is constant so there is no point calculating it each time when query runs. ","pontos":-1},{"corpo":"This will work. It's messy because in BAT files you can't use set var=\\ like you can in unix. The fact that echo doesn't understand quotes is also messy, and could lead to trouble if contains shell meta characters. set FILENAME=%~f1 echo s/Some Pattern/%FILENAME%/ | sed -e \"s/\\\\/\\\\\\\\/g\" sedcmd.tmp sed -f sedcmd.tmp inputfile del /q sedcmd.tmp [Edited]: I am suprised that it didn't work for you. I just tested it, and it worked on my machine. I am using sed from http://sourceforge.net/projects/unxutils and using cmd.exe to run those commands in a bat file. ","pontos":2},{"corpo":"Well, I don't know what the original problem was, but when I update Cygwin recently the error message stopped popping up. My guess it that rebasing was necessary. ","pontos":0},{"corpo":"Delphi pointers are 32-bit. Period. Your Delphi developer may be able to 'store' the 64-bit values you want to return to him, but he can't access the memory that they point to, so it's pretty futile. Previously, I'd written:- A 64-bit version of Delphi is on Codegear/Embarcadero's road map for \"middle of 2009\". Product quality seems to be (at last!) taking precedence over hitting ship dates exactly, so don't hold your breath... But, in August 2010, Embarcadero published a new roadmap here. This doesn't give specific dates, but mentions a 64-bit Compiler Preview, with Projected Availability, 1st Half of 2011. ","pontos":6},{"corpo":" What does unexpectedly mean in this context? Does it mean it core dumped or just exited non-zero? It means it died with an unhandled exception, i.e. it crashed. ","pontos":0},{"corpo":"I don't think there such a feature out of the box. However, you could write a RS plugin that does this. But this would be another question... ","pontos":0},{"corpo":"Who else is involved in the database? Are you the only person making schema changes (creating new objects, releasing new stored procedures, permissioning new users)? Make sure that the number of users doing anything that could impact performance is reduced to as close to zero as possible, ideally including you. Make sure that you're testing your backups - ideally run a DEV box that is recreating the production environment periodically, 1. a DEV box is a good idea, 2. a backup is only useful if you can restore from it. Create groups for the various apps that connect to your database, so when a new user comes along you don't guess what permissions they need, just add them to the group, meanwhile permission the database objects to only the groups that need them Use indices, primary keys, foreign keys, constraints, stats and whatever other tools your database supports. Normalise. Optimise the most common code against your box - bad stored procedures/data access code will kill you. ","pontos":5},{"corpo":"I haven't used the AuthorizeAttribute that comes in Preview 4 yet. I rolled my own, because I have been using the MVC framework since the first CTP. I took a quick look at the attribute in reflector and it is doing what I mentioned above internally, except they use the hex equivalent of 401. I will need to look further up the call, to see where the exception is caught, because more than likely that is where they are doing the redirect. This is the functionality you will need to override. I am not sure if you can do it yet, but I will post back when I find it and give you a work around, unless Haacked sees this and posts it himself. ","pontos":0},{"corpo":"You might or might not already know this (R# does suffer from a lack of discoverability, unless you get the one-page key-shortcut page printed out), but ALT-INS opens a box which can at least mass-generate properties for fields. Not sure if that's any use - it's not the same as a retrospective encapsulation. ","pontos":3},{"corpo":"I'm not certain I fully understand the problem, but just to hack slash at it you could try: SELECT TOP 1 FROM cteLevelOne ORDER BY CustID DESC That assumes that the CustID is also in order as in the example, and not something like a GUID. ","pontos":1},{"corpo":"I tried learning from Programming Python and I didn't like it. I'm going to give Python in a Nutshell a try as per suggestions below. ","pontos":0},{"corpo":"Depending on your situation, you might have another option: in-license third-party code. I've consulted at a couple of companies where that would be the sensible choice, although seemingly \"throwing away IP\" can be a big barrier for management. At my current company, we seriously considered the viable option of using third-party code to replace our core framework, but that idea was ultimately rejected more for business reasons than technical reasons. To directly answer your question, we finally chose to rewrite the legacy framework - a decision we didn't take lightly! 14 months on, we don't regret this choice at all. Just considering the time spent fixing bugs, our new framework has nearly paid for itself. On the negative side, it is not quite feature-complete yet so we are in the unenviable position of maintaining two separate frameworks in parallel until we can port the last of our \"front-end\" applications. ","pontos":1},{"corpo":"I've never come across a tool that would do the job. Instead I've used individual files, numbered so that I know which order to run them: essentially, a manual version of Rails migrations, but without the rollback. Here's the sort of thing I'm talking about: 000-clean.sql # wipe out everything in the DB 001-schema.sql # create the initial DB objects 002-fk.sql # apply referential integrity (simple if kept separate) 003-reference-pop.sql # populate reference data 004-release-pop.sql # populate release data 005-add-new-table.sql # modification 006-rename-table.sql # another modification... I've never actually run into any problems doing this, but it's not very elegant. It's up to you to track which scripts need to run for a given update (a smarter numbering scheme could help). It also works fine with source control. Dealing with surrogate key values (from autonumber columns) can be a pain, since the production database will likely have different values than the development DB. So, I try never to reference a literal surrogate key value in any of my modification scripts if at all possible. ","pontos":4},{"corpo":"I don't trust programmatic migrations. If it's a simple change, such as adding a NULLable column, I'll just add it directly to the live server. If it's more complex or requires data changes, I'll write a pair of SQL migration files and test them against a replica database. When using migrations, always test the rollback migration. It is your emergency \"oh shit\" button. ","pontos":5},{"corpo":"Does make think one of the targets is failing? If so, it will stop the make after the running jobs finish. You can use -k to tell it to continue even if an error occurs. ","pontos":0},{"corpo":"C2143 basically says that the compiler got a token that it thinks is illegal in the current context. One of the implications of this error is that the actual problem may exist before the line that triggers the compiler error. As Greg said I think we need to see more of your code to diagnose this problem. I'm also not sure why you think the fact that this is valid C++ code is helpful when attempting to figure out why it doesn't compile as C? C++ is (largely) a superset of C so there's any number of reasons why valid C++ code might not be syntactically correct C code, not least that C++ treats structs as classes! ","pontos":0},{"corpo":"pylint is the best such tool I've found. Due to Python's nature it's difficult to statically analyze it, but it will catch undefined variables, basic type errors, unused code, etc. You'll want to tweak the configuration file, as by default it outputs many warnings I consider useless or harmful. Here's part of my dealing with warning silencing: [MESSAGES CONTROL] # Brain-dead errors regarding standard language features # W0142 = *args and **kwargs support # W0403 = Relative imports # Pointless whinging # R0201 = Method could be a function # W0212 = Accessing protected attribute of client class # W0613 = Unused argument # W0232 = Class has no __init__ method # R0903 = Too few public methods # C0301 = Line too long # R0913 = Too many arguments # C0103 = Invalid name # R0914 = Too many local variables # PyLint's module importation is unreliable # F0401 = Unable to import module # W0402 = Uses of a deprecated module # Already an error when wildcard imports are used # W0614 = Unused import from wildcard # Sometimes disabled depending on how bad a module is # C0111 = Missing docstring # Disable the message(s) with the given id(s). disable=W0142,W0403,R0201,W0212,W0613,W0232,R0903,W0614,C0111,C0301,R0913,C0103,F0401,W0402,R0914 ","pontos":87},{"corpo":"I forgot that in C you have to declare all your variables before any code. ","pontos":6},{"corpo":"You should check out Pyflakes, Pylint, and PyChecker. I've personally used both Pyflakes and Pylint, and found them both to be very helpful for catching those little things you hate to mess up on. Pylint generally requires a bit more configuration than Pyflakes. Also noteworthy: Eclipse's PyDev plugin comes in with a built in Pylint output parser. ","pontos":13},{"corpo":"You could use the IISReset command line tool to stop/restart iis. So you could write a simple batch file to stop iis, copy your files, and then restart iis. I'm not sure how to integrate this with the VS publish feature however. ","pontos":0},{"corpo":"There isn't much information on this out there but it seems to be their own customized controls plus an IE component (and not Qt like Google Earth). This forum thread has a little bit of information. ","pontos":1},{"corpo":"Don't you need to recompute the size of the scrollBox after the layout? ","pontos":0},{"corpo":"You shouldn't ever really need to do this. Most software that claims to require the default instance (like Great Plains or Dynamics) doesn't actually. If you repost with your situation (installed X, then Y, but need to accomplish Z) I bet you'll get some good workarounds. ","pontos":0},{"corpo":"Redmine ran fine on our Windows build server from the command line, sans IDE, using Mongrel and SQLite. Granted, ours isn't a VPS, but at any rate Linux isn't required for this app. ","pontos":2},{"corpo":"Ok, I worked around this. I made a custom ActionResult (HttpForbiddenResult) and custom ActionFilter (NoFallBackAuthorize). To avoid redirection, HttpForbiddenResult marks responses with status code 403. FormsAuthentication doesn't catch responses with this code so the login redirection is effectively skipped. The NoFallBackAuthorize filter checks to see if the user is authorized much like the, included, Authorize filter. It differs in that it returns HttpForbiddenResult when access is denied. The HttpForbiddenResult is pretty trivial: public class HttpForbiddenResult : ActionResult { public override void ExecuteResult(ControllerContext context) { if (context == null) { throw new ArgumentNullException(\"context\"); } context.HttpContext.Response.StatusCode = 0x193; // 403 } } It doesn't appear to be possible to skip the login page redirection in the FormsAuthenticationModule. ","pontos":5},{"corpo":"We just did a large AIR app that used PDF quite a bit - make sure you save yourself some heartache and write some code to check the acrobat version or that it's even installed - if they don't have it you won't get an error, just a blank HTML control. I know, it sounds obvious, but still... ","pontos":4},{"corpo":"You will have to tell us the type of data you are given. As per your last question: remember that an average can be calculated in real time by either storing the sum and the number of data points (two numbers), or the current average and the number of data points (again, two numbers). For instance: class Averager { double avg; int n; public: Averager() : avg(0), n(0) {} void addPoint(double v) { avg = (n * avg + v) / (n + 1); n++; } double average() const { return avg; } }; ","pontos":2},{"corpo":"Wikipedia: High-pass filter Low-pass filter Band-pass filter These \"high\", \"low\", and \"band\" terms refer to frequencies. In high-pass, you try to remove low frequencies. In low-pass, you try to remove high. In band pass, you only allow a continuous frequency range to remain. Choosing the cut-off frequency depends upon your application. Coding these filters can either be done by simulating RC circuits or by playing around with Fourier transforms of your time-based data. See the wikipedia articles for code examples. ","pontos":13},{"corpo":"They are generally Electrical circuits that tend to pass parts of analog signals. High pass tends to transmit more of the high frequency parts and low pass tends to pass more of the low frequency parts. They can be simulated in software. A walking average can act as a low pass filter for instance and the difference between a walking average and it's input can work as a high pass filter. ","pontos":3},{"corpo":"If you just want want the highest recursion depth couldn't you do something like this?Then, when you actually query the CTE just look for the row with max(Depth)? Like so: DECLARE @LookupID int --Our test value SET @LookupID = 1; WITH cteLevelOne (ParentID, CustID, Depth) AS ( SELECT a.ParentID, a.CustID, 1 FROM tblCustomer AS a WHERE a.CustID = @LookupID UNION ALL SELECT a.ParentID, a.CustID, c.Depth + 1 FROM tblCustomer AS a INNER JOIN cteLevelOne AS c ON a.CustID = c.ParentID WHERE c.CustID a.CustID ) select * from CTELevelone where Depth = (select max(Depth) from CTELevelone) or, adapting what trevor suggests, this could be used with the same CTE: select top 1 * from CTELevelone order by Depth desc I don't think CustomerID was necessarily what you wanted to order by in the case you described, but I wasn't perfectly clear on the question either. ","pontos":2},{"corpo":"I don't have a recommendation, but I do have some feedback on the Telerik recommendations. I can't stand their tools myself. The performance of their more complicated controls (e.g., Tree, Grid) is very sluggish and feels very un-web 2.0. ","pontos":1},{"corpo":"Module level suppression messages need to be pasted into the same file as the code that is raising the FxCop error before the namespace declaration or in assemblyinfo.cs. Additionally, you will need to have CODE_ANALYSIS defined as a conditional compiler symbols (Project > Properties > Build). Once that is in place, do a complete rebuild of project and the next time you run FxCop the error should be moved to the \"Excluded in Source\" tab. Also, one small tip, but if you are dealing with a lot of FxCop exclusions it might be useful to wrap a region around them so you can get them out of the way. ","pontos":2},{"corpo":"Try tidylib. You can get some really basic bindings as part of the elementtidy module (builds elementtrees from HTML documents). http://effbot.org/downloads/#elementtidy import _elementtidy xhtml, log = _elementtidy.fixup(\" html /html \") print log line 1 column 1 - Warning: missing !DOCTYPE declaration line 1 column 7 - Warning: discarding unexpected /html line 1 column 14 - Warning: inserting missing 'title' element Parsing the log should give you pretty much everything you need. ","pontos":4},{"corpo":"I can't reproduce this, hitting either Ctrl+E, Ctrl+A or the arrow keys updates the command line correctly. Are you running 10.5.4? Is it perhaps a bug in earlier versions? ","pontos":1},{"corpo":"In FxCop 1.36 there is actually a project option on the \"Spelling Analysis\" tab that will supress analysis for any generated code. If you don't want to turn analysis off for all generated code, you need to make sure that you add a CODE_ANALYSIS symbol to the list of conditional compilation symbols (project properties, Build tab). Without this symbol defined, the SupressMessage attributes will be removed from the compiled code so FxCop won't see them. The other problem with your SuppressMessage attribute is that you are listing a \"Target\" of a specific method name (in this case WindowsClient.MainForm.InitializeComponent():System.Void) and listing a specific \"Scope\". You may want to try removing these; otherwise you should add this SuppressMessage to each instance of the method. You should also upgrade to the RTM version of FxCop 1.36, the beta will not automatically detect the newer version. ","pontos":4},{"corpo":"We have used SQL Server Express Edition in some of our smaller applications, maybe 5+ users, and smaller databases. The 4GB is very limiting in a high transaction environments, and in some cases we have had to migrate our customer to SQL Server Standard Edition. ","pontos":2},{"corpo":"I've encountered this bug, and while I don't know how to solve it, you can work around it by pressing ","pontos":1},{"corpo":"It really comes down to the nature of your database and application. What kind of application(s) are hitting SQL Server? In my experience, it only handles 5-10 users with a heavy read/write application. ","pontos":0},{"corpo":"I don't know enough about the guts of the file systems to answer the first, except when I read the first descriptions of NTFS it sounded an awful lot like the Berkley Fast Filesystem. As for the second, there are plenty of greps for Windows. When I had to use Windows in the past, I always installed Cygwin first thing. ","pontos":0},{"corpo":"I think you are a little bit confused. There is no 'Unix' and 'Windows' file systems. The *nix family of filesystems include ext3, ZFS, UFS etc. Windows primarily has had support for FAT16/32 and their own filesystem NTFS. However today linux systems can read and write to NTFS. More filesystems here I can't tell you why one could be better than the other though. ","pontos":4},{"corpo":"First, there is no such thing as \"the Unix file system\". Second, upon what premise does your argument rest? Did you hear someone say it was superior? Perhaps if you offered some source, we could critique the specific argument. Edit: Okay, according to http://en.wikipedia.org/wiki/Comparison_of_file_systems, NTFS has more green boxes than both UFS1 and UFS2. If green boxes are your measure of \"better\", then NTFS is \"better\". Still a stupid question. :-p ","pontos":7},{"corpo":"well the *nix filesystems do a far better job of actual file managment than fat16/32 or NTFS. The *nix systems try to prevent the need for a defrag over windows doing...nothing? Other than that I don't really know what would make one better than the other. ","pontos":1},{"corpo":"This question is far too vague to be useful to you or anyone else. Also, Wikipedia is your primary source of info on SQL Server, fail? The first matrix of the MSDN page for Features Supported by the Editions of SQL Server 2008 is titled \"Scalability.\" The only edition with any features marked \"Yes\" is Enterprise (you get Partitioning, Data compression, Resource governor, and Partition table parallelism.) And it goes down the line from there, Express does not support many of the features designed for \"scale.\" If your main demand is space, how soon will you exceed 4GB? If your main demand is high availability and integrity, don't even bother with Express. \"Scalable\" is quickly becoming a weasel-/buzz-word, alongside \"robust.\" People use it when they haven't thought hard enough about what they mean. ","pontos":0},{"corpo":"One of the fundamental differences in filesystem semantics between Unix and Windows is the idea of inodes. On Windows, a file name is directly attached to the file data. This means that the OS prevents somebody from deleting a file that is currently open. On some versions of Windows you can rename a file that is currently open, and on some versions you can't. On Unix, a file name is a pointer to an inode, which is the place the file data is actually stored. This has a couple of implications: You can have two different filenames that refer to the same underlying file. This is often called a hard link. There is only one copy of the file data, so changes made through one filename will appear in the other. You can delete (also known as ) a file that is currently open. All that happens is the directory entry is removed, but this doesn't affect any other process that might still have the file open. The process with the file open hangs on to the inode, rather than to the directory entry. When the process closes the file, the OS deletes the inode because there are no more directory entries pointing at it and no more processes with the inode open. This difference is important, but it is unrelated to things like the performance of . ","pontos":18},{"corpo":"+1 on the execution plan. From here you can see where all the time is being spent in your particular query. Eg. 85% of the time is spent table scanning a particular table, can you put an index on that table to improve it? etc etc. ","pontos":0},{"corpo":"I did subclass and it was easy and did work. I still don't like it so much. I was already subclassing column styles for other reasons. I'd rather handle all databinding myself, where I can more easily change it and test it. This whole mixing of the UI with the data is old school, and not in a good way. Thanks very much for your answers, it's good to have second opinions. Mike ","pontos":0},{"corpo":"There's no easy way to find out the memory size of a python object. One of the problems you may find is that Python objects - like lists and dicts - may have references to other python objects (in this case, what would your size be? The size containing the size of each object or not?). There are some pointers overhead and internal structures related to object types and garbage collection. Finally, some python objects have non-obvious behaviors. For instance, lists reserve space for more objects than they have, most of the time; dicts are even more complicated since they can operate in different ways (they have a different implementation for small number of keys and sometimes they over allocate entries). There is a big chunk of code (and an updated big chunk of code) out there to try to best approximate the size of a python object in memory. There's also some simpler approximations. But they will always be approximations. You may also want to check some old description about PyObject (the internal C struct that represents virtually all python objects). ","pontos":55},{"corpo":"The trunk should generally be your main development source. Otherwise you will spend a lot of time merging in new features. I've seen it done the other way and it usually leads to a lot of last minute integration headaches. We label our releases so we can quickly respond to production emergencies without distribing active development. ","pontos":2},{"corpo":"Attempting to manage maintenance of current production code in line with new development is problematic at best. In order to mitigate those problems code should branch into a maintenance line once testing efforts have completed and the code is ready for delivery. Additionally, the mainline should branch to assist in release stabilization, to contain experimental development efforts, or to house any development efforts whose lifecycle extends across multiple releases. A non-maintenance branch should be created only when there is the likelihood (or certainty) of collisions among the code that would be difficult to manage any other way. If the branch does not solve a logistical problem, it will create one. Normal release development occurs in the mainline. Developers check into and out of the mainline for normal release work. Development work for patches to current Production code should be in the branch for that release and then merged with the mainline once the patch has passed testing and is deployed. Work in non-maintenance branches should be coordinated on a case-by-case basis. ","pontos":4},{"corpo":"For me, it depends on the software I'm using. Under CVS, I would just work in \"trunk\" and never tag/branch, because it was really painful to do otherwise. In SVN, I would do my \"bleeding edge\" stuff in trunk, but when it was time to do a server push get tagged appropriately. I recently switching to git. Now I find that I never work in trunk. Instead I use a named \"new-featurename\" sandbox branch and then merge into a fixed \"current-production\" branch. Now that I think about it, I really should be making \"release-VERSIONNUMBER\" branches before merging back into \"current-production\" so I can go back to older stable versions... ","pontos":1},{"corpo":"If you are gonna be working through a release cycle, big feature, you get marooned to a branch. Otherwise we work in trunk, and branch for every production release at the moment we build. Previous production builds are moved at that time to old_production_ and current prod release is always just production. All our build server knows about production is how to deploy the production branch, and we kick that build off with a force trigger. ","pontos":2},{"corpo":"You may get both added and removed lines with git log, like: git log --shortstat --reverse --pretty=oneline From this, you can write a similar script to the one you did using this info. In python: #!/usr/bin/python \"\"\" Display the per-commit size of the current git branch. \"\"\" import subprocess import re import sys def main(argv): git = subprocess.Popen([\"git\", \"log\", \"--shortstat\", \"--reverse\", \"--pretty=oneline\"], stdout=subprocess.PIPE) out, err = git.communicate() total_files, total_insertions, total_deletions = 0, 0, 0 for line in out.split('\\n'): if not line: continue if line[0] != ' ': # This is a description line hash, desc = line.split(\" \", 1) else: # This is a stat line data = re.findall( ' (\\d+) files changed, (\\d+) insertions\\(\\+\\), (\\d+) deletions\\(-\\)', line) files, insertions, deletions = ( int(x) for x in data[0] ) total_files += files total_insertions += insertions total_deletions += deletions print \"%s: %d files, %d lines\" % (hash, total_files, total_insertions - total_deletions) if __name__ == '__main__': sys.exit(main(sys.argv)) ","pontos":19},{"corpo":"It depends on the size of your development effort. Multiple teams working in parallel won't be able to work effectively all on the same code (trunk). If you have just a small group of people working and your main concern is cutting a branch so you can continue to work while going back to the branch for making bug-fixes to the current production code that would work. This is a trivial use of branching and not too burdensome. If you have a lots of parallel development you'll want to have branches for each of the efforts but that'll also require more discipline: Making sure your branches are tested and ready to merge back. Scheduling merges so two groups aren't trying to merge at the same time etc. Some branches are under development for so long that you have to permit merges from the trunk to the branch in order to reduce the number of surprises when finally merging back to the trunk. You will have to experiment if you have a large group of developers and get a feel for what works in your situation. Here is a page from Microsoft that may be somewhat useful: http://msdn.microsoft.com/en-us/library/aa730834(VS.80).aspx ","pontos":4},{"corpo":"While nifty, the revision keyword trick only updates the file when it's changed in that revision - if you don't change the file, then it will continue to reflect the old revision. If you want the software to always reflect the overall revision number, then you'll have to delve into the relevant SVN entries file and extract it, which isn't too difficult (it's an XML file). Wikipedia does this on their version page to indicate the revision of the software that's running live; the code is here - look for the getSvnRevision() method. ","pontos":12},{"corpo":"I used to get these all the time on Apache1/fastcgi. I think it's caused by fastcgi hanging up before Ruby is done. Switching to mongrel is a good first step, but there's more to do. It's a bad idea to cull from web services on live pages, particularly from Rails. Rails is not thread-safe. The number of concurrent connections you can support equals the number of mongrels (or Passenger processes) in your cluster. If you have one mongrel and someone accesses a page that calls a web service that takes 10 seconds to time out, every request to your website will timeout during that time. Most of the load balancers just cycle through your mongrels blindly, so if you have two mongrels, every other request will timeout. Anything that can be unpredictably slow needs to happen in a job queue. The first hit to /slow/action adds the job to the queue, and /slow/action keeps on refreshing via page refreshes or queries via ajax until the job is finished, and then you get your results from the job queue. There are a few job queues for Rails nowadays, but the oldest and probably most widely used one is BackgroundRB. Another alternative, depending on the nature of your app, is to cull the service every N minutes via cron, cache the data locally, and have your live page read from the cache. ","pontos":2},{"corpo":"Chris, They're different beasts. WHS backup is pretty much automatic and uses deltas - Vista's is manual and I don't believe offers incremental updates. While your solution (Vista + network copy) would preserve your data it has two problems I an see; Your documents will only have the latest revision. If you find something was corrupted a month ago it could be very awkward to recover it. Vista's shadow copies may help though. As soon as you install a program/patch/config your Vista backup is out of date and needs remade, or these repeated if you reinstall. These might not be dealbreakers and indeed Vista's backup is pretty decent, it's just nowhere near as good as WHS. In my opinion WHS leaves almost everything else standing, you can be sure this tech will be in the \"big brother\" server versions shortly. ","pontos":4},{"corpo":"You should do as much client-side processing as possible. This will enable your application to scale better than doing processing server-side. To solve your temperamental user problem, you could look into making your client processes run at a very low priority so there's no noticeable decrease in performance on the part of the user. ","pontos":3},{"corpo":"Your simplest answer lies in the next version of css (3), which currently no browser supports. For now you are relegated to calculating heights in javascript and setting them on the left side. If the navigation is so important to be positioned in such a way, run it along the top. you could also do a visual trick by moving the borders to the container and the bigger inner, and make it appear to be the same size. this makes it look the same, but it isn't. div style=\"border-left:solid 1px black;border-bottom:solid 1px black;\" div style=\"float:left; width: 150px; border-top: 1px solid;\" ul li nav1 /li li nav2 /li li nav3 /li li nav4 /li /ul /div div style=\"float:left; width: 250px; border:solid 1px black;border-bottom:0;\" Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna Lorem ipsum dolor sit amet, consectetur adipisicing elit, ... /div div style=\"clear:both;\" /div /div ","pontos":9},{"corpo":"@hoyhoy If a designer can make this work in html, then he can have this design. If he is a true master of web design, he will realize that this is a limitation of the media, as video is not possible in magazine ads. If he would like to simulate weight by giving the 2 columns equal importance, than change the borders, so that they appear to be of the same weight, and make the colors of the borders contrast to the font color of the columns. But as for making the physical elements the same height, you can only do that with a table construct, or setting the heights, at this point in time. To simulate them appearing the same size, they don't have to be the same size. ","pontos":0},{"corpo":"The Haskell wikibook: http://en.wikibooks.org/wiki/Haskell which includes the text from the great tutorial Yet Another Haskell Tutorial. (The \"Generic Haskell User Guide\" paper is a fine paper, but I think it is a particularly bad recommendation for a beginning Haskell programmer, as it is more of an academic paper presenting extensions to Haskell and basically a different language \"Generic Haskell\" (i.e. Haskell with an old version of Generics) instead of standard Haskell 98. irony If you were looking for dense reading about Haskell, start with the Haskell 98 report. /irony ) ","pontos":11},{"corpo":"We bootstrapped with subsonic and are now trying to evaluate if we are going to switch to nhibernate now that we are at the pain points of subsonic. Our other option is to create some middle ground where we use subsonic to query and load up arbitrary objects with their \"execute as typed list\" functionality that does a name based mapping off of an arbitrary linq style sql statement. Or to try and recreate some of it in nhibernate and refactor the rest. So I say subsonic makes sense in small apps, but maintenance on subsonic apps gets pretty hairy, we have especially hard times with overlapping validation code, and pre/post in code triggered events. For an active record pattern, subsonic is definitely 80% there, but does somethings in a flaky way, and stops you from having any real control over your inheritance hierarchy, since every class must inherit a table to get back to that table. ","pontos":3},{"corpo":"There are several key aspects to multi-agent computing, distribution and independence are among them. Multi-agents don't have to be on different machines, they could as @Kyle says, be multiple processes on a single chip or machine, but they act without explicit centralised direction. They might act in concert, so they have certain synchronisation rules - doing their jobs separately before coming together to compare results, for example. Generally though the reasoning behind the segmentation into separate agents is to allow for differing priorities to guide each agent's actions and reactions. Perhaps using an economic model to divide up common resources or because the different functions are physically separated so don't need to interact tightly with each other. sweeping generalisation Is it something to ignore? Well it's not really anything in particular so it's a little like \"can I ignore the concept of quicksort?\" If you don't understand what quicksort is then you're not going to fail to be a developer because most of your life will be totally unaffected. If you have more understanding of different architectures and models, you'll have more knowledge to deploy in new and unpredictable places. sweeping generalisation Ten years ago, 'multi-agent systems' (MAS) was one of those phrases that appeared everywhere in the academic literature. These days it is less prevalent, but some of the ideas it represents are really useful in some places. But totally unnecessary in others. So I hope that's clear ;) ","pontos":3},{"corpo":"My favorite Monad tutorial: http://www.haskell.org/haskellwiki/All_About_Monads (out of 170,000 hits on a Google search for \"monad tutorial\"!) @Stu: The point of monads is to allow you to add (usually) sequential semantics to otherwise pure code; you can even compose monads (using Monad Transformers) and get more interesting and complicated combined semantics, like parsing with error handling, shared state, and logging, for example. All of this is possible in pure code, monads just allow you to abstract it away and reuse it in modular libraries (always good in programming), as well as providing convenient syntax to make it look imperative. Haskell already has operator overloading[1]: it uses type classes much the way one might use interfaces in Java or C# but Haskell just happens to also allow non-alphanumeric tokens like + and > as infix identifiers. It's only operator overloading in your way of looking at it if you mean \"overloading the semicolon\" [2]. It sounds like black magic and asking for trouble to \"overload the semicolon\" (picture enterprising Perl hackers getting wind of this idea) but the point is that without monads there is no semicolon, since purely functional code does not require or allow explicit sequencing. This all sounds much more complicated than it needs to. sigfpe's article is pretty cool but uses Haskell to explain it, which sort of fails to break the chicken and egg problem of understanding Haskell to grok Monads and understanding Monads to grok Haskell. [1] This is a separate issue from monads but monads use Haskell's operator overloading feature. [2] This is also an oversimplification since the operator for chaining monadic actions is >>= (pronounced \"bind\") but there is syntactic sugar (\"do\") that lets you use braces and semicolons and/or indentation and newlines. ","pontos":10},{"corpo":"I really like python, it's usually my language of choice these days for small (non-gui) stuff that I do on my own. However, for some larger Python projects I've tackled, I'm finding that it's not quite the same as programming in say, C++. I was working on a language parser, and needed to represent an AST in Python. This is certainly within the scope of what Python can do, but I had a bit of trouble with some refactoring. I was changing the representation of my AST and changing methods and classes around a lot, and I found I missed the strong typing that would be available to me in a C++ solution. Python's duck typing was almost too flexible and I found myself adding a lot of code to try to check my types as the program ran. And then I couldn't really be sure that everything was properly typed unless I had 100% code coverage testing (which I didn't at the time). Actually, that's another thing that I miss sometimes. It's possible to write syntactically correct code in Python that simply won't run. The compiler is incapable of telling you about it until it actually executes the code, so in infrequently-used code paths such as error handlers you can easily have unseen bugs lurking around. Even code that's as simple as printing an error message with a % format string can fail at runtime because of mismatched types. I haven't used Python for any GUI stuff so I can't comment on that aspect. ","pontos":10},{"corpo":"+1 on the Clbuttic mistake, I think it is important for \"bad word\" filters to scan for both leading and trailing spaces (e.g., \" ass \") as opposed for just the exact string so that we won't have words like clbuttic, clbuttes, buttert, buttess, etc. ","pontos":3},{"corpo":"I thought most of the virus scanners nowadays use sandbox techniques to check for \"bad\" behavior. Therefore the polymorphic virusses will also be detected. of course these detection techniques are also known to virus creators, and can easily be bypassed using a bunch of random, unharmfull, code executions before the actual payload. ","pontos":2},{"corpo":" is a class attribute, not an instance attribute. It shows up in , but not in . The distinction is obscured somewhat because when you access an attribute on an instance, the class dict is a fallback. So in the above example, will give you the value of . ","pontos":35},{"corpo":"I believe that os.system just invokes whatever command shell is configured for the user, so I don't think you can do it in a platform independent way. My command shell could be anything from bash, emacs, ruby, or even quake3. Some of these programs aren't expecting the kind of arguments you are passing to them and even if they did there is no guarantee they do their escaping the same way. ","pontos":3},{"corpo":"Refactoring is inevitable on larger codebases and the lack of static typing makes this much harder in python than in statically typed languages. ","pontos":2},{"corpo":"These articles may help: Git vs. Mercurial: Please Relax (Git is MacGyver and Mercurial is James Bond) The Differences Between Mercurial and Git Edit: Comparing Git and Mercurial to celebrities seems to be a trend. Here's one more: Git is Wesley Snipes, Mercurial is Denzel Washington ","pontos":345},{"corpo":"I think the VB6 units are not the same with the VB.Net one. So you have to do a conversion. ","pontos":0},{"corpo":"Sometime last year I evaluated both git and hg for my own use, and decided to go with hg. I felt it looked like a cleaner solution, and worked better on more platforms at the time. It was mostly a toss-up, though. More recently, I started using git because of git-svn and the ability to act as a Subversion client. This won me over and I've now switched completely to git. I think it's got a slightly higher learning curve (especially if you need to poke around the insides), but it really is a great system. I'm going to go read those two comparison articles that John posted now. ","pontos":5},{"corpo":"This is what I use: def shellquote(s): return \"'\" + s.replace(\"'\", \"'\\\\''\") + \"'\" The shell will always accept a quoted filename and remove the surrounding quotes before passing it to the program in question. Notably, this avoids problems with filenames that contain spaces or any other kind of nasty shell metacharacter. Udpdate: If you are using Python 3.3 or later, use shlex.quote instead of rolling your own. ","pontos":33},{"corpo":"Perhaps you have a specific reason for using . But if not you should probably be using the module. You can specify the pipes directly and avoid using the shell. The following is from PEP324: Replacing shell pipe line ------------------------- output=`dmesg | grep hda` == p1 = Popen([\"dmesg\"], stdout=PIPE) p2 = Popen([\"grep\", \"hda\"], stdin=p1.stdout, stdout=PIPE) output = p2.communicate()[0] ","pontos":45},{"corpo":"As a quick answer I would say to come up with a series of categories and have switchable logging levels, e.g. info, warning, error, critical, etc. Then make it easy to set the logging level to tune the level of detail that you need. Typically, set the logging level in a config file and stop and restart the app. I would also publicize to the developers what the meaning is for each of the levels. edit: I would also set up a system to rotate out, compress and archive log files on a regular basis, maybe nightly. ","pontos":1},{"corpo":"I'm afraid there is no way you can do it without PInvoke. To give focus to some window you should call SetForegroundWindow function, see this article for details. ","pontos":0},{"corpo":"For persistence.xml, specifically, you can put a persistence unit in a separate JAR, which you can deploy separately from your web application WAR, or both together in an EAR archive, depending on what your application server supports. For example, the JBoss manual describes this as Deploy EAR with EJB3 JAR. For struts-config.xml I expect that you are going to have to override the Struts code that loads it, if you want to use a non-standard location. I don't know about the Velocity templates. In general, web applications only load resources from within the WAR, for security reasons. There are other techniques you can use, but you may find it easier to try weblets, which seems to be a framework designed to let you load resources from a separate JAR. ","pontos":0},{"corpo":"This depends on whether you're talking about a closed QA review and a public beta. If it's a public beta it's not advisable to let users directly edit your bug list. Someone should be assigned to aggregate user comments and reports and discern which are actual bugs and which are duplicates and which give some sort of clue on how to replicate them. If this, however, is a bug item that is posted by your legitimate QA personnel, you have a competence problem with regards to your employees. Proper guidelines must be set on how to report bugs, especially in getting replication steps straight. ","pontos":0},{"corpo":"Write a good but not too lengthy tutorial on using the tracker and what is required for each field. Make a general purpose reference example that others can use if they get stuck. I have a reference copy for editing Docbook manual pages and by using this repeatedly I already know most of the syntax by heart. ","pontos":1},{"corpo":" Is it better to go all the way and log everything across multiple attempts/days, or log only what you need to (given hdd is cheap). The fact harddrives are cheap really isn't a good reason to verbosely log everything possible, for a few reasons.. For one, with a very busy application, you really don't want to slow it down and tie up disc-writes writing logs (harddrives are pretty slow). The second point, and the more important one - there's really very little to gain from terabytes worth of logs.. For development, they can are useful, but you don't need to keep more than a few minutes of them.. Some logging is of course useful, having different levels is about the only way to go about it - for example debug() info() only get logged if requested (in a config, or command line flag), then maybe warning() and error() get sent to a log file For most of the things I've written (smallish scripts) I generally just have a debug() function, that checks if --verbose is set, and prints the message.. That way I can shove debug(\"some value: %s\" % (avar)) when needed, and not have to worry about going back and removing debugging print() statements everwhere. For web applications, I generally just use the web-server logs for statistics, and the error log. I use things like mod_rewrite's log when needed, but it would be idiotic to leave this enabled beyond development (as it creates many many lines on each page request) I suppose it depends on the application itself, but generally, for big applications use multiple levels of logs that can be activated when needed. For smaller things, a --verbose flag or equivalent, for web applications, log errors and (to a point) log hits. Basically, in \"production\" log only the information you can use, in development log everything you could possible need to fix problems. ","pontos":2},{"corpo":"I've worked with both techniques and I would say that developing on the trunk and branching off stable points as releases is the best way to go. Those people above who object saying that you'll have: Constant build problems for daily builds Productivity loss when a a developer commits a problem for all other people on the project have probably not used continuous integration techniques. It's true that if you don't perform several test builds during the day, say once every hour or so, will leave themselves open to these problems which will quickly strangle the pace of development. Doing several test builds during the day quickly folds in updates to the main code base so that other's can use it and also alerts you during the day if someone has broken the build so that they can fix it before going home. As pointed out, only finding out about a broken build when the nightly build for running the regression tests fails is sheer folly and will quickly slow things down. Have a read of Martin Fowler's paper on Continuous Integration. We rolled our own such system for a major project (3,000kSLOC) in about 2,000 lines of Posix sh. ","pontos":65},{"corpo":"Nothing. They both do the same, both perform about equally. The only reason you should choose one over the other is if you help out with a project that already uses one.. The other possible reason for choosing one is an application or service which only supports one of the system.. For example, I pretty much chose to learn git because of github.. ","pontos":11},{"corpo":"To remove a file entirely from a git repository (Say you commited a file with a password in it, or accidently commited temporary files) git filter-branch --index-filter 'git update-index --remove filename' HEAD Then I think you have to commit, and push -f if it's in remote branches (remember it might annoy people if you start changing the repository's history.. and if they have pulled from you before, they could still have the file) ","pontos":2},{"corpo":"Premature optimization is the root of all evil. 15K coordinates aren't that much. Why not iterate over the 15K coordinates and see if that's really a performance problem? You could save a lot of work and maybe it never gets too slow to even notice. ","pontos":0},{"corpo":"+1 flot, requires jQuery though, so might not play well with GWT, I haven't used that. ","pontos":0},{"corpo":"I tried mono 1.9.1 (Mono 2.0 beta) and had some problems with sorting, generated columns, and some nasty exceptions. ","pontos":3},{"corpo":"I used to think that the quality of the bug report was tantamount. I still think so... bugs that I report have much more useful information in them than the ones entered by QA or by Operations. However, I've come around to admiring FogBugz's model. It's extremely simple to enter a bug. Just knowing there is an error condition is helpful, even if there's not a lot of supporting information. Plus, users feel like something is getting done. ","pontos":3},{"corpo":"I'd use a database simply for maintainability - also multiple edits on a file may cause some getting missed out. ","pontos":1},{"corpo":"I think that an unordered_map and hash_map are more or less the same thing. The difference is that the STL doesn't officially have a hash_map (what you're using is probably a compiler specific thing), so unordered_map is the fix for that omission. unordered_map is just that... unordered. You can't depend on it preserving any ordering on iteration. ","pontos":0},{"corpo":"@wesc: STL has std::map... so what's the difference with unordered_map? I don't think STL would implement twice the same thing and call it differently. ","pontos":-2},{"corpo":"I can think of a couple of reasons: A modicum of security by obscurity - it's slightly more work to tamper with POST submissions than GET Caching and resubmit rules are more restrictive for POST than GET. I'm not entirely sure this would matter for the OpenID use case, though. Bots wouldn't follow the POST form, but would follow the redirect. This could impact server load. Different browsers have different max lengths for GET requests - but none of them are as large as POST. Some browsers will warn on redirect to another domain. They'll also warn if you're submitting POST to a non-HTTPS url. By turning JavaScript off, I can have a relatively secure experience, and not be silently redirected to another domain. I don't know that any of these are a slam-dunk reason to choose POST - unless the amount of data being sent exceeds the querystring length for some major browser. ","pontos":6},{"corpo":"I'm assuming that the part the doesn't work is . Django will be trying a dictionary lookup, but using the string and not the value of the loop variable. Django did the same thing when it resolved to the attribute of the object, rather than looking for a variable called . I think you will need to do some preprocessing of the data in your view before you render it in your template. ","pontos":7},{"corpo":"Sorry, read your last comment wrong. Yes, hash_map is not in STL, map is. But unordered_map and hash_map are the same from what I've been reading. map -> log (n) insertion, retrieval, iteration is efficient (and ordered by key comparison) hash_map/unordered_map -> constant time insertion and retrieval, iteration time is not guarantee to be efficient Neither of these will work for you by themselves, since the map orders things based on the key content, and not the insertion sequence (unless your key contains info about the insertion sequence in it). You'll have to do either what you described (list + hash_map), or create a key type that has the insertion sequence number plus an appropriate comparison function. ","pontos":2},{"corpo":"How about a dictionary? Something like this: myStruct = {'field1': 'some val', 'field2': 'some val'} Then you can use this to manipulate values: print myStruct['field1'] myStruct['field2'] = 'some other values' And the values don't have to be strings. They can be pretty much any other object. ","pontos":39},{"corpo":"There is at least one definite reason to go for storing in the database. You can use INSERT DELAYED in MySQL (or similar constructs in other databases), which returns immediately. You won't get any return data from the database with these kinds of queries, and they are not guaranteed to be applied. By using INSERT DELAYED, you won't slow down your app to much because of the logging. The database is free to write the INSERTs to disk at any time, so it can bundle a bunch of inserts together. You need to watch out for using MySQL's built in timestamp function (like CURRENT_TIMESTAMP or CUR_DATE()), because they will be called whenever the query is actually executed. So you should make sure that any time data is generated in your programming language, and not by the database. (This paragraph might be MySQL-specific) ","pontos":9},{"corpo":"If your enumerated values are dense enough, you can define an array to hold the strings and just look them up (use NULL for any skipped value and add a special case handler on your lookup routine). char *DogList[] = { \"vizsla\", /* element 0 */ NULL, NULL, NULL, \"terrier\", /* element 3 */ ... }; This is inefficient for sparse enumerations. Even if the enumeration is not dense, you can use an array of structs to hold the mapping. typedef struct DogMaps { DogType index; char * name; } DogMapt; DogMapt DogMap[] = { {kVizsla, \"vizsla\"}, {kTerrier, \"terrier\"}, {kYellowLab, \"yellow lab\"}, NULL }; The second approach is very flexible, but it does mean a search through the mapping every time you need to use the data. For large data sets consider a b-tree or hash instead of an array. Either method can be generalized to connect more data. In the first use an array of structs, in the second just add more members to the struct. You will, of course, want to write various handlers to simplify your interaction with these data structures. @Hershi By all means, separate code and data. The above examples are meant to be clear rather than functional. I blush to admit that I still use whitespace separated flat files for that purpose, rather than the kind of structured input you exhibit, but my production code would read as much of the data from external sources as possible. Wait, I see that you mean code generation. Sure. Nothing wrong with that. I suspect, though that the OP was interested in what the generated code should look like... ","pontos":1},{"corpo":"You're going to have to use triggers for that. ","pontos":2},{"corpo":"a defaul constraint only works on inserts, for an update use a trigger ","pontos":4},{"corpo":"My suggestion would be to create a stored procedure which defaults the lastUpdate to getdate(). I've tried to avoid triggers in the past because pre-SQL2005 locating and editing them was a pain in the rump. Especially for developers who are new to your project. Also add that as the default value for your column definition. ","pontos":-1},{"corpo":"Without a shadow of a doubt it's memory, unless of course you already have 4GB. It's relatively cheap these days, tends to speed everything up pretty darn well and just seems to have the best 'bang for your buck' when it comes to hardware upgrades. ","pontos":4},{"corpo":"I would reformat Then add more ram ","pontos":0},{"corpo":" Apparently, gcc doesn't behave like the one described in The C Programming language, where it says that the command cc helloworld.c produces a file called a.out which can be run by typing a.out on the prompt. A Unix hasn't behaved in that way by default (so you can just write the executable name without ./ at the front) in a long time. It's called a.exe, because else Windows won't execute it, as it gets file types from the extension. ","pontos":1},{"corpo":"Is it possible that the exception is being thrown in another thread? Obviously your calling code is single threaded, but maybe the library you are consuming is doing some multithreaded operations under the covers. ","pontos":3},{"corpo":" dF: that's pretty cool... I didn't know that I could access the fields in a class using dict. Mark: the situations that I wish I had this are precisely when I want a tuple but nothing as \"heavy\" as a dictionary. You can access the fields of a class using a dictionary because the fields of a class, its methods and all its properties are stored internally using dicts (at least in Cython). ...Which leads us to your second comment. Believing that Python dicts are \"heavy\" is an extremely non-pythonistic concept. And reading such comments kills my Python Zen. That's not good. You see, when you declare a class you are actually creating a pretty complex wrapper around a dictionary - so, if anything, you are adding more overhead than by using a simple dictionary. An overhead which, by the way, is meaningless in any case. If you are working on performance critical applications, use C or something. ","pontos":13},{"corpo":"Across how many files? If you just want to separate class definitions from implementation then try this article in the C++ faqs. That's about the only way I know of that works at the moment, but some IDEs (Eclipse CDT for example) won't link this method properly and you may get a lot of errors. However writing your own makefiles or using Visual C++ this has always worked for me :-) ","pontos":5},{"corpo":"Use a WD Raptor or even VelociRaptor as system disk and have a larger lower noise disk for your data. ","pontos":1},{"corpo":"Regardless of whether the assembly has been compiled as a release build the exception should certainly 'bubble' up to the caller, there's no reason an assembly not being compiled in debug mode should have any affect on that. I'd agree with Daniel is suggesting that perhaps the exception is occurring on a separate thread - try hooking the thread exception event in Application.ThreadException. This should be raised when any unhandled thread exception occurs. You could adapt your code thus:- using System.Threading; ... void Application_ThreadException(object sender, ThreadExceptionEventArgs e) { throw new ParserException(e.Exception.Message, e.Exception); } ... var exceptionHandler = new ThreadExceptionEventHandler(Application_ThreadException); Application.ThreadException += exceptionHandler; try { // Execution stopped at parser.prog() TimeDefParser.prog_return prog_ret = parser.prog(); return prog_ret == null ? null : prog_ret.value; } catch (Exception ex) { throw new ParserException(ex.Message, ex); } finally { Application.ThreadException -= exceptionHandler; } ","pontos":8},{"corpo":"You can set up VS.Net to break as soon as any exception occurs. Just run your project in debug mode, and it will stop as soon as the exception is thrown. Then you should have a better idea of why it isn't being caught. Also, you can put some code in to catch all unhandled exceptions. Read the link for more info, but the basics are these two lines. Application.ThreadException += new ThreadExceptionEventHandler(ThreadExceptionHandler); // Catch all unhandled exceptions in all threads. AppDomain.CurrentDomain.UnhandledException += new UnhandledExceptionEventHandler(UnhandledExceptionHandler); ","pontos":2},{"corpo":"I finally revisited this topic, and, using help from BrokenGlass on writing WAVE header, updated csvorbis. I've added an OggDecodeStream that can be passed to to simply play any (compatible) Ogg Vorbis stream. Example usage: using (var file = new FileStream(oggFilename, FileMode.Open, FileAccess.Read)) { var player = new SoundPlayer(new OggDecodeStream(file)); player.PlaySync(); } 'Compatible' in this case means 'it worked when I tried it out'. The decoder is fully managed, works fine on Microsoft .Net - at the moment, there seems to be a regression in Mono's that causes distortion. Outdated: I am surprised but the method Dinah mentioned actually works. However, I was thinking about playing short \"jingle\" sounds on various events occurring in the program, I don't want to launch user's media player each time I need to do a 'ping!' sound. As for the code project link - this is unfortunately only a P/Invoke wrapper. ","pontos":6},{"corpo":"Oh and in reference to what Kibbee said; if you select Debug|Exceptions in VS and just click all the boxes in the 'thrown' column it should pick everything up AFAIK as a 'first chance exception', i.e. VS will indicate when the exception is about to be processed by everything else and break on the relevant code. This should help with debugging. ","pontos":1},{"corpo":"I'm completely inexperienced with yaws, but I have a troubleshooting suggestion: What happens if you remove the config file completely? If it still starts yaws without a config file, that could be a clear sign that something is being cached. For what it's worth, with a quick 5 minutes of googling, I found no mention of any caching behavior. ","pontos":0},{"corpo":"I agree with the others -- set a default value of GetDate() on the LastUpdate column and then use a trigger to handle any updates. Just something simple like this: CREATE TRIGGER KeepUpdated on Profiles FOR UPDATE, INSERT AS UPDATE dbo.Profiles SET LastUpdate = GetDate() WHERE Username IN (SELECT Username FROM inserted) If you want to get really fancy, have it evaluate what's being changed versus what's in the database and only modify LastUpdate if there was a difference. Consider this... 7am - User 'jsmith' is created with a last name of 'Smithe' (oops), LastUpdate defaults to 7am 8am - 'jsmith' emails IT to say his name is incorrect. You immediately perform the update, so the last name is now 'Smith' and (thanks to the trigger) LastUpdate shows 8am 2pm - Your slacker coworker finally gets bored with StumbleUpon and checks his email. He sees the earlier message from 'jsmith' regarding the name change. He runs: UPDATE Profiles SET LastName='Smith' WHERE Username='jsmith' and then goes back to surfing MySpace. The trigger doesn't care that the last name was already 'Smith', however, so LastUpdate now shows 2pm. If you just blindly change LastUpdate whenever an update statement runs, it's TECHNICALLY correct because an update did happen, but it probably makes more sense to actually compare the changes and act accordingly. That way, the 2pm Update statement by the coworker would still run, but LastUpdate would still show 8am. --Kevin ","pontos":20},{"corpo":" \"Also, you can put some code in to catch all unhandled exceptions. Read the link for more info, but the basics are these two lines.\" This is false. This used to catch all unhandled exceptions in .NET 1.0/1.1 but it was a bug and it wasn't supposed to and it was fixed in .NET 2.0. AppDomain.CurrentDomain.UnhandledException Is only intended to be used as a last chance logging saloon so you can log the exception before the program exits. It wont catch the exception as of 2.0 onwards (although in .NET 2.0 at least there is a config value you can modify to make it act like 1.1 but it isn't recommended practice to use this.). Its worth noting that there are few exceptions that you cannot catch, such as StackOverflowException and OutOfMemoryException. Otherwise as other people have suggested it might be an exception in a background thread somewhere. Also I'm pretty sure you can't catch some/all unmanaged/native exceptions either. ","pontos":0},{"corpo":"I don't get it...your catch block just throws a new exception (with the same message). Meaning that your statement of: The problem is that in some cases (not all) that my try/catch block won't catch it and instead stops execution as an unhandled exception. is exactly what is expected to happen. ","pontos":0},{"corpo":" Are there any general advice or workarounds for organizing or redistributing templated member definitions across multiple files? Yes; don't. The C++ spec permits a compiler to be able to \"see\" the entire template (declaration and definition) at the point of instantiation, and (due to the complexities of any implementation) most compilers retain this requirement. The upshot is that #inclusion of any template header must also #include any and all source required to instantiate the template. The easiest way to deal with this is to dump everything into the header, inline where posible, out-of-line where necessary. If you really regard this as an unacceptable affront, a common option is to split the template into the usual header/implementation pair, and then #include the implementation file at the end of the header. C++'s \"export\" feature may or may not provide another workaround. The feature is poorly supported and poorly defined; although it in principle should permit some kind of separate compilation of templates, it doesn't necessarily obviate the demand that the compiler be able to see the entire template body. ","pontos":21},{"corpo":"I agree with Daniel Auger and kronoz that this smells like an exception that has something to do with threads. Beyond that, here are my other questions: What does the complete error message say? What kind of exception is it? Based on the stack trace you've provided here, isn't the exception thrown by you code in TimeDefLexer.mTokens()? ","pontos":0},{"corpo":"It depends on what kind of sanitizing you are doing. For protecting against SQL injection, don't do anything to the data itself. Just use prepared statements, and that way, you don't have to worry about messing with the data that the user entered, and having it negatively affect your logic. You have to sanitize a little bit, to ensure that numbers are numbers, and dates are dates, since everything is a string as it comes from the request, but don't try to do any checking to do things like block keywords or anything. For protecting against XSS attacks, it would probably be easier to fix the data before it's stored. However, as others mentioned, sometimes it's nice to have a pristine copy of exactly what the user entered, because once you change it, it's lost forever. It's almost too bad there's not a fool proof way to ensure you application only puts out sanitized HTML the way you can ensure you don't get caught by SQL injection by using prepared queries. ","pontos":7},{"corpo":"There's no standard way to do this. Further, the call stack must typically be recorded at the time of the exception being thrown; once it has been caught the stack has unrolled, so you no longer know what was going on at the point of being thrown. In VC++ on Win32/Win64, you might get usable-enough results by recording the value from the compiler intrinsic _ReturnAddress() and ensuring that your exception class constructor is __declspec(noinline). In conjunction with the debug symbol library, I think you could probably get the function name (and line number, if your .pdb contains it) that corresponds to the return address using SymGetLineFromAddr64. ","pontos":1},{"corpo":"Yeah there is nothing different about throwing exceptions in using blocks. Remember that the using block basically translates to: IDisposable disposable = null; try { disposable = new WhateverYouWantedToMake(); } finally { disposable.Dispose() } So you will have to roll your own catching if you want to catch anything but catching/throwing is a completely separate concern from the using. The finally is almost guaranteed to execute (save an uncatchable exception (e.g. stackoverflow or outofmemory) or someone pulling the power out of the PC). ","pontos":4},{"corpo":"I don't really understand the question - you throw an exception as you normally would. If implements , then: using ( MyThing thing = new MyThing() ) { ... throw new ApplicationException(\"oops\"); } And will be called as you leave the block, as the exception's thrown. If you want to combine a try/catch/finally and a using, you can either nest them: try { ... using ( MyThing thing = new MyThing() ) { ... } ... } catch ( Exception e ) { .... } finally { .... } (Or put the try/catch/finally in the using): using ( MyThing thing = new MyThing() ) { ... try { ... } catch ( Exception e ) { .... } finally { .... } ... } // thing.Dispose is called now Or you can unroll the and explicitly call in the block as @Quarrelsome demonstrated, adding any extra exception-handling or -recovery code that you need in the (or in the ). EDIT: In response to @Toran Billups, if you need to process exceptions aside from ensuring that your method is called, you'll either have to use a and or unroll the - I don't thinks there's any other way to accomplish what you want. ","pontos":7},{"corpo":"I have read Working Effectively With Legacy Code, and I agree it is very useful for dealing with \"untestable\" code. Some techniques only apply to compiled languages (I'm working on \"old\" PHP apps), but I would say most of the book is applicable to any language. Refactoring books sometimes assume the code is in semi-ideal or \"maintenance aware\" state before refactoring, but the systems I work on are less than ideal and were developed as \"learn as you go\" apps, or as first apps for some technologies used (and I don't blame the initial developers for that, since I'm one of them), so there are no tests at all, and code is sometimes messy. This book addresses this kind of situation, whereas other refactoring books usually don't (well, not to this extent). I should mention that I haven't received any money from the editor nor author of this book ;), but I found it very interesting, since resources are lacking in the field of legacy code (and particularly in my language, French, but that's another story). ","pontos":0},{"corpo":"Subversion is not an ideal solution for binary files, regardless of how little has changed it will save a new copy each time you check it in. Moreover, although Subversion has some locking capabilities, it doesn't lock by default, which means that if two persons modify the same binary file the one that checks in the last will overwrite the other one's changes. Also, there's no tool out there that's as integrated with the Adobe design tools as Version Cue is. Subversion is great for text-based content, but really really not suited to the kind of files you will be working with. ","pontos":1},{"corpo":"Your question is a little ambiguous - are you looking to keep track of the first instances of every letter? If so, an array of length 26 might be the best option. Whenever you insert text into a string at a position lower than the index you have, just compute the offset based on the length of the inserted string. ","pontos":2},{"corpo":"I'm not sure I understand your question. In C any data that's not overwritten is carried over into the next iteration of the loop, and imagine that C++ works much the same way. ","pontos":1},{"corpo":"There's an excellent book written by John Robbins which tackles many difficult debugging questions. The book is called Debugging Applications for Microsoft .NET and Microsoft Windows. Despite the title, the book contains a host of information about debugging native C++ applications. In this book, there is a lengthy section all about how to get the call stack for exceptions that are thrown. If I remember correctly, some of his advice involves using structured exception handling (SEH) instead of (or in addition to) C++ exceptions. I really cannot recommend the book highly enough. ","pontos":5},{"corpo":"You could trying using the MS-DOS subst command to assign your source code directory to the D: drive. ","pontos":1},{"corpo":"Basic answer: mylist = [\"b\", \"C\", \"A\"] mylist.sort() This modifies your original list (i.e. sorts in-place). To get a sorted copy of the list, without changing the original, use the function: for x in sorted(mylist): print x However, the examples above are a bit naive, because they don't take locale into account, and perform a case-sensitive sorting. You can take advantage of the optional parameter to specify custom sorting order (the alternative, using , is a deprecated solution, as it has to be evaluated multiple times - is only computed once per element). So, to sort according to the current locale, taking language-specific rules into account ( is a helper function from functools): sorted(mylist, key=cmp_to_key(locale.strcoll)) And finally, if you need, you can specify a custom locale for sorting: import locale locale.setlocale(locale.LC_ALL, 'en_US.UTF-8') # vary depending on your lang/locale assert sorted((u'Ab', u'ad', u'aa'), key=cmp_to_key(locale.strcoll)) == [u'aa', u'Ab', u'ad'] Last note: you will see examples of case-insensitive sorting which use the method - those are incorrect, because they work only for the ASCII subset of characters. Those two are wrong for any non-English data: # this is incorrect! mylist.sort(key=lambda x: x.lower()) # alternative notation, a bit faster, but still wrong mylist.sort(key=str.lower) ","pontos":184},{"corpo":"Have you tried using an HTML control instead of the server control? Does it also cause a compilation error? input type=\"text\" id=\"TextBox4\" runat=\"server\" value=\" %=TextFromString% \" / ","pontos":1},{"corpo":"The way to delete commands is to find them in the Subscribed Feeds section of the main help page: ubiq help | about:ubiquity Scroll down to \"Subscribed Feeds\" in the right hand column Click '[unsubscribe]' for the one you want to delete. Profit! ","pontos":2},{"corpo":"I have used Subversion for this exact thing, and Theo is right, you have to remember to lock your files. I am on CS2 and so have not used Version Cue, but I have not been able to find a whole lot online about other folks using it either, for some reason. The other problem I had using Subversion related to disk space. Subversion stores an alternate \"shadow copy\" of your files in your working directory. For Photoshop and Illustrator this is normally not that big of a deal, but I was using Premiere and After Effects as well, and the disk space required for the shadow copies doubled my disk usage. You might also check out Gridiron's new Gridiron Flow product, which John Nack raves about. I would love to use it - it's due out about now, and it will likely run in the several-hundred dollar range, I think... Update 3/6/2009: Gridiron Flow is out, and it does versioning on a single machine, but it's not clear from their demos whether it does collaborative versioning. Also, I just stumbled across this very good comparison of subversion, git mercurial for managing a home directory - including various versions of large Photoshop files. ","pontos":1},{"corpo":"I use passive view, a flavor of the Model View Presenter pattern, with any web forms like development (.NET) to increase testability/maintainability/etc For example, your code-behind file might look something like this Partial Public Class _Default Inherits System.Web.UI.Page Implements IProductView Private presenter As ProductPresenter Protected Overrides Sub OnInit(ByVal e As System.EventArgs) MyBase.OnInit(e) presenter = New ProductPresenter(Me) End Sub Protected Sub Page_Load(ByVal sender As Object, ByVal e As System.EventArgs) Handles Me.Load presenter.OnViewLoad() End Sub Private ReadOnly Property PageIsPostBack() As Boolean Implements IProductView.PageIsPostBack Get Return Page.IsPostBack End Get End Property Public Property Products() As System.Collections.Generic.List(Of Product) Implements Library.IProductView.Products Get Return DirectCast(gridProducts.DataSource(), List(Of Product)) End Get Set(ByVal value As System.Collections.Generic.List(Of Product)) gridProducts.DataSource = value gridProducts.DataBind() End Set End Property End Class This code behind is acting as a very thin view with zero logic. This logic is instead pushed into a presenter class that can be unit tested. Public Class ProductPresenter Private mView As IProductView Private mProductService As IProductService Public Sub New(ByVal View As IProductView) Me.New(View, New ProductService()) End Sub Public Sub New(ByVal View As IProductView, ByVal ProductService As IProductService) mView = View mProductService = ProductService End Sub Public Sub OnViewLoad() If mView.PageIsPostBack = False Then PopulateProductsList() End If End Sub Public Sub PopulateProductsList() Try Dim ProductList As List(Of Product) = mProductService.GetProducts() mView.Products = ProductList Catch ex As Exception Throw ex End Try End Sub End Class ","pontos":3},{"corpo":" Is Visual Studio prompting you for the path to the source file? No. If it isn't then it doesn't think it has symbols for the callstack. Setting the source path should work without having to map the exact original location. Symbols are loaded successfully. It shows the callstack, but double clicking on an entry doesn't bring me to the source code. I can of course search in files for the line in question, but this is hard work :) ","pontos":0}]